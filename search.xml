<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Java Collections</title>
      <link href="2022/02/12/Java-Collections/"/>
      <url>2022/02/12/Java-Collections/</url>
      
        <content type="html"><![CDATA[<h1 id="应用场景"><a class="markdownIt-Anchor" href="#应用场景"></a> 应用场景</h1><ul><li>无法预测存储数据的数量</li><li>同时存储具有一对一关系的数据</li><li>需要进行数据的增删</li><li>数据重复的问题</li></ul><h1 id="集合框架的体系结构"><a class="markdownIt-Anchor" href="#集合框架的体系结构"></a> 集合框架的体系结构</h1><h2 id="collection-类的对象"><a class="markdownIt-Anchor" href="#collection-类的对象"></a> Collection - 类的对象</h2><ul><li>List<ul><li>ArrayList</li></ul></li><li>Queue<ul><li>LinkedList</li></ul></li><li>Set<ul><li>HashSet</li></ul></li></ul><h2 id="map-key-value-pairs"><a class="markdownIt-Anchor" href="#map-key-value-pairs"></a> Map - key value pairs</h2><ul><li>HashMap</li></ul><h1 id="list"><a class="markdownIt-Anchor" href="#list"></a> List</h1><ul><li>List是元素有序并且可以重复的集合，成为序列</li><li>List可以精确的控制每个元素的插入位置，或删除某个位置的元素</li><li>List的两个主要实现是ArrayList和LinkedList</li></ul><h2 id="arraylist"><a class="markdownIt-Anchor" href="#arraylist"></a> ArrayList</h2><ul><li>ArrayList底层是由数组实现的</li><li>动态增长（倍增)，以满足应用程序的需求</li><li>在列表尾部插入或删除数据非常有效，增删中间部分的元素则不是非常高效</li><li>更适合查找和更新元素</li><li>ArrayList中的元素可以为null</li></ul><h1 id="set"><a class="markdownIt-Anchor" href="#set"></a> Set</h1><ul><li>Set是元素无序并且不可以重复的集合</li></ul><h2 id="hashset"><a class="markdownIt-Anchor" href="#hashset"></a> HashSet</h2><ul><li>HashSet是Set的一个重要的实现类，</li><li>HashSet中的元素无序并且不可以重复</li><li>HashSet中只允许一个null元素</li><li>具有良好的存取和查找性能</li></ul><h2 id="迭代器-iterator"><a class="markdownIt-Anchor" href="#迭代器-iterator"></a> 迭代器 Iterator</h2><ul><li>Iterator接口可以以统一的方法对各种集合元素进行遍历</li><li>hasNext()方法检测集合中是否还有下一个元素</li><li>next()方法返回集合中的下一个元素</li></ul><h1 id="map"><a class="markdownIt-Anchor" href="#map"></a> Map</h1><ul><li>Map中的数据是以key value的形式存储的</li><li>key value是以Entry类型的对象实例存在</li><li>可以通过key值快速得查找value</li><li>一个映射不能包含重复的key， value可以重复</li><li>每个key最多映射到一个value</li></ul><h2 id="hashmap"><a class="markdownIt-Anchor" href="#hashmap"></a> HashMap</h2><ul><li>给予哈希表得Map实现</li><li>允许使用null值和null key</li><li>key值不允许重复</li><li>HashMap中的entry对象是无序排列得</li></ul><h1 id="集合排序"><a class="markdownIt-Anchor" href="#集合排序"></a> 集合排序</h1><ul><li>使用Collections类的sort()方法</li><li>使用Comparator和Comparable接口进行排序</li></ul><h2 id="comparator接口"><a class="markdownIt-Anchor" href="#comparator接口"></a> Comparator接口</h2><ul><li>强行对某个对象进行整体排序的比较函数</li><li>可以将comparator传递给sort方法 （如Collections.sort或者Arrays.sort）</li><li>int compare(T o1, T o2) 比较用来排序的两个参数<ul><li>if o1 &lt; o2, return negative integer</li><li>if o1 == o2, return 0</li><li>if o1 &gt; o2, return positive integer</li></ul></li><li></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Exceptions in Java</title>
      <link href="2022/02/11/Exceptions-in-Java/"/>
      <url>2022/02/11/Exceptions-in-Java/</url>
      
        <content type="html"><![CDATA[<h1 id="什么是异常"><a class="markdownIt-Anchor" href="#什么是异常"></a> 什么是异常</h1><ul><li>错误在我们编写程序的过程中会经常发生，包括编译期间和运行期间的错误</li><li>在程序运行过程中，意外发生的情况，背离我们程序本身意图的表现，都可以理解为异常</li></ul><h1 id="异常分类"><a class="markdownIt-Anchor" href="#异常分类"></a> 异常分类</h1><ul><li>Throwable<ul><li>Error<ul><li>OutOfMemoryError</li><li>ThreadDeath</li><li>…</li></ul></li><li>Exception<ul><li>程序本身可以处理的异常</li><li>unchecked exception （runtime exception）<ul><li>NullPointerException</li><li>ArrayIndexOutOfBoundsException</li><li>…</li></ul></li><li>checked exception<ul><li>IOException</li><li>SQLException</li><li>…</li></ul></li></ul></li></ul></li></ul><h1 id="捕获异常"><a class="markdownIt-Anchor" href="#捕获异常"></a> 捕获异常</h1><ul><li>对于运行时异常，错误或可查异常，Java技术所要求的异常处理方式有所不同</li><li>对于可查异常必须捕捉，或者声明抛出</li><li>允许忽略不可查的RuntimeException 和 Error</li></ul><h1 id="异常处理"><a class="markdownIt-Anchor" href="#异常处理"></a> 异常处理</h1><ul><li>通过5个关键字来实现： try, catch, finally, throw, throws</li></ul><h2 id="捕获异常-2"><a class="markdownIt-Anchor" href="#捕获异常-2"></a> 捕获异常</h2><ul><li>try: 执行可能产生异常的代码</li><li>catch: 捕获异常</li><li>finally: 无论是否发生异常，总是执行的代码</li></ul><h2 id="声明异常"><a class="markdownIt-Anchor" href="#声明异常"></a> 声明异常</h2><ul><li>throws: 声明可能要抛出的异常</li></ul><h2 id="抛出异常"><a class="markdownIt-Anchor" href="#抛出异常"></a> 抛出异常</h2><ul><li>手动抛出异常</li></ul><h2 id="try-catch-finally"><a class="markdownIt-Anchor" href="#try-catch-finally"></a> try catch finally</h2><ul><li>try之后可以接零个或多个catch， 如果没有catch，则必须接一个finally</li></ul><h2 id="throw-throws"><a class="markdownIt-Anchor" href="#throw-throws"></a> throw throws</h2><ul><li>可以通过throws声明将要抛出何种类型的异常， 通过throw将产生的异常抛出</li></ul><h1 id="throws"><a class="markdownIt-Anchor" href="#throws"></a> throws</h1><ul><li>如果一个方法可能会出现异常，但没有能力处理这种异常，可以在方法声明处用throws子句来声明抛出异常</li><li>throws语句用在方法定义时，生命该方法要抛出的异常类型</li><li>当方法抛出异常列表中的异常时，方法将不对这些类型及其子类类型的异常做处理，而抛向方法的调用者，由它去处理</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">public int divideIntegers(int a, int b) throws Exception &#123;</span><br><span class="line">    return a &#x2F; b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public static void main(String[] args) &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">        int answer &#x3D; divideIntegers(5, 10);</span><br><span class="line">    &#125; catch(ArithmeticException e) &#123;</span><br><span class="line">        </span><br><span class="line">    &#125; catch(InputMismatchException e) &#123;</span><br><span class="line"></span><br><span class="line">    &#125; catch(Exception e) &#123;</span><br><span class="line"></span><br><span class="line">    &#125; finally &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="throw"><a class="markdownIt-Anchor" href="#throw"></a> throw</h1><ul><li>throw用来抛出一个异常</li><li>抛出的只能够是可抛出类throwable或者其子类的实例对象</li><li>自己抛出的异常，自己处理</li><li>抛出异常使用throws由调用者处理</li></ul><h1 id="自定义异常"><a class="markdownIt-Anchor" href="#自定义异常"></a> 自定义异常</h1><ul><li>使用Java内置的异常类可以描述在编程时出现的大部分异常情况</li><li>也可以通过自定义异常描述特定业务产生的异常类型</li><li>自定义异常就是定义一个类，去继承Throwable类或者它的子类</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public class CustomException extends Exception &#123;</span><br><span class="line">    public CustomExpcetion () &#123;</span><br><span class="line">        super(&quot;Custom exception message&quot;)；</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="异常链"><a class="markdownIt-Anchor" href="#异常链"></a> 异常链</h1><ul><li><p>有时候我们会捕获一个异常后再抛出另一个异常</p></li><li><p>顾名思义就是：将异常发生的原因一个穿一个穿起来，把底层的异常信息传给上层，这样逐层抛出</p></li><li><p>新的异常可以保留原有异常的信息</p></li><li><p>构造方法的定义如下</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Exception(String mesasge, Throwable cause)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">public void methodOne() throws FirstException &#123;</span><br><span class="line">    throw new FirstException(&quot;first exception&quot;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public void methodTwo() throws SecondException &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">        methodOne();</span><br><span class="line">    &#125; catch (FirstException e) &#123;</span><br><span class="line">        throw new SecondException(&quot;Second Exception&quot;, e);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public void methodThree() throws ThirdException &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">        methodTwo();</span><br><span class="line">    &#125; catch (SecondException e) &#123;</span><br><span class="line">        ThridException exception &#x3D; new ThirdException(&quot;third exception&quot;);</span><br><span class="line">        exception.initCause(e); &#x2F;&#x2F; initCause是Exception中的另外一个成员方法，用于添加cause，原有异常的信息</span><br><span class="line">        throw exception;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Polymorphism in Java</title>
      <link href="2022/02/10/Polymorphism-in-Java/"/>
      <url>2022/02/10/Polymorphism-in-Java/</url>
      
        <content type="html"><![CDATA[<h1 id="编译时多态"><a class="markdownIt-Anchor" href="#编译时多态"></a> 编译时多态</h1><ul><li>设计时多态方法重载</li></ul><h1 id="运行时多态"><a class="markdownIt-Anchor" href="#运行时多态"></a> 运行时多态</h1><ul><li>程序运行时动态决定调用那个方法</li></ul><h1 id="必要条件"><a class="markdownIt-Anchor" href="#必要条件"></a> 必要条件</h1><ol><li>满足继承关系</li><li>父类引用指向子类对象</li></ol><h1 id="向上转型"><a class="markdownIt-Anchor" href="#向上转型"></a> 向上转型</h1><ul><li>父类引用指向子类实例，可以调用子类重写父类的方法以及父类派生的方法，无法调用子类独有的方法</li><li>父类中的静态方法无法被子类重写，所以向上转型之后，只能调用到父类原有的静态方法</li></ul><h1 id="向下转型"><a class="markdownIt-Anchor" href="#向下转型"></a> 向下转型</h1><ul><li>子类引用指向父类对象，此处可以使用<code>instanceof</code>进行检查，避免类型转换时的安全性问题</li><li>可以调用子类独有的方法</li></ul><h1 id="抽象类-abstract-class"><a class="markdownIt-Anchor" href="#抽象类-abstract-class"></a> 抽象类 abstract class</h1><ul><li>限制实例化</li><li>只能被继承</li><li>应用场景： 某个父类只是知道其子类应该包含怎样的方法，但无法准确知道这些子类如何实现这些方法</li></ul><h1 id="抽象方法-abstract-method"><a class="markdownIt-Anchor" href="#抽象方法-abstract-method"></a> 抽象方法 abstract method</h1><ul><li>不能有方法体</li><li>必须由子类实现</li><li>子类如果没有重写父类的所有抽象方法，则也要定义为抽象类</li></ul><h1 id="接口-interface"><a class="markdownIt-Anchor" href="#接口-interface"></a> 接口 Interface</h1><ul><li>当多个类具有相同能力的时候，可以使用接口抽象出相同的能力</li><li>接口定义了某一批类所需要遵守的规范</li><li>接口不关心这些类的内部数据，也不关心这些类里的方法的实现细节，它只规定这些类里必须提供某些方法</li><li>接口方法可以不写<code>abstract</code>关键字，并且默认为public的访问权限</li><li>当类实现接口时，需要去实现接口中的所有抽象方法，否则需要将该类设置为抽象类</li><li>接口中可以定义常量，默认为<code>public static final</code></li></ul><h2 id="默认方法"><a class="markdownIt-Anchor" href="#默认方法"></a> 默认方法</h2><ul><li>自JDK1.8之后，接口中可以存在默认方法，使用<code>default</code>关键字定义</li><li>默认方法可以带方法体，子类实现接口时可以不用实现默认方法</li><li>子类可以重写默认方法，并可以通过接口的引用调用</li></ul><h2 id="静态方法"><a class="markdownIt-Anchor" href="#静态方法"></a> 静态方法</h2><ul><li>自JDK1.8之后，接口中可以存在静态方法，使用<code>static</code>关键字定义</li><li>静态方法可以带方法体，子类可以通过使用接口名访问接口的静态方法</li></ul><h2 id="多重实现"><a class="markdownIt-Anchor" href="#多重实现"></a> 多重实现</h2><ul><li>子类可以继承一个父类，但是可以实现多个接口</li><li>当多个接口中具有相同签名的方法时，子类需要重写方法</li><li>当父类和接口具有相同签名的方法时，父类方法具有优先权</li><li>当父类和接口具有相同名字的变量时，子类需要重新定义该变量，父类中的变量不具有优先权</li></ul><h2 id="接口的继承"><a class="markdownIt-Anchor" href="#接口的继承"></a> 接口的继承</h2><ul><li>接口也可以实现继承关系</li><li>接口可以继承多个父接口</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">public interface ParentOne &#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public interface ParentTwo &#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public interface Child extends ParentOne, ParentTwo &#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="内部类"><a class="markdownIt-Anchor" href="#内部类"></a> 内部类</h1><ul><li>内部类提供了更好的封装，不允许其他外部类访问内部类的信息</li></ul><h2 id="成员内部类"><a class="markdownIt-Anchor" href="#成员内部类"></a> 成员内部类</h2><ul><li>最常见的内部类，也称为普通内部类</li><li>内部类在外部使用时，无法直接实例化，需要借由外部类信息才能完成实例化</li><li>内部类的访问修饰符，可以是任意的，但是访问权限会受到修饰符的影响</li><li>内部类可以直接访问外部类的成员（包括成员属性和成员方法），如果出现同名属性，优先访问内部类中定义的</li><li>外部类访问内部类的信息需要通过内部类的实例，无法直接访问</li><li>内部类编译后得class文件名：外部类$内部类.class</li></ul><h3 id="获取内部类对象实例"><a class="markdownIt-Anchor" href="#获取内部类对象实例"></a> 获取内部类对象实例</h3><ol><li>new 外部类.new 内部类</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Person.Heart myHeart &#x3D; new Person().new Heart();</span><br></pre></td></tr></table></figure><ol start="2"><li>外部类对象.new 内部类</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">myHeart &#x3D; myPerson.new Heart();</span><br></pre></td></tr></table></figure><ol start="3"><li>外部类对象.获取方法</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">myHeart &#x3D; myPerson.getHeart();</span><br></pre></td></tr></table></figure><h2 id="静态内部类"><a class="markdownIt-Anchor" href="#静态内部类"></a> 静态内部类</h2><ul><li>静态内部类中，只能直接访问外部类的静态成员</li><li>需要使用外部类的实例对象来访问非静态成员</li><li>访问静态内部类对象实例时，可以不依赖于外部类对象</li></ul><h3 id="获取静态内部类实例"><a class="markdownIt-Anchor" href="#获取静态内部类实例"></a> 获取静态内部类实例</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Person.Heart myHeart &#x3D; new Person.Heart();</span><br></pre></td></tr></table></figure><h2 id="方法内部类"><a class="markdownIt-Anchor" href="#方法内部类"></a> 方法内部类</h2><ul><li>定义在外部类方法中的内部类，也成为局部内部类</li><li>方法内部类中无法定义静态成员</li><li>类中可以使用final，abstract成员</li><li>和方法内部成员使用规则一样，class前面不可以添加public，private，protected，static等关键字</li></ul><h2 id="匿名内部类"><a class="markdownIt-Anchor" href="#匿名内部类"></a> 匿名内部类</h2><ul><li>将类的定义和类的创建放在一起完成，程序只会用到一次类的实例，所以类名无关紧要</li><li>对于抽象类Person来说，如果我们想调用其中的抽象方法，一种做法是创建一个实现read方法的子类</li><li>但是如果这个子类只会被用到一次，那这个子类的名字就不重要，就可以使用匿名内部类来解决</li><li>无法使用private，public，protected，static修饰</li><li>无法编写构造方法，但是可以添加初始化代码块</li><li>不能出现静态成员</li><li>可以实现接口也可以继承父类，但是不能同时</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">public abstract class Person &#123;</span><br><span class="line">    public abstract void read();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public class PersonTest &#123;</span><br><span class="line">    public void getRead(Person person) &#123;</span><br><span class="line">        person.read();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        PersonTest personTest &#x3D; new PersonTest();</span><br><span class="line"></span><br><span class="line">        personTest.getRead(new Person() &#123;</span><br><span class="line"></span><br><span class="line">            @Override</span><br><span class="line">            public void read() &#123;</span><br><span class="line">                System.out.println(&quot;implement read method in Person parent abstract class&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="匿名类的例子"><a class="markdownIt-Anchor" href="#匿名类的例子"></a> 匿名类的例子</h3><ul><li><p>在我们使用comparator对Collections进行排序的时候可以使用匿名类来省去创建子类的过程</p></li><li><p>不使用匿名类对List排序</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; create a child class implements parent Comparator</span><br><span class="line">public class CustomComparator implements Comparator&lt;String&gt; &#123;</span><br><span class="line">    @Override</span><br><span class="line">    public int compare(String o1, String o2) &#123;</span><br><span class="line">        return o1.compareTo(o2);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public class testComparator() &#123;</span><br><span class="line">    List&lt;String&gt; list &#x3D; new ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; use CustomComparator to sort list</span><br><span class="line">    Collections.sort(list, new CustomComparator());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>使用匿名类对list排序</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">public class testComparator() &#123;</span><br><span class="line">    List&lt;String&gt; list &#x3D; new ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    Collections.sort(list, new Comparator&lt;String&gt;() &#123;</span><br><span class="line">        public int compare(String o1, String o2) &#123;</span><br><span class="line">            return o1.compareTo(o2);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>自Java1.8以后，可以使用lambda expression来省去方法名，匿名方法</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public class testComparator() &#123;</span><br><span class="line">    List&lt;String&gt; list &#x3D; new ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    Collections.sort(list, (x, y) -&gt; x.compareTo(y));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>因为上面的匿名方法和String里面定义的compareTo方法一样，我们可以使用method reference来更加简化代码</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public class testComparator() &#123;</span><br><span class="line">    List&lt;String&gt; list &#x3D; new ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    Collections.sort(list, String::compareTo);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Design Pattern - Singleton in Java</title>
      <link href="2022/02/09/Design-Pattern-Singleton-in-Java/"/>
      <url>2022/02/09/Design-Pattern-Singleton-in-Java/</url>
      
        <content type="html"><![CDATA[<h1 id="目的"><a class="markdownIt-Anchor" href="#目的"></a> 目的</h1><ul><li>使得类的一个对象成为该类系统中唯一的实例</li></ul><h1 id="定义"><a class="markdownIt-Anchor" href="#定义"></a> 定义</h1><ul><li>一个类有且仅有一个实例，并且自行实例化向整个系统提供</li></ul><h1 id="要点"><a class="markdownIt-Anchor" href="#要点"></a> 要点</h1><ol><li>某个类只能有一个实例</li><li>必须自行创建实例</li><li>必须自行向这个系统提供这个实例</li></ol><h1 id="实现"><a class="markdownIt-Anchor" href="#实现"></a> 实现</h1><ol><li>只提供私有的构造方法</li><li>含有一个该类的静态私有对象</li><li>提供一个静态的公有方法用于创建，获取静态私有对象</li></ol><ul><li>Create class instance when class is loaded</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">public class SingletonOne &#123;</span><br><span class="line">  &#x2F;&#x2F; private class constructor</span><br><span class="line">  private SingletonOne () &#123;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  &#x2F;&#x2F; private static instance</span><br><span class="line">  private static SingletonOne INSTANCE &#x3D; new SingletonOne();</span><br><span class="line"></span><br><span class="line">  &#x2F;&#x2F; return instance in public method</span><br><span class="line">  public static SingletonOne getInstance() &#123;</span><br><span class="line">    return INSTANCE;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; SingletonOne instance &#x3D; SingletonOne.getInstance();</span><br></pre></td></tr></table></figure><ul><li>Only create instance when the method is being called</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">public class SingletonTwo &#123;</span><br><span class="line">  private SingletonTwo () &#123;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  private static SingletonTwo INSTANCE &#x3D; null;</span><br><span class="line"></span><br><span class="line">  public static SingletonTwo getInstance() &#123;</span><br><span class="line">    if (INSTANCE &#x3D;&#x3D; null) INSTANCE &#x3D; new SingletonTwo();</span><br><span class="line">    return INSTANCE;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="注意"><a class="markdownIt-Anchor" href="#注意"></a> 注意</h1><ul><li>lazy loading 存在线程风险 1<ol><li>同步锁</li><li>双重校验锁</li><li>静态内部类</li><li>枚举</li></ol></li></ul><h1 id="优点"><a class="markdownIt-Anchor" href="#优点"></a> 优点</h1><ol><li>在内存中只有一个对象，节省内存空间</li><li>避免频繁地创建对象，提高性能</li><li>避免对共享资源的多重占用</li></ol><h1 id="缺点"><a class="markdownIt-Anchor" href="#缺点"></a> 缺点</h1><ol><li>扩展比较困难</li><li>如果实例化后的对象长期不利用，系统将默认为垃圾进行回收，造成对象状态丢失</li></ol><h1 id="场景"><a class="markdownIt-Anchor" href="#场景"></a> 场景</h1><ol><li>创建对象时占用资源过多，但同时有需要用到该类对象</li><li>对系统内资源要求统一读写，如读写配置信息</li><li>当多个实例存在可能引起程序逻辑错误，如号码生成器 （ID）</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Design Patterns </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elastic Search</title>
      <link href="2022/01/02/Elastic-Search/"/>
      <url>2022/01/02/Elastic-Search/</url>
      
        <content type="html"><![CDATA[<h1 id="basics"><a class="markdownIt-Anchor" href="#basics"></a> Basics</h1><ul><li>Nodes store the data that we add to ElasticSearch</li><li>A cluster is a collection of nodes</li><li>Data is stored as document which are JSON objects</li><li>Documents are grouped together with indices</li></ul><h2 id="the-purpose-of-sharding"><a class="markdownIt-Anchor" href="#the-purpose-of-sharding"></a> The purpose of sharding</h2><ul><li>mainly to be able to store more documents</li><li>to easier fit large indices onto nodes</li><li>improved performance<ul><li>parallelization of queries increases the throughput of an index</li></ul></li></ul><h2 id="configuring-the-number-of-shards"><a class="markdownIt-Anchor" href="#configuring-the-number-of-shards"></a> Configuring the number of shards</h2><ul><li>an index contains a single shard by default</li><li>increase the number of shards with the Split API</li><li>reduce the number of shards with the Shrink API</li><li>when changing the number of shards, new index will be created and documents in the old index will be migrated to the new index</li></ul><h2 id="replication"><a class="markdownIt-Anchor" href="#replication"></a> Replication</h2><ul><li><p>replication is configured at the index level</p></li><li><p>replication works by creating copies of shards, referred to as replica shards</p></li><li><p>a shard that has been replicated is called a primary shard</p></li><li><p>a primary shard and its replica shards are referred as a replication group</p></li><li><p>replica shards are a complete copy of a shard</p></li><li><p>a replica shard can serve search requests, exactly like its primary shard</p></li><li><p>the number of replicas can be configured at index creation</p></li><li><p>node can store multiple shards, and primary shard and replica shards will never be stored in the same node. So the data will NOT be lost if the node fails</p></li></ul><h2 id="snapshots"><a class="markdownIt-Anchor" href="#snapshots"></a> snapshots</h2><ul><li>ElasticSearch supports taking snapshots as backups</li><li>snapshots can be used to restore to a given point in time</li><li>snapshots can be taken at the index level, or for the entire cluster</li><li>use snapshots for backups, and replication for high availability and performance</li></ul><h2 id="increasing-query-throughput-with-replication"><a class="markdownIt-Anchor" href="#increasing-query-throughput-with-replication"></a> increasing query throughput with replication</h2><ul><li>replica shards of a replication group can serve different search requests simultaneously<ul><li>this increases the number of requests that can be handled at the same time</li></ul></li><li>ElasticSearch intelligently routes requests to the best shard</li><li>CPU parallelization (CPU has multiple cores now and can run queries on different threads at the same time) improves performance if multiple replica shards are stored on the same node</li></ul><h2 id="master-eligible-node"><a class="markdownIt-Anchor" href="#master-eligible-node"></a> Master-eligible node</h2><ul><li>the node may be elected as the cluster’s master node</li><li>a master node is responsible for creating and deleting indices, among others</li><li>may be used for having dedicated master nodes<ul><li>useful for large clusters</li><li>meaning that this master node will not be serving requests, only focusing on its own tasks</li></ul></li></ul><h2 id="data-node"><a class="markdownIt-Anchor" href="#data-node"></a> Data node</h2><ul><li>enables a node to store data</li><li>storing data includes performing queries related to that data, such as search queries</li><li>for relatively small clusters, this role is almost always enabled</li></ul><h1 id="managing-documents"><a class="markdownIt-Anchor" href="#managing-documents"></a> Managing Documents</h1><ul><li>Delete index</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DELETE &#x2F;index_name</span><br></pre></td></tr></table></figure><ul><li>create index</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT &#x2F;index_name</span><br><span class="line">&#123;</span><br><span class="line">  &quot;settings&quot;: &#123;</span><br><span class="line">    &quot;number_of_shards&quot;: 2</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="indexing-documents"><a class="markdownIt-Anchor" href="#indexing-documents"></a> indexing documents</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">POST &#x2F;products&#x2F;_doc</span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;: &quot;Coffee Maker&quot;,</span><br><span class="line">  &quot;price&quot;: 53,</span><br><span class="line">  &quot;in_stack&quot;: 10</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="retrieving-document-by-id"><a class="markdownIt-Anchor" href="#retrieving-document-by-id"></a> Retrieving document by ID</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET &#x2F;products&#x2F;_doc&#x2F;document_ID</span><br></pre></td></tr></table></figure><h2 id="updating-document"><a class="markdownIt-Anchor" href="#updating-document"></a> Updating document</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">POST &#x2F;products&#x2F;_update&#x2F;document_ID</span><br><span class="line">&#123;</span><br><span class="line">  &quot;doc&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &quot;new name&quot;,</span><br><span class="line">    &quot;new field&quot;: &quot;this is a new field&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="upserts"><a class="markdownIt-Anchor" href="#upserts"></a> Upserts</h2><ul><li>insert the new document if not exists, and run the script if the document exists</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">POST &#x2F;products&#x2F;_update&#x2F;101</span><br><span class="line">&#123;</span><br><span class="line">  &quot;script&quot;: &#123;</span><br><span class="line">    &quot;source&quot;: &quot;ctx._source.in_stock++</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;upsert&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &quot;name&quot;,</span><br><span class="line">    &quot;price&quot;: 399,</span><br><span class="line">    &quot;in_stock&quot;: 5</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="delete-document"><a class="markdownIt-Anchor" href="#delete-document"></a> Delete document</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DELETE &#x2F;products&#x2F;_doc&#x2F;101</span><br></pre></td></tr></table></figure><h2 id="routing"><a class="markdownIt-Anchor" href="#routing"></a> Routing</h2><ul><li>routing is the process of resolving a shard for a document</li><li>the default routing strategy ensures that documents are distributed evenly</li></ul><h2 id="optimistic-concurrency-control"><a class="markdownIt-Anchor" href="#optimistic-concurrency-control"></a> Optimistic concurrency control</h2><ul><li>prevent overwriting documents inadvertently dur to concurrent operations</li><li>primary terms<ul><li>a way to distinguish between old and new primary shards</li><li>essentially a counter for how many times the primary shard has changed</li><li>the primary term is appended to write operations</li></ul></li><li>sequence numbers<ul><li>appended to write operations together with the primary term</li><li>essentially a counter that is incremented for each write operation</li><li>the primary shard increases the sequence number</li><li>enables ElasticSearch to order write operations</li></ul></li><li>sending write requests to ElasticSearch concurrently may overwrite changes made by other concurrent processes</li><li>we use the primary terms and sequence number fields</li><li>ElasticSearch will reject a write operation if it contains the wrong primary term or sequence number</li></ul><h2 id="updating-multiple-document"><a class="markdownIt-Anchor" href="#updating-multiple-document"></a> Updating multiple document</h2><ul><li>the query creates a snapshot to do optimistic concurrency control</li><li>search queries and bulk requests are sent to replication groups sequentially<ul><li>ElasticSearch retries these queries up to ten times</li><li>if the queries still fail, the whole query is aborted</li><li>any changes already made to documents, are NOT rolled back</li></ul></li><li>the API returns information about failures</li></ul><h1 id="mapping-and-analysis"><a class="markdownIt-Anchor" href="#mapping-and-analysis"></a> Mapping and Analysis</h1><ul><li>a field’s values are stored in one of several data structures<ul><li>the data structure depends on the field’s data type</li></ul></li><li>ensures efficient data access</li></ul><h2 id="inverted-indices"><a class="markdownIt-Anchor" href="#inverted-indices"></a> Inverted indices</h2><ul><li><p>mapping between terms (tags) and which documents contain them</p></li><li><p>outside the context of analyzers, we use the terminology ‘terms’</p></li><li><p>an inverted index is created for EACH text field</p></li><li><p>values for a text field are analyzed and the results are stored within an inverted index</p></li><li><p>each field has a dedicated inverted index</p></li><li><p>an inverted index is a mapping between terms and which documents contain them</p></li><li><p>terms are sorted alphabetically for performance reasons</p></li><li><p>created and maintained by Apache Lucene</p></li><li><p>inverted indices enable fast searches</p></li></ul><p>Note: for array of strings</p><ul><li>In ElasticSearch, there is no dedicated array data type, any field can contain zero or more values by default, however, all values in the array must be of the same data type</li><li>when adding a field dynamically, the first value in the array determines the field type</li><li>meaning for array of strings, ElasticSearch would have created a inverted index mapping table for it</li></ul><h2 id="keyword-data-type"><a class="markdownIt-Anchor" href="#keyword-data-type"></a> keyword data type</h2><ul><li><p>keyword fields are analyzed with the keyword analyzer</p></li><li><p>the keyword analyzer is an no-op analyzer</p><ul><li>it outputs the unmodified string as a single token</li><li>this token is then placed into the inverted index</li></ul></li><li><p>used for exact matching of values</p></li><li><p>typically used for filtering, aggregations, and sorting</p></li><li><p>for full-text searches, use the text data type instead</p></li></ul><h2 id="arrays"><a class="markdownIt-Anchor" href="#arrays"></a> Arrays</h2><ul><li>there is no such thing as an array data type</li><li>any field may contain zero or more values<ul><li>no configuration or mapping needed</li><li>simply supply an array when indexing a document</li></ul></li><li>how is the array stored in the ElasticSearch internally?<ul><li>e.g. if it is an array of strings</li><li>the strings are simply concatenated before being analyzed</li><li>and the resulting tokens are stored within an inverted index as normal String data type</li></ul></li></ul><h2 id="dates"><a class="markdownIt-Anchor" href="#dates"></a> Dates</h2><ul><li>specified in one of the three ways<ul><li>specially formatted strings</li><li>milliseconds since the epoch</li><li>seconds since the epoch</li></ul></li><li>epoch refers to the 1st of Jan 1970</li><li>custom formats are supported</li></ul><h3 id="how-date-fields-are-stored"><a class="markdownIt-Anchor" href="#how-date-fields-are-stored"></a> How date fields are stored</h3><ul><li>stored internally as milliseconds since the epoch</li><li>any valid value that you supply at index time is converted to a long value internally</li><li>dates are converted to the UTC timezone</li><li>the same date conversion happens for search queries too</li></ul><h2 id="missing-fields"><a class="markdownIt-Anchor" href="#missing-fields"></a> Missing fields</h2><ul><li>all fields are ElasticSearch are optional</li><li>you can leave out a field when indexing documents</li><li>unlike relational databases when you need to allow NULL values</li><li>some integrity checks need to be done at the application level<ul><li>e.g. having required fields</li></ul></li><li>adding a field mapping does not make a field required</li><li>searches automatically handle missing fields</li></ul><h2 id="stemming-and-stop-words"><a class="markdownIt-Anchor" href="#stemming-and-stop-words"></a> Stemming and stop words</h2><h3 id="stemming"><a class="markdownIt-Anchor" href="#stemming"></a> Stemming</h3><ul><li>reduces words to their root form<ul><li>e.g. loved -&gt; love</li><li>drinking -&gt; drink</li></ul></li></ul><h3 id="stop-words"><a class="markdownIt-Anchor" href="#stop-words"></a> stop words</h3><ul><li>words that are filtered out during the text analysis<ul><li>common words such as ‘a’, ‘the’, ‘at’, ‘of’, ‘on’ etc…</li></ul></li><li>they provide little to no value to the relevance scoring</li><li>fairly common to remove such words<ul><li>less common in ElasticSearch today than in the past</li><li>the relevance algorithm has been improved significantly</li></ul></li><li>not removed by default</li></ul><h2 id="analyzer"><a class="markdownIt-Anchor" href="#analyzer"></a> Analyzer</h2><h3 id="standard-analyzer"><a class="markdownIt-Anchor" href="#standard-analyzer"></a> Standard analyzer</h3><ul><li>splits text at word boundaries and removes punctuation<ul><li>done by the standard tokenizer</li></ul></li><li>lowercase letter with the lowercase token filter</li><li>contains the stop token filter (for removing stop words, disabled by default)</li></ul><h3 id="simple-analyzer"><a class="markdownIt-Anchor" href="#simple-analyzer"></a> Simple analyzer</h3><h3 id="whitespace-analyzer"><a class="markdownIt-Anchor" href="#whitespace-analyzer"></a> whitespace analyzer</h3><h3 id="keyword-analyzer"><a class="markdownIt-Anchor" href="#keyword-analyzer"></a> keyword analyzer</h3><h3 id="pattern-analyzer"><a class="markdownIt-Anchor" href="#pattern-analyzer"></a> pattern analyzer</h3><ul><li>a regular expression is used to match token separators<ul><li>it should match whatever should split the text into tokens</li></ul></li><li>this analyzer is very flexible</li><li>the default pattern matches all non-word characters</li><li>lowercase letters by default</li></ul><h1 id="introduction-to-searching"><a class="markdownIt-Anchor" href="#introduction-to-searching"></a> Introduction to Searching</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">GET &#x2F;product&#x2F;default&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match_all&quot;: &#123;&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>search queries will hit the coordinating node first, and this node will broadcast the query to all the other nodes, they will fetch the result and combine them together and return it.</li></ul><h2 id="term-level-queries"><a class="markdownIt-Anchor" href="#term-level-queries"></a> term level queries</h2><ul><li>search for exact matches, case sensitive, searching the inverted index, not the original document</li><li>term level queries are more suited for searching static values, like enums</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Elastic Search </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dot net + React</title>
      <link href="2021/12/09/Dot-net-React/"/>
      <url>2021/12/09/Dot-net-React/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
        <tags>
            
            <tag> .NET </tag>
            
            <tag> React </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring Framework</title>
      <link href="2021/11/05/Spring-Framework/"/>
      <url>2021/11/05/Spring-Framework/</url>
      
        <content type="html"><![CDATA[<h1 id="spring-framework-stereotypes"><a class="markdownIt-Anchor" href="#spring-framework-stereotypes"></a> Spring Framework Stereotypes</h1><ul><li>Stereotype - a fixed general image or ser of characteristics which represent a particular type of person or thing</li><li>Spring Stereotypes are <code>class</code> level annotations used to define Spring Beans<ul><li><strong>when classes annotated with Spring Stereotypes are detected via the component scan, an instance of the class will be added to the Spring context</strong></li></ul></li><li>Available Spring Stereotypes<ul><li><code>@Component</code></li><li><code>@Controller</code></li><li><code>@RestController</code></li><li><code>@Repository</code></li><li><code>@Service</code></li></ul></li></ul><table><thead><tr><th>Annotation</th><th>Description</th></tr></thead><tbody><tr><td>@Component</td><td>Indicates that an annotated class is a component and it will be created as a bean</td></tr><tr><td>@Controller</td><td>indicates that an annotated class has the role of a Spring MVC controller</td></tr><tr><td>@RestController</td><td>convenience annotation which extends @Controller and @ResponseBody</td></tr><tr><td>@Repository</td><td>indicates class is a Repository, a mechanism for encapsulating storage, retrieval, and search behavior which emulates a collection of objects</td></tr><tr><td>@Service</td><td>indicates that an annotated class is a Service, an operation offered as an interface that stands alone in the model, with no encapsulated state</td></tr></tbody></table><h1 id="spring-component-scan"><a class="markdownIt-Anchor" href="#spring-component-scan"></a> Spring Component Scan</h1><ul><li>Spring Beans defined with Spring Stereotypes are detected with Spring component scan</li><li>On startup, Spring is told to scan packages for classes with Spring Stereotype annotations</li><li>This configuration is Spring Framework specific, not Spring Boot</li><li>Spring Boot’s auto configuration will tell Spring to perform a component scan of the package of the main class<ul><li>this includes all sub packages of the main class package</li></ul></li><li>when using Spring Boot, if class is outside of the main class package tree, you must declare the package scan manually</li></ul><h1 id="spring-bean-scopes"><a class="markdownIt-Anchor" href="#spring-bean-scopes"></a> Spring Bean Scopes</h1><ul><li><code>Singleton</code> - (default) only one instance of the bean is created in the IoC container</li><li><code>Prototype</code> - A new instance is created each time the bean is requested</li><li><code>Request</code> - For web app, a single instance per http request, only valid in the context of a web aware Spring applicationContext</li><li><code>Session</code> - for web app, a single instance per http session, only valid in the context of a web aware Spring applicationContext</li><li><code>Global-session</code> - a single instance per global session, typically only used in a Portlet context, only valid in the context of a web aware Spring applicationContext</li><li><code>Application</code> - bean is scoped to the lifecycle of a ServletContext, only valid in the context of web aware</li><li><code>WebSocket</code> - scopes a single bean definition to the lifecycle of a WebSocket, only valid in the context of a web aware Spring applicationContext</li><li><code>Custom Scope</code> - Spring Scopes are extensible, and you can define your own scope by implementing Spring’s scope interface</li></ul><h2 id="declaring-bean-scope"><a class="markdownIt-Anchor" href="#declaring-bean-scope"></a> Declaring Bean Scope</h2><ul><li>No declaration needed for singleton scope</li><li>in Java configuration use <code>@Scope</code> annotation</li><li>in XML configuration file scope is an XML attribute of the bean tag</li><li>99% of the time singleton scope is fine</li></ul><h1 id="external-properties"><a class="markdownIt-Anchor" href="#external-properties"></a> External Properties</h1><ul><li>Why use External Properties?<ul><li>hard coding values which can change is considered a bad practice</li><li>makes your application rigid and hard to change</li><li>you want your application to be portable<ul><li>deployment artifact (jar, war) should be deployable to different environments</li></ul></li></ul></li><li>what can change?<ul><li>usernames, passwords, urls, API keys, paths, queue names etc…</li></ul></li></ul><h2 id="which-property-files-to-use"><a class="markdownIt-Anchor" href="#which-property-files-to-use"></a> which property files to use</h2><ul><li>using application.properties or application.yml in packaged JAR or WAR</li><li>using profile specific properties or YAML files for profile specific properties</li><li>for deployments, override properties that change with environment variables<ul><li>typically 70 - 80% of values do not change, only override what is needed</li><li>environment variables offer a secure way of seeing sensitive values such as passwords</li></ul></li></ul><h2 id="properties-setting-hierarchy-from-low-to-high"><a class="markdownIt-Anchor" href="#properties-setting-hierarchy-from-low-to-high"></a> Properties Setting Hierarchy (from low to high)</h2><ol><li>application.properties</li><li>environment variables</li><li>command line variables</li></ol><h1 id="thymeleaf"><a class="markdownIt-Anchor" href="#thymeleaf"></a> Thymeleaf</h1><ul><li>Thymeleaf is a Java template engine producing XML, XHTML and HTML5</li><li>Thymeleaf is a replacement of JSPs</li><li>Thymeleaf is a natural template engine (the templates are viewable in a web browser)</li><li>is not tied to web environment (can be used for producing HTML for emails)</li><li>Thymeleaf is not a web framework</li></ul><h1 id="request-methods"><a class="markdownIt-Anchor" href="#request-methods"></a> Request Methods</h1><ul><li>GET<ul><li>is a request for a resource (html file, javascript file, image, etc…)</li><li>is used when you visit a website</li></ul></li><li>HEAD<ul><li>is like GET, but only asks for meta information without the body</li></ul></li><li>POST<ul><li>is used to post data to the server</li><li>typical use case for POST is to post form data to the server (like a checkout form)</li><li>POST is a create request</li></ul></li><li>PUT<ul><li>is a request for the enclosed entity be stored at the supplied URI, if the entity exists, it is expected to be updated</li><li>PUT is a create OR update request</li></ul></li><li>DELETE<ul><li>is a request to delete the specified resource</li></ul></li><li>TRACE<ul><li>will echo the received request, can be used to see if request was altered by intermediate servers</li></ul></li><li>OPTIONS<ul><li>returns the HTTP methods supported by the server for the specified URL</li></ul></li></ul><h2 id="safe-methods"><a class="markdownIt-Anchor" href="#safe-methods"></a> Safe methods</h2><ul><li>safe methods are considered safe to use because they only fetch information and do not cause changes on the server</li><li>the safe methods are: GET, HEAD, OPTIONS, and TRACE</li></ul><h2 id="idempotent-methods"><a class="markdownIt-Anchor" href="#idempotent-methods"></a> Idempotent methods</h2><ul><li>a quality of an action such that repetitions of the action have no further effect on the outcome</li><li>PUT and DELETE are Idempotent methods</li><li>safe methods (GET, HEAD, OPTIONS and TRACE) are also Idempotent</li><li>being truly idempotent is not enforced by the protocol</li></ul><h2 id="non-idempotent-methods"><a class="markdownIt-Anchor" href="#non-idempotent-methods"></a> Non-Idempotent methods</h2><ul><li>POST is NOT idempotent</li><li>multiple POSTs are likely to create multiple resources</li><li>Ever seen websites asking you to click submit only once?</li></ul><h2 id="http-status-codes"><a class="markdownIt-Anchor" href="#http-status-codes"></a> HTTP Status Codes</h2><ul><li>100 series are information in nature</li><li>200 series indicate successful request<ul><li>200 Okay, 201 Created, 204 Accepted</li></ul></li><li>300 series are redirections<ul><li>301 Moved Permanently</li></ul></li><li>400 series are client errors<ul><li>400 Bad Request, 401 Not Authorized, 404 Not Found</li></ul></li><li>500 series are server side errors<ul><li>500 Internel Server Error, 503 Service Unavailable</li></ul></li></ul><h1 id="developer-tools"><a class="markdownIt-Anchor" href="#developer-tools"></a> Developer Tools</h1><ul><li>added to project via artifact ‘spring-boot-devtools’</li><li>developer tools are automatically disabled when running a packaged application</li><li>by default, not included in repackaged archives</li></ul><h2 id="features"><a class="markdownIt-Anchor" href="#features"></a> Features</h2><ul><li>by default you need to select Build -&gt; Make project</li><li>there is an advanced setting you can change to make this more seamless</li></ul><h2 id="template-caching"><a class="markdownIt-Anchor" href="#template-caching"></a> Template caching</h2><ul><li>by default templates are cached for performance</li><li>but caching will require a container restart to refresh the cache</li><li>developer tools will disable template caching so the restart is not required to see changes</li></ul><h2 id="livereload"><a class="markdownIt-Anchor" href="#livereload"></a> LiveReload</h2><ul><li>LiveReload is a technology to automatically trigger a browser refresh when resources are changed</li><li>Spring boot developer tools includes a LiveReload server</li></ul><h1 id="entity-relationships"><a class="markdownIt-Anchor" href="#entity-relationships"></a> Entity Relationships</h1><ul><li>One to One<ul><li>One entity is related to one other entity</li></ul></li><li>One to Many<ul><li>One entity is related to many entities (List, Set, Map, SortedSet, SortedMap)</li></ul></li><li>Many to One<ul><li>the inverse relationship of one to many</li></ul></li><li>Many to Many<ul><li>many entities are related to many entities</li><li>each has a list or set reference to the other</li><li>a join table us used to define the relationships (mapping table)</li></ul></li></ul><h2 id="unidirectional-vs-bidirectional"><a class="markdownIt-Anchor" href="#unidirectional-vs-bidirectional"></a> Unidirectional vs Bidirectional</h2><ul><li>Unidirectional is one way<ul><li>mapping is only done one way, one side of the relationship will not know about the other</li></ul></li><li>Bidirectional is two way<ul><li>both sides know about each other</li><li>generally recommended to use bidirectional, since you can navigate the object graph in either direction</li></ul></li></ul><h2 id="owning-side"><a class="markdownIt-Anchor" href="#owning-side"></a> Owning side</h2><ul><li>the Owning side in the relationship will hold the foreign key in the database</li><li>one to one is the side where the foreign key is specified</li><li>one to many and many to one is the <code>Many</code> side</li><li>mappedBy is used to define the field with <code>owns</code> the reference of the relationship</li></ul><h2 id="fetch-type"><a class="markdownIt-Anchor" href="#fetch-type"></a> Fetch type</h2><ul><li>Lazy - data is not required until referenced</li><li>Eager - data is queried up front</li></ul><h2 id="jpa-cascade-types"><a class="markdownIt-Anchor" href="#jpa-cascade-types"></a> JPA Cascade Types</h2><ul><li>JPA Cascade types control how state changes are cascaded from parent objects to child objects</li><li>Types<ul><li>PERSIS</li><li>MERGE</li><li>REFRESH</li><li>REMOVE</li><li>DETACH</li><li>ALL</li></ul></li><li>by default, no operations are cascaded</li></ul><h2 id="embeddable-types"><a class="markdownIt-Anchor" href="#embeddable-types"></a> Embeddable Types</h2><ul><li>JPA / Hibernate support embeddable types</li><li>these are used to define a common set of properties</li><li>for example, an order might have a billing address and a shipping address</li><li>an embeddable type could be used for the address properties for reuse</li></ul><h2 id="inheritance"><a class="markdownIt-Anchor" href="#inheritance"></a> Inheritance</h2><ul><li>mappedSuperclass - entities inherit from a super class, a database table IS NOT created for the super class</li><li>Single Table - default - one table is used for all subclasses</li><li>Joined Table - base class and subclasses have their own tables, fetching subclass entities require a join to the parent table (subclasses will not have the common properties from the parent class)</li><li>Table Per Class - each subclass has its own table (no table for parent class. common properties will exist in all subclasses)</li></ul><h2 id="create-and-update-timestamps"><a class="markdownIt-Anchor" href="#create-and-update-timestamps"></a> Create and Update Timestamps</h2><ul><li>often a best practice to use create and update timestamps on your entities for audit purposes</li><li>JPA supports <code>@PrePersist</code> and <code>@PreUpdate</code> which can be used for support audit timestamps via JPA lifecycle callbacks</li><li>hibernate provides <code>@CreationTimestamp</code> and <code>@UpdateTimestamp</code></li></ul><h1 id="hibernate-ddl-auto"><a class="markdownIt-Anchor" href="#hibernate-ddl-auto"></a> Hibernate DDL Auto</h1><ul><li>DDL - Data Definition Language</li><li>DML - Data Manipulation Language</li><li>Hibernate property is set by the Spring property</li><li>options are<ul><li>none</li><li>validate - check if there is any table or columns that are missing</li><li>update - find missing table and columns and update the existing DB, not good for PROD environment</li><li>create - create the DB</li><li>create-drop - create the DB and drop the DB when application instance stops running.</li></ul></li><li>Spring boot will use create-drop for embedded databases (HSQL, H2, Derby) or none</li></ul><h2 id="ddl-vs-dml"><a class="markdownIt-Anchor" href="#ddl-vs-dml"></a> DDL vs DML</h2><ul><li>DDL is used to define database structures such as tables and indexes, while DML is used with data operations such as inserts and updates</li></ul><h2 id="initialize-with-hibernate"><a class="markdownIt-Anchor" href="#initialize-with-hibernate"></a> Initialize with Hibernate</h2><ul><li>data can be loaded from <code>import.sql</code>, this is a file that can be created in the root path</li><li>Hibernate feature, not Spring specific</li><li>must be on root of class path</li><li>only executed if Hinernate’s DDL auto property is set to <code>create</code> or <code>create-drop</code></li></ul><h2 id="spring-jdbc"><a class="markdownIt-Anchor" href="#spring-jdbc"></a> Spring JDBC</h2><ul><li>Spring’s datasource initializer via Spring Boot will by default load <code>schema.sql</code> and <code>data.sql</code> from the root of the class path</li><li>Spring Boot will also load from <code>schema-$&#123;platform&#125;.sql</code> and <code>data-$&#123;platform&#125;.sql</code></li><li>must set <code>spring.datasource.platform</code> property</li><li>may conflict with Hinernate DDL auto property<ul><li>if using Spring datasource initializer, should set DDL auto property to <code>none</code> or <code>validate</code></li></ul></li></ul><h2 id="spring-data-jpa-query-method"><a class="markdownIt-Anchor" href="#spring-data-jpa-query-method"></a> Spring Data JPA Query Method</h2><ul><li>define method in interface</li><li>method name rules: findBy + <code>&lt;PROPERTY_NAME&gt;</code></li><li>it will create the query based on method name and query the database to find the data and return to us.</li><li>no manual implementation needed.</li></ul><h2 id="repository-layer-and-service-layer"><a class="markdownIt-Anchor" href="#repository-layer-and-service-layer"></a> Repository layer and Service layer</h2><ul><li>All your business logic should be in the Service Layer.</li><li>Any access to the Database (any storage) should go to the Repository Layer.</li><li>Lets take an Example. You have to save an entity(Person). But before saving the Person you want to make sure that the Person’s FirstName does not exist already.<br />So the validation part should go to the business layer.<br />In the service Layer</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">PersonRepository repository; </span><br><span class="line">public Person save(Person p)&#123;</span><br><span class="line">   Person p &#x3D; findByName(p.getName();</span><br><span class="line">   if (p !&#x3D; null)&#123;</span><br><span class="line">          return some customException();</span><br><span class="line">   &#125;</span><br><span class="line">   return repository.save(p); </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public Person findByName(String name)&#123;</span><br><span class="line">     return repository.findByName(name);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p>And in your Repository Layer just concentrate on DB Operation.</p></li><li><p><code>View&lt;--&gt;Controller( create instance of Model class)&lt;--&gt;Service&lt;---&gt;Repository</code></p></li></ul><h1 id="lombok"><a class="markdownIt-Anchor" href="#lombok"></a> Lombok</h1><ul><li>hooks in via the annotation processor API</li><li>the raw source code is passed to Lombok for code generation before the Java complier continues</li><li>thus, produces properly compiled Java code in conjunction with the Java compiler</li><li>under the classes you can view the compiled class files</li><li>IntelliJ will decompile to show you the source code</li></ul><h2 id="ides"><a class="markdownIt-Anchor" href="#ides"></a> IDEs</h2><ul><li>since compiled code is change, and source files are not, IDE’s can get confused by this</li><li>more of an issue for IDEs several years old</li><li>modern IDEs such as IntelliJ, Eclipse support Project Lombok</li><li>Plug in Installation may be necessary</li><li>IntelliJ<ul><li>verify you have enabled annotation processing under compiler settings</li></ul></li></ul><h2 id="features-2"><a class="markdownIt-Anchor" href="#features-2"></a> features</h2><ul><li><code>val</code> - local variables declared final</li><li><code>var</code> - mutable local variables</li><li><code>@NonNull</code> - Null check, will throw NPE if parameter is null</li><li><code>@Cleanup</code> - will call close() on resource/connection in finally block</li><li><code>@Getter</code> - creates getter methods for all properties</li><li><code>@Setter</code> - creates setter for all non-final properties</li><li><code>@ToString</code><ul><li>generates String of classname, and each field separated by commas</li><li>optional parameter to include field names</li><li>optional parameter to include call to the super toString method</li></ul></li><li><code>@EqualsAndHashCode</code><ul><li>generates implementations of <code>equals(Object other)</code> and <code>hashCode()</code></li><li>by default will use all non-static, non-transient properties</li><li>can optionally exclude specific properties</li></ul></li><li><code>@NoArgsConstructor</code><ul><li>generates no args constructor</li><li>will cause compiler error if there are final fields</li><li>can optionally force, which will initialize final fields with 0 / false / null</li></ul></li><li><code>@RequiredArgsConstructor</code><ul><li>generates a constructor for all fields that are final or marked @NonNull</li><li>constructor will throw a NullPointerException if any <code>@NonNull</code> fields are null</li></ul></li><li><code>@AllArgsConstructor</code><ul><li>generates a constructor for all properties of class</li><li>any @NotNull properties will have null check</li></ul></li><li><code>@Data</code><ul><li>generates typical boilerplate code for POJOs</li><li>combines - <code>@Getter</code>, <code>@Setter</code>, <code>@ToString</code>, <code>@EqualsAndHashCode</code>, <code>@RequiredArgsConstructor</code></li><li>no constructor is generated if constructors have been explicitly declared</li></ul></li><li><code>@Value</code><ul><li>the immutable variant of <code>@Data</code></li><li>all fields are made private and final by default</li></ul></li><li><code>@NonNull</code><ul><li>set on parameter of method or constructor and a NullPointerException will be thrown if parameter is null</li></ul></li><li><code>@Builder</code><ul><li>implements the builder pattern for object creation</li></ul></li><li><code>@SneakyThrows</code><ul><li>throw checked exceptions without declaring in calling method’s throws clause</li></ul></li><li><code>@Synchronized</code><ul><li>a safer implementation of Java’s synchronized</li></ul></li><li><code>@Getter(lazy = true)</code><ul><li>for expensive getters</li><li>will calculate value first time and cache</li><li>additional gets will read from cache</li></ul></li><li><code>@Log</code><ul><li>creates a Java util logger</li></ul></li><li><code>@Slf4j</code><ul><li>creates a SLF4J logger</li><li>recommended - SLF4J is a generic logging facade</li><li>spring boot’s default logger is LogBack</li></ul></li></ul><h1 id="testing-terminology"><a class="markdownIt-Anchor" href="#testing-terminology"></a> Testing Terminology</h1><ul><li>Code under test<ul><li>this is the code you are testing</li></ul></li><li>Test fixture<ul><li>a test fixture is a fixed state of a set of objects used as a baseline for running tests. The purpose of a test fixture is to ensure that there is a well known and fixed environment in which tests are run so that results are repeatable</li><li>includes: input data, mock objects, loading database with known data etc…</li></ul></li></ul><h2 id="unit-tests"><a class="markdownIt-Anchor" href="#unit-tests"></a> Unit Tests</h2><ul><li>code written to test code under test</li><li>designed to test specific sections of code</li><li>percentage of lines of code tested is code coverage<ul><li>ideal coverage is in the 70-80% range</li></ul></li><li>should be unity and execute very fast</li><li>should have no external dependencies<ul><li>no databases, no Spring Context etc…</li></ul></li></ul><h2 id="integration-tests"><a class="markdownIt-Anchor" href="#integration-tests"></a> Integration tests</h2><ul><li>designed to test behaviors between objects and parts of the overall system</li><li>much larger scope</li><li>can include Spring Context, database, and message brokers</li><li>will run much slower than unit tests</li></ul><h2 id="functional-tests"><a class="markdownIt-Anchor" href="#functional-tests"></a> Functional tests</h2><ul><li>typically means you are testing the running application</li><li>application is live, likely deployed in a known environment</li><li>functional touch points are tested</li><li>i.e. using a web driver, calling web services, sending / receiving messages etc…(Selenium)</li></ul><h2 id="tdd"><a class="markdownIt-Anchor" href="#tdd"></a> TDD</h2><ul><li>test driven development</li><li>write tests first, which will fail, then code to fix the tests</li></ul><h2 id="bdd"><a class="markdownIt-Anchor" href="#bdd"></a> BDD</h2><ul><li>behavior driven development</li><li>builds on TDD and specifies that tests of any unit of software should be specified in terms of desired behavior of the unit<ul><li>often implemented with DSLs to create natural language tests</li><li>JBehave, Cucumber, Spock</li></ul></li></ul><h2 id="mock"><a class="markdownIt-Anchor" href="#mock"></a> Mock</h2><ul><li>a fake implementation of a class used for testing, like a test double</li></ul><h2 id="spy"><a class="markdownIt-Anchor" href="#spy"></a> Spy</h2><ul><li>a partial mock, allowing you to override select methods of a real class</li></ul><h2 id="testing-goals"><a class="markdownIt-Anchor" href="#testing-goals"></a> Testing goals</h2><ul><li>generally, you will want the majority of your tests to be unit tests</li><li>bringing up the Spring Context makes your tests exponentially slower</li><li>try to test specific business logic in unit tests</li><li>use Integration tests to test interactions</li><li>think of a pyramid, base is unit tests, middle is integration tests, top is functional tests</li></ul><h2 id="test-scope-dependencies"><a class="markdownIt-Anchor" href="#test-scope-dependencies"></a> Test scope dependencies</h2><ul><li>using spring-boot-starter-test<ul><li>JUnit - the default standard for unit testing Java applications</li><li>Spring test and Spring boot Test - utilities and integration test support for Spring Boot applications</li><li>AssertJ - a fluent assertion library</li><li>Hamcrest - a library of matcher objects</li><li>Mockito - a Java mocking framework</li><li>JSONassert - an assertion library for JSON</li><li>JSONPath - XPath for JSON</li></ul></li></ul><h2 id="junit-annotations"><a class="markdownIt-Anchor" href="#junit-annotations"></a> JUnit Annotations</h2><table><thead><tr><th>Annotation</th><th>Description</th></tr></thead><tbody><tr><td>@Test</td><td>identifies a method as a test method</td></tr><tr><td>@Before</td><td>executed before each test, it is used to prepare the test environment (e.g. read input data, initialize the class)</td></tr><tr><td>@After</td><td>executed after each test, it is used to cleanup the test environment, it can also save memory by cleaning up expensive memory structures</td></tr><tr><td>@BeforeClass</td><td>executed once, before the start of all tests, methods marked with this annotation need to be defined as static to work with JUnit</td></tr><tr><td>@AfterClass</td><td>executed once, after all tests have been finished, methods annotated with this annotation need to be defined as static to work with JUnit</td></tr><tr><td>@Ignore</td><td>marks that the test should be ignored</td></tr><tr><td>@Test(expected = Exception.class)</td><td>fails if the method does not throw the named exception</td></tr><tr><td>@Test(timeout = 10)</td><td>fails if the method takes longer than 100 milliseconds</td></tr></tbody></table><h2 id="spring-boot-annotations"><a class="markdownIt-Anchor" href="#spring-boot-annotations"></a> Spring Boot Annotations</h2><table><thead><tr><th>Annotation</th><th>Description</th></tr></thead><tbody><tr><td>@RunWith(SpringRunner.class)</td><td>run test with Spring Context</td></tr><tr><td>@SpringBootTest</td><td>search for Spring boot application for configuration</td></tr><tr><td>@TestConfiguration</td><td>specify a Spring configuration for you test</td></tr><tr><td>@MockBean</td><td>injects Mockito mock</td></tr><tr><td>@SpyBean</td><td>injects Mockito Spy</td></tr><tr><td>@JsonTest</td><td>creates a Jackson or Gson object mapper via Spring boot</td></tr><tr><td>@WebMvcTest</td><td>used to test web context without a full http server</td></tr><tr><td>@DataJpaTest</td><td>used to test data layer with embedded database</td></tr></tbody></table><p>…</p><h2 id="argumentcaptor"><a class="markdownIt-Anchor" href="#argumentcaptor"></a> ArgumentCaptor</h2><ul><li>ArgumentCaptor allows us to capture an argument passed to a method in order to inspect it. This is especially useful when we can’t access the argument outside of the method we’d like to test.</li><li>For example, consider an EmailService class with a send method that we’d like to test:</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">public class EmailService &#123;</span><br><span class="line"></span><br><span class="line">    private DeliveryPlatform platform;</span><br><span class="line"></span><br><span class="line">    public EmailService(DeliveryPlatform platform) &#123;</span><br><span class="line">        this.platform &#x3D; platform;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void send(String to, String subject, String body, boolean html) &#123;</span><br><span class="line">        Format format &#x3D; Format.TEXT_ONLY;</span><br><span class="line">        if (html) &#123;</span><br><span class="line">            format &#x3D; Format.HTML;</span><br><span class="line">        &#125;</span><br><span class="line">        Email email &#x3D; new Email(to, subject, body);</span><br><span class="line">        email.setFormat(format);</span><br><span class="line">        platform.deliver(email);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>In EmailService.send, notice how platform.deliver takes a new Email as an argument. As part of our test, we’d like to check that the format field of the new Email is set to Format.HTML. In order to do this, we need to capture and inspect the argument that is passed to platform.deliver.</li></ul><h3 id="set-up-the-unit-test"><a class="markdownIt-Anchor" href="#set-up-the-unit-test"></a> Set up the unit test</h3><ul><li>First, let’s create our unit test class:</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">RunWith(MockitoJUnitRunner.class)</span><br><span class="line">public class EmailServiceUnitTest &#123;</span><br><span class="line"></span><br><span class="line">    @Mock</span><br><span class="line">    DeliveryPlatform platform;</span><br><span class="line"></span><br><span class="line">    @InjectMocks</span><br><span class="line">    EmailService emailService;</span><br><span class="line">  </span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>We’re using the @Mock annotation to mock DeliveryPlatform, which is automatically injected into our EmailService with the @InjectMocks annotation.</li></ul><h3 id="add-an-argumentcaptor-field"><a class="markdownIt-Anchor" href="#add-an-argumentcaptor-field"></a> Add an ArgumentCaptor field</h3><ul><li>Second, let’s add a new ArgumentCaptor field of type Email to store our captured argument:</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">@Captor</span><br><span class="line">ArgumentCaptor&lt;Email&gt; emailCaptor;</span><br></pre></td></tr></table></figure><h3 id="capture-the-argument"><a class="markdownIt-Anchor" href="#capture-the-argument"></a> Capture the argument</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Mockito.verify(platform).deliver(emailCaptor.capture());</span><br></pre></td></tr></table></figure><ul><li>We can then get the captured value and store it as a new Email object:</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Email emailCaptorValue &#x3D; emailCaptor.getValue();</span><br></pre></td></tr></table></figure><h3 id="inspect-the-captured-value"><a class="markdownIt-Anchor" href="#inspect-the-captured-value"></a> Inspect the captured value</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">@Test</span><br><span class="line">public void whenDoesSupportHtml_expectHTMLEmailFormat() &#123;</span><br><span class="line">    String to &#x3D; &quot;info@baeldung.com&quot;;</span><br><span class="line">    String subject &#x3D; &quot;Using ArgumentCaptor&quot;;</span><br><span class="line">    String body &#x3D; &quot;Hey, let&#39;use ArgumentCaptor&quot;;</span><br><span class="line"></span><br><span class="line">    emailService.send(to, subject, body, true);</span><br><span class="line"></span><br><span class="line">    Mockito.verify(platform).deliver(emailCaptor.capture());</span><br><span class="line">    Email value &#x3D; emailCaptor.getValue();</span><br><span class="line">    assertEquals(Format.HTML, value.getFormat());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="exception-handling-in-spring-mvc"><a class="markdownIt-Anchor" href="#exception-handling-in-spring-mvc"></a> Exception Handling in Spring MVC</h1><h2 id="http-status-code"><a class="markdownIt-Anchor" href="#http-status-code"></a> HTTP status code</h2><ul><li>HTTP 5XX server error<ul><li>HTTP 500 - internal server error</li><li>generally, any unhandled exception</li><li>other 500 errors are generally not used with Spring MVC</li></ul></li><li>HTTP 4XX client errors - generally checked exceptions<ul><li>400 bad request - cannot process due to client error</li><li>401 unauthorized - authentication required</li><li>404 not found - resource not found</li><li>405 method not allowed, HTTP method not allowed</li></ul></li></ul><h2 id="responsestatus"><a class="markdownIt-Anchor" href="#responsestatus"></a> @ResponseStatus</h2><ul><li>allows you to annotate custom exception classes to indicate to the framework the HTTP status you want returned when that exception is thrown</li><li>global to the application</li></ul><h2 id="exceptionhandler"><a class="markdownIt-Anchor" href="#exceptionhandler"></a> @ExceptionHandler</h2><ul><li>works at the controller level</li><li>allows you to define custom exception handling</li><li>can be used with <code>@ResponseStatus</code> for just printing a http status</li><li>can be used to return a specific view</li><li>also can take total control and work with the Model and View</li><li>Model cannot be a parameter of an ExceptionHandler method</li></ul><h2 id="handlerexceptionresolver"><a class="markdownIt-Anchor" href="#handlerexceptionresolver"></a> @HandlerExceptionResolver</h2><ul><li>is an interface you can implement for custom exception handling</li><li>used internally by Spring MVC</li><li>note Model is not passed</li></ul><h1 id="docker"><a class="markdownIt-Anchor" href="#docker"></a> Docker</h1><h2 id="what-is-docker"><a class="markdownIt-Anchor" href="#what-is-docker"></a> What is Docker?</h2><ul><li>Docker is a standard for Linux containers</li><li>a Container is an isolated runtime inside of Linux</li><li>a Container provides a private machine like space under Linux</li><li>Containers will run under any modern Linux Kernel</li></ul><h2 id="containers-can"><a class="markdownIt-Anchor" href="#containers-can"></a> Containers can</h2><ul><li>Have their own process space</li><li>their own network interface</li><li>run processes as Root (inside the container)</li><li>have their own disk space<ul><li>can share with host too</li></ul></li><li>Container is not a VM</li></ul><h2 id="docker-terminology"><a class="markdownIt-Anchor" href="#docker-terminology"></a> Docker Terminology</h2><ul><li>Docker Image - the representation of a Docker container, kind of like a JAR or WAR file in Java</li><li>Docker Container - the standard runtime of Docker, effectively a deployed and running Docker image, like a Spring Boot Executable JAR</li><li>Docker Engine - the code which manages Docker stuff, creates and runs Docker containers</li></ul><h2 id="notes-about-docker-images-and-containers"><a class="markdownIt-Anchor" href="#notes-about-docker-images-and-containers"></a> Notes about Docker Images and Containers</h2><ul><li>Containers are like snapshots of Docker images</li><li>Docker images are built by Docker files which contains multiple layers, each layer is a Command and will generate a file for the image. The layers will be re-created everytime when we run a new container for an image.</li><li>e.g. when you <code>docker run -d mongo</code>, a new container for the image <code>mongo</code> will be created, and there is a layer for this container where you can store data in it. But when you <code>docker stop &lt;Container_ID&gt;</code> and re-start using <code>docker run -d mongo</code>, a new container with different Container ID will be created, so your old data in the previous container will not show in your new container. You can map a storage path to the container, so the current container and all future containers will save data into the directory you setup. Which will make the data persistence.</li></ul><h2 id="docker-housekeeping"><a class="markdownIt-Anchor" href="#docker-housekeeping"></a> Docker housekeeping</h2><h3 id="cleaning-up-after-docker"><a class="markdownIt-Anchor" href="#cleaning-up-after-docker"></a> Cleaning up after Docker</h3><ul><li>with development use docker can leave behind a lot of files</li><li>these files will grow and consume a lot of disk space</li><li>this is less of an issue on production systems where containers aren’t being built and restarted all the time</li><li>there are 3 key areas of house keeping<ul><li>containers</li><li>images</li><li>volumes</li></ul></li></ul><h1 id="mysql"><a class="markdownIt-Anchor" href="#mysql"></a> MySQL</h1><h2 id="mysql-features"><a class="markdownIt-Anchor" href="#mysql-features"></a> MySQL features</h2><ul><li>Stored procedures<ul><li>a piece of code inside of the database that execute against the database, runs locally on the database</li></ul></li><li>Triggers<ul><li>when something happens in the database e.g. insert a record, the trigger will run before or after that transaction</li></ul></li><li>Cursors<ul><li>point a place in a large set of data so you can scroll through it and look into the next record or previous record.</li></ul></li><li>Updated views<ul><li>a virtual table, stored inside the database</li></ul></li><li>Query cache<ul><li>database is going to remember in memory the result of your query, when you ask for that data again, it doesn’t have to go back to the file system to get the data.</li></ul></li><li>Subselects<ul><li>nested queries.</li></ul></li></ul><h2 id="acid-compliance"><a class="markdownIt-Anchor" href="#acid-compliance"></a> ACID compliance</h2><ul><li>atomicity - all or nothing</li><li>consistency - transactions are valid to rules of the DB</li><li>isolation - results of transactions are as if they are done end to end</li><li>durability - once a transaction is committed, it remains so (DB will not losing data)</li></ul><h2 id="rdbms-deployment-architectures"><a class="markdownIt-Anchor" href="#rdbms-deployment-architectures"></a> RDBMS deployment architectures</h2><ul><li>typically is driven by needs of scalability and availability</li><li>can be done on a single non-dedicated server or many dedicated servers</li><li>communication is typically over a network socket (MySQL: 3306)</li><li>the client will need software called a <code>driver</code> to talk to the database over the network socket.</li></ul><h2 id="mysql-data-types"><a class="markdownIt-Anchor" href="#mysql-data-types"></a> MySQL data types</h2><ul><li>a data type defines the data type of a column</li><li>MySQL does support the standard ANSI SQL data types</li><li>data types are broken down into the following categories<ul><li>numeric</li><li>date and time</li><li>string</li><li>spatial (location, places)</li><li>JSON</li></ul></li></ul><h2 id="mysql-installation-options"><a class="markdownIt-Anchor" href="#mysql-installation-options"></a> MySQL installation options</h2><h3 id="native-installation"><a class="markdownIt-Anchor" href="#native-installation"></a> Native installation</h3><ul><li>meaning install on your opearting system</li></ul><h3 id="running-mysql-in-a-container"><a class="markdownIt-Anchor" href="#running-mysql-in-a-container"></a> Running MySQL in a Container</h3><ul><li>MySQL can also be run inside a technology called containers</li><li>Docker is a highly popular container technology</li><li>through Docker, you can run MySQL locally using pre built image from Docker hub</li></ul><h2 id="connecting-to-mysql"><a class="markdownIt-Anchor" href="#connecting-to-mysql"></a> Connecting to MySQL</h2><ul><li>Local connection<ul><li>connecting to MySQL from the command line on the machine running MySQL</li><li>to login to docker: <code>docker exec -it yuan-mysql bash</code></li><li>to connect to mysql server in Docker: <code>mysql --user=root -p</code></li></ul></li><li>remote / client connection<ul><li>using some type of client software on the same machine running MySQL</li><li>or connecting to the MySQL server from a different machine over the network</li></ul></li></ul><h1 id="mongo-db"><a class="markdownIt-Anchor" href="#mongo-db"></a> Mongo DB</h1><h2 id="about-mongo-db"><a class="markdownIt-Anchor" href="#about-mongo-db"></a> About Mongo DB</h2><ul><li>Mongo DB is a document oriented database</li><li>developed in C++</li><li>MongoDB is a NoSQL database</li><li>MongoDB documents are stored in BSON<ul><li>binary JSON</li></ul></li></ul><h2 id="why-use-mongo-db"><a class="markdownIt-Anchor" href="#why-use-mongo-db"></a> Why use Mongo DB?</h2><ul><li>MongoDB is great for high insert systems<ul><li>such as sensor readings, social media systems, advertising systems</li></ul></li><li>good when you need schema flexibility</li><li>can also support a high number of reads per second</li></ul><h2 id="why-avoid-mongodb"><a class="markdownIt-Anchor" href="#why-avoid-mongodb"></a> Why avoid MongoDB?</h2><ul><li>MongoDB has no concept of transactions<ul><li>No ACID</li><li>no locking for transactional support, hence faster inserts</li></ul></li><li>not good for concurrent updates</li></ul><h1 id="reactive-manifesto"><a class="markdownIt-Anchor" href="#reactive-manifesto"></a> Reactive Manifesto</h1><h2 id="responsive"><a class="markdownIt-Anchor" href="#responsive"></a> Responsive</h2><ul><li>the system responds in a timely manner</li><li>responsiveness is the cornerstone of useability and utility</li><li>responsiveness also means problems may be detected quickly and dealt with effectively</li><li>responsive systems provide rapid and consistent response times</li><li>consistent behavior simplifies error handling, builds end user confidence, and encourages further interaction</li></ul><h2 id="resilient"><a class="markdownIt-Anchor" href="#resilient"></a> Resilient</h2><ul><li>system stays responsive in the face of failure</li><li>resilience is achieved by replication, containment, isolation and delegation</li><li>failures are contained within each component</li><li>parts of the system can fail, without compromising the system as a whole</li><li>recovery of each component is delegated to another</li><li>high availability is ensured by replication where necessary</li></ul><h2 id="elastic"><a class="markdownIt-Anchor" href="#elastic"></a> Elastic</h2><ul><li>the system stays responsive under varying workload</li><li>reactive systems can react to changes in the input rate by increasing or decreasing resources allocated to service inputs</li><li>reactive systems achieve elasticity ina cost effective way on commodity hardware and software platforms</li></ul><h2 id="message-driven"><a class="markdownIt-Anchor" href="#message-driven"></a> Message Driven</h2><ul><li>reactive systems rely on asynchronous message passing to establish a boundary between components<ul><li>this ensures loose coupling, isolation, and location transparency</li></ul></li><li>message passing enables load management, elasticity, and flow control</li><li>location transparent messaging makes management of failure possible</li><li>non blocking communication allows recipients to only consume resources while active, leading to less system overhead.</li></ul><h2 id="reactive-programming-with-reactive-systems"><a class="markdownIt-Anchor" href="#reactive-programming-with-reactive-systems"></a> reactive programming with reactive systems</h2><ul><li>reactive programming is a useful implementation technique</li><li>reactive programming focuses on non-blocking, asynchronous execution - a key characteristic of reactive systems</li><li>reactive programming is just one tool in building reactive systems</li></ul><h1 id="reactive-programming"><a class="markdownIt-Anchor" href="#reactive-programming"></a> Reactive Programming</h1><ul><li>reactive programming is an asynchronous programming paradigm focused on streams of data</li><li>reactive programs also maintain a continuous interaction with their environment, but at a speed which is determined by the environment, not the program itself. Interactive programs work at their own pace and mostly deal with communication, while reactive programs only work in response to external demands and mostly deal with accurate interrupt handling, real time programs are usually reactive.</li></ul><h2 id="common-use-cases"><a class="markdownIt-Anchor" href="#common-use-cases"></a> Common use cases</h2><ul><li>external service calls</li><li>highly concurrent message consumers</li><li>spreadsheets</li><li>abstraction over asynchronous processing<ul><li>abstract whether or not your program is synchronous or asynchronous</li></ul></li></ul><h2 id="features-opf-reactive-programming"><a class="markdownIt-Anchor" href="#features-opf-reactive-programming"></a> features opf reactive programming</h2><ul><li>data streams</li><li>asynchronous</li><li>non-blocking</li><li>backpressure</li><li>failures as messages</li></ul><h2 id="data-streams"><a class="markdownIt-Anchor" href="#data-streams"></a> data streams</h2><ul><li>data streams can be just about anything</li><li>mouse clicks, or other user interactions</li><li>JMS messages, RESTful service calls, Twitter feed, Stock trades, list of data from a database</li><li>a stream is a sequence of events ordered in time</li><li>events you want to listen to</li></ul><h2 id="asynchronous"><a class="markdownIt-Anchor" href="#asynchronous"></a> Asynchronous</h2><ul><li>events are captured asynchronously</li><li>a function is defined to execute when an event is emitted</li><li>another function is defined if an error is emitted</li><li>another function is defined when complete is emitted</li></ul><h2 id="observer-pattern"><a class="markdownIt-Anchor" href="#observer-pattern"></a> Observer pattern</h2><ul><li>you have a subject and an observer</li><li>when the subject is going to change, it will notify the observer</li></ul><h2 id="non-blocking"><a class="markdownIt-Anchor" href="#non-blocking"></a> Non-blocking</h2><ul><li>the concept of using non blocking is important</li><li>in blocking, the code will stop and wait for more dta (reading from disk, network etc…)</li><li>non blocking in contrast, will process available data, ask to be notified when more is available, then continue</li></ul><h2 id="back-pressure"><a class="markdownIt-Anchor" href="#back-pressure"></a> back pressure</h2><ul><li>the ability of the subscriber to throttle data</li></ul><h2 id="failures-as-messages"><a class="markdownIt-Anchor" href="#failures-as-messages"></a> failures as messages</h2><ul><li>exceptions are not thrown in a traditional sense<ul><li>would break processing of stream</li></ul></li><li>exceptions are processed by a handler function</li></ul><h1 id="reactive-streams"><a class="markdownIt-Anchor" href="#reactive-streams"></a> Reactive Streams</h1><h2 id="spring-reactive-types"><a class="markdownIt-Anchor" href="#spring-reactive-types"></a> Spring Reactive Types</h2><ul><li>two new reactive types are introduced with Spring framework 5</li><li><code>Mono</code> is a publisher with zero or one elements in data stream</li><li><code>Flux</code> is a publisher with zero or MANY elements in the data stream</li><li>both types implement the reactive streams publisher interface</li></ul><h1 id="webflux"><a class="markdownIt-Anchor" href="#webflux"></a> WebFlux</h1><table><thead><tr><th>web MVC</th><th>webFlux</th></tr></thead><tbody><tr><td>@Controller, @RequestMapping</td><td>Router functions</td></tr><tr><td>spring-webmvc</td><td>spring-webflux</td></tr><tr><td>Servlet API</td><td>HTTP / Reactive Streams</td></tr><tr><td>Servlet Container</td><td>Tomcat, Jetty, Netty, Undertow</td></tr></tbody></table><h1 id="restful-web-services"><a class="markdownIt-Anchor" href="#restful-web-services"></a> RESTful web services</h1><ul><li>because of their simplicity and versatility, RESTful web services have become the de facto standard for web services</li><li>REST - representational state transfer<ul><li>representational - typically JSON or XML</li><li>state transfer - typically via HTTP</li></ul></li></ul><h2 id="terminology"><a class="markdownIt-Anchor" href="#terminology"></a> terminology</h2><ul><li>verbs - HTTP methods: GET, PUT, POST, DELETE</li><li>messages - the payload of the action(JSON / XML)</li><li>URI - uniform resource identifier<ul><li>a unique string identifying a resource</li></ul></li><li>URL - uniform resource locator<ul><li>a URI with network information</li></ul></li><li>Idempotence<ul><li>the property of certain operations in mathematics and computer science that they can be applied multiple times without changing the result beyond the initial application</li><li>in other words, you can exercise the operation multiple times, without changing the result</li><li>example: refreshing a web page (HTTP GET operation)</li></ul></li><li>Stateless - service does not maintain any client state</li><li>HATEOAS - hypermedia as the engine of application state<ul><li>a REST client should then be able to use server-provided links dynamically to discover all the available actions and resources it needs, as access proceeds, the server responds with text that includes hyperlinks to other actions that are currently available</li></ul></li></ul><h2 id="get"><a class="markdownIt-Anchor" href="#get"></a> GET</h2><ul><li>use: to read data from resource</li><li>read only</li><li>idempotent</li><li>safe operation - does not change state of resource</li></ul><h2 id="put"><a class="markdownIt-Anchor" href="#put"></a> PUT</h2><ul><li>use: to insert or update</li><li>idempotent - multiple PUT will not change result</li><li>like saving a file multiple times</li><li>not safe operation - does change state of resource</li></ul><h2 id="post"><a class="markdownIt-Anchor" href="#post"></a> POST</h2><ul><li>use: to create new object</li><li>non-idempotent - multiple POSTs is expected to create multiple objects</li><li>not safe operation - does change state of resource</li><li>only non-idempotent, non-safe HTTP verb</li></ul><h2 id="delete"><a class="markdownIt-Anchor" href="#delete"></a> DELETE</h2><ul><li>use: to delete an object</li><li>idempotent - multiple DELETEs will have same effect / behavior</li><li>not safe operation, does change the state of resource</li></ul><h1 id="mapstruct"><a class="markdownIt-Anchor" href="#mapstruct"></a> MapStruct</h1><ul><li>MapStruct is a code generator for Java bean mapping<ul><li>helps reduce coding for type conversions</li><li>when dealing with Rest services, a common use case is to expose API data using DTOs (Data Transfer Object)</li><li>as project grows bigger, it is not good to expose POJO directly to Rest services. MapStruct is helping us to convert POJO to DTOs, then export DTOs to Rest service to be consumed by public</li></ul></li></ul><h1 id="content-negotiation"><a class="markdownIt-Anchor" href="#content-negotiation"></a> Content Negotiation</h1><h2 id="content-negotiating-view-resolver"><a class="markdownIt-Anchor" href="#content-negotiating-view-resolver"></a> Content Negotiating view resolver</h2><ul><li>used by Spring MVC to determine view handler to use</li><li>auto configured by Spring boot</li><li>the content negotiating view resolver will determine the view to use to render the data of the model to the client</li></ul><h2 id="content-type"><a class="markdownIt-Anchor" href="#content-type"></a> Content type</h2><ul><li>view to use is determined by Content Type in HTTP header<ul><li>application/json, application/xml, text/html</li></ul></li><li>if view for requested Content type is not found, HTTP status 406 not acceptable is returned.</li></ul><h1 id="helper-library-and-classes"><a class="markdownIt-Anchor" href="#helper-library-and-classes"></a> Helper Library and Classes</h1><h2 id="structure"><a class="markdownIt-Anchor" href="#structure"></a> Structure</h2><ul><li>the project should follow a structure from database to frontend: Database -&gt; Repository -&gt; Service -&gt; Controller -&gt; View</li></ul><h2 id="jpa"><a class="markdownIt-Anchor" href="#jpa"></a> JPA</h2><ul><li>H2 in memory database</li></ul><h2 id="thymeleaf-2"><a class="markdownIt-Anchor" href="#thymeleaf-2"></a> Thymeleaf</h2><ul><li>frontend template engine, model can be added to view dynamically</li></ul><h2 id="dependency-injection"><a class="markdownIt-Anchor" href="#dependency-injection"></a> Dependency Injection</h2><ul><li>Repositories and Services can be injected when needed, use Annotations @Service, @Component</li><li>classes marked as @Component, @Service and @Controller will be managed by Spring Application Context, it will inject necessary class to the right place when needed. (Beans)</li></ul><h2 id="configuration"><a class="markdownIt-Anchor" href="#configuration"></a> Configuration</h2><ul><li>config files can be Java, YAML, or XML</li><li>application.properties can define project profiles</li></ul><h2 id="jpa-entity-relationships"><a class="markdownIt-Anchor" href="#jpa-entity-relationships"></a> JPA entity relationships</h2><ul><li>One to Many</li><li>Many to One</li><li>Many to Many (needs mapping table)</li></ul><h2 id="jpa-query-methods"><a class="markdownIt-Anchor" href="#jpa-query-methods"></a> JPA Query methods</h2><ul><li>e.g. findByDescription</li><li>this is done by the library, findBy + property name</li><li>library will do the implementations for you</li></ul><h2 id="project-lombok"><a class="markdownIt-Anchor" href="#project-lombok"></a> Project Lombok</h2><ul><li>will do the constructors, getters, setters and even builder patterns for you</li></ul><h2 id="junit"><a class="markdownIt-Anchor" href="#junit"></a> JUnit</h2><ul><li>Unit Test framework</li></ul><h2 id="mockito"><a class="markdownIt-Anchor" href="#mockito"></a> Mockito</h2><ul><li>for unit tests, we do not want to bring in Spring Application Context</li><li>so to manage Repositories and Services, we need Mockito to create some Mock component for us</li><li>when(), thenReturn(), verify(), ArgumentCaptor, MockMvc…</li></ul><h2 id="webjars"><a class="markdownIt-Anchor" href="#webjars"></a> WebJars</h2><ul><li>bring in bootstrap library</li></ul><h2 id="web-data-binder"><a class="markdownIt-Anchor" href="#web-data-binder"></a> Web Data Binder</h2><ul><li>binds HTTP variables to Java object</li><li>specifically handling form posts and binding form variables to Java data objects</li><li>whereas Rest service we could use RestTemplate</li></ul><h2 id="validations"><a class="markdownIt-Anchor" href="#validations"></a> Validations</h2><ul><li>@NotBlank, @NotNull, @Max, @Min…</li><li>annotations to data models, for form validations</li></ul><h2 id="exceptions"><a class="markdownIt-Anchor" href="#exceptions"></a> Exceptions</h2><ul><li>@ResponseStatus</li><li>@ControllerAdvice</li><li>dealing with exceptions and custom error messages</li></ul><h2 id="reactive-programming-2"><a class="markdownIt-Anchor" href="#reactive-programming-2"></a> Reactive Programming</h2><ul><li>Mono, Flux</li><li>WebFlux</li><li>Reactive vs Servlet</li></ul><h2 id="resttemplate"><a class="markdownIt-Anchor" href="#resttemplate"></a> RestTemplate</h2><ul><li>bind Rest Response to Java objects</li></ul><h2 id="webclient"><a class="markdownIt-Anchor" href="#webclient"></a> WebClient</h2><ul><li>performing web request</li></ul><h2 id="mapstruct-2"><a class="markdownIt-Anchor" href="#mapstruct-2"></a> MapStruct</h2><ul><li>auto mapper</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>git advanced</title>
      <link href="2021/10/14/git-advanced/"/>
      <url>2021/10/14/git-advanced/</url>
      
        <content type="html"><![CDATA[<h1 id="head-and-detached-head"><a class="markdownIt-Anchor" href="#head-and-detached-head"></a> HEAD and detached HEAD</h1><h2 id="head"><a class="markdownIt-Anchor" href="#head"></a> HEAD</h2><ul><li>when you checkout to a branch, git is pointing to the latest commit in that branch, which is the HEAD of that branch</li></ul><h2 id="detached-head"><a class="markdownIt-Anchor" href="#detached-head"></a> Detached HEAD</h2><ul><li>you can also checkout to a specific commit in any branch, when you do that, that commit becomes a detached HEAD, it doesn’t belong to any branch anymore.</li><li>if you made some changes in the detached HEAD and commit it, it is better to create a new branch (which contains all the changes you made), before switching back to other branches, then you could merge the new branch into the master branch. Otherwise if you don’t create a new branch, the changes you made in detached mode will be lost.</li></ul><h1 id="undo-changes"><a class="markdownIt-Anchor" href="#undo-changes"></a> Undo changes</h1><h2 id="git-restore"><a class="markdownIt-Anchor" href="#git-restore"></a> git restore</h2><ul><li>you could use <code>git restore &lt;file-name&gt;</code> or <code>git restore .</code> to revert all unstaged changes</li></ul><h2 id="git-clean"><a class="markdownIt-Anchor" href="#git-clean"></a> git clean</h2><ul><li>you could use <code>git clean -d</code> to delete new files (unstaged)</li></ul><h2 id="undo-staged-changes"><a class="markdownIt-Anchor" href="#undo-staged-changes"></a> Undo staged changes</h2><ul><li><code>git restore --staged &lt;file-name&gt;</code></li><li>this will copy the latest commited file to the staging area, which basically means it will revert all changes that currently are in the staging area now</li></ul><h1 id="deleting-commits"><a class="markdownIt-Anchor" href="#deleting-commits"></a> Deleting commits</h1><h2 id="soft"><a class="markdownIt-Anchor" href="#soft"></a> soft</h2><ul><li><code>git reset --soft HEAD~1</code></li><li>commit will be deleted, changes will still be in the staging area</li></ul><h2 id="mixed-default"><a class="markdownIt-Anchor" href="#mixed-default"></a> mixed (default)</h2><ul><li><code>git reset HEAD~1</code></li><li>commit will be deleted, changes will be removed from the staging area, but the changes will still be in the working directory</li></ul><h2 id="hard"><a class="markdownIt-Anchor" href="#hard"></a> hard</h2><ul><li><code>git reset --hard HEAD~1</code></li><li>commit will be deleted, all changes will be removed from the staging area, the all changes will be removed from the working directory too</li></ul><h1 id="stash"><a class="markdownIt-Anchor" href="#stash"></a> Stash</h1><h2 id="add-current-changes-to-stash-with-a-comment"><a class="markdownIt-Anchor" href="#add-current-changes-to-stash-with-a-comment"></a> add current changes to Stash with a comment</h2><ul><li><code>git stash push -m &quot;message&quot;</code></li></ul><h2 id="see-the-list-of-stashed-changes"><a class="markdownIt-Anchor" href="#see-the-list-of-stashed-changes"></a> see the list of stashed changes</h2><ul><li><code>git stash list</code></li></ul><h2 id="add-changes-back-to-unstaged-state-and-remove-from-stash"><a class="markdownIt-Anchor" href="#add-changes-back-to-unstaged-state-and-remove-from-stash"></a> add changes back to unstaged state and remove from Stash</h2><ul><li><code>git stash pop &lt;index&gt;</code></li></ul><h2 id="add-changes-back-to-unstaged-state-but-also-keep-it-at-stash"><a class="markdownIt-Anchor" href="#add-changes-back-to-unstaged-state-but-also-keep-it-at-stash"></a> add changes back to unstaged state but also keep it at Stash</h2><ul><li><code>git stash apply &lt;index&gt;</code></li></ul><h2 id="remove-a-particular-stash-from-the-list"><a class="markdownIt-Anchor" href="#remove-a-particular-stash-from-the-list"></a> remove a particular stash from the list</h2><ul><li><code>git stash drop &lt;index&gt;</code></li></ul><h2 id="clear-the-entire-stash-list"><a class="markdownIt-Anchor" href="#clear-the-entire-stash-list"></a> clear the entire stash list</h2><ul><li><code>git stash clear</code></li></ul><h1 id="reflog"><a class="markdownIt-Anchor" href="#reflog"></a> Reflog</h1><ul><li>allows us to bring back lost information, it could be commits or branches</li><li>use <code>git reflog</code> you will see a list of commits for the last 30 days, even the commits you deleted, which can’t be found in <code>git log</code>. Then you could use <code>git reset --hard &lt;commit hash code&gt;</code> to retrieve lost commits</li></ul><h1 id="merge"><a class="markdownIt-Anchor" href="#merge"></a> Merge</h1><h2 id="fast-forward"><a class="markdownIt-Anchor" href="#fast-forward"></a> fast forward</h2><p><img src="/../images/git-advanced/merge-fast-forward.png" alt="" /></p><ul><li>can only be used when no additional commit in master (after feature branch was created)</li><li>MERGE moves HEAD forward to the latest commit but does not create new commit</li></ul><h2 id="fast-forward-with-squash"><a class="markdownIt-Anchor" href="#fast-forward-with-squash"></a> fast forward with squash</h2><ul><li><code>git merge --squash &lt;branch name&gt;</code></li><li>all commits you made in the feature branch will be combined into one new commit when you MERGE it to the master branch</li><li>more specifically, when you use <code>--squash</code>, all the changes you made across all commits will be move to the staging area in the master branch.</li></ul><h2 id="recursive"><a class="markdownIt-Anchor" href="#recursive"></a> recursive</h2><p><img src="/../images/git-advanced/merge-recursive.png" alt="" /></p><ul><li>additional commits in both master and feature branch after feature branch was created</li><li>additional commit is created in master branch when MERGE</li><li>NOTE: when you use recursive MERGE, all commits either originated from the feature branch or the master branch, will be showing in the log history. But to revert the commit, you only need to revert for 1 step: <code>git reset --hard HEAD~1</code></li><li>if you don’t want to see the commits from the feature branch to be display in your master git log history, you could use <code>--squash</code> with recursive MERGE</li></ul><h2 id="rebase"><a class="markdownIt-Anchor" href="#rebase"></a> rebase</h2><p><img src="/../images/git-advanced/merge-rebase.png" alt="" /></p><ul><li>when you have new commits for both master branch and feature branch (after you created the feature branch), you could use <code>rebase</code> to let the latest commit in master branch becomes the new base commit for commits created in feature branch</li><li>after <code>rebase</code> in the feature branch, all commits you made in the feature branch will have new commit code, even though the changes for these commits are the same. These might raise issues when working with others outside the repo because you will have different commit history</li></ul><h3 id="when-to-use-rebase"><a class="markdownIt-Anchor" href="#when-to-use-rebase"></a> when to use rebase?</h3><ul><li>you could use <code>rebase</code> when there is new commits in the master branch</li></ul><h3 id="why-use-rebase"><a class="markdownIt-Anchor" href="#why-use-rebase"></a> why use rebase?</h3><ol><li>feature branch relies on additional commits in the master branch, then you could rebase the master into feature branch</li><li>feature branch is finished, you want to merge it into master without creating new merge commit</li></ol><ul><li>you could first rebase master into feature branch</li><li>then you could use fast-forward merge because now your master branch don’t have any new commits to your feature branch (because you rebased)</li></ul><h2 id="cherry-pick"><a class="markdownIt-Anchor" href="#cherry-pick"></a> cherry-pick</h2><ul><li>add a specific commit from feature branch to your master branch</li><li>a new commit ID will be created, even though the commit content is the same</li><li>useful when you want just a commit to be in your master branch, but you don’t want to merge the entire feature branch</li></ul><h1 id="github"><a class="markdownIt-Anchor" href="#github"></a> Github</h1><h2 id="deleteing-commits-in-github"><a class="markdownIt-Anchor" href="#deleteing-commits-in-github"></a> deleteing commits in github</h2><ul><li>we could use <code>git reset --hard HEAD~1</code> to delete local commits</li><li>but when we use <code>git push</code> to push to remote git repo, it will fail because our local branch is behind the remote branch</li><li>we could use <code>git push --force origin master</code> to force push changes to remote repo, in this case the remote commits will be deleted.</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Wishlist 2022</title>
      <link href="2021/10/14/Wishlist-2022/"/>
      <url>2021/10/14/Wishlist-2022/</url>
      
        <content type="html"><![CDATA[<ol><li>Get AWS SAP Certificate</li><li>Learn Spring Boot</li><li>Join a Hackathon project</li><li>Create a personal project using AWS</li><li>Find a new job by the end of 2022 - Done</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Wishlist </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS DVA review</title>
      <link href="2021/09/12/AWS-DVA-review/"/>
      <url>2021/09/12/AWS-DVA-review/</url>
      
        <content type="html"><![CDATA[<h1 id="i-passed"><a class="markdownIt-Anchor" href="#i-passed"></a> I PASSED!</h1><p><img src="/../images/AWS-DVA-Review/AWSCertifiedDeveloperAssociatecertificate.png" alt="" /><br /><a href="https://www.credly.com/badges/1ccb74e0-f7a1-4e64-9ca2-c1c5b1ece31a?source=linked_in_profile">View My Certificate</a></p><h1 id="elb-asg"><a class="markdownIt-Anchor" href="#elb-asg"></a> ELB + ASG</h1><h2 id="why-use-a-load-balancer"><a class="markdownIt-Anchor" href="#why-use-a-load-balancer"></a> Why use a load balancer</h2><ul><li>spread load across multiple downstream instances</li><li>expose a single point of access (DNS) to your application</li><li>seamlessly handle faliures of downstream instances</li><li>do regular health checks to your instances</li><li>provide SSL termination (HTTPS) for your websites</li><li>enforce stickness with cookies</li><li>high availability across zones</li><li>separate public traffic from private traffic</li></ul><h3 id="elb-integrated-with-many-aws-services"><a class="markdownIt-Anchor" href="#elb-integrated-with-many-aws-services"></a> ELB integrated with many AWS services</h3><ul><li>EC2, ASG, ECS</li><li>ACM, CloudWatch</li><li>Route 53, WAF, Global Accelerator</li></ul><h2 id="alb"><a class="markdownIt-Anchor" href="#alb"></a> ALB</h2><ul><li>Layer 7 (HTTP)</li><li>load balancing to multiple HTTP applications across machines (target groups)</li><li>load balancing to multiple applications on the same machine (containers)</li><li>support for HTTP and WebSockets</li><li>support redirects (from HTTP to HTTPS)</li><li>routing tables to different target groups<ul><li>based on path in URL</li><li>based on hostname in URL</li><li>routing based on query string, headers</li></ul></li><li>ALB are a great fit for micro services and container based application</li><li>has a port mapping feature to redirect to a dynamic port in ECS</li><li>in comparison, we need multiple CLB per application</li><li>the application doesn’t see the client IP directly</li></ul><h3 id="target-groups"><a class="markdownIt-Anchor" href="#target-groups"></a> Target groups</h3><ul><li>EC2 instances</li><li>ECS tasks</li><li>lambda functions (HTTP request is translated into a JSON event)</li><li>IP addresses - must be private IPs</li><li>ALB can route to multiple target groups, each target group could have multiple instances</li><li>health checks are at the target group level</li><li>you can set rules to decide which target groups to redirect the traffic</li></ul><h2 id="nlb"><a class="markdownIt-Anchor" href="#nlb"></a> NLB</h2><ul><li>layer 4 (TCP and UDP)</li><li>handle millions of request per second, lower latency</li><li>NLB has one static IP per AZ, and supports assigning Elastic IP (helpful for whitelisting specific IP)</li><li>NLB are used for extreme performance, TCP or UDP traffic</li></ul><h2 id="sticky-sessions"><a class="markdownIt-Anchor" href="#sticky-sessions"></a> Sticky Sessions</h2><ul><li>it is possible to implement stickness so that the same client is always redirected to the same instance behind a load balancer</li><li>this works for CLB and ALB</li><li>the cookie used for stickness has an expiration date you control</li><li>use case: make sure the user doesn’t lose his session data</li><li>enabling stickness may bring imbalance to the load over the backend EC2 instnaces</li></ul><h2 id="ssl-server-name-indication"><a class="markdownIt-Anchor" href="#ssl-server-name-indication"></a> SSL - server name indication</h2><ul><li>SNL solves the problem of loading multiple SSL certificates onto one web server (to serve multiple websites)</li><li>it is a newer protocol, and requires the client to indicate the hostname and the target server in the initial SSL handshake</li><li>the server will then find the correct certificate, or return the default one</li><li>only works for ALB and NLB, CloudFront</li></ul><h2 id="connection-draining-de-registration-delay"><a class="markdownIt-Anchor" href="#connection-draining-de-registration-delay"></a> Connection Draining (De-registration delay)</h2><ul><li>time to complete the in-flight requests while the instance is de-registering or unhealthy</li><li>stops sending new requests to the EC2 instances which is de-registering</li><li>between 1 to 3600 seconds (default 300 seconds)</li><li>can be disabled (set value to 0)</li><li>set to a low value if your requests are short</li><li>instances will be terminated after the draining time is over</li></ul><h2 id="x-forwarded-for-and-x-forwarded-proto"><a class="markdownIt-Anchor" href="#x-forwarded-for-and-x-forwarded-proto"></a> X-Forwarded-For and X-Forwarded-Proto</h2><ul><li>X-Forwarded-For<ul><li>The X-Forwarded-For (XFF) header is a de-facto standard header for identifying the originating IP address of a client connecting to a web server through an HTTP proxy or a load balancer. When traffic is intercepted between clients and servers, server access logs contain the IP address of the proxy or load balancer only. To see the original IP address of the client, the X-Forwarded-For request header is used.</li></ul></li><li>X-Forwarded-Proto<ul><li>The X-Forwarded-Proto (XFP) header is a de-facto standard header for identifying the protocol (HTTP or HTTPS) that a client used to connect to your proxy or load balancer. Your server access logs contain the protocol used between the server and the load balancer, but not the protocol used between the client and the load balancer. To determine the protocol used between the client and the load balancer, the X-Forwarded-Proto request header can be used.</li></ul></li></ul><h2 id="asg"><a class="markdownIt-Anchor" href="#asg"></a> ASG</h2><ul><li>A launch configuration (launch template is the newer version)<ul><li>AMI + instance type</li><li>EC2 user data</li><li>EBS volume</li><li>security groups</li><li>SSH key pair</li></ul></li><li>min size, max size, initial capacity</li><li>network + subnets information</li><li>load balancer information (so ASG knows which target group to launch the instnace), ASG and ELB can be linked</li><li>scaling policies</li><li>it is possible to scale an ASG based on CloudWatch alarms</li><li>an alarm monitors a metric (such as average CPU)</li><li>metrics are computed for the overall ASG instnaces</li><li>to update an ASG, you must provide a new launch configuration or new launch template</li><li>IAM roles attached to an ASG will get assigned to EC2 instances launched</li><li>ASG is free, you need to pay for the underlying resources launched</li></ul><h3 id="scaling-policies"><a class="markdownIt-Anchor" href="#scaling-policies"></a> Scaling Policies</h3><ul><li>Target tracking scaling<ul><li>most simple and easy to setup</li><li>example: I want the average ASG CPU to stay at around 40%</li></ul></li><li>Simple / Step scaling<ul><li>when a CloudWatch alarm is triggered, then add 2 units</li><li>when a CloudWatch alarm is triggered, then remove 1 unit</li><li>the difference between simple and step scaling policies are: for step policy, you can create step adjustments, and ASG will change the number of instances based on the size of the alarm breach.</li></ul></li><li>scheduled actions<ul><li>anticipate a scaling based on known usage patterns</li><li>example: increase the min capacity to 10 at 5pm on Fridays</li></ul></li><li>predictive scaling<ul><li>continuously forecast load and schedule scaling ahead</li></ul></li></ul><h3 id="good-metrics-to-scale-on"><a class="markdownIt-Anchor" href="#good-metrics-to-scale-on"></a> Good metrics to scale on</h3><ul><li>CPU utilization</li><li>request count per target</li><li>average network in / out</li></ul><h3 id="scaling-cooldowns"><a class="markdownIt-Anchor" href="#scaling-cooldowns"></a> Scaling cooldowns</h3><ul><li>after a scaling policy happens, you are in the cooldown period (default is 300 seconds)</li><li>during the cooldown period, the ASG will not launch or terminate additional instance (to allow for metrics to stablize)</li><li>advice: use a ready to use AMI to reduce configuration time in order to be serving request faster and reduce the cooldown period</li></ul><h1 id="rds"><a class="markdownIt-Anchor" href="#rds"></a> RDS</h1><ul><li><p>managed DB service for DB use SQL as a language</p></li><li><p>it allows you to create databases in the cloud that are managed by AWS</p><ul><li>Postgres</li><li>MySQL</li><li>MariaDB</li><li>Oracle</li><li>SQL server</li><li>Aurora</li></ul></li><li><p>RDS is a managed service</p><ul><li>automated provisioning, OS patching</li><li>continuous backups and restore to specific timestamp (point in time restore)</li><li>monitoring dashboards</li><li>read replicas for improved read performance</li><li>Multi AZ setup for DR</li><li>maintenance windows for upgrades</li><li>scaling capability</li><li>storage backup by EBS</li><li>RDS DB will be launched in a VPC in an AZ</li></ul></li><li><p>you can’t SSH into your instances</p></li></ul><h2 id="rds-backups"><a class="markdownIt-Anchor" href="#rds-backups"></a> RDS backups</h2><ul><li>Automated backups<ul><li>daily full backup of the database</li><li>transaction logs are backuped by RDS every 5 mins</li><li>ability to restore to any point in time (from oldest to 5 mins ago)</li><li>7 days retention (can be increased to 35 days)</li></ul></li><li>DB snapshots<ul><li>manually triggered by the user</li><li>retention of backup for as long as you want</li></ul></li></ul><h2 id="rds-storage-auto-scaling"><a class="markdownIt-Anchor" href="#rds-storage-auto-scaling"></a> RDS storage auto scaling</h2><ul><li>helps you increase storage on your RDS DB instnace dynamically</li><li>when RDS detects you are running out of free database storage, it scales automatically</li><li>avoid manually scaling your database storage</li><li>you have to set Maximum storage threshold</li><li>automatically modify storage if<ul><li>free storage is less than 10% of allocated storage</li><li>low storage lasts at least 5 mins</li><li>6 hours have passed since last modification</li></ul></li><li>useful for applications with unpredictable workloads</li></ul><h2 id="rds-read-replicas-for-read-scalability"><a class="markdownIt-Anchor" href="#rds-read-replicas-for-read-scalability"></a> RDS read replicas for read scalability</h2><ul><li>up to 5 read replicas</li><li>within AZ, cross AZ or cross region</li><li>replication is async, so reads are eventually consistent</li><li>replicas can be promoted to their own DB</li><li>applications must update the connection string to leverage read replicas</li></ul><h2 id="rds-read-replicas-use-case"><a class="markdownIt-Anchor" href="#rds-read-replicas-use-case"></a> RDS read replicas - use case</h2><ul><li>you have a production database, that is taking on normal load</li><li>you want to run a reporting application to run some analytics</li><li>you create a read replica to run the new workload there</li><li>the production application is unaffected</li><li>read replicas are used for SELECT only kind of statements</li></ul><h2 id="rds-read-replicas-network-cost"><a class="markdownIt-Anchor" href="#rds-read-replicas-network-cost"></a> RDS read replicas - network cost</h2><ul><li>in AWS there is a network cost when data goes from one AZ to another</li><li>for RDS read replicas, within the same region, you don’t pay that fee, but you do need to pay if data goes to another region</li></ul><h2 id="rds-multi-az-dr"><a class="markdownIt-Anchor" href="#rds-multi-az-dr"></a> RDS multi AZ (DR)</h2><ul><li>SYNC replication</li><li>one DNS name - automatic app failover to standby</li><li>increase availability</li><li>failover in case of loss of AZ, loss of network, instance or storage failure</li><li>no manual intervention in apps</li><li>not used for scaling (standby instance can’t be read or write)</li><li>NOTE: the read replicas can be setup as Multi AZ for DR</li></ul><h2 id="rds-from-single-az-to-multi-az"><a class="markdownIt-Anchor" href="#rds-from-single-az-to-multi-az"></a> RDS from single AZ to Multi AZ</h2><ul><li>zero downtime operation (no need to stop the DB)</li><li>just click on modify for the database</li><li>the following happens internally<ul><li>a snapshot is taken</li><li>a new DB is restored from the snapshot in a new AZ</li><li>synchronization is established between the two databases</li></ul></li></ul><h2 id="rds-security-encryption"><a class="markdownIt-Anchor" href="#rds-security-encryption"></a> RDS security - encryption</h2><ul><li>at rest encryption<ul><li>possibility to encrypt the master and read replicas with AWS KMS - AES-256 encryption</li><li>encryption has to be defined at launch time</li><li>if the master is not encrypted, the read replicas cannot be encrypted</li></ul></li><li>in flight encryption<ul><li>SSL certificates to encrypt data to RDS in flight</li><li>provide SSL options with trust certificate when connecting to database</li></ul></li></ul><h2 id="rds-encryption-operations"><a class="markdownIt-Anchor" href="#rds-encryption-operations"></a> RDS encryption operations</h2><ul><li>encrypting RDS backups<ul><li>snapshots of unencrypted RDS databases are un-encrypted</li><li>snapshots of encrypted RDS databases are encrypted</li><li>can copy a snapshot into an encrypted one</li></ul></li><li>to encrypt an un-encrypted RDS database<ul><li>create a snapshot of the un-encrypted database</li><li>copy the snapshot and enable encryption for the snapshot</li><li>restore the database from the encrypted snapshot</li><li>migrate applications to the new database, and delete the old database</li></ul></li></ul><h2 id="rds-security-network-and-iam"><a class="markdownIt-Anchor" href="#rds-security-network-and-iam"></a> RDS security - Network and IAM</h2><ul><li>network security<ul><li>RDS databases are usually deployed within a private subnet, not in a public one</li><li>RDS security works by leveraging security groups (the same concept as for EC2 instances) - it controls which IP / security group can communicate with RDS</li></ul></li><li>Access management<ul><li>IAM policies help control who can manage AWS RDS</li><li>traditional username and password can be used to login into the database</li><li>IAM based authentication can be used to login into RDS MySQL and postgreSQL</li></ul></li></ul><h2 id="aurora"><a class="markdownIt-Anchor" href="#aurora"></a> Aurora</h2><ul><li>Aurora is a proprietary technology from AWS</li><li>postgres and MySQL are both supported as Aurora DB</li><li>Aurora is AWS cloud optimized and claims 5x performance improvement over MySQL on RDS, over 3x performance of Postgres on RDS</li><li>Aurora storage automatically grows in increments of 10GB, up to 64TB</li><li>Aurora can have 15 replicas while MySQL has 5, and the replication process is faster</li><li>failover in Aurora is instantaneous, it is HA native</li><li>user to connect to write endpoint or read endpoint, these endpoints will redirect traffic to the correct instances.</li><li>Security is the same as RDS</li><li>Aurora has 4 features<ul><li>one writer, multiple reader</li><li>one writer, multiple readers - parallel query</li><li>multiple writers</li><li>severless</li></ul></li></ul><h1 id="elasticache"><a class="markdownIt-Anchor" href="#elasticache"></a> ElastiCache</h1><ul><li>the same way RDS is to get managed relational databases</li><li>ElatiCache is to get managed Redis and Memcachced</li><li>Caches are in memory databases with really high performance, low latency</li><li>helps reduce load off of databases for read intensive workloads</li><li>helps make your application stateless</li><li>AWS takes care of OS maintenance and patching, optimizations, setup, configuration, monitoring, failure recovery and backups</li><li>using ElastiCache involves heavy application code changes</li></ul><h2 id="db-cache"><a class="markdownIt-Anchor" href="#db-cache"></a> DB cache</h2><ul><li>Application queries ElastiCache, if not avaialble, get from RDS and store in ElastiCache</li><li>helps relieve load in RDS</li><li>cache must have an invalidation strategy to make sure only the most current data is used in there</li></ul><h2 id="user-session-store"><a class="markdownIt-Anchor" href="#user-session-store"></a> User session store</h2><ul><li>user logs into any of the application</li><li>the application writes the session data into ElastiCache</li><li>the user hits another instance of our application</li><li>the instance retrieves the data and the user is already logged in</li></ul><h2 id="redis-vs-memcached"><a class="markdownIt-Anchor" href="#redis-vs-memcached"></a> Redis vs Memcached</h2><table><thead><tr><th>Redis</th><th>Memcached</th></tr></thead><tbody><tr><td>Multi AZ with auto failover</td><td>multi node for partitioning of data (sharding)</td></tr><tr><td>read replicas to scale reads and have HA</td><td>no HA</td></tr><tr><td>data durability using AOF persistence</td><td>non persistent</td></tr><tr><td>backup and restore features</td><td>no back and restore</td></tr><tr><td>-</td><td>Multi threaded architecture</td></tr></tbody></table><ul><li>Redis Auth<ul><li>if you enable encryption in transit, you can enable Redis Auth, you need to setup a token for your application to connect to Redis.</li></ul></li></ul><h2 id="caching-implementation-considerations"><a class="markdownIt-Anchor" href="#caching-implementation-considerations"></a> Caching implementation considerations</h2><ul><li>is it safe to cache data<ul><li>data may be out of data, eventaully consistent</li></ul></li><li>is caching effective for that data<ul><li>pattern: data changing slowly, few keys are frequently needed, good to use caching</li><li>anti pattern: data changing rapidly, all large keys space frequently needed, not good to use caching</li></ul></li><li>is data structured well for caching?<ul><li>key value caching, or caching of aggregations results?</li><li>caching is good for well structured data</li></ul></li></ul><h2 id="lazy-loading-cache-aside-lazy-population"><a class="markdownIt-Anchor" href="#lazy-loading-cache-aside-lazy-population"></a> lazy loading / cache aside / lazy population</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># python</span><br><span class="line"></span><br><span class="line">def get_user(user_id):</span><br><span class="line">  &#x2F;&#x2F; check the cache</span><br><span class="line">  record &#x3D; cache.get(user_id)</span><br><span class="line"></span><br><span class="line">  if record is None:</span><br><span class="line">    &#x2F;&#x2F; run a DB query</span><br><span class="line">    record &#x3D; db.query(&quot;select * from users where id &#x3D; ?&quot;, user_id)</span><br><span class="line">    &#x2F;&#x2F; populate the cache</span><br><span class="line">    cache.set(user_id, record)</span><br><span class="line">    return record</span><br><span class="line">  else:</span><br><span class="line">    return record</span><br></pre></td></tr></table></figure><h2 id="write-through-add-or-update-cache-when-database-is-updated"><a class="markdownIt-Anchor" href="#write-through-add-or-update-cache-when-database-is-updated"></a> write through - add or update cache when database is updated</h2><ul><li>when there is a write call</li></ul><ol><li>write to DB</li><li>write to cache</li></ol><ul><li>pros<ul><li>data in cache is never stale, reads are quick</li><li>wirte penalty vs read penalty (each write requires 2 calls)</li></ul></li><li>cons<ul><li>missing data until it is added/ updated in the DB, mitigation is to implement lazy loading strategy as well, combine 2 strategies together</li><li>cache churn - a lot of the data will never be read</li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># python</span><br><span class="line"></span><br><span class="line">def save_user(user_id, values):</span><br><span class="line"></span><br><span class="line">  # save to DB</span><br><span class="line">  record &#x3D; db.query(&quot;update users ... where id &#x3D; ?&quot;, user_id, values)</span><br><span class="line"></span><br><span class="line">  # push into cache</span><br><span class="line">  cache.set(user_id, record)</span><br><span class="line"></span><br><span class="line">  return record</span><br></pre></td></tr></table></figure><h2 id="cache-evictions-and-ttl-time-to-live"><a class="markdownIt-Anchor" href="#cache-evictions-and-ttl-time-to-live"></a> cache evictions and TTL (time to live)</h2><ul><li>cache eviction can occur in 3 ways<ul><li>you delete item explicity in the cache</li><li>item is evicted because the memory is full and it is not recently used (LRU)</li><li>you set an item TTL</li></ul></li><li>TTL are helpful for any kind of data<ul><li>leaderboard</li><li>comments</li><li>activity streams</li></ul></li><li>TTL can range from few seconds to hours or days</li><li>if too many evictions happen due to memory, you should scale up or out</li></ul><h2 id="final-words"><a class="markdownIt-Anchor" href="#final-words"></a> Final words</h2><ul><li>lazy loading is easy to implement and works for many situations as a foundation, especially on the read side</li><li>write through is usually combined with lazy loading as targeted for the queries or workloads that benefit from this optimization</li><li>setting a TTL is usually not a bad idea, except when you are using write through, set it to a sensible value for your application</li><li>only cache data that makes sense</li></ul><h2 id="elasticache-replication-cluster-mode-disabled"><a class="markdownIt-Anchor" href="#elasticache-replication-cluster-mode-disabled"></a> ElastiCache replication - cluster mode disabled</h2><ul><li>one primary node, up to 5 replicas</li><li>asynchronous replication</li><li>the primary node is used for read and write</li><li>the other nodes are read only</li><li>we have only one shard, and all nodes are in the shard, each node has all the data</li><li>guard against data loss if node failure</li><li>multi AZ enabled by default for failover</li><li>helpful to scale read performance</li></ul><h2 id="elasticache-replication-cluster-mode-enabled"><a class="markdownIt-Anchor" href="#elasticache-replication-cluster-mode-enabled"></a> ElastiCache replication - cluster mode enabled</h2><ul><li>data is partitioned across shards (helpful to scale writes)</li><li>each shard has a primary and up to 5 replica nodes, each shard has part of the data</li><li>multi AZ capability</li><li>up to 500 nodes per cluster</li></ul><h1 id="route-53"><a class="markdownIt-Anchor" href="#route-53"></a> Route 53</h1><ul><li><p>DNS</p><ul><li>Domain Name System which translates the human friendly hostnames into the machine IP addresses</li></ul></li><li><p>Route 53</p><ul><li>A highly available, scalable, fully managed and authoritive DNS</li><li>route 53 is also a Domain Registrar</li><li>ability to check the health of your resources</li><li>the only AWS service which provides 100% availability SLA</li></ul></li></ul><h2 id="hosted-zones"><a class="markdownIt-Anchor" href="#hosted-zones"></a> Hosted zones</h2><ul><li>a container for records that define how to route traffic to a domain and its subdomains</li><li>public hosted zones<ul><li>contains records that specify how to route traffic on the internet (public domain names)</li></ul></li><li>private hosted zones<ul><li>contain records that specify how you route traffic within one or more VPCs (private domain names)</li></ul></li></ul><h2 id="cname-vs-alias"><a class="markdownIt-Anchor" href="#cname-vs-alias"></a> CNAME vs alias</h2><ul><li><p>CNAME</p><ul><li>points a hostname to any other hostname</li><li>only for non root domain</li></ul></li><li><p>Alias</p><ul><li>points a hostname to an AWS resource</li><li>works for root domain and non root domain</li><li>free of charge</li><li>native health check</li><li>automatically recognizes changes in the resource’s IP addresses</li></ul></li><li><p>Alias targets</p><ul><li>ELB</li><li>CloudFront distributions</li><li>API gateway</li><li>Elastic Beanstalk environments</li><li>S3 websites</li><li>VPC interface endpoints</li><li>Global accelerator</li><li>route 53 record in the same hosted zone</li></ul></li><li><p>You cannot set an Alias record for an EC2 DNS name</p></li></ul><h2 id="route-53-routing-policies"><a class="markdownIt-Anchor" href="#route-53-routing-policies"></a> Route 53 - routing policies</h2><ul><li>define how route 53 responds to DNS queries</li><li>route 53 supports the following routing policies<ul><li>simple</li><li>weighted</li><li>failover</li><li>latency based</li><li>geolocation</li><li>multi value answer</li><li>geoproximity (using route 53 traffic flow feature)</li></ul></li></ul><h2 id="simple"><a class="markdownIt-Anchor" href="#simple"></a> Simple</h2><ul><li>typically, route traffic to a single resource</li><li>can specify multiple values in the same record</li><li>if multiple values are returned, a random one is chosen by the client</li><li>when Alias enabled, sepecify only one AWS resource</li><li>can’t be associated with health checks</li></ul><h2 id="weighted"><a class="markdownIt-Anchor" href="#weighted"></a> Weighted</h2><ul><li>control the percentage of the requests that go to each specific resource</li><li>assign each record a relative weight</li><li>DNS records must have the same name and type</li><li>use cases: load balancing between regions, testing new application versions…</li><li>assign a weight of 0 to a record to stop sending traffic to a resource</li><li>if all records have weight of 0, then all records will be returned equally</li></ul><h2 id="latency"><a class="markdownIt-Anchor" href="#latency"></a> latency</h2><ul><li>redirect to the resource that has the least latency close to us</li><li>super helpful when latency for users is a priority</li><li>latency is based on traffic between users and AWS regions</li><li>Germany users may be directed to the US</li><li>can be associated with health checks (has a failover capability)</li></ul><h2 id="health-checks"><a class="markdownIt-Anchor" href="#health-checks"></a> health checks</h2><ul><li>HTTP health checks are only for public resources</li><li>health check =&gt; automated DNS failover</li></ul><ol><li>health checks that monitor an endpoint</li><li>health checks that monitor other health checks (calculated health checks)</li><li>health checks that monitor cloudwatch alarms</li></ol><ul><li>health checks are integrated with CW metrics</li></ul><h3 id="monitor-an-endpoint"><a class="markdownIt-Anchor" href="#monitor-an-endpoint"></a> monitor an endpoint</h3><ul><li>about 15 global health checks will check the endpoint health<ul><li>healthy / unhealthy threshold = 3</li><li>interval - 30 seconds</li><li>supported protocol: HTTP, HTTPS, TCP</li><li>if &gt; 18% of health checks report the endpoint is healthy, route 53 consider it is healthy, otherwise, it is unhealthy</li><li>ability to choose which locations you want route 53 to use</li></ul></li><li>health checks pass only when the endpoint responds with the 2xx and 3xx status codes</li><li>health checks can be setup to pass or fail based on the text in the first 5120 bytes of the response</li><li>your ELB must allow the incoming requests from the route 53 health checkers IP address range</li></ul><h3 id="calculated-health-checks"><a class="markdownIt-Anchor" href="#calculated-health-checks"></a> calculated health checks</h3><ul><li>combine the results of multiple health checks into a single health check</li><li>you can use OR, AND, or NOT</li><li>can monitor up to 256 child health checks</li><li>specify how many of the health checks need to pass to make the parent pass</li><li>usage: perform maintenance to your website without causing all health checks to fail</li></ul><h3 id="private-hosted-zones"><a class="markdownIt-Anchor" href="#private-hosted-zones"></a> private hosted zones</h3><ul><li>route 53 health checks are outside the VPC</li><li>they can’t access private endpoint</li><li>you can create a CloudWatch metric and associate a CloudWatch alarm, then create a health check that checks the alarm itself, if the CloudWatch alarm status becomes ALARM, the health checker will become to unhealthy</li></ul><h2 id="failover"><a class="markdownIt-Anchor" href="#failover"></a> failover</h2><ul><li>create two records associate with 2 resources</li><li>primary and secondary records</li><li>primary record must associated with a health checker</li><li>if the primary record is unhealthy, DNS will return IP address of the secondary resource</li></ul><h2 id="geolocation"><a class="markdownIt-Anchor" href="#geolocation"></a> Geolocation</h2><ul><li>different from latency based</li><li>this routing is based on user location</li><li>specify location by Continent, Country, or by US state</li><li>should create a default record (in case there is no match on location)</li><li>use cases: website localization, restrict content distribution, load balancing…</li><li>can be associated with health checks</li></ul><h2 id="geoproximity"><a class="markdownIt-Anchor" href="#geoproximity"></a> Geoproximity</h2><ul><li>route traffic to your resources based on the geographic location of users and resources</li><li>ability to shift more to resources based on the defined bias</li><li>to change the size of the geographic region, specify bias values<ul><li>to expand (1 to 99), more traffic to the resource</li><li>to shrink (-1 to -99), less traffic to the resource</li></ul></li><li>resource can be<ul><li>AWS resources (AWS region)</li><li>non AWS resources (latitude and longitude)</li></ul></li><li>you must use route 53 traffic flow (advanced) to use this feature</li></ul><h3 id="traffic-flow"><a class="markdownIt-Anchor" href="#traffic-flow"></a> Traffic flow</h3><ul><li>simplify the process of creating and maintaing records in large and complex configurations</li><li>visual editor to manage complex routing decision trees</li><li>configurations can be saved as traffic flow policy<ul><li>can be applied to different route 53 hosted zones</li><li>supports versioning</li></ul></li></ul><h2 id="multi-value"><a class="markdownIt-Anchor" href="#multi-value"></a> multi value</h2><ul><li>use when routing traffic to multiple resources</li><li>route 53 return multiple values / resources</li><li>can be associated with health checks (return only values for healthy resources)</li><li>up to 8 healthy records are returned for each multi value query</li><li>multi value is not a substitude for having an ELB (it is more like a client side load balancing)</li></ul><h1 id="vpc"><a class="markdownIt-Anchor" href="#vpc"></a> VPC</h1><ul><li>VPC: private network to deploy your resource</li><li>subnet: allow you to partition your network inside your VPC (AZ resource)</li><li>a public subnet is a subnet that is accessible from the internet</li><li>a private subnet is a subnet that is not accessible from the internet</li><li>to define access to the internet and between subnets, we use route tables</li></ul><h2 id="internet-gateway-and-nat-gateways"><a class="markdownIt-Anchor" href="#internet-gateway-and-nat-gateways"></a> Internet gateway and NAT gateways</h2><ul><li>internet gateways helps our VPC instances connect with the internet</li><li>public subnets have a route to the internet gateway</li><li>NAT gateways (AWS managed) and NAT instances (self managed) allow your instances in your private subnets to access the internet while remaining private</li></ul><h2 id="nacl-and-security-groups"><a class="markdownIt-Anchor" href="#nacl-and-security-groups"></a> NACL and security groups</h2><ul><li>NACL (network ACL)<ul><li>a firewall which controls traffic from and to subnet</li><li>can have ALLOW and DENY rules</li><li>are attached at the subnet level</li><li>rules only include IP addresses</li></ul></li><li>security groups<ul><li>a firewall that controls traffic to and from an ENI / an EC2 instance</li><li>can have only ALLOW rules</li><li>rules include IP addresses and other security groups</li></ul></li></ul><table><thead><tr><th>Security group</th><th>Network ACL</th></tr></thead><tbody><tr><td>operates at the instance level</td><td>operates at the subnet level</td></tr><tr><td>supports allow rules only</td><td>supports allow rules and deny rules</td></tr><tr><td>is stateful: return traffic is automatically allowed, regardless of any rules</td><td>is stateless: return traffic must be explicitly allowed by rules</td></tr><tr><td>we evaluate all rules before deciding whether to allow traffic</td><td>we process rules in number order when deciding whether to allow traffic</td></tr><tr><td>applies to an instance only if someone specifies the security group when launching the instance, or associate the security group with the instance later on</td><td>automatically applies to all instances in the subnets it’s associated with (therefore, you don’t have to rely on users to specify the security group)</td></tr></tbody></table><h2 id="vpc-flow-logs"><a class="markdownIt-Anchor" href="#vpc-flow-logs"></a> VPC Flow logs</h2><ul><li>capture information about IP traffic going into your interfaces<ul><li>VPC flow logs</li><li>subnet flow logs</li><li>ENI (elastic network interface) flow logs</li></ul></li><li>helps to monitor and troubleshoot connectivity issues<ul><li>subnets to internet</li><li>subnets to subnets</li><li>internet to subnets</li></ul></li><li>captures network information from AWS managed interfaces too: Elastic load balancers, ElastiCache, RDS, Aurora, etc…</li><li>VPC flow logs data can go to S3 / CloudWatch logs</li></ul><h2 id="vpc-peering"><a class="markdownIt-Anchor" href="#vpc-peering"></a> VPC Peering</h2><ul><li>connect two VPCs, privately using AWS network</li><li>make them behave as if they were in the same network</li><li>must not have overlapping CIDR</li><li>VPC peering connection is not transitive (must be established for each VPC that need to communicate with one another)</li></ul><h2 id="vpc-endpoints"><a class="markdownIt-Anchor" href="#vpc-endpoints"></a> VPC endpoints</h2><ul><li>endpoints allow you to connect to AWS services using a private network instead of the public www network</li><li>this gives you enhanced security and lower latency to access AWS services</li><li>VPC endpoint gateway: S3 and DynamoDB</li><li>VPC endpoint interface: the rest AWS rervices</li><li>only used within your VPC</li></ul><h2 id="site-to-site-vpn-and-direct-connect"><a class="markdownIt-Anchor" href="#site-to-site-vpn-and-direct-connect"></a> Site to site VPN and Direct connect</h2><ul><li>site to site VPN<ul><li>connect an on premises VPN to AWS</li><li>the connection is automatically encrypted</li><li>goes over the public internet</li></ul></li><li>direct connect<ul><li>establish a physical connection between on premises and AWS</li><li>the connection is private, secure, and fast</li><li>goes over a private network</li><li>takes at least a month to establish</li></ul></li><li>NOTE: site to site VPN and direct connect cannot access VPC endpoints</li></ul><h1 id="s3"><a class="markdownIt-Anchor" href="#s3"></a> S3</h1><h2 id="buckets"><a class="markdownIt-Anchor" href="#buckets"></a> buckets</h2><ul><li>S3 allows people to store objects in buckets</li><li>buckets must have a globally unique name</li><li>buckets are defined at the region level</li></ul><h2 id="objects"><a class="markdownIt-Anchor" href="#objects"></a> objects</h2><ul><li>objects have a key</li><li>the key is the FULL path</li><li>the key is composed of prefix + object name</li><li>there is no concept of directories within buckets</li><li>just keys with very long names that contain slashes</li><li>object values are the content of the body<ul><li>max object size is 5TB</li><li>if uploading more than 5GB, must use multi-part upload</li></ul></li><li>metadata (list of text key / value pairs - system or user metadata)</li><li>tags (unicode key / value pair, up to 10) - useful for security / lifecycle</li><li>version ID (if versioning is enabled)</li></ul><h2 id="versioning"><a class="markdownIt-Anchor" href="#versioning"></a> versioning</h2><ul><li>you can version your files in S3</li><li>it is enabled at the bucket level</li><li>same key overwrite will increment the version: 1,2,3…</li><li>it is best practice to version your buckets<ul><li>protect against unintended deletes</li><li>easy roll back to previous version</li></ul></li><li>note:<ul><li>any file that is not versioned prior to enabling versioning will have version null</li><li>suspending versioning does not delete the previous versions</li></ul></li></ul><h2 id="encryption-for-objects"><a class="markdownIt-Anchor" href="#encryption-for-objects"></a> Encryption for objects</h2><h3 id="sse-s3"><a class="markdownIt-Anchor" href="#sse-s3"></a> SSE-S3</h3><ul><li>encryption using keys handled and managed by S3</li><li>object is encrypted server side</li><li>AES-256 encryption type</li></ul><h3 id="sse-kms"><a class="markdownIt-Anchor" href="#sse-kms"></a> SSE-KMS</h3><ul><li>encryption using keys handled and managed by KMS</li><li>KMS advantages: user control + audit trail</li><li>object is encrypted server side</li></ul><h3 id="sse-c"><a class="markdownIt-Anchor" href="#sse-c"></a> SSE-C</h3><ul><li>server side encryption using data keys fully managed by the customer outside of AWS</li><li>S3 does not store the encryption key you provide</li><li>HTTPS must be used, because you need to send the encryption key in the header</li><li>encryption key must be provided in HTTP headers, for every HTTP request made</li></ul><h3 id="client-side-encryption"><a class="markdownIt-Anchor" href="#client-side-encryption"></a> client side encryption</h3><ul><li>client library such as the Amazon S3 encryption client</li><li>clients must encrypt data themselves before sending to S3</li><li>clients must decrypt the data themselves when retrieving from S3</li><li>customer fully manages the keys and encryption cycle</li></ul><h3 id="encryption-in-transit-ssltls"><a class="markdownIt-Anchor" href="#encryption-in-transit-ssltls"></a> Encryption in transit (SSL/TLS)</h3><ul><li>Amazon S3 exposes<ul><li>HTTP endpoint: non encrypted</li><li>HTTPS endpoint: encryption in flight</li></ul></li><li>you are free to use the endpoint you want, but HTTPS is recommended</li><li>most clients would use the HTTPS endpoint by default</li><li>HTTPS is mandatory for SSE-C</li></ul><h2 id="security"><a class="markdownIt-Anchor" href="#security"></a> security</h2><ul><li>user based<ul><li>IAM policies - which API calls should be allowed for a specific user from IAM console</li></ul></li><li>resource based<ul><li>bucket policies - bucket wide rules from the S3 console - allows cross account</li><li>object ACL - finer grain</li><li>bucket ACL - less common</li></ul></li><li>NOTE: an IAM principal can access an S3 object if<ul><li>the user IAM permissions allow it OR the resource policy alloow it</li><li>AND there is no explicit DENY</li></ul></li></ul><h3 id="bucket-settings-for-block-public-access"><a class="markdownIt-Anchor" href="#bucket-settings-for-block-public-access"></a> bucket settings for block public access</h3><ul><li>block public access to buckets and objects granted through<ul><li>new access control lists</li><li>any access control lists</li><li>new public bucket or access point policies</li><li>block public and cross account access to buckets and objects through any public bucket or access point policies</li></ul></li><li>these settings were created to prevent company data leaks</li><li>if you know your bucket should never be public, leave these on</li><li>can be set at the account level</li></ul><h3 id="others"><a class="markdownIt-Anchor" href="#others"></a> others</h3><ul><li>networking<ul><li>supports VPC endpoints (for instances in VPC without www internet)</li></ul></li><li>logging and audit<ul><li>S3 access logs can be stored in other S3 buckets</li><li>API calls can be logged in AWS cloudtrail</li></ul></li><li>user security<ul><li>MFA delete: MFA can be required in versioned buckets to delete objects</li><li>pre-signed URLs: URLs that are valid for a limited time (premium videos service for logged in users)</li></ul></li></ul><h2 id="cors"><a class="markdownIt-Anchor" href="#cors"></a> CORS</h2><ul><li>an origin is a scheme, host, and port</li><li>CORS means cross origin resource sharing</li><li>web browser based mechanism to allow requests to other origins while visiting the main origin</li><li>the requests won’t be fulfilled unless the other origin allows for the requests, using CORS headers</li><li>if a client does a cross origin request on our S3 bucket, we need to enable the correct CORS headers</li><li>you can allow for a specific origin or for * (for all origins)</li></ul><h2 id="consistency-model"><a class="markdownIt-Anchor" href="#consistency-model"></a> consistency model</h2><ul><li>strong consistency as of Dec 2020</li></ul><h1 id="aws-cli-sdk-iam-roles-and-policies"><a class="markdownIt-Anchor" href="#aws-cli-sdk-iam-roles-and-policies"></a> AWS CLI, SDK, IAM Roles and policies</h1><ul><li>AWS CLI Dry run<ul><li>tells you if your command would have succeed or not without actually executing it</li></ul></li><li>AWS CLI STS decode erros<ul><li>decode API error messgaes using the STS command line</li></ul></li></ul><h2 id="aws-ec2-instance-metadata"><a class="markdownIt-Anchor" href="#aws-ec2-instance-metadata"></a> AWS EC2 instance metadata</h2><ul><li>it allows AWS EC2 instance to learn about themselves without using an IAM role for that purpose</li><li>the URL is <a href="http://169.254.169.254/latest/meta-data/">http://169.254.169.254/latest/meta-data/</a></li><li>you can retrieve the IAM role name from the metadata, but you cannot retrieve the IAM policy</li><li>metadata = info about the EC2 instance</li><li>user data = launch script of the EC2 instance</li></ul><h2 id="mfa-with-cli"><a class="markdownIt-Anchor" href="#mfa-with-cli"></a> MFA with CLI</h2><ul><li>to use MFA with the CLI, you must create a temporary session</li><li>to do so, you must run the STS GetSessionToken API call</li></ul><h2 id="aws-sdk"><a class="markdownIt-Anchor" href="#aws-sdk"></a> AWS SDK</h2><ul><li>what if you want to perform actions on AWS directly from your applications code?</li><li>you can use an SDK</li><li>we have to use the AWS SDK when coding against AWS services such as DynamoDB</li><li>if you don’t specify or configure a default region, then us-east-1 will be chosen by default</li></ul><h2 id="aws-limit"><a class="markdownIt-Anchor" href="#aws-limit"></a> AWS limit</h2><ul><li>API rate limits<ul><li>DescribeInstances API for EC2 has a limit of 100 calls per seconds</li><li>GetObject on S3 has a limit of 5500 GET per second per prefix</li><li>for intermittent errors: implement <code>exponential backoff</code></li><li>for consistent errors: request an API throttling limit increase</li></ul></li><li>service quotas<ul><li>running on-demand standard instances: 1152 vCPU</li><li>you can request a service limit increase by opening a ticket</li><li>you can request a service quota increase by using the service quotas API</li></ul></li></ul><h3 id="exponential-backoff"><a class="markdownIt-Anchor" href="#exponential-backoff"></a> Exponential Backoff</h3><ul><li>if you get ThrottlingException intermittently, use exponential backoff</li><li>retry mechanism already included in AWS SDK API calls</li><li>must implement yourself if using the AWS API as-is or in specific cases<ul><li>must only implement the retries on 5xx server errors and throttling</li><li>do not implement on the 4xx client errors</li></ul></li></ul><h2 id="aws-cli-credentials-provider-chain"><a class="markdownIt-Anchor" href="#aws-cli-credentials-provider-chain"></a> AWS CLI credentials provider chain</h2><ul><li>the CLI will look for credentials in this order</li></ul><ol><li>command line options</li><li>environment variables</li><li>CLI credentials file</li><li>CLI configuration file</li><li>container credentials</li><li>instance profile credentials</li></ol><h2 id="aws-sdk-default-credentials-provider-chain"><a class="markdownIt-Anchor" href="#aws-sdk-default-credentials-provider-chain"></a> AWS SDK default credentials provider chain</h2><ul><li>the java SDK will look for credentials in this order</li></ul><ol><li>java system properties</li><li>environment variables</li><li>the default credential profiles file</li><li>Amazon ECS container credentials</li><li>instance profile credentials</li></ol><h3 id="credentials-scenario"><a class="markdownIt-Anchor" href="#credentials-scenario"></a> Credentials Scenario</h3><ul><li><p>an application deployed on an EC2 instance is using environment variables with credentials from an IAM user to call the Amazon S3 API</p></li><li><p>The IAM user has S3FullAccess permissions</p></li><li><p>the application only uses one S3 bucket, so according to best practices</p><ul><li>an IAM role and EC2 instance profile was created for the EC2 instance</li><li>the role was assigned the minimum permissions to access that one S3 bucket</li></ul></li><li><p>the IAM instance profile was assigned to the EC2 instance, but it still had access to all S3 buckets, why?</p></li><li><p>the credentials provider chain is still giving priorities to the environment variables</p></li></ul><h3 id="credentials-best-practice"><a class="markdownIt-Anchor" href="#credentials-best-practice"></a> credentials best practice</h3><ul><li>never store AWS credentials in your code</li><li>best practice is for credentials to be inherited from the credentials chain</li><li>if working within AWS, use IAM roles<ul><li>EC2 instance roles for EC2 instances</li><li>ECS roles for ECS tasks</li><li>lambda roles for lambda functions</li></ul></li><li>if working outside AWS, use environment variables / named profiles</li></ul><h2 id="signing-aws-api-requests"><a class="markdownIt-Anchor" href="#signing-aws-api-requests"></a> signing AWS API requests</h2><ul><li>when you call the AWS HTTP API, you sign the request so that AWS can identify you, using your AWS credentials (access key and secret key)</li><li>note: some requests to Amazon S3 don’t need to be signed</li><li>if you use the SDK or CLI, the HTTP requests are signed for you</li><li>you should sign an AWS HTTP request using Signature v4 (SigV4)</li></ul><h3 id="sigv4-options"><a class="markdownIt-Anchor" href="#sigv4-options"></a> sigV4 options</h3><ul><li>HTTP header</li><li>query string in URL</li></ul><h1 id="s3-and-athena-advanced"><a class="markdownIt-Anchor" href="#s3-and-athena-advanced"></a> S3 and Athena Advanced</h1><h2 id="s3-mfa-delete"><a class="markdownIt-Anchor" href="#s3-mfa-delete"></a> S3 MFA delete</h2><ul><li>MFA forces user to generate a code on a device before doing important operations on S3</li><li>to use MFA delete, we need to enable versioning on the S3 bucket</li><li>you will need MFA to<ul><li>permanently delete an object version</li><li>suspend versioning on the bucket</li></ul></li><li>you won’t need MFA for<ul><li>enabling versioning</li><li>listing deleted versions</li></ul></li><li>only the bucket owner can enable / disable MFA delete</li><li>MFA delete can only be enabled using the CLI</li></ul><h2 id="s3-default-encryption-vs-bucket-policies"><a class="markdownIt-Anchor" href="#s3-default-encryption-vs-bucket-policies"></a> S3 default encryption vs bucket policies</h2><ul><li>one way to force encryption is to use a bucket policy and refuse any API call to PUT an S3 object without encryption headers</li><li>another way is to use the default encryption option in S3</li><li>note: bucket policies are evaluated before default encryption</li></ul><h2 id="s3-access-logs"><a class="markdownIt-Anchor" href="#s3-access-logs"></a> S3 access logs</h2><ul><li>for audit purpose, you may want to log all access to S3 buckets</li><li>any request made to S3, from any account, authorized or denied, will be logged into another S3 bucket</li><li>that data can be analyzed using data analysis tools…</li><li>or Amazon Athena</li><li>do not set your logging bucket to be the monitored bucket</li><li>it will create a logging loop, and your bucket will grow in size exponentially</li></ul><h2 id="s3-replication-crr-or-srr"><a class="markdownIt-Anchor" href="#s3-replication-crr-or-srr"></a> S3 replication (CRR or SRR)</h2><ul><li><p>must enable versioning in source and destination</p></li><li><p>cross region replication - CRR</p></li><li><p>same region replication - SRR</p></li><li><p>buckets can be in different accounts</p></li><li><p>copying is asynchronous</p></li><li><p>must give proper IAM permissions to S3</p></li><li><p>CRR use cases: compliance, lower latency access for users in another region, replicatioin across accounts</p></li><li><p>SRR use cases: log aggregation, live replication between production and test accounts</p></li><li><p>after activating, only new objects are replicated (not retroactive), existing objects will not be replicated</p></li><li><p>for DELETE operations</p><ul><li>can replicate delete markers from source to target (optional setting)</li><li>deletions with a version ID are not replicated (to avoid malicious deletes), it means if you delete an object using its version ID, this operation will not be replicated</li></ul></li><li><p>there is no chaining of replication</p><ul><li>if bucket 1 has replication into bucket 2, which has replication into bucket 3</li><li>then objects created in bucket 1 are not replicated to bucket 3</li></ul></li></ul><h2 id="s3-pre-signed-urls"><a class="markdownIt-Anchor" href="#s3-pre-signed-urls"></a> S3 pre signed URLs</h2><ul><li>can generate per signed URLs using SDK or CLI<ul><li>for downloads (easy, can use the CLI)</li><li>for uploads (harder, must use the SDK)</li></ul></li><li>valid for a default of 3600 seconds, can change timeout with <code>--expires-in [TIME_BY_SECONDS]</code> argument</li><li>users given a pre signed URL inherit the permissions of the person who generated the URL for GET / PUT</li><li>examples<ul><li>allow only logged in users to download a permium video on your S3 buckets</li><li>allow an ever changing list of users to download files by generating URLs dynamically</li><li>allow temporarily a user to upload a file to a precise location in our bucket</li></ul></li></ul><h2 id="amazon-glacier-and-glacier-deep-archive"><a class="markdownIt-Anchor" href="#amazon-glacier-and-glacier-deep-archive"></a> Amazon Glacier and Glacier Deep Archive</h2><ul><li>Amazon Glacier - 3 retrival options<ul><li>expedited - 1 to 5 mins</li><li>standard - 3 to 5 hours</li><li>bulk - 5 to 12 hours</li><li>minimum storage duration of 90 days</li></ul></li><li>Amazon Glacier Deep Archive - for long term storage - cheaper<ul><li>standard - 12 hours</li><li>bulk - 48 hours</li><li>minimum storage duration of 180 days</li></ul></li></ul><h2 id="s3-lifecycle-rules"><a class="markdownIt-Anchor" href="#s3-lifecycle-rules"></a> S3 lifecycle rules</h2><ul><li>transition actions: it defines when objects are transitioned to another storage class<ul><li>move objects to standard IA class 60 days after creation</li><li>move to Glacier for archiving after 6 months</li></ul></li><li>expiration actions: configure objects to expire (delete) after some time<ul><li>access log files can be set to delete after a year</li><li>can be used to delete old versions of files (if versioning is enabled)</li><li>can be used to delete incomplete multi part uploads</li></ul></li><li>rules can be created for a certain prefix</li><li>rules can be created for certain object tags</li></ul><h2 id="s3-performance"><a class="markdownIt-Anchor" href="#s3-performance"></a> S3 performance</h2><ul><li>Amazon S3 automatically scales to high request rates, latency 100-200ms</li><li>your application can achieve at least 3500 PUT/COPY/POST/DELETE and 5500 GET/HEAD requests per second per prefix in a bucket</li><li>there are no limits to the number of prefixes (prefix is a folder in S3) in a bucket</li></ul><h3 id="kms-limitation"><a class="markdownIt-Anchor" href="#kms-limitation"></a> KMS limitation</h3><ul><li>if you SSE-KMS, S3 performance may be impacted by the KMS limits</li><li>when you upload, it calls the GenerateDataKey KMS API</li><li>when you download it, it calls the Decrypt KMS API</li><li>count towards the KMS quota per second (5500, 10000, 30000 based on region)</li><li>you can request a quota increase using the service quotas console</li></ul><h3 id="multi-part-upload"><a class="markdownIt-Anchor" href="#multi-part-upload"></a> multi part upload</h3><ul><li>recommended for files &gt; 100MB, must be used for files &gt; 5GB</li><li>can help parallelize uploads (speed up transfers)</li></ul><h3 id="s3-transfer-acceleration"><a class="markdownIt-Anchor" href="#s3-transfer-acceleration"></a> S3 transfer acceleration</h3><ul><li>increase transfer speed by transferring file to an AWS edge location which will forward the data to the S3 bucket in the target region</li><li>compatible with multi part upload</li></ul><h3 id="s3-byte-range-fetches"><a class="markdownIt-Anchor" href="#s3-byte-range-fetches"></a> S3 byte range fetches</h3><ul><li>parallelize GETs by requesting specific byte ranges</li><li>better resilience in case of failures</li><li>can be used to speed up downloads</li><li>can be used to retrieve only partial data (for example the head of a file)</li></ul><h2 id="s3-select-and-glacier-select"><a class="markdownIt-Anchor" href="#s3-select-and-glacier-select"></a> S3 select and Glacier select</h2><ul><li>retrieve less data using SQL by performing servide side filtering</li><li>can filter by rows and columns (complex query not supported)</li><li>less network transfer, less CPU cost client side</li></ul><h2 id="s3-event-notifications"><a class="markdownIt-Anchor" href="#s3-event-notifications"></a> S3 event notifications</h2><ul><li>use case: generate thumbnails of images uploaded to S3</li><li>can create as many S3 events as desired</li><li>S3 event notifications typically deliver events in seconds but can sometimes take a minute or longer</li><li>it two writes are made to a single non-versioned object at the same time, it is possible that only a single event notification will be sent</li><li>if you want to ensure that an event notification is sent for every successful write, you can enable versioning on your bucket</li><li>compared to CloudWatch event or EventBridge, S3 event notifications have lower latency and lower costs, it works better with S3</li></ul><h1 id="aws-athena"><a class="markdownIt-Anchor" href="#aws-athena"></a> AWS Athena</h1><ul><li>serverless service to perform analytics directly against S3 files</li><li>uses SQL language to query the files</li><li>has a JDBC / ODBC driver</li><li>charged per query and amount of data scanned</li><li>supports CSV, JSON, ORC, Avro and Parquet (built on Presto)</li><li>use cases: business intelligence, analytics, reporting, analyze and query, VPC flow logs, ELB logs, CloudTrail trails, etc…</li><li>exam tip: analyze data directly on S3 =&gt; use Athena</li></ul><h1 id="aws-cloudfront"><a class="markdownIt-Anchor" href="#aws-cloudfront"></a> AWS CloudFront</h1><ul><li>CDN</li><li>improves read performance, content is cached at the edge</li><li>216 point of presence globally (edge locations)</li><li>DDoS protection, integration, with Shield, AWS WAF</li><li>can expose external HTTPS and can talk to internal HTTPS backends</li></ul><h2 id="origins"><a class="markdownIt-Anchor" href="#origins"></a> Origins</h2><ul><li>S3 bucket<ul><li>for distributing files and caching them at the edge</li><li>enhanced security with CloudFront OAI</li><li>CloudFront can be used as ingress (to upload files to S3)</li></ul></li><li>Custom Origin (HTTP)<ul><li>ALB</li><li>EC2 instance</li><li>S3 website (must first enable the bucket as a static S3 website)</li><li>any HTTP backend you want</li></ul></li></ul><h2 id="cloudfront-geo-restriction"><a class="markdownIt-Anchor" href="#cloudfront-geo-restriction"></a> CloudFront Geo Restriction</h2><ul><li>you can restrict who can access your distribution<ul><li>whitelist: allow your users to access your content only if they are in one of the countries on a list of approved countries</li><li>blacklist: prevent your users from accessing your content if they are in one of the countries on a blacklist of banned countries</li></ul></li><li>the country is determined using a third party geo IP database</li><li>use case: copyright laws to control access to content</li></ul><h2 id="cloudfront-vs-s3-crr"><a class="markdownIt-Anchor" href="#cloudfront-vs-s3-crr"></a> CloudFront vs S3 CRR</h2><ul><li>CloudFront<ul><li>global edge network</li><li>files are cached for a TTL</li><li>great for static content that must be available everywhere</li></ul></li><li>S3 CRR<ul><li>must be setup for each region you want to replication to happen</li><li>files are updated in near real time</li><li>read only</li><li>great for dynamic content that needs to be available at low latency in few regions</li></ul></li></ul><h2 id="cloudfront-caching"><a class="markdownIt-Anchor" href="#cloudfront-caching"></a> CloudFront caching</h2><ul><li>cache based on<ul><li>headers</li><li>session cookies</li><li>query string parameters</li></ul></li><li>the cache lives at each CloudFront edge location</li><li>you want to maximize the cache hit rate to minimize request on the origin</li><li>control the TTL, can be set by the origin usign the cache-control header, expires header…</li><li>you can invalidate part of the cache using the CreateInvalidation API</li></ul><h2 id="cloudfront-signed-url-signed-cookies"><a class="markdownIt-Anchor" href="#cloudfront-signed-url-signed-cookies"></a> CloudFront signed URL / signed cookies</h2><ul><li>you want to distrbute paid shared content to premium users over the world</li><li>we can use CloudFront signed URL / signed cookie, we attach a policy with<ul><li>includes URL expiration</li><li>includes IP ranges to access the data from</li><li>trusted signers (which AWS accounts can create signed URLs)</li></ul></li><li>how long should the URL be valid for<ul><li>shared content (movie, music): make it short (a few minutes)</li><li>private content (private to the user): you can make it for years</li></ul></li><li>signed URL: access to individual files (one signed URL per file)</li><li>signed cookies: access to multiple files (one signed cookie for many files)</li></ul><h2 id="cloudfront-signed-url-vs-s3-pre-signed-url"><a class="markdownIt-Anchor" href="#cloudfront-signed-url-vs-s3-pre-signed-url"></a> CloudFront signed URL vs S3 pre signed URL</h2><h3 id="signed-url"><a class="markdownIt-Anchor" href="#signed-url"></a> Signed URL</h3><ul><li>allow access to a path, no matter the origin</li><li>account wide key pair, only the root can manage it</li><li>can filter by IP, path, date, expiration</li><li>can leverage caching features</li></ul><h3 id="s3-pre-signed-url"><a class="markdownIt-Anchor" href="#s3-pre-signed-url"></a> S3 pre signed URL</h3><ul><li>issue a request as the person who pre signed the URL</li><li>uses the IAM key of the signing IAM principal (has the same access as the IAM user who create the URL)</li><li>limited lifetime</li></ul><h2 id="cloudfront-signed-url-process"><a class="markdownIt-Anchor" href="#cloudfront-signed-url-process"></a> CloudFront signed URL process</h2><ul><li>two types of signers<ul><li>either a trusted key group (recommended)<ul><li>can leverage APIs to create and rotate keys (and IAM for API security)</li></ul></li><li>an AWS account that contains a CloudFront key pair<ul><li>need to manage keys using the root account and the AWS console</li><li>not recommended because you shouldn’t use the root account for this</li></ul></li></ul></li><li>in your CloudFront distribution, create one or more trusted key groups</li><li>you generate your own public / private key<ul><li>the private key is used by your applications to sign URLs</li><li>the public key is used by cloudfront to verify URLs</li></ul></li></ul><h2 id="price-classes"><a class="markdownIt-Anchor" href="#price-classes"></a> Price classes</h2><ul><li>you can reduce the number of edge locations for cost reduction</li><li>three price classes<ul><li>price class All: all regions - best performance</li><li>price class 200: most regions, but excludes the most expensive regions</li><li>price class 100: only the least expensive regions</li></ul></li></ul><h2 id="multiple-origin"><a class="markdownIt-Anchor" href="#multiple-origin"></a> Multiple origin</h2><ul><li>to route to different kind of origins based on the content type</li><li>based on path pattern<ul><li>/images/*</li><li>/api/*</li><li>/*</li></ul></li></ul><h2 id="origin-groups"><a class="markdownIt-Anchor" href="#origin-groups"></a> origin groups</h2><ul><li>to increase high availability and do failover</li><li>origin group: one primary and one secondary origin</li><li>if the primary origin fails, the second one is used (works for both EC2 instance and S3 buckets)</li></ul><h2 id="field-level-encryption"><a class="markdownIt-Anchor" href="#field-level-encryption"></a> field level encryption</h2><ul><li>protect user sensitive information throught application stack</li><li>adds an additional layer of security along with HTTPS</li><li>sensitive information encrypted at the edge close to user</li><li>uses asymmetric encryption</li><li>usage:<ul><li>specify set of fields in POST request that you want to be encrypted (up to 10 fields)</li><li>specify the public key to encrypt them</li><li>fields will be encrypted using the public key at edge locations and will be decrypted when the request reached the web servers</li></ul></li></ul><h1 id="ecs"><a class="markdownIt-Anchor" href="#ecs"></a> ECS</h1><h2 id="docker"><a class="markdownIt-Anchor" href="#docker"></a> Docker</h2><ul><li><p>Docker is a software development platform to deploy apps</p></li><li><p>apps are packaged in containers that can be run on any OS</p></li><li><p>apps run the same, regardless of where they are run</p><ul><li>any machine</li><li>no compatibility issues</li><li>predictable behavior</li><li>less work</li><li>easier to maintain and deploy</li><li>works with any language, any OS, any technology</li></ul></li><li><p>Docker images are stored in Docker repositories</p></li><li><p>public: Docker hub</p></li><li><p>private: Amazon ECR</p></li><li><p>Docker vs VM</p><ul><li>docker is sort of a virtualization technology, but not exactly</li><li>resources are shared with the host =&gt; many containers on one server</li></ul></li><li><p>Docker containers management</p><ul><li>to manage containers, we need a container management platform</li><li>3 choices</li><li>ECS: Amazon’s own platform</li><li>Fargate: Amazon’s own serverless platform</li><li>EKS: Amazon’s managed Kubernates (open source)</li></ul></li></ul><h2 id="ecs-clusters-overview"><a class="markdownIt-Anchor" href="#ecs-clusters-overview"></a> ECS clusters overview</h2><ul><li>ECS clusters are logical grouping of EC2 instances</li><li>EC2 instances run the ECS agent (Docker container)</li><li>the ECS agents registers the instance to the ECS cluster</li><li>the EC2 instances run a special AMI, made specifically for ECS</li></ul><h2 id="ecs-task-definitions"><a class="markdownIt-Anchor" href="#ecs-task-definitions"></a> ECS task definitions</h2><ul><li>tasks definintions are metadata in JSON form to tell ECS how to run a Docker Container</li><li>it contains crucial information around<ul><li>Image name</li><li>port binding for container and host (80 -&gt; 8080)</li><li>memory and CPU required</li><li>environment variables</li><li>networking information</li></ul></li></ul><h2 id="ecs-service"><a class="markdownIt-Anchor" href="#ecs-service"></a> ECS service</h2><ul><li>ECS service help define how many tasks should run and how they should be run</li><li>they ensure that the number of tasks desired is running across our fleet of EC2 instances</li><li>they can be linked to ELB / NLB / ALB if needed</li></ul><h2 id="ecs-service-with-load-balancer"><a class="markdownIt-Anchor" href="#ecs-service-with-load-balancer"></a> ECS service with load balancer</h2><ul><li>ALB has the dynamic port forwarding feature</li><li>when you create ECS tasks it assign random port numbers to tasks</li><li>multiple ECS tasks can be run on a single EC2 instances with different port numbers</li><li>ALB can use the dynamic port forwarding feature to route traffic to these tasks based on their port number</li></ul><h2 id="ecr"><a class="markdownIt-Anchor" href="#ecr"></a> ECR</h2><ul><li>ECR is a private Docker image reporsitory</li><li>access is controlled through IAM (if you have permission errors, check the policy)</li></ul><h3 id="how-to-login-to-ecr-using-aws-cli"><a class="markdownIt-Anchor" href="#how-to-login-to-ecr-using-aws-cli"></a> how to login to ECR using AWS CLI</h3><ul><li>if you have AWS CLI version 1<ul><li><code>$(aws ecr get-login --no-include-email --region eu-west-1)</code></li><li>then you need to execute the output of the above command</li></ul></li><li>if you have AWS CLI version 2<ul><li><code>aws ecr get-login-password --region eu-west-1 | docker login --username AWS --password-stdin 12334556790.dkr.ecr.eu-west-1.amazonaws.com</code></li><li>you could just execute the above command which is using the pipe feature</li></ul></li><li>Docker push and pull</li></ul><h2 id="fargate"><a class="markdownIt-Anchor" href="#fargate"></a> Fargate</h2><ul><li>when launching an ECS cluster, we have to create our EC2 instances</li><li>if we need to scale, we need to add EC2 instances</li><li>so we need to manage infrastructure…</li><li>with Fargate, it is all serverless</li><li>we don’t provision EC2 instances</li><li>we just create task definitions, and AWS will run our containers for us</li></ul><h2 id="ecs-iam-roles-deep-dive"><a class="markdownIt-Anchor" href="#ecs-iam-roles-deep-dive"></a> ECS IAM roles deep dive</h2><ul><li>EC2 instance profile<ul><li>for EC2 instance to run ECS task, we need to install ECS agent on the EC2 instance</li><li>ECS will do these things</li><li>make API calls to ECS service</li><li>send container logs to CloudWatch logs</li><li>pull docker image from ECR</li><li>so ECS agent will use the EC2 instance profile role to do these things</li></ul></li><li>ECS task role<ul><li>when we run ECS tasks on EC2 instance, each task will have its own role</li><li>we use different roles for the different ECS services run</li><li>task role in defined in the task definition</li></ul></li></ul><h2 id="ecs-tasks-placement"><a class="markdownIt-Anchor" href="#ecs-tasks-placement"></a> ECS tasks placement</h2><ul><li>when a task of type EC2 is launched, ECS must determine where to place it, with the constraints of CPU, memory, and available port</li><li>similarly, when a service scales in, ECS needs to determine which task to terminate</li><li>to assist with this, you can define a task placement strategy and task placement constraints</li><li>NOTE: this is only for ECS with EC2, not for Fargate</li></ul><h3 id="ecs-task-placement-process"><a class="markdownIt-Anchor" href="#ecs-task-placement-process"></a> ECS task placement process</h3><ul><li>task placement strategies are a best effort</li><li>when Amazon ECS places tasks, it uses the following process to select container instances</li></ul><ol><li>identify the instances that satisfy the CPU, memory, and port requirements in the task definition</li><li>identify the instances that satisfy the task placement constraints</li><li>identify the instances that satisfy the placement strategies</li></ol><h3 id="ecs-task-placement-strategies"><a class="markdownIt-Anchor" href="#ecs-task-placement-strategies"></a> ECS task placement strategies</h3><ul><li>Binpack<ul><li>place tasks based on the least available amount of CPU or memory</li><li>this minimize the number of instances in use (cost savings)</li></ul></li><li>random<ul><li>place the task randomly</li></ul></li><li>spread<ul><li>place the task evenly based on the specified value</li><li>example: instanceID, availability zone</li></ul></li><li>you can also mix the placement strategies together, e.g. use Spread for the AZ and Binpack for memory</li></ul><h3 id="ecs-task-placement-constraints"><a class="markdownIt-Anchor" href="#ecs-task-placement-constraints"></a> ECS task placement constraints</h3><ul><li>distinctInstance: place each task on a different container instance</li><li>memberOf: places task on instances that satisfy an expression<ul><li>uses the Cluster Query language</li><li>e.g. place tasks only on t2 instances</li></ul></li></ul><h2 id="ecs-service-auto-scaling"><a class="markdownIt-Anchor" href="#ecs-service-auto-scaling"></a> ECS service auto scaling</h2><ul><li>CPU and RAM is tracked in CloudWatch at the ECS service level</li><li>target tracking: target a specific average CloudWatch metric</li><li>step scaling: scale based on CloudWatch alarms</li><li>scheduled scaling: based on predictable changes</li><li>ECS service scaling (task level) != EC2 auto scaling (instance level)</li><li>Fargate auto scaling is much easier to setup (because of serverless)</li></ul><h2 id="ecs-cluster-capacity-provider"><a class="markdownIt-Anchor" href="#ecs-cluster-capacity-provider"></a> ECS cluster capacity provider</h2><ul><li>a capacity provider is used in association with a cluster to determine the infrastructure that a task runs on<ul><li>for ECS and Fargate users, the FARGATE and FARGATE_SPOT capacity providers are added automatically</li><li>for Amazon ECS on EC2, you need to associate the capacity provider with an auto scaling group</li></ul></li><li>when you run a task or a service, you define a capacity provider strategy, to prioritize in which provider to run</li><li>this allows the capacity provider to automatically provision infrastructure for you</li><li>if you set the average CPU to be at most 70%, then cluster capacity provider will create a new EC2 instance for you when you create a new task to run</li></ul><h2 id="ecs-data-volumes"><a class="markdownIt-Anchor" href="#ecs-data-volumes"></a> ECS data volumes</h2><h3 id="ec2-task-strategies"><a class="markdownIt-Anchor" href="#ec2-task-strategies"></a> EC2 task strategies</h3><ul><li>the EBS volume is already mounted onto the EC2 instances</li><li>this allows your Docker containers to mount the EBS volume and extend the storage capacity of your task</li><li>Problem: if your task moves from one EC2 instance to another one, it won’t be the same EBS volume and data, because EBS volume is mounted to the old EC2 instance</li><li>use cases:<ul><li>mount a data volume between different containers on the same instance</li><li>extend the temporary storage of a task</li></ul></li></ul><h3 id="efs-file-systems"><a class="markdownIt-Anchor" href="#efs-file-systems"></a> EFS file systems</h3><ul><li>works for both EC2 tasks and Fargate tasks</li><li>ability to mount EFS volumes onto tasks</li><li>tasks launched in any AZ will be able to share the same data in the EFS volume</li><li>Fargate + EFS = serverless + data storage without managing servers</li><li>use case: persistent multi AZ shared storage for your containers</li></ul><h3 id="bind-mounts-sharing-data-between-containers"><a class="markdownIt-Anchor" href="#bind-mounts-sharing-data-between-containers"></a> Bind Mounts sharing data between containers</h3><ul><li>works for both EC2 tasks (using local EC2 instance storage) and Fargate tasks (get 4GB for volume mounts)</li><li>useful to share an ephemeral storage between multiple containers part of the same ECS task</li><li>great for sidecar container pattern where the sidecar can be used to send metrics / logs to other destinations</li></ul><h1 id="beanstalk"><a class="markdownIt-Anchor" href="#beanstalk"></a> Beanstalk</h1><h2 id="developer-problems-on-aws"><a class="markdownIt-Anchor" href="#developer-problems-on-aws"></a> developer problems on AWS</h2><ul><li><p>managing infrastructure</p></li><li><p>deploying code</p></li><li><p>configuring all the databases, load balancers, etc…</p></li><li><p>scaling concerns</p></li><li><p>most web apps have the same architecture (ALB + ASG)</p></li><li><p>all the developers want is for their code to run</p></li><li><p>possibly, consistently across different applications and environments</p></li></ul><h2 id="elastic-beanstalk-overview"><a class="markdownIt-Anchor" href="#elastic-beanstalk-overview"></a> Elastic Beanstalk overview</h2><ul><li>a developer centric view of deploying an application on AWS</li><li>it uses all components’ we have seen before: EC2, ASG, ELB, RDS…</li><li>managed services<ul><li>automatically handles capacity provisioning, load balancing, scaling, application health monitoring, instance configuration…</li><li>just the application code is the responsiblity of the developer</li></ul></li><li>we still have full control over the configuration</li><li>Beanstalk is free but you pay for the underlying instances</li></ul><h2 id="components"><a class="markdownIt-Anchor" href="#components"></a> Components</h2><ul><li><p>application: collection of Elastic Beanstalk components (environments, versions, configurations)</p></li><li><p>application version: an iteration of your application code</p></li><li><p>environment</p><ul><li>collection of AWS resources running an application version (only one application version at a time)</li><li>tiers: web server environment tier and worker environment tier</li><li>you can create multiple environmnets (dev, test, prod…)</li></ul></li><li><p>web environment</p><ul><li>use ELB with multiple EC2 instances running on different AZs and ASG to scale</li></ul></li><li><p>worker environment</p><ul><li>use SQS queue with multiple EC2 instances running on different AZs and ASG will scale based on SQS’s length</li></ul></li></ul><h2 id="beanstalk-deployment-options"><a class="markdownIt-Anchor" href="#beanstalk-deployment-options"></a> Beanstalk deployment options</h2><h3 id="all-at-once"><a class="markdownIt-Anchor" href="#all-at-once"></a> All at once</h3><ul><li>fastest deployment</li><li>application has downtime</li><li>great for quick iterations in development environment</li><li>no additional cost</li></ul><h3 id="rolling"><a class="markdownIt-Anchor" href="#rolling"></a> Rolling</h3><ul><li>application is running below capacity</li><li>can set the bucket size, bucket size is the number of new instances we launched each time</li><li>application is running both versions simultaneously</li><li>no additional cost</li><li>long deployment</li></ul><h3 id="rolling-with-additional-batches"><a class="markdownIt-Anchor" href="#rolling-with-additional-batches"></a> Rolling with additional batches</h3><ul><li>application is running at capacity</li><li>can set the bucket size</li><li>application is running both versions simultaneously</li><li>small additional cost</li><li>additional batch is removed at the end of the deployment</li><li>longer deployment</li><li>good for production environment</li></ul><h3 id="immutable"><a class="markdownIt-Anchor" href="#immutable"></a> Immutable</h3><ul><li>zero downtime</li><li>new code is deployed to new instances on a temporary ASG</li><li>high cost, double capacity</li><li>longest deployment</li><li>quick rollback in case of failures (just terminate new ASG)</li><li>great for production</li></ul><h3 id="blue-green"><a class="markdownIt-Anchor" href="#blue-green"></a> Blue / Green</h3><ul><li>not a direct feature of Elastic Beanstalk</li><li>zero downtime and release facility</li><li>create a new stage environment and deploy version 2 there</li><li>the new environment (green) can be validated independently and roll back if issue happens</li><li>route 53 can be setup using weighted policies to redirect a little bit of traffic to the stage environment</li><li>using Beanstalk, swap URLs when done with the environment test</li></ul><h3 id="traffic-splitting-canary-testing"><a class="markdownIt-Anchor" href="#traffic-splitting-canary-testing"></a> Traffic splitting (Canary Testing)</h3><ul><li>new application version is deployed to a temporary ASG with the same capacity</li><li>a small percetage of traffic is sent to the temporary ASG for a configuraion amount of time</li><li>deployment health is monitored</li><li>if there is a deployment failure, this triggers an automated roll back (very quick)</li><li>no application downtime</li><li>new instances are migrated from the temporary to the original ASG</li><li>old application version is then terminated</li></ul><h3 id="deploy-using-cli"><a class="markdownIt-Anchor" href="#deploy-using-cli"></a> Deploy using CLI</h3><ul><li>describe dependencies</li><li>package code as zip, and describe dependencies</li><li>console: upload zip file  (creates new app version), and then deploy</li><li>CLI: create new app version using CLI (uploads zip), and then deploy</li><li>Elastic Beanstalk will deploy the zip on each EC2 instance, resolve dependencies and start the application</li></ul><h2 id="beanstalk-lifecycle-policy"><a class="markdownIt-Anchor" href="#beanstalk-lifecycle-policy"></a> Beanstalk lifecycle policy</h2><ul><li>Elastic Beanstalk can store at most 1000 application versions</li><li>if you don’t remove old versions, you won’t be able to deploy anymore</li><li>to phase out old application versions, use a lifecycle policy<ul><li>based on time (old versions are removed)</li><li>based on space (when you have too many versions)</li></ul></li><li>versions that are currently used won’t be deleted</li><li>option not to delete the source bundle in S3 to prevent data loss</li></ul><h2 id="beanstalk-extensions"><a class="markdownIt-Anchor" href="#beanstalk-extensions"></a> Beanstalk extensions</h2><ul><li>a zip file containing our code must be deployed to Elastic Beanstalk</li><li>all the parameters set in the UI can be configured with code using files</li><li>requriements<ul><li>in the <code>.ebextensions/</code> directory in the root of source code</li><li>YAML / JSON format</li><li><code>.config</code> extensions (example: <code>logging.config</code>)</li><li>able to modify some default settings using: <code>option_settings</code></li><li>ability to add resources such as RDS, ElastiCache, DynamoDB, etc…</li></ul></li><li>resources managed by <code>.ebextensions</code> get deleted if the environment goes away</li></ul><h2 id="beanstalk-vs-cloudformation"><a class="markdownIt-Anchor" href="#beanstalk-vs-cloudformation"></a> Beanstalk vs CloudFormation</h2><ul><li>under the hood, Elastic Beanstalk relies on CloudFormation</li><li>CloudFormation is used to provision other AWS services</li><li>use case: you can define CloudFormation resources in your <code>.ebextensions</code> to provision ElastiCache, S3 bucket, or anything you want.</li></ul><h2 id="elastic-beanstalk-cloning"><a class="markdownIt-Anchor" href="#elastic-beanstalk-cloning"></a> Elastic Beanstalk cloning</h2><ul><li>clone an environment with the exact same configuration</li><li>useful for deploying a test version of your application</li><li>all resources and configuration are preserved<ul><li>load balancer type and configuration</li><li>RDS database type (but data is not preserved)</li><li>environment variables</li></ul></li><li>after cloning an environment, you can change settings</li></ul><h2 id="beanstalk-migration"><a class="markdownIt-Anchor" href="#beanstalk-migration"></a> Beanstalk migration</h2><h3 id="load-balancer"><a class="markdownIt-Anchor" href="#load-balancer"></a> load balancer</h3><ul><li>after creating an Elastic Beanstalk environmnet, you cannot change the ELB type</li><li>to migrate to a different ELB<ol><li>create a new env with the same configuration except LB, create your new LB here</li><li>deploy your application onto the new env</li><li>perform a CNAME swap or Route 53 update so all your traffic can be direct to the new env</li></ol></li></ul><h3 id="rds-2"><a class="markdownIt-Anchor" href="#rds-2"></a> RDS</h3><ul><li><p>RDS can be provisioned with Beanstalk, which is greate for dev / test</p></li><li><p>this is not great for production as database lifecycle is tied to the Beanstalk environment lifecycle</p></li><li><p>the best for prod is to separately create an RDS database and provide our Beanstalk application with the connection string</p></li><li><p>but what if you have already created Beanstalk application with the RDS in production? How to migrate it to a new environment without RDS?</p></li></ul><ol><li>create a snapshot of RDS DB (as a safeguard)</li><li>go to the RDS console and protect the RDS database from deletion</li><li>create a new environment, without RDS, point your application to the existing RDS in the old env</li><li>perform a CNAME swap or Route 53 update, confirm it is working</li><li>terminate the old env (RDS will not be deleted because you prevent it in the console)</li><li>delete the CloudFormation stack manually (it will be in DELETE_FAILED state because it can’t delete RDS)</li></ol><h2 id="single-docker"><a class="markdownIt-Anchor" href="#single-docker"></a> single Docker</h2><ul><li>run your application as a single Docker container</li><li>either provide<ul><li>Dockerfile: Elastic Beanstalk will build and run the Docker container</li><li>Dockerrun.aws.json (v1): describe where the Docker image is (already built)</li></ul></li><li>Beanstalk in single Docker container does not use ECS</li></ul><h2 id="multi-docker-containers"><a class="markdownIt-Anchor" href="#multi-docker-containers"></a> Multi Docker containers</h2><ul><li>multi docker helps run multiple containers per EC2 instance in EB</li><li>this will create for you<ul><li>ECS cluster</li><li>EC2 instances, configured to use the ECS cluster</li><li>load balancer (in HA mode)</li><li>task definitions and execution</li></ul></li><li>requries a config Dockerrun.aws.json (v2) at the root of the source code</li><li>Dockerrun.aws.json is used to generate the ECS task definition</li></ul><h2 id="elastic-beanstalk-and-https"><a class="markdownIt-Anchor" href="#elastic-beanstalk-and-https"></a> Elastic Beanstalk and HTTPS</h2><ul><li>Beanstalk with HTTPS<ul><li>idea: load the SSL certificate onto the load balancer</li><li>can be done from the console (EB console, load balancer configuration)</li><li>can be done from the code: <code>.ebextensions/securelistener-alb.config</code></li><li>SSL certificate can be provisioned using ACM or CLI</li><li>must configure a security group rule to allow incoming port 443 (HTTPS port)</li></ul></li><li>Beanstalk redirect HTTP to HTTPS<ul><li>configure your instances to redirect HTTP to HTTPS</li><li>configure the application load balancer with a rule</li><li>make sure health checks are not redirected (so they keep giving 200 OK, otherwise they will receive 301 and 302…)</li></ul></li></ul><h2 id="web-server-vs-worker-environment"><a class="markdownIt-Anchor" href="#web-server-vs-worker-environment"></a> Web server vs worker environment</h2><ul><li>if your application performs tasks that are long to complete, offload these tasks to a dedicated worker environment</li><li>decoupling your application into two tiers is common</li><li>example: processing a video, generating a zip file, etc…</li><li>you can define periodic tasks in a file <code>cron.yaml</code></li></ul><h2 id="custom-platform-advanced"><a class="markdownIt-Anchor" href="#custom-platform-advanced"></a> custom platform (advanced)</h2><ul><li>custom platforms are very advanced, they allow to define from scratch<ul><li>the OS</li><li>additional software</li><li>scripts that Beanstalk runs on these platforms</li></ul></li><li>use case: app language is incompatible with Beanstalk and doesn’t use Docker</li><li>to create your own platform<ul><li>define an AMI using Platform.yaml file</li><li>build that platform using the Packer software (open source tool to create AMIs)</li></ul></li><li>custom platform vs Custom image<ul><li>custom image is to tweak an existing Beanstalk platform</li><li>custom platform is to create an entirely new Beanstalk platform</li></ul></li></ul><h1 id="cicd"><a class="markdownIt-Anchor" href="#cicd"></a> CICD</h1><h2 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h2><ul><li>we now know how to create resources in AWS manually</li><li>we know how to interact with AWS CLI</li><li>we have seen how to deploy code to AWS using Elastic Beanstalk</li><li>all these manual steps make it very likely for us to do mistakes</li><li>what we would like is to push our code in a repository and have it deployed onto the AWS<ul><li>automatically</li><li>the right way</li><li>making sure it is tested before deploying</li><li>with possibility to go into different stages</li><li>with manual approval where needed</li></ul></li><li>to be a proper AWS developer, we need to learn AWS CICD</li></ul><h2 id="continuous-integration"><a class="markdownIt-Anchor" href="#continuous-integration"></a> Continuous integration</h2><ul><li>developers push the code to a code repository often (github, codecommit, bitbucket, etc…)</li><li>a testing / build server checks the code as soon as it is pushed (codebuild, Jenkins CI, etc…)</li><li>the developer gets feedback about the tests and checks that have passed / failed</li><li>find bugs early, fix bugs</li><li>deliver faster as the code is tested</li><li>deploy often</li></ul><h2 id="continuous-delivery"><a class="markdownIt-Anchor" href="#continuous-delivery"></a> Continuous delivery</h2><ul><li>ensure that the software can be released reliably whenever needed</li><li>ensures deployments happen often and are quick</li><li>automated deployment</li></ul><h2 id="codecommit"><a class="markdownIt-Anchor" href="#codecommit"></a> CodeCommit</h2><ul><li><p>version control is the ability to understand the various changes that happened to the code over time</p></li><li><p>all these are enabled by using a version control system such as git</p></li><li><p>a git repository can live on one’s machine, but it usually lives on a central online repository</p></li><li><p>benefits are</p><ul><li>collaborate with other developers</li><li>make sure the code is backed up somewhere</li><li>make sure it is fully viewable and auditable</li></ul></li><li><p>git repositories can be expensive</p></li><li><p>the industry incldues</p><ul><li>github</li><li>bitbucket</li></ul></li><li><p>AWS CodeCommit</p><ul><li>private git repositories</li><li>no size limit on repositories</li><li>fully managed, HA</li><li>code only in AWS, increased security and compliance</li><li>secure</li><li>integrated with Jenkins / CodeBuild / other CI tools</li></ul></li></ul><h3 id="security-2"><a class="markdownIt-Anchor" href="#security-2"></a> security</h3><ul><li>interactions are done using git</li><li>authentication in git<ul><li>SSH keys: AWS users can configure SSH keys in their IAM console</li><li>HTTPS: done through the AWS CLI Authentication helper ot generating HTTPS credentials</li><li>MFA can be enabled for extra security</li></ul></li><li>Authorization in git<ul><li>IAM policies manage user / roles rights to repositories</li></ul></li><li>encryption<ul><li>repositories are automatically encrypted at rest using KMS</li><li>encrypted in transit (can only use HTTPS and SSH - both secure)</li></ul></li><li>cross account access<ul><li>do not share your SSH keys</li><li>do not share your AWS credentials</li><li>use IAM role in your AWS account and use AWS STS (with AssumeRole API)</li></ul></li></ul><h3 id="codecommit-vs-github"><a class="markdownIt-Anchor" href="#codecommit-vs-github"></a> CodeCommit vs Github</h3><ul><li>Similarities<ul><li>both are git repositories</li><li>both support code review</li><li>github and CodeCommit can be integrated with AWS CodeBuild</li><li>both support HTTPS and SSH method of authentication</li></ul></li><li>differences<ul><li>security<ul><li>github: github users</li><li>codecommit: AWS IAM users / roles</li></ul></li><li>hosted:<ul><li>github: hosted by github</li><li>github enterprise: self hosted on your servers</li><li>codecommit: managed and hosted by AWS</li></ul></li><li>UI<ul><li>github UI is fully featured</li></ul></li></ul></li></ul><h3 id="notifications"><a class="markdownIt-Anchor" href="#notifications"></a> notifications</h3><ul><li>you can trigger notifications in CodeCommit using AWS SNS or AWS lambda or CloudWatch event rules</li><li>use cases for notifications SNS / lambda<ul><li>deletion of branches</li><li>trigger for pushes that happens in master branch</li><li>notify external build system</li><li>trigger AWS lambda function to perform codebase analysis</li></ul></li><li>use cases for CloudWatch event rules<ul><li>trigger for pull request updates</li><li>commit comment event</li><li>CloudWatch event rules goes into an SNS topic</li></ul></li></ul><h2 id="codepipeline"><a class="markdownIt-Anchor" href="#codepipeline"></a> CodePipeline</h2><ul><li>Continuous delivery</li><li>visual workflow</li><li>source: github / codecommit / S3</li><li>build: codebuild / Jenkins</li><li>load testing: third party tools</li><li>deploy: AWS code deploy / Beanstalk / CloudFormation / ECS</li><li>made of stages<ul><li>each stage can have sequential actions or parallel actions</li><li>stages examples: build / test / deploy / load test</li><li>manual approval can be defined at any stage</li></ul></li></ul><h3 id="artifacts"><a class="markdownIt-Anchor" href="#artifacts"></a> artifacts</h3><ul><li>each pipeline stage can create artifacts</li><li>artifacts are passed stored in S3 and passed on to the next stage</li></ul><h3 id="troubleshooting"><a class="markdownIt-Anchor" href="#troubleshooting"></a> troubleshooting</h3><ul><li>codepipeline state changes happen in CloudWatch events, which can in return create SNS notifications<ul><li>you can create events for failed pipelines</li><li>you can create events for cancelled stages</li></ul></li><li>if codepipeline fails a stage, your pipeline stops and you can get information in the console</li><li>CloudTrail can be used to audit AWS API calls</li><li>if pipeline can’t perform an action, make sure the IAM service role attached does have enough permissions</li></ul><h2 id="codebuild"><a class="markdownIt-Anchor" href="#codebuild"></a> CodeBuild</h2><ul><li><p>fully managed build service</p></li><li><p>alternative to other build tools such as Jenkins</p></li><li><p>continuous scaling (no servers to manage or provision - no build queue)</p></li><li><p>pay for usage: the time it takes to complete the builds</p></li><li><p>leverages Docker under the hood for reproducible builds</p></li><li><p>possibility to extend capabilities leveraging our own base Docker images</p></li><li><p>secure: integration with KMS for encryption of build artifacts, IAM for build permissions, and VPC for network security, CloudTrail for API calls logging</p></li><li><p>source code from github / codecommit / codepipeline / S3</p></li><li><p>build instructions can be defined in code (buildspec.yml file)</p></li><li><p>output logs to S3 and AWS cloudwatch logs</p></li><li><p>metrics to monitor codebuild statistics</p></li><li><p>use cloudwatch alarms to detect failed builds and trigger notifications</p></li><li><p>cloudwatch events / lambda as a Glue</p></li><li><p>SNS notifications</p></li><li><p>ability to reproduce codebuild locally to troubleshoot in case of errors</p></li><li><p>builds can be defined within CodePipeline or Codebuild itself</p></li></ul><h3 id="buildspec"><a class="markdownIt-Anchor" href="#buildspec"></a> BuildSpec</h3><ul><li>buildspec.yml file must be at the root of your code</li><li>define environment variables<ul><li>plaintext variables</li><li>secure secrets: use SSM parameter store</li></ul></li><li>phases<ul><li>install: install dependencies you may need for your build</li><li>pre build: final commands to execute before build</li><li>build: actual build commands</li><li>post build: finishing touches (zip output)</li></ul></li><li>artifacts: what to upload to S3</li><li>cache: files to cache to S3 for future build speedup</li></ul><h3 id="local-build"><a class="markdownIt-Anchor" href="#local-build"></a> local build</h3><ul><li>in case of need of deep troubleshooting beyond logs</li><li>you can run CodeBuild on your laptop (after installing Docker)</li><li>for this, leverage CodeBuild agent</li></ul><h3 id="codebuild-in-vpc"><a class="markdownIt-Anchor" href="#codebuild-in-vpc"></a> CodeBuild in VPC</h3><ul><li>by default, your Codebuild containers are launched outside your VPC</li><li>therefore, by default, it cannot access resources in a VPC</li><li>you can specify a VPC configuration<ul><li>VPC ID</li><li>subnet ID</li><li>security group ID</li></ul></li><li>they your build can access resources in your VPC</li><li>use case: integration tests, data query, internal load balancers</li></ul><h2 id="codedeploy"><a class="markdownIt-Anchor" href="#codedeploy"></a> CodeDeploy</h2><ul><li>we want to deploy our application automatically to many EC2 instances</li><li>these instances are not managed by Elastic Beanstalk</li><li>there are several ways to handle deployments using open source tools (Ansible, Terraform, Chef, Pupper, etc…)</li></ul><h3 id="steps"><a class="markdownIt-Anchor" href="#steps"></a> Steps</h3><ul><li>Each EC2 machine (or on premises machine) must be running the CodeDeploy agent</li><li>the agent is continuously polling AWS codeDeploy for work to do</li><li>CodeDeploy sends appspec.yml file</li><li>application is pulled from github or S3</li><li>EC2 will run the deployment instructions</li><li>CodeDeploy agent will report of success / faliure of deployment on the instance</li></ul><h3 id="other-information"><a class="markdownIt-Anchor" href="#other-information"></a> other information</h3><ul><li>EC2 instances are grouped by deployment group (dev / test / prod)</li><li>lots of flexibility to define any kind of deployments</li><li>CodeDeploy can be chained into CodePipeline and use artifacts from there</li><li>CodeDeploy can reuse existing setup tools, works with any application, auto scaling integraion</li><li>Note: Blue / Green only works with EC2 instances (not on premises)</li><li>support for AWS lambda deployments</li><li>CodeDeploy does not provision resources</li></ul><h3 id="primary-components"><a class="markdownIt-Anchor" href="#primary-components"></a> primary components</h3><ul><li>application: unique name</li><li>compute platform: EC2 or on premises or lambda</li><li>deployment configuration: deployment rules for success / failures<ul><li>EC2 or on premises: you can specify the minimum number of healthy instances for the deployment</li><li>lambda: specify how traffic ;is routed to your updated lambda function versions</li></ul></li><li>deployment group: group of tagged instances (allows to deploy gradually)</li><li>deployment type: in place deployment or Blue/Green deployment</li><li>IAM instance profile: need to give EC2 the permissions to pull from S3 / github</li><li>application revision: application code + appspec.yml file</li><li>service role: role for CodeDeploy to perform what it needs</li><li>target revision: target deployment application version</li></ul><h3 id="appspec"><a class="markdownIt-Anchor" href="#appspec"></a> Appspec</h3><ul><li>file section: how to source and copy from S3 / github to filesystem</li><li>hooks: set of instructions to do to deploy the new version (hooks can have timeouts)<ul><li>applicationStop</li><li>DownloadBundle</li><li>BeforeInstall</li><li>AfterInstall</li><li>ApplicationStart</li><li>ValidateService: really important</li></ul></li></ul><h3 id="deployment-config"><a class="markdownIt-Anchor" href="#deployment-config"></a> Deployment config</h3><ul><li>Configs:<ul><li>one a time: one instance at a time, one instance fails =&gt; deployment stops</li><li>half at a time: 50%</li><li>all at once: quick but no healthy host, downtime, good for dev</li><li>custom: min healthy host = 75%</li></ul></li><li>failures:<ul><li>instances stay in failed state</li><li>new deployments will first be deployed to failed state instances</li><li>to rollback: re-deploy old deployment or enable automated rollback for failures</li></ul></li><li>deployment targets<ul><li>set of EC2 instances with tags</li><li>directly to an ASG</li><li>mix of ASG / tags so you can build deployment segments</li><li>customization in scripts with DEPLOYMENT_GROUP_NAME environment variables</li></ul></li></ul><h3 id="codedeploy-for-ec2-and-asg"><a class="markdownIt-Anchor" href="#codedeploy-for-ec2-and-asg"></a> CodeDeploy for EC2 and ASG</h3><ul><li><p>code deploy to EC2</p><ul><li>define how to deploy the application using appspec.yml + deployment strategy</li><li>will do in place update to your fleet of EC2 instances</li><li>can use hooks to verify the deployment after each deployment phase</li></ul></li><li><p>code deploy to ASG</p><ul><li>in place updates<ul><li>updates current existing EC2 instances</li><li>instances newly created by an ASG will also get automated deployments</li></ul></li><li>Blue / Green deployment<ul><li>a new auto scaling group is created (settings are copied)</li><li>choose how long to keep the old instances</li><li>must be using an ELB (for directing traffic to new ASG group)</li></ul></li></ul></li></ul><h2 id="codestar"><a class="markdownIt-Anchor" href="#codestar"></a> CodeStar</h2><ul><li>CodeStar is an integrated solution that regroups: github, codecommit, codebuild, codeDeploy, CloudFormation, codepipeline, cloudwatch</li><li>helps quickly create CICD ready projects for EC2, lambda, Beanstalk</li><li>supported language: C#, Go, HTML5, Java, Node.js, PHP, Python, Ruby</li><li>issue tracking integration with JIRA, Github issues</li><li>ability to integrate with Cloud9 to obtain a web IDE</li><li>one dashboard to view all your components</li><li>free services, pay only for the underlying usage of other services</li><li>limited customization</li></ul><h1 id="cloudformation"><a class="markdownIt-Anchor" href="#cloudformation"></a> CloudFormation</h1><h2 id="infrastructure-as-code"><a class="markdownIt-Anchor" href="#infrastructure-as-code"></a> infrastructure as code</h2><ul><li><p>manual work will be very tough to reproduce</p><ul><li>in another region</li><li>in another AWS account</li><li>within the same region if everything was deleted</li></ul></li><li><p>CloudFormation would be the code to create / update / delete our infrastructure</p></li><li><p>CloudFormation is a declarative way of outlining your AWS infrastructure, for any resources</p></li><li><p>CloudFormation creates the resources for you in the right order, with the exact configuration that you sepcify</p></li></ul><h2 id="benefits"><a class="markdownIt-Anchor" href="#benefits"></a> benefits</h2><ul><li><p>infrastructure as code</p><ul><li>no resources are manually created, which is excellent for control</li><li>the code can be version controlled for example using git</li><li>changes to the infrastructure are reviewed through code</li></ul></li><li><p>cost</p><ul><li>each resources within the stack is stagged with an identifier so you can easily see how much a stack costs you</li><li>you can estimate the costs of your resources using the CloudFormation template</li><li>savings strategy: in dev, you could automation deletion of templates at 5pm and recreate anything at 8am safely</li></ul></li><li><p>productivity</p><ul><li>ability to destroy and recreate an infrastructure on the cloud on the fly</li><li>automated generation of diagram for your templates</li><li>declarative programming (no need to figure out ordering and orchestration)</li></ul></li><li><p>separation of concern: create many stacks for many apps, and many layers</p></li><li><p>don’t reinvent the wheel</p><ul><li>leverage existing templates on the web</li><li>leverage the documentation</li></ul></li></ul><h2 id="how-cloudformation-works"><a class="markdownIt-Anchor" href="#how-cloudformation-works"></a> how cloudformation works</h2><ul><li>templates have to be uplaoded in S3 and then referenced in cloudformation</li><li>to update a template, we can’t edit previous ones, we have to reupload a new version of the template to AWS</li><li>stacks are identified by a name</li><li>deleting a stack deletes every single artifact that was created by CloudFormation</li></ul><h2 id="deploying-cloudformation-template"><a class="markdownIt-Anchor" href="#deploying-cloudformation-template"></a> deploying cloudformation template</h2><ul><li>manual way<ul><li>editing templates in the CloudFormation designer</li><li>using the console to input parameters</li></ul></li><li>automated way<ul><li>editing templates in a YAML file</li><li>using the AWS CLI to deploy the templates</li><li>recommended way when you fully want to automate your flow</li></ul></li></ul><h2 id="building-blocks"><a class="markdownIt-Anchor" href="#building-blocks"></a> building blocks</h2><ul><li>templates components<ul><li>resources: your AWS resources declared in the template (mandatory)</li><li>parameters: the dynamic inputs for your template</li><li>mappings: the static variables for your templates</li><li>outputs: references to what has been created</li><li>conditionals: list of conditions to perform resource creation</li><li>metadata</li></ul></li><li>template helpers<ul><li>references</li><li>functions</li></ul></li></ul><h2 id="resources"><a class="markdownIt-Anchor" href="#resources"></a> resources</h2><ul><li><p>resources are the core of your CloudFormation template</p></li><li><p>they repreesent the different AWS components that will be created and configured</p></li><li><p>resources are declared and can reference each other</p></li><li><p>AWS figures out creation, updates and deletes of resources for us</p></li><li><p>can I create a dynamic amount of resources</p><ul><li>no you can’t</li></ul></li><li><p>is every AWS services suported</p><ul><li>almost, only a few are not</li></ul></li></ul><h2 id="parameters"><a class="markdownIt-Anchor" href="#parameters"></a> parameters</h2><ul><li>parameters are a way to provide inputs to your AWS CloudFormation template</li><li>they are important to know about if<ul><li>you want to resue your templates across the company</li><li>some inputs can not be determined ahead of time</li></ul></li><li>parameters are extremely powerful, controlled, and can precent errors from happening in your templates thanks you types</li></ul><h3 id="how-to-reference-a-parameter"><a class="markdownIt-Anchor" href="#how-to-reference-a-parameter"></a> how to reference a parameter</h3><ul><li>the <code>Fn::Ref</code> function can be leveraged to reference parameters</li><li>parameters can be used anywhere in a template</li><li>the shorthand for this in YAML is <code>!Ref</code></li><li>the function can also reference other elements within the template</li></ul><h3 id="pseudo-parameters"><a class="markdownIt-Anchor" href="#pseudo-parameters"></a> Pseudo parameters</h3><ul><li>AWS offers us pseudo parameters in any CloudFormation template</li><li>these can be used at any time and are enabled by default</li></ul><h2 id="mappings"><a class="markdownIt-Anchor" href="#mappings"></a> mappings</h2><ul><li>mappings are fixed variables within your CloudFormation template</li><li>they are very handy to differentiate between different environments (dev vs prod), regions, AMI types, etc…</li><li>all the values are hardcoded within the template</li></ul><h3 id="when-would-you-use-mappings-vs-parameters"><a class="markdownIt-Anchor" href="#when-would-you-use-mappings-vs-parameters"></a> when would you use mappings vs parameters</h3><ul><li>mappings are great when you know in advance all the values that can be taken and that they can be deduced from variables such as<ul><li>region</li><li>AZ</li><li>AWS account</li><li>environment</li></ul></li><li>they allow safer control over the template</li><li>use parameters when the values are really user specific</li></ul><h3 id="accessing-mapping-values"><a class="markdownIt-Anchor" href="#accessing-mapping-values"></a> accessing mapping values</h3><ul><li>we use <code>Fn::FindInMap</code> to return a named value from a specific key</li><li><code>!FindInMap [MapName, TopLevelKey, SecondLevelKey]</code></li></ul><h2 id="outputs"><a class="markdownIt-Anchor" href="#outputs"></a> outputs</h2><ul><li>the outputs section declares optional outputs values that we can import into other stacks (if you export them first)</li><li>you can also view the outputs in the AWS console or using the AWS CLI</li><li>they are very useful for example if you define a network CloudFormation, and output the variables such as VPC ID, and your subnet IDs</li><li>it is the best way to perform some collaboration cross stack, as you let export handle their own part of the stack</li><li>you can’t delete a CloudFormation stack if its outputs are being referenced by another CloudFormation stack</li></ul><h3 id="outputs-example"><a class="markdownIt-Anchor" href="#outputs-example"></a> outputs example</h3><ul><li>create a SSH security group as part of one template</li><li>we create an output that references that security group</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Outputs:</span><br><span class="line">  StackSSHSecurityGroup:</span><br><span class="line">    Description: The SSH security group for our company</span><br><span class="line">    Value: !Ref MyCompanyWideSSHSecurityGroup</span><br><span class="line">    Export:</span><br><span class="line">      Name: SSHSecurityGroup</span><br></pre></td></tr></table></figure><h3 id="cross-stack-reference"><a class="markdownIt-Anchor" href="#cross-stack-reference"></a> Cross stack reference</h3><ul><li>we then create a second template that leverages that security group</li><li>for this, we use the <code>Fn::ImportValue</code> function</li><li>you can’t delete the underlying stack until all the references are deleted too</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Resources:</span><br><span class="line">  MySecureInstance:</span><br><span class="line">    Type: AWS::EC2::Instance</span><br><span class="line">    Properties:</span><br><span class="line">      AvailabilityZone: us-east-1a</span><br><span class="line">      ImageId: ami-xxxxxxxx</span><br><span class="line">      InstanceType: t2.micro</span><br><span class="line">      SecurityGroups:</span><br><span class="line">        - !ImportValue SSHSecurityGroup</span><br></pre></td></tr></table></figure><h2 id="conditions"><a class="markdownIt-Anchor" href="#conditions"></a> conditions</h2><ul><li>conditions are used to control the creation of resources or outputs based on a condition</li><li>conditions can be whatever you want them to be, but common ones are<ul><li>environment</li><li>region</li><li>parameter value</li></ul></li><li>each condition can reference another condition, parameter value or mapping</li></ul><h3 id="define-a-conditon"><a class="markdownIt-Anchor" href="#define-a-conditon"></a> define a conditon</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Conditions:</span><br><span class="line">  CreateProdResources: !Equals [ !Ref EnvType, prod]</span><br></pre></td></tr></table></figure><ul><li>the logical ID is for you to choose, it is how you name condition</li><li>the intrinsic function can by any of the following<ul><li><code>Fn::And</code></li><li><code>Fn::Equals</code></li><li><code>Fn::If</code></li><li><code>Fn::Not</code></li><li><code>Fn::Or</code></li></ul></li></ul><h3 id="using-a-condition"><a class="markdownIt-Anchor" href="#using-a-condition"></a> using a condition</h3><ul><li>conditions can be applied to resources / outputs</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Resources:</span><br><span class="line">  Mountpoint:</span><br><span class="line">    Type: &quot;AWS::EC2::VolumeAttachment&quot;</span><br><span class="line">    Condition: CreateProdResources</span><br></pre></td></tr></table></figure><h2 id="intrinsic-functions"><a class="markdownIt-Anchor" href="#intrinsic-functions"></a> Intrinsic functions</h2><h3 id="fnref"><a class="markdownIt-Anchor" href="#fnref"></a> Fn::Ref</h3><ul><li>can be leveraged to reference<ul><li>parameters</li><li>resources</li></ul></li></ul><h3 id="fngetatt"><a class="markdownIt-Anchor" href="#fngetatt"></a> Fn::GetAtt</h3><ul><li>attributes are attached to any resources you create</li><li>to know the attributes of your resources, the best place to look at is the documentation</li><li>example: AZ of an EC2 machine</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Resources:</span><br><span class="line">  EC2Instance:</span><br><span class="line">    Type: &quot;AWS::EC2::Instance&quot;</span><br><span class="line">    Properties:</span><br><span class="line">      ImageId: ami-xxxxx</span><br><span class="line">      InstanceType: t2.micro</span><br><span class="line"></span><br><span class="line">NewVolume:</span><br><span class="line">  Type: &quot;AWS::EC2::Instance&quot;</span><br><span class="line">  Condition: CreateProdResources</span><br><span class="line">  Properties:</span><br><span class="line">    Size: 100</span><br><span class="line">    AvailabilityZone:</span><br><span class="line">      !GetAtt EC2Instance.AvailabilityZone</span><br></pre></td></tr></table></figure><h3 id="fnfindinmap"><a class="markdownIt-Anchor" href="#fnfindinmap"></a> Fn::FindInMap</h3><ul><li>we use Fn::FindInMap to return a named value from a specific key</li><li>!FindInMap [MapName, TopLevelKey, SecondLevelKey]</li></ul><h3 id="fnimportvalue"><a class="markdownIt-Anchor" href="#fnimportvalue"></a> Fn::ImportValue</h3><ul><li>import values that are exported in other templates</li></ul><h3 id="fnjoin"><a class="markdownIt-Anchor" href="#fnjoin"></a> Fn::Join</h3><ul><li>join values with a delimiter</li><li>!Join [delimiter, [a, b, c]]</li></ul><h3 id="fnsub"><a class="markdownIt-Anchor" href="#fnsub"></a> Fn::Sub</h3><ul><li>used to substitute variables from a text, it is a very handy function that will allow you to fully customize your templates</li><li>for example: you can combine Fn::Sub with references or AWS Pseudo variables</li><li>String must contain ${VariableName} and will substitute them</li></ul><h3 id="condition-functions"><a class="markdownIt-Anchor" href="#condition-functions"></a> Condition Functions</h3><ul><li>the logical ID is for you to choose, it is how you name condition</li></ul><h2 id="cloudformation-rollbacks"><a class="markdownIt-Anchor" href="#cloudformation-rollbacks"></a> CloudFormation rollbacks</h2><ul><li>stack creation fails<ul><li>default: everything rolls back, we can look at the log</li><li>option to disable rollback and troubleshoot what happened</li></ul></li><li>stack update fails:<ul><li>the stack automatically rolls back to the previous known working state</li><li>ability to see in the log     what happened and error messages</li></ul></li></ul><h2 id="changesets"><a class="markdownIt-Anchor" href="#changesets"></a> ChangeSets</h2><ul><li>when you update a stack, you need to know what changes before it happens for greater confidence</li><li>ChangeSets won’t say if the update will be successful</li></ul><h2 id="nested-stacks"><a class="markdownIt-Anchor" href="#nested-stacks"></a> Nested Stacks</h2><ul><li>stacks as part of other stacks</li><li>they allow you to isolate repeated patterns / common components in separate stacks and call them from other stacks</li><li>Example:<ul><li>load balancer configuration that is re used</li><li>security group that is re used</li></ul></li><li>nested stacks are considered best practice</li><li>to update a nested stack, always update the parent (root stack)</li></ul><h3 id="cross-stack-vs-nested-stack"><a class="markdownIt-Anchor" href="#cross-stack-vs-nested-stack"></a> Cross stack vs nested stack</h3><ul><li><p>Cross stacks</p><ul><li>helpful when stacks have different lifecycles</li><li>use outputs export and Fn::ImportValue</li><li>when you need to pass export values to many stacks</li></ul></li><li><p>nested stacks</p><ul><li>helpful when components must be re used</li><li>example: re use how to properly configure an application load balancer</li><li>the nested stack only is important to the higher level stack</li></ul></li></ul><h2 id="stacksets"><a class="markdownIt-Anchor" href="#stacksets"></a> StackSets</h2><ul><li>create, update, or delete stacks across multiple accounts and regions with a single operation</li><li>administrator account to create StackSets</li><li>trusted accounts to create, update, delete stack instances from StackSets</li><li>when you update a stack set, all associated stack instances are updated throughout all accounts and regions</li></ul><h2 id="cloudformation-drift"><a class="markdownIt-Anchor" href="#cloudformation-drift"></a> CloudFormation drift</h2><ul><li><p>CloudFormation allows you to create infrastructure</p></li><li><p>but it doesn’t protect you against manual configuration changes</p></li><li><p>how do we know if our resources have drifted?</p></li><li><p>we can use CloudFormation drift</p></li></ul><h1 id="monitoring"><a class="markdownIt-Anchor" href="#monitoring"></a> Monitoring</h1><ul><li>AWS CloudWatch<ul><li>metrics: collect and track key metrics</li><li>log: collect, monitor, analyze, and store log files</li><li>events: send notifications when certain events happen in your AWS</li><li>alarms: react in real-time to metrics / events</li></ul></li><li>X-Ray<ul><li>troubleshooting application performance and errors</li><li>distrbuted tracing of microservices</li></ul></li><li>CloudTrail<ul><li>internal monitoring of API calls being made</li><li>audit changes to AWS resources by your users</li></ul></li></ul><h2 id="cloudwatch-metrics"><a class="markdownIt-Anchor" href="#cloudwatch-metrics"></a> CLoudWatch metrics</h2><ul><li>CloudWatch provides metrics for every services in AWS</li><li>metric is a variable to monitor</li><li>metric belong to namespaces</li><li>dimension is an attribute of a metric</li><li>up to 10 dimensions per metric</li><li>metrics have timestamps</li><li>can create CloudWatch dashboards of metrics</li></ul><h3 id="detailed-monitoring"><a class="markdownIt-Anchor" href="#detailed-monitoring"></a> Detailed monitoring</h3><ul><li>EC2 instance metrics have metrics every 5 minutes</li><li>with detailed monitoring, you get data every 1 minute</li><li>use detailed monitoring if you want to scale faster for your ASG</li><li>the AWS free tier allows us to have 10 detailed monitoring metrics</li><li>NOTE: EC2 memory usage is by default not pushed (must be pushed from inside the instance as a custom metric)</li></ul><h2 id="cloudwatch-custom-metrics"><a class="markdownIt-Anchor" href="#cloudwatch-custom-metrics"></a> CloudWatch Custom metrics</h2><ul><li>possibility to define and send your own custom metrics to CloudWatch</li><li>example: RAM usage, disk space, number of logged in users</li><li>use API call PutMetricData</li><li>ability to use dimensions (attribute) to segment metrics<ul><li>instance id</li><li>environment name</li></ul></li><li>matric resolution<ul><li>standard: 60 seconds</li><li>high resolution: 1 / 5 / 10 / 30 seconds - higher cost</li></ul></li><li>important: the API accepts metric data points two weeks in the past and two hours in the future (make sure to configure your EC2 instance time correctly)</li></ul><h2 id="cloudwatch-logs"><a class="markdownIt-Anchor" href="#cloudwatch-logs"></a> CloudWatch logs</h2><ul><li><p>applicatoins can send logs to CloudWatch using the SDK</p></li><li><p>CLoudWatch can collect log from</p><ul><li>Elastic Beanstalk: collection of logs from application</li><li>ECS: colletion from containers</li><li>AWS lambda: collection from function logs</li><li>VPC flow logs: VPC specific logs</li><li>API gateway</li><li>CLoudTrail based on filter</li><li>CloudWatch log agents: for example on EC2 machines</li><li>route 53: log DNS queries</li></ul></li><li><p>cloudWatch logs can go to</p><ul><li>batch exporter to S3 for archival</li><li>stream to elasticSearch cluster for further analysis</li></ul></li><li><p>ClouWatch logs can use filter expressions</p></li><li><p>logs storage architecture</p><ul><li>log groups: arbitrary name, usually representing an application</li><li>log stream: instances within application / log files / containers</li></ul></li><li><p>can define log expiration policies (never, 30 days, etc…)</p></li><li><p>using the AWS CLI we can tail CloudWatch logs</p></li><li><p>to send logs to CloudWatch, make sure IAM permissions are correct</p></li><li><p>security: encryption of logs using KMS at the group level</p></li></ul><h2 id="cloudwatch-logs-for-ec2"><a class="markdownIt-Anchor" href="#cloudwatch-logs-for-ec2"></a> CloudWatch logs for EC2</h2><ul><li>by default, no logs from EC2 machine will go to CloudWatch</li><li>you need to run a CloudWatch agent on EC2 to push the log files you want</li><li>make sure IAM permissions are correct</li><li>the CLoudWatch log agent can be setup on premises too</li></ul><h3 id="cloudwatch-logs-agent-vs-unified-agent"><a class="markdownIt-Anchor" href="#cloudwatch-logs-agent-vs-unified-agent"></a> CloudWatch logs agent vs Unified agent</h3><ul><li>CloudWatch logs agent<ul><li>old version of the agent</li><li>can only send to CloudWatch logs</li></ul></li><li>CloudWatch Unified agent<ul><li>collect additional system level metrics such as RAM, processes, etc…</li><li>collect logs to send to CloudWatch logs</li><li>centralized configuration using SSM parameters store</li></ul></li></ul><h2 id="cloudwatch-logs-metric-filter"><a class="markdownIt-Anchor" href="#cloudwatch-logs-metric-filter"></a> CloudWatch logs metric filter</h2><ul><li>CloudWatch logs can use filter expressions<ul><li>for exampe: find a specific IP inside of a log</li><li>or count occurrences of ERROR in your logs</li><li>metric filters can be used to trigger alarms</li></ul></li><li>filter do not retroactively filter data. (it doesn’t not filter historical data, only data since filter is created is counted).</li><li>filters only publish the metric data points for events that happen after the filter was created</li><li>can be integrated with CloudWatch alarms, SNS, etc…</li></ul><h2 id="cloudwatch-alarms"><a class="markdownIt-Anchor" href="#cloudwatch-alarms"></a> CloudWatch alarms</h2><ul><li>alarms are used to trigger notifications for any metric</li><li>various options</li><li>alarm states<ul><li>OK</li><li>INSUFFICIETN_DATA</li><li>ALARM</li></ul></li><li>period<ul><li>length of time in seconds to evaluate the metric</li><li>high resolution custom metrics: 10 sec, 30 sec or multiple of 60 sec</li></ul></li></ul><h3 id="cloudwatch-alarm-targets"><a class="markdownIt-Anchor" href="#cloudwatch-alarm-targets"></a> CloudWatch alarm targets</h3><ul><li>stop, terminate, reboot or recover EC2 instances</li><li>trigger auto scaling action</li><li>send notification to SNS</li></ul><h3 id="good-to-know"><a class="markdownIt-Anchor" href="#good-to-know"></a> good to know</h3><ul><li>alarms can be created based on CloudWatch logs metrics filters</li><li>to test alarms and notifications, you could set the alarm state using CLI</li></ul><h2 id="cloudwatch-events"><a class="markdownIt-Anchor" href="#cloudwatch-events"></a> CloudWatch Events</h2><ul><li>event pattern: intercept events from AWS service<ul><li>EC2 instance state change, code build failure, S3…</li><li>can intercept any API call with CloudTrail integration</li></ul></li><li>schedule or Cron</li><li>A json payload is created from the event and passed to a target</li></ul><h2 id="cloudwatch-event-bridge"><a class="markdownIt-Anchor" href="#cloudwatch-event-bridge"></a> CloudWatch event bridge</h2><ul><li>EventBridge is the next evolution of CloudWatch events</li><li>default event bus: generated by AWS service</li><li>partner event bus: receive events from SaaS service or applications</li><li>custom event bus: for you own application</li><li>event buses can be accessed by other AWS accounts</li><li>rules: how to process the events (similar to CloudWatch event rules)</li></ul><h3 id="schema-registry"><a class="markdownIt-Anchor" href="#schema-registry"></a> Schema registry</h3><ul><li>eventBridge can analyze the events in your bus and infer the schema</li><li>the schema registry allows you to generate code for your application that will know in advance how data is structured in the event bus</li><li>schema can be versioned</li></ul><h2 id="amazon-eventbridge-vs-cloudwatch-events"><a class="markdownIt-Anchor" href="#amazon-eventbridge-vs-cloudwatch-events"></a> Amazon EventBridge vs CloudWatch events</h2><ul><li>EventBridge builds upon and extends CloudWatch events</li><li>it uses the same service API and endpoint, and the same underlying service infrastructure</li><li>EventBridge allows extension to add event buses for your custom applications and third party SaaS apps</li><li>EventBridge has the schema registry capability</li><li>EventBridge has a different name to mark the new capabilities</li><li>over time, the CloudWatch events name will be replaced with EventBridge</li></ul><h2 id="x-ray"><a class="markdownIt-Anchor" href="#x-ray"></a> X-Ray</h2><ul><li>debugging in Production, the old way<ul><li>test locally</li><li>add log statements everywhere</li><li>re deploy in production</li></ul></li><li>log formats differ across applications using CLoudWatch and analytics is hard</li></ul><h3 id="x-ray-advantages"><a class="markdownIt-Anchor" href="#x-ray-advantages"></a> X-ray advantages</h3><ul><li>troubleshooting performance</li><li>understand dependencies in a microservices architecture</li><li>pinpoint service issues</li><li>review request behavior</li><li>find errors and exceptions</li></ul><h3 id="tracing"><a class="markdownIt-Anchor" href="#tracing"></a> tracing</h3><ul><li>tracing is an end to end way to following a request</li><li>each component dealing with the request adds its own trace</li><li>tracing is made of segments</li><li>annotations can be added to traces to provide extra information</li><li>ability to trace<ul><li>every request</li><li>sample request (as a percentage for example or a rate per minute)</li></ul></li><li>X-Ray security<ul><li>IAM for authorization</li></ul></li></ul><h3 id="how-to-enable"><a class="markdownIt-Anchor" href="#how-to-enable"></a> How to enable?</h3><ol><li>Your code must import the AWS X-Ray SDK</li></ol><ul><li>very little code modification needed</li><li>the application SDK will then capture<ul><li>calls to AWS service</li><li>HTTP / HTTPS requests</li><li>database calls</li><li>queue calls</li></ul></li></ul><ol start="2"><li>install X-Ray daemon or enable X-Ray AWS integration</li></ol><ul><li>X-Ray daemon works as a low level UDP packet interceptor</li><li>lambda / other AWS services already run the X-Ray daemon for you</li><li>each application must have the IAM rights to write data to X-Ray</li></ul><h3 id="x-ray-magic"><a class="markdownIt-Anchor" href="#x-ray-magic"></a> X-Ray magic</h3><ul><li>X-Ray service collects data from all the different services</li><li>service map is computed from all the segments and traces</li><li>X-Ray is graphical, so even non technical people can help troubleshoot</li></ul><h3 id="x-ray-troubleshooting"><a class="markdownIt-Anchor" href="#x-ray-troubleshooting"></a> X-Ray troubleshooting</h3><ul><li>if X-Ray is not working on EC2<ul><li>ensure the EC2 IAM role has the proper permissions</li><li>ensure the EC2 instance is running the X-Ray daemon</li></ul></li><li>to enable on AWS lambda<ul><li>ensure it has an IAM execution role with proper policy</li><li>ensure that X-Ray is imported in the code</li></ul></li></ul><h2 id="x-ray-instrumentation-and-concepts"><a class="markdownIt-Anchor" href="#x-ray-instrumentation-and-concepts"></a> X-Ray instrumentation and concepts</h2><ul><li>instrumentation means the measure of product’s performance, diagnose errors and to write trace information</li><li>to instrument your application code, you use the X-Ray SDK</li><li>many SDK require only configuration changes</li><li>you can modify your application code to customize and annotation the data that the SDK sends to X-Ray, using interceptors, filters, handlers, middleware…</li></ul><h3 id="x-ray-concepts"><a class="markdownIt-Anchor" href="#x-ray-concepts"></a> X-Ray concepts</h3><ul><li>segments: each application / service will send them</li><li>subsegments: if you need more details in your segment</li><li>trace: segments collected together to form an end to end trace</li><li>sampling: decrease the amount of requests sent to X-Ray, reduce cost</li><li>annotations: key value pairs used to index traces and use with filters</li><li>metadata: key value pairs, not indexed, not used for searching</li><li>the X-Ray daemon / agent has a config to send traces cross account<ul><li>make sure the IAM permissions are correct - the agent will assume the role</li><li>this allows to have a central account for all your application tracing</li></ul></li></ul><h3 id="x-ray-sampling-rules"><a class="markdownIt-Anchor" href="#x-ray-sampling-rules"></a> X-Ray sampling rules</h3><ul><li>with sampling rules, you control the amount of data that you record</li><li>you can modify sampling rules without changing your code</li><li>by default, the X-Ray SDK records the first request each second, and five percent of any additional requests</li><li>one request per  second is the reservior, which requests that at least one trace is recorded each second as long the service is serving requests</li><li>Five percent is the rate, at which additional requests beyond the reservior size are sampled</li></ul><h2 id="x-ray-with-beanstalk"><a class="markdownIt-Anchor" href="#x-ray-with-beanstalk"></a> X-Ray with Beanstalk</h2><ul><li>Elastic Beanstalk platforms include the X-Ray daemon</li><li>you can run the daemon by setting an option in the Elastic Beanstalk console or with a configuration file (in .ebextension/xray-daemon.config)</li><li>make sure to give your instance profile the correct IAM permissions so that the X-Ray daemon can function correctly</li><li>then make sure your application code is intrumentated with the X-Ray SDK</li><li>note: the X-Ray daemon is not provided for multicontainer Docker</li></ul><h2 id="cloudtrail"><a class="markdownIt-Anchor" href="#cloudtrail"></a> CloudTrail</h2><ul><li>provides governance, compliance, and audit for your AWS account</li><li>CloudTrail is enabled by default</li><li>get an history of events / API calls made within your AWS accounts by<ul><li>console</li><li>SDK</li><li>CLI</li><li>AWS services</li></ul></li><li>can put logs from CloudTrail into CLoudWatch logs or S3</li><li>a trail can be applied to All regions (default), or a single region</li><li>if a resource is deleted in AWS, investigate CloudTrail first</li></ul><h3 id="cloudtrail-events"><a class="markdownIt-Anchor" href="#cloudtrail-events"></a> CloudTrail events</h3><ul><li>management events<ul><li>operations that are performed on resources in you account</li><li>examples<ul><li>configuring security</li><li>configuring rules for routing data</li><li>setting up logging</li></ul></li><li>by default, trails are configured to log management events</li><li>can separate read events (that don’t modify resources) and write events (that may modify resources)</li></ul></li><li>data events<ul><li>by default, data events are not logged (because high volume operations)</li><li>S3 object-level activity</li><li>can separate read and write events</li><li>lambda function execution activity</li></ul></li></ul><h3 id="cloudtrail-insights"><a class="markdownIt-Anchor" href="#cloudtrail-insights"></a> CloudTrail insights</h3><ul><li>enable CloudTrail insights to detect unusual activity in your account<ul><li>inaccurate resource provisioning</li><li>hitting service limits</li><li>bursts of IAM actions</li><li>gaps in periodic maintenance activity</li></ul></li><li>CloudTrail insights analyzes normal management events to create a baseline</li><li>and then continuously analyzes write events to detect usuaual patterns<ul><li>anomalies appear in the CloudTrail console</li><li>event is sent to S3</li><li>eventBridge is generated</li></ul></li></ul><h3 id="cloudtrail-events-retention"><a class="markdownIt-Anchor" href="#cloudtrail-events-retention"></a> CloudTrail events retention</h3><ul><li>events are stored for 90 days in CloudTrail</li><li>to keep events beyond this period, log them to S3 and use Athena</li></ul><h2 id="cloudtrail-vs-cloudwatch-vs-x-ray"><a class="markdownIt-Anchor" href="#cloudtrail-vs-cloudwatch-vs-x-ray"></a> CloudTrail vs CloudWatch vs X-Ray</h2><ul><li>CloudTrail<ul><li>audit API calls made by users / services / AWS console</li><li>useful to detect unauthorized calls or root cause of changes</li></ul></li><li>CloudWatch<ul><li>metrics over time for monitoring</li><li>logs for storing application log</li><li>alarms to send notifications in case of unexpected metrics</li></ul></li><li>X-Ray<ul><li>automated trace analysis and central service map visualization</li><li>latency, errors and fault analysis</li><li>request tracking across distributed systems</li></ul></li></ul><h1 id="sqs"><a class="markdownIt-Anchor" href="#sqs"></a> SQS</h1><h2 id="communications-between-applications"><a class="markdownIt-Anchor" href="#communications-between-applications"></a> Communications between applications</h2><ul><li>Synchronous<ul><li>synchronous between applications can be problematic if there are sudden spikes of traffic</li><li>what if you need to suddenly encode 1000 videos but usually it is 10?</li></ul></li><li>asynchronous<ul><li>it is better to decouple your applications</li><li>SQS: queue model</li><li>SNS: pub/sub model</li><li>Kinesis: real time streaming model</li><li>these services can scale independently from our application</li></ul></li></ul><h2 id="sqs-standard-queue"><a class="markdownIt-Anchor" href="#sqs-standard-queue"></a> SQS - standard queue</h2><ul><li>fully managed service, used to decouple applications</li><li>attributes<ul><li>unlimited throughput, unlimited number of messages in queue</li><li>default retention of messages: 4 to 14 days</li><li>law latency</li><li>limitation of 256 KB per message sent</li></ul></li><li>can have duplicate messages (at least once delivery, occasionally)</li><li>can have out of order messages (best effort ordering)</li></ul><h2 id="producing-messages"><a class="markdownIt-Anchor" href="#producing-messages"></a> Producing messages</h2><ul><li>produced to SQS using the SDK (SendMessage API)</li><li>the message is persisted in SQS until a consumer deletes it</li></ul><h2 id="comsuming-messages"><a class="markdownIt-Anchor" href="#comsuming-messages"></a> comsuming messages</h2><ul><li>consumers (running on EC2 instances, servers, or lambda)</li><li>poll SQS for messages (receive up to 10 messages at a time)</li><li>process the messages (example: insert the message into an RDS database)</li><li>delete the messages using the DeleteMessage API</li></ul><h2 id="multiple-ec2-instances-consumers"><a class="markdownIt-Anchor" href="#multiple-ec2-instances-consumers"></a> multiple EC2 instances consumers</h2><ul><li>consumers receive and process messages in parallel</li><li>at least once delivery</li><li>best effort message ordering</li><li>consumers delete messages after processing them</li><li>we can scale consumers horizontally to improve throughput of processing (using ASG)</li></ul><h2 id="security-3"><a class="markdownIt-Anchor" href="#security-3"></a> security</h2><ul><li>encryption<ul><li>in flight encryption using HTTPS API</li><li>at rest encryption using KMS keys</li><li>client side encryption if the client wants to perform encryption / decryption itself</li></ul></li><li>access controls: IAM policies to regulate access to SQS API</li><li>SQS access policies: (similar to S3 bucket policies)<ul><li>useful for cross account access to SQS queues</li><li>useful for allowing other services (SNS, S3…) to write to an SQS queue</li></ul></li></ul><h2 id="message-visibility-timeout"><a class="markdownIt-Anchor" href="#message-visibility-timeout"></a> message visibility timeout</h2><ul><li><p>after a message is polled by a consumer, it becomes invisible to other consumers</p></li><li><p>by default, the message visibility timeout is 30 seconds</p></li><li><p>that means the message has 30 seconds to be processed</p></li><li><p>after the message visibility timeout is over, the message is visible again in SQS</p></li><li><p>if a message is not processed within the visibility timeout, it will be received by consumer again so it will be processed twice</p></li><li><p>a consumer could call the ChangeMessageVisibility API to get more time</p></li><li><p>if visibility timeout is high, and consumer crashes, it will take longer time for the message to become visible in the queue and being consumed by others</p></li><li><p>if the visibility timeout is low, we may get duplicates</p></li></ul><h2 id="dead-letter-queue"><a class="markdownIt-Anchor" href="#dead-letter-queue"></a> Dead letter queue</h2><ul><li>if a consumer fails to process a message within the visibility timeout, the message goes back to the queue</li><li>we can set a threshold of how many times a message can go back to the queue</li><li>after the MaximumRecevies threshold is exceeded, the message goes into a dead letter queue</li><li>useful for debugging</li><li>make sure to process the messages in the DLQ before they expire<ul><li>good to set a retention of 14 days in the DLQ</li></ul></li></ul><h2 id="delay-queue"><a class="markdownIt-Anchor" href="#delay-queue"></a> delay queue</h2><ul><li>delay a message (consumers don’t see it immediately) up to 15 minutes</li><li>default is 0 seconds (message is available right away)</li><li>can set a default at queue level</li><li>can override the default on send using the DelaySeconds parameter</li></ul><h2 id="long-polling"><a class="markdownIt-Anchor" href="#long-polling"></a> long polling</h2><ul><li>when a consumer requests messages from the queue, it can optionally wait for messages to arrive if there are none in the queue</li><li>this is called long polling</li><li>long polling decreases the number of API calls made to SQS while increasing the efficiency and latency of your application</li><li>the wait time can be between 1 to 20 seconds</li><li>long polling is preferable to short polling</li><li>long polling can be enabled at the queue level or at the API level using WaitTimeSeconds</li></ul><h2 id="sqs-extended-client"><a class="markdownIt-Anchor" href="#sqs-extended-client"></a> SQS extended client</h2><ul><li>message size limit is 256 KB, how to send large messages?</li><li>using the SQS extended client (Java Library)</li><li>it can be implemented using any language, it first uploads the large object to S3</li><li>then send the metadata of that object to SQS, once the consumer received the metadata, it will fetch the real object from S3.</li></ul><h2 id="fifo-queue"><a class="markdownIt-Anchor" href="#fifo-queue"></a> FIFO queue</h2><ul><li>First in first out</li><li>limited throughput: 300 messages / second, without batching, 3000 m/s with batching</li><li>exactly once send capability (by removing duplicates)</li><li>messages are processed in order by the consumer</li></ul><h3 id="fifo-deduplication"><a class="markdownIt-Anchor" href="#fifo-deduplication"></a> FIFO deduplication</h3><ul><li>deduplication interval is 5 minutes</li><li>two deduplication methods<ul><li>content based deduplication: will do a SHA-256 hash of the message body</li><li>explicitly provide a message deduplication ID</li></ul></li><li>if the queue receives messages with the same hash key or the same deduplication ID, it will refuse to receive the message</li></ul><h3 id="message-grouping"><a class="markdownIt-Anchor" href="#message-grouping"></a> message grouping</h3><ul><li>if you specify the same value of MessageGroupID in an SQS FIFO queue, you can only have one consumer, and all the messages are in order</li><li>to get ordering at the level of a subset of messages, specify different values for MessageGroupID<ul><li>messages that share a common message group ID will be in order within the group</li><li>each group ID can have a different consumer (parallel processing)</li><li>ordering across groups is not guaranteed</li></ul></li></ul><h1 id="sns"><a class="markdownIt-Anchor" href="#sns"></a> SNS</h1><ul><li><p>what if you want to send one message to many receivers?</p></li><li><p>the event producer only sends message to one SNS topic</p></li><li><p>as many event receivers as we want to listen to the SNS topic notifications</p></li><li><p>each subscriber to the topic will get all the messages (note: new feature to filter messages)</p></li><li><p>up to 10 million subscriptions per topic</p></li><li><p>100k topics limit</p></li><li><p>subscribers can be</p><ul><li>SQS</li><li>HTTP / HTTPS</li><li>lambda</li><li>emails</li><li>SMS messages</li><li>mobile notifications</li></ul></li><li><p>SNS integrates with a lot of AWS services</p><ul><li>many AWS services can send data directly to SNS for notifications</li><li>CloudWatch alarms</li><li>ASG notifications</li><li>S3</li><li>CloudFormation (upon state changes =&gt; failed to build etc…)</li></ul></li></ul><h2 id="how-to-publish"><a class="markdownIt-Anchor" href="#how-to-publish"></a> How to publish</h2><ul><li>topic publish (using the SDK)<ul><li>create a topic</li><li>create a subscription</li><li>publish to the topic</li></ul></li><li>direct publish (for mobile apps SDK)<ul><li>create a platform application</li><li>create a platform endpoint</li><li>publish to the platform endpoint</li><li>works with Google GCM, Apple APNS, Amazon ADM…</li></ul></li></ul><h2 id="security-4"><a class="markdownIt-Anchor" href="#security-4"></a> security</h2><ul><li>encryption<ul><li>in flight encryption using HTTPS API</li><li>at rest encryption using KMS keys</li><li>client side encryption if the client wants to perform encryption / decryption itself</li></ul></li><li>access controls: IAM policies to regulate access to the SNS API</li><li>SNS access policies (similar to S3 bucket policies)<ul><li>useful for cross account to SNS topic</li><li>useful for allowing other services to write to an SNS topic</li></ul></li></ul><h2 id="sns-sqs-fan-out"><a class="markdownIt-Anchor" href="#sns-sqs-fan-out"></a> SNS + SQS: Fan out</h2><ul><li>push once in SNS, receive in all SQS queues that are subscribers</li><li>fully decoupled, no data loss</li><li>SQS allows for: data persistence, delayed processing and retries of work</li><li>ability to add more SQS subscribers over time</li><li>make sure your SQS queue access policy allows for SNS to write</li></ul><h2 id="s3-events-to-multiple-queues"><a class="markdownIt-Anchor" href="#s3-events-to-multiple-queues"></a> S3 events to multiple queues</h2><ul><li>for the same combination of: event type and prefix, you can only have one S3 event rule</li><li>if you want to send the same S3 event to many SQS queues, use fanout (SNS + SQS)</li></ul><h2 id="sns-fifo"><a class="markdownIt-Anchor" href="#sns-fifo"></a> SNS - FIFO</h2><ul><li>similar features as SQS FIFO<ul><li>ordering by message group ID</li><li>deduplication using a deduplication ID or Content based deduplication</li></ul></li><li>can only have SQS FIFO queues as subscribers</li><li>limited throughput (same throughput as SQS FIFO)</li></ul><h2 id="message-filtering"><a class="markdownIt-Anchor" href="#message-filtering"></a> message filtering</h2><ul><li>JSON policy used to filter messages sent to SNS topic’s subscriptions</li><li>if a subscription doesn’t have a filter policy, it receives every message</li></ul><h1 id="kinesis"><a class="markdownIt-Anchor" href="#kinesis"></a> Kinesis</h1><h2 id="kinesis-data-streams"><a class="markdownIt-Anchor" href="#kinesis-data-streams"></a> Kinesis data streams</h2><ul><li>billing is per shard provisioned, can have as many shards as you want</li><li>retention between 1 to 365 days</li><li>ability to reprocess data (because data will not be deleted by consumer, it stays in Kinesis data streams until retention period is over)</li><li>once data is inserted in Kinesis, it can’t be deleted (immutability)</li><li>data that shares the same partition goes to the same shard (shard level ordering)</li><li>producers: AWS SDK, Kinesis Producer Library (KPL), Kinesis agent</li><li>consumers<ul><li>write your own: Kinesis Client Library (KCL), AWS SDK</li><li>managed: AWS lambda, Kinesis data firehose, Kinesis data analytics</li></ul></li></ul><h3 id="kinesis-data-streams-security"><a class="markdownIt-Anchor" href="#kinesis-data-streams-security"></a> Kinesis data streams security</h3><ul><li>control access / authorization using IAM policies</li><li>encryption in flight using HTTPS</li><li>encryption at rest using KMS</li><li>you can implement encryption / decryption of data on client side</li><li>VPC endpoints available for Kinesis to access within VPC (e.g. EC2 instance in private subnet access Kinesis data stream using VPC endpoint)</li><li>monitor API calls using CloudTrail</li></ul><h2 id="kinesis-consumers"><a class="markdownIt-Anchor" href="#kinesis-consumers"></a> Kinesis consumers</h2><h3 id="kinesis-consumer-types"><a class="markdownIt-Anchor" href="#kinesis-consumer-types"></a> Kinesis consumer types</h3><table><thead><tr><th>Shared fanout consumer - pull</th><th>enhanced fanout consumer - push</th></tr></thead><tbody><tr><td>low number of consuming applications</td><td>multiple consuming applications for the same stream</td></tr><tr><td>read throughput 2MB/ second per shard across all consumers</td><td>2 MB / second per consumer per shard</td></tr><tr><td>max 5 GetRecords API calls / sec</td><td>-</td></tr><tr><td>latency ~200ms</td><td>latency ~ 70ms</td></tr><tr><td>minimize cost</td><td>higher cost</td></tr><tr><td>consumers poll data from Kinesis using GetRecords API call</td><td>Kinesis push data to consumers over HTTP</td></tr><tr><td>returns up to 10MB or up to 10000 records</td><td>soft limit of 5 consumer applications per data stream</td></tr></tbody></table><h2 id="kinesis-client-library-kcl"><a class="markdownIt-Anchor" href="#kinesis-client-library-kcl"></a> Kinesis Client library (KCL)</h2><ul><li>a Java library that helps read record from a Kinesis Data Stream with distributed applications sharing the read workload</li><li>each shard is to be read by only one KCL instance<ul><li>e.g. 4 shards =&gt; max 4 KCL instances</li></ul></li><li>progress is checkpointed into DynamoDB (needs IAM access from KCL instance to DynamoDB), this means if one KCL instance is down, DynamoDB will save the checkpoint and knows where to resume when KCL instance goes backup</li><li>track other workers and share the work amongst shards using DynamoDB</li><li>KCL can run on EC2, elastic Beanstalk and on premises</li><li>records are read in order at the shard level</li><li>versions<ul><li>KCL 1.x (supports shared consumer)</li><li>KCL 2.x (supports shared and enhanced fanout consumer)</li></ul></li></ul><h2 id="kinesis-operations"><a class="markdownIt-Anchor" href="#kinesis-operations"></a> Kinesis operations</h2><h3 id="shard-splitting"><a class="markdownIt-Anchor" href="#shard-splitting"></a> Shard splitting</h3><ul><li>used to increase the Stream capacity</li><li>used to divide a hot shard</li><li>the old shard is closed and will be deleted once the data is expired (until the retention period is over)</li><li>no automatic scaling (manually increase / decrease capacity)</li><li>can’t split into more than two shards in a single operation</li></ul><h3 id="merging-shards"><a class="markdownIt-Anchor" href="#merging-shards"></a> merging shards</h3><ul><li>decrease the Stream capacity and save costs</li><li>can be used to group two shards with low traffic</li><li>old shards are closed and will be deleted once the data is expired</li><li>can’t merge more than two shards in a single operation</li></ul><h2 id="kinesis-data-firehose"><a class="markdownIt-Anchor" href="#kinesis-data-firehose"></a> Kinesis data firehose</h2><ul><li>fully managed service, no administration, automatic scaling, serverless<ul><li>target: redshift, S3, ElasticSearch</li><li>third party</li><li>custom HTTP endpoint</li></ul></li><li>pay for data going through firehose</li><li>near real time<ul><li>60 seconds latency minimum for non full batches</li><li>or minimum 32 MB of data at a time</li><li>it is not real time because it will batch the data into 60 seconds of data or 32MB of data</li></ul></li><li>supports many data formats, conversions, transformations, compression</li><li>supports custom data transformations using AWS lambda</li><li>can send failed or all data to a backup S3 bucket</li></ul><h3 id="kinesis-data-streams-vs-firehose"><a class="markdownIt-Anchor" href="#kinesis-data-streams-vs-firehose"></a> Kinesis data streams vs Firehose</h3><table><thead><tr><th>Kinesis data streams</th><th>Kinesis data firehose</th></tr></thead><tbody><tr><td>streaming service for ingest at scale</td><td>load streaming data into S3 / redshift / ElasticSearch / Thrid party / custom HTTP</td></tr><tr><td>write custom code (producer / consumer)</td><td>fully managed</td></tr><tr><td>real time (~200ms)</td><td>near real time (60 seconds or 32MB)</td></tr><tr><td>manage scaling (shard spliting / shard merging)</td><td>automatic scaling</td></tr><tr><td>data storage for 1 to 365 days</td><td>no data storage</td></tr><tr><td>supports replay capability</td><td>doesn’t support replay capability</td></tr></tbody></table><h2 id="kinesis-data-analytics-sql-application"><a class="markdownIt-Anchor" href="#kinesis-data-analytics-sql-application"></a> Kinesis data analytics (SQL application)</h2><ul><li>perform real time analytics on Kinesis streams using SQL</li><li>fully managed, no server to provision</li><li>automatic scaling</li><li>real time analytics</li><li>pay for actual consumption rate</li><li>can create streams out of the real time queries</li><li>use cases<ul><li>time series analytics</li><li>real time dashboards</li><li>real time metrics</li></ul></li></ul><h2 id="sqs-vs-sns-vs-kinesis"><a class="markdownIt-Anchor" href="#sqs-vs-sns-vs-kinesis"></a> SQS vs SNS vs Kinesis</h2><h3 id="sqs-2"><a class="markdownIt-Anchor" href="#sqs-2"></a> SQS</h3><ul><li>consumer pull data</li><li>data is deleted after being consumed</li><li>can have as many as workers as we want</li><li>no need to provision throughput</li><li>ordering guarantees only on FIFO queues</li><li>individual message delay capability</li></ul><h3 id="sns-2"><a class="markdownIt-Anchor" href="#sns-2"></a> SNS</h3><ul><li>push data to many subscribers</li><li>data is not persisted (lost if not delivered)</li><li>pub/sub</li><li>no need to provision throughput</li><li>integrates with SQS for fanout architecture pattern</li><li>FIFO capability for SQS FIFO</li></ul><h3 id="kinesis-2"><a class="markdownIt-Anchor" href="#kinesis-2"></a> Kinesis</h3><ul><li>standard: pull data, 2 MB per shard</li><li>enhanced fanout: push data, 2 MB per shard per consumer</li><li>possibility to replay data</li><li>meant for real time big data, analytics and ETL</li><li>ordering at the shard level</li><li>data expires after X days</li><li>must provision throughput</li></ul><h2 id="kinesis-vs-sqs-ordering"><a class="markdownIt-Anchor" href="#kinesis-vs-sqs-ordering"></a> Kinesis vs SQS ordering</h2><ul><li>let’s assume 100 trucks, 5 kinesis shards, 1 SQS FIFO</li><li>Kinesis data streams<ul><li>on average you will have 20 trucks per shard</li><li>trucks will have their data ordered within each shard</li><li>the maximum amount of consumer in parallel we can have is 5</li></ul></li><li>SQS FIFO<ul><li>you only have one SQS FIFO queue</li><li>you will have 100 group ID</li><li>you can have up to 100 consumers (due to the 100 group ID)</li><li>you have up to 300 message per second (or 3000 if using batching, because one GetRecords API call can receive up to 10 messages)</li></ul></li></ul><h1 id="lambda"><a class="markdownIt-Anchor" href="#lambda"></a> Lambda</h1><h2 id="what-is-serverless"><a class="markdownIt-Anchor" href="#what-is-serverless"></a> what is serverless</h2><ul><li>serverless is a new paradigm in which the developers don’t have to manage servers anymore</li><li>they just deploy code</li><li>serverless was pioneered by AWS lambda but now also includes anything that is managed: databases, messaging, storage, etc…</li><li>serverless does not mean there are no servers, it means you just don’t manage / provision / see them</li></ul><h3 id="serverless-in-aws"><a class="markdownIt-Anchor" href="#serverless-in-aws"></a> serverless in AWS</h3><ul><li>lambda</li><li>DynamoDB</li><li>Cognito</li><li>API Gateway</li><li>S3</li><li>SNS and SQS</li><li>Kinesis data firehose</li><li>Aurora serverless</li><li>Step functions</li><li>Fargate</li></ul><h2 id="lambda-synchronous-invocations"><a class="markdownIt-Anchor" href="#lambda-synchronous-invocations"></a> Lambda synchronous invocations</h2><ul><li>synchronous: CLI, SDK, API Gateway, ALB<ul><li>results is returned right away</li><li>error handling must happen client side</li></ul></li></ul><h2 id="lambda-integration-with-alb"><a class="markdownIt-Anchor" href="#lambda-integration-with-alb"></a> lambda integration with ALB</h2><ul><li>to expose a lambda function as an HTTP endpoint</li><li>you can use the ALB or an API gateway</li><li>the lambda function must be registered in a target group</li><li>ALB will convert the request HTTP to JSON and convert the response JSON to HTTP</li></ul><h3 id="alb-multi-healer-values"><a class="markdownIt-Anchor" href="#alb-multi-healer-values"></a> ALB multi healer values</h3><ul><li>ALB can support multi header values</li><li>when you enable multi value headers, HTTP headers and query string parametersthat are sent with multiple values are shown as arrays within the AWS lambda event and response objects</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">HTTP</span><br><span class="line">http:&#x2F;&#x2F;example.com&#x2F;path?name&#x3D;foo&amp;name&#x3D;bar</span><br><span class="line"></span><br><span class="line">JSON</span><br><span class="line">&quot;queryStringParameters&quot;:&#123;&quot;name&quot;:[&quot;foo&quot;, &quot;bar&quot;]&#125;</span><br></pre></td></tr></table></figure><h2 id="lambdaedge"><a class="markdownIt-Anchor" href="#lambdaedge"></a> lambda@Edge</h2><ul><li><p>you have deployed a CDN using CloudFront</p></li><li><p>what if you wanted to run a global lambda alongside?</p></li><li><p>or how to implement request filtering before reaching your application?</p></li><li><p>for this, you can use Lambda@edge, deploy lambda functions alongside your CloudFront CDN</p><ul><li>build more responsive applications</li><li>you don’t manage servers, lambda is deployed globally</li><li>customize the CDN content</li><li>pay only for what you use</li></ul></li><li><p>you can use lambda to change CloudFront requests and responses</p><ul><li>after CloudFront receives a request from a viewer</li><li>before CloudFront forwards the request to the origin</li><li>after CloudFront receives the response from the origin</li><li>before CloudFront forwards the response to the viewer</li></ul></li><li><p>you can also generate responses to viewers without ever sending the request to the origin</p></li></ul><h2 id="lambda-asynchronous-invocations"><a class="markdownIt-Anchor" href="#lambda-asynchronous-invocations"></a> lambda - asynchronous invocations</h2><ul><li>S3, SNS, CloudWatch events</li><li>the events are placed in an event queue</li><li>lambda attempts to retry on errors<ul><li>3 tries total</li><li>1 minute after first, then 2 minutes wait</li></ul></li><li>make sure the processing is idempotent (result is the same after retry)</li><li>if the function is retried, you will see duplicate logs entries in CloudWatch logs</li><li>can define a DLQ - SNS or SQS - for failed processing (need correct IAM permissions for lambda to write to SQS)</li><li>asynchronous invocations allow you to speed up the processing if you don’t need to wait for the result</li></ul><h2 id="lambda-event-source-mapping"><a class="markdownIt-Anchor" href="#lambda-event-source-mapping"></a> lambda event source mapping</h2><ul><li>Kinesis data Streams and DynamoDB Streams</li><li>SQS and SQS FIFO queue</li><li>common denominator: records need to be pulled from the source</li><li>your lambda function is invoked synchronously</li></ul><h3 id="streams-and-lambda-kinesis-and-dynamodb"><a class="markdownIt-Anchor" href="#streams-and-lambda-kinesis-and-dynamodb"></a> Streams and lambda (Kinesis and DynamoDB)</h3><ul><li>an event source mapping creates an iterator for each shard, processes items in order</li><li>start with new items, from the beginning or from timestamp</li><li>processed items aren’t removed from the stream (other consumers can read them again)</li><li>if traffic is low, we can use batch window to accumulate records before processing</li><li>you can process multiple batches in parallel<ul><li>up to 10 batches per shard</li><li>in order processing is still guaranteed for each partition key</li></ul></li></ul><h3 id="streams-and-lambda-error-handling"><a class="markdownIt-Anchor" href="#streams-and-lambda-error-handling"></a> Streams and lambda - error handling</h3><ul><li>by default, if your function returns an error, the entire batch is reprocessed until the function succeeds, or the items in the batch expire</li><li>to ensure in order processing, processing for the affected shard is paused until the error is resolved</li><li>you can configure the event source mapping to<ul><li>discard old events</li><li>restrict the number of retries</li><li>split the batch on error (to work around lambda timeout issue, maybe there is not enough time to process the whole batch, so we split the batch to make it small and faster to process)</li></ul></li><li>discarded events can go to a Destination</li></ul><h3 id="sqs-and-sqs-fifo-with-lambda"><a class="markdownIt-Anchor" href="#sqs-and-sqs-fifo-with-lambda"></a> SQS and SQS FIFO with lambda</h3><ul><li><p>event source mapping will pull SQS (long polling)</p></li><li><p>specify batch size (1 to 10 messages)</p></li><li><p>recommended: set the queue visibility timeout to 6x the timeout of your lambda function</p></li><li><p>to use a DLQ:</p><ul><li>setup on the SQS queue, not lambda (DLQ for lambda is only for async invocations)</li><li>or use a lambda Destination for failures</li></ul></li><li><p>lambda also supports in order processing for FIFO queues, scaling up to the number of active message groups</p></li><li><p>for standard queues, items aren’t necessarily processed in order</p></li><li><p>lambda scales up to process a standard queue as quickly as possible</p></li><li><p>when an error occurs, batches are returned to the queue as individual items and might be processed in a different grouping than the original batch</p></li><li><p>occasionally, the event source mapping receive the same item from the queue twice, even if no function error occurred</p></li><li><p>lambda deletes items from the queue after they are processed successfully</p></li><li><p>you can configure the source queue to send items to a DLQ if they can’t be processed</p></li></ul><h3 id="lambda-event-mapper-scaling"><a class="markdownIt-Anchor" href="#lambda-event-mapper-scaling"></a> lambda event mapper scaling</h3><ul><li>Kinesis data streams and DynamoDB streams<ul><li>one lambda invocation per stream shard</li><li>if you use parallelization, up to 10 batches processed per shard simultaneously</li></ul></li><li>SQS standard<ul><li>lambda adds 60 more instances per minute to scale up</li><li>up to 1000 batches of messages processed simultaneously</li></ul></li><li>SQS FIFO<ul><li>messages with the same group ID will be processed in order</li><li>the lambda function scales to the number of active message groups</li></ul></li></ul><h2 id="lambda-destinations"><a class="markdownIt-Anchor" href="#lambda-destinations"></a> lambda - Destinations</h2><ul><li>for asynchronous invocations, we can define destinations for successful and failed event<ul><li>SQS</li><li>SNS</li><li>lambda</li><li>EventBridge bus</li></ul></li><li>note: AWS recommends you use Destinations instead of DLQ now (but both can be used at the same time)</li></ul><h2 id="lambda-permissions-iam-roles-and-resource-policies"><a class="markdownIt-Anchor" href="#lambda-permissions-iam-roles-and-resource-policies"></a> lambda permissions - IAM roles and resource policies</h2><ul><li>lambda execution role<ul><li>grants the lambda function permissions to AWS services / resources</li><li>when you use an event source mapping to invoke your function, lambda uses the execution role to read event data (e.g. lambda need permission to pull messages from SQS)</li></ul></li><li>lambda resource based policies<ul><li>use resource based policies to give other accounts and AWS services permission to use your lambda resources</li><li>similar to S3 bucket policies for S3 bucket</li><li>an IAM principal can access lambda<ul><li>if the IAM policy attached to the principal authorizes it (user access)</li><li>or if the resource based policy authorizes (service access)</li></ul></li><li>when an AWS service like S3 calls your lambda function, the resource based policy gives it access</li></ul></li></ul><h2 id="lambda-environment-variables"><a class="markdownIt-Anchor" href="#lambda-environment-variables"></a> lambda environment variables</h2><ul><li>environment variable = key / value pair in string form</li><li>adjust the function behavior without updating code</li><li>the environment variable are available to your code</li><li>lambda service adds its own system environment variables as well</li><li>helpful to store secrets (encrypted by KMS)</li><li>secrets can be encrypted by the lambda service key, or your own CMK</li></ul><h2 id="lambda-logging-and-monitoring"><a class="markdownIt-Anchor" href="#lambda-logging-and-monitoring"></a> lambda logging and monitoring</h2><ul><li>CLoudWatch logs<ul><li>lambda execution logs are stored in AWS CloudWatch logs</li><li>make sure your AWS lambda function has an execution role with an IAM policy that authorizes writes to CloudWatch logs</li></ul></li><li>CLoudWatch metrics<ul><li>lambda metrics are displayed in AWS CloudWatch metrics</li><li>invocations, Durations, concurrent executions</li><li>error count, success rates, throttles</li><li>async delivery failures</li><li>iterator age (lagging for Kinesis and DynamoDB streams)</li></ul></li></ul><h3 id="lambda-tracing-with-x-ray"><a class="markdownIt-Anchor" href="#lambda-tracing-with-x-ray"></a> lambda tracing with X-Ray</h3><ul><li>enable in lambda configuration (active tracing)</li><li>runs the X-Ray daemon for you</li><li>use AWS X-Ray SDK in code</li><li>ensure lambda function has a correct IAM execution role to write to X-Ray<ul><li>the managed policy is called: <code>AWSXRayDaemonWriteAccess</code></li></ul></li></ul><h2 id="lambda-in-vpc"><a class="markdownIt-Anchor" href="#lambda-in-vpc"></a> lambda in VPC</h2><h3 id="lambda-by-default"><a class="markdownIt-Anchor" href="#lambda-by-default"></a> lambda by default</h3><ul><li>by default, your lambda function is launched outside your own VPC (in an AWS owned VPC)</li><li>therefore it cannot access resources in your VPC</li></ul><h3 id="lambda-in-vpc-2"><a class="markdownIt-Anchor" href="#lambda-in-vpc-2"></a> lambda in VPC</h3><ul><li>you must define the VPC ID, the subnets and the security groups</li><li>lambda will create an ENI in your subnets</li><li>lambda needs <code>AWSLambdaVPCAccessExecutionRole</code></li></ul><h3 id="internet-access"><a class="markdownIt-Anchor" href="#internet-access"></a> internet access</h3><ul><li>a lambda function in your VPC does not have internet access</li><li>deploying a lambda function in a public subnet does not give it internet access or a public IP</li><li>deploying a lambda function in a private subnet gives it internet access if you have a NAT gateway / NAT instance</li><li>you can use VPC endpoints to privately access AWS services without a NAT</li></ul><h2 id="lambda-function-performance"><a class="markdownIt-Anchor" href="#lambda-function-performance"></a> lambda function performance</h2><h3 id="configuration"><a class="markdownIt-Anchor" href="#configuration"></a> configuration</h3><ul><li>RAM<ul><li>from 128MB to 3008MB in 64MB increments</li><li>the more RAM you add, the more vCPU credits you get</li><li>at 1792MB, a function has the equivalent of one full vCPU</li><li>after 1792MB, you get more than one CPU, and need to use multi threading in your code to benefit from it</li></ul></li><li>if your application is CPU-bound (computation heavy), increase RAM</li><li>timeout: default 3 seconds, maximum is 900 seconds</li></ul><h3 id="lambda-execution-context"><a class="markdownIt-Anchor" href="#lambda-execution-context"></a> lambda execution context</h3><ul><li>the execution context is a temporary runtime environment that initialize any external dependencies of your lambda code</li><li>great for database connections, HTTP clients, SDK clients…</li><li>the execution context is maintained for some time in anticipation of another lambda function invocation</li><li>the next function invocation can reuse the context to execution time and save time in initializing connections objects (e.g. establish database connection outside of function handler)</li><li>the execution context includes the <code>/tmp</code> directory</li></ul><h3 id="lambda-function-tmp-space"><a class="markdownIt-Anchor" href="#lambda-function-tmp-space"></a> lambda function <code>/tmp</code> space</h3><ul><li>if your lambda function needs to download a big file to work</li><li>if your lambda function needs disk space to perform operations</li><li>you can use the <code>/tmp</code> directory</li><li>max size is 512 MB</li><li>the directory content remains when the execution context is frozen, providing transient cache that can be used for multiple invocations (helpful to checkpoint your work)</li><li>for permanent persistence of object, use S3</li></ul><h2 id="lambda-concurrency"><a class="markdownIt-Anchor" href="#lambda-concurrency"></a> lambda concurrency</h2><ul><li>concurrency limit: up to 1000 concurrent executions across entire account, so if one of your lambda function takes up all the concurrencies (if you didn’t setup reserved concurrency limit), the other lambda functions will be throttled.</li><li>can set a reserved concurrency at the function level</li><li>each invocation over the concurrency limit will trigger a throttle</li><li>throttle behavior</li><li>if synchronous invocation = return throttle error 429</li><li>if asynchronous invocation = retry automatically and then go to DLQ</li><li>if you need a higher limit, open a support ticket</li></ul><h3 id="lambda-concurrency-and-asynchronous-invocations"><a class="markdownIt-Anchor" href="#lambda-concurrency-and-asynchronous-invocations"></a> lambda concurrency and asynchronous invocations</h3><ul><li>if the function doesn’t have enough concurrency available to process all events, additional requests are throttled</li><li>for throttling errors and system errors, lambda returns the event to the queue and attempts to run the funtion again for up to 6 hours</li><li>the retry interval increases exponentially from 1 second after the first attempt to a maximum of 5 minutes</li></ul><h3 id="cold-start-and-provisioned-concurrency"><a class="markdownIt-Anchor" href="#cold-start-and-provisioned-concurrency"></a> Cold start and provisioned concurrency</h3><ul><li>cold start<ul><li>new instance =&gt; code is loaded and code outside the handler run (init)</li><li>if the init is large, this process can take some time</li><li>first request served by new instances has higher latency than the rest</li></ul></li><li>provisioned concurrency<ul><li>concurrency is allocated before the function is invoked (in advance)</li><li>so the cold start never happens and all invocations have low latency</li><li>application auto scaling can manage concurrency</li></ul></li></ul><h2 id="lambda-external-dependencies"><a class="markdownIt-Anchor" href="#lambda-external-dependencies"></a> lambda external dependencies</h2><ul><li>if your lambda function depends on external libraries<ul><li>for example AWS X-Ray SDK, database client, etc…</li></ul></li><li>you need to install the packages alongside your code and zip it together</li><li>upload the zip straight to lambda if less than 50MB, else to S3 first and reference from S3</li><li>native libraries work: they need to be complied on Amazon Linux</li><li>AWS SDK comes by default with every lambda function</li></ul><h2 id="lambda-and-cloudformation"><a class="markdownIt-Anchor" href="#lambda-and-cloudformation"></a> lambda and CloudFormation</h2><h3 id="inline"><a class="markdownIt-Anchor" href="#inline"></a> inline</h3><ul><li>inline functions are very simple</li><li>use the code.zipfile property</li><li>you cannot include function dependencies with inline functions</li></ul><h3 id="through-s3"><a class="markdownIt-Anchor" href="#through-s3"></a> through S3</h3><ul><li>you must store the lambda zip in S3</li><li>you must refer the S3 zip location in the CloudFormation code<ul><li>S3 bucket</li><li>S3 key: full path to zip</li><li>S3 object version: if versioned bucket</li></ul></li><li>if you update the code in S3, but don’t update S3 bucket, S3 key or S3 object version, CloudFormation won’t update your function because it will not detect the change</li></ul><h2 id="lambda-layers"><a class="markdownIt-Anchor" href="#lambda-layers"></a> lambda layers</h2><ul><li>externalize dependencies to re use them</li></ul><h2 id="lambda-container-images"><a class="markdownIt-Anchor" href="#lambda-container-images"></a> lambda container images</h2><ul><li>deploy lambda function as container images of up to 10GB from ECR</li><li>pack complex dependencies, large dependencies in a container</li><li>base images are available</li><li>can create your own image as long as it implements the lambda runtime API</li><li>test the containers locally using the lambda runtime interface emulator</li><li>unified workflow to build apps</li></ul><h2 id="lambda-versions-and-aliases"><a class="markdownIt-Anchor" href="#lambda-versions-and-aliases"></a> lambda versions and aliases</h2><h3 id="lambda-versions"><a class="markdownIt-Anchor" href="#lambda-versions"></a> lambda versions</h3><ul><li>when you work on a lambda function, we work on <code>$LATEST</code>, which is an unpublished mutable version</li><li>when we are ready to publish a lambda function, we create a version</li><li>versions are immutable</li><li>versions have increasing version numbers</li><li>versions get their own ARN</li><li>version = code + configuration</li><li>each version of the lambda function can be accessed</li></ul><h3 id="lambda-aliases"><a class="markdownIt-Anchor" href="#lambda-aliases"></a> lambda aliases</h3><ul><li>aliases are pointers to lambda function versions</li><li>we can define a dev, test, prod aliases and have them point at different lambda versions</li><li>aliases are mutable</li><li>aliases enable Blue / Green deployment by assigning weights to lambda functions</li><li>aliases enable stable configuration of our event triggers / destinations</li><li>aliases have their own ARNs</li><li>aliases cannot reference other aliases</li></ul><h2 id="lambda-and-codedeploy"><a class="markdownIt-Anchor" href="#lambda-and-codedeploy"></a> lambda and CodeDeploy</h2><ul><li>CodeDeploy can help you automate traffic shift for lambda aliases</li><li>feature is integrated within the SAM framework</li><li>linear<ul><li>grow traffic every N minutes until 100%</li></ul></li><li>canary<ul><li>try X percent then 100%</li></ul></li><li>AllAtOnce<ul><li>immediate</li></ul></li><li>can create pre and post traffic hooks to check the health of the lambda function</li></ul><h2 id="lambda-limits-good-to-know-per-region"><a class="markdownIt-Anchor" href="#lambda-limits-good-to-know-per-region"></a> lambda limits good to know - per region</h2><ul><li>memory allocation: 128MB - 10 GB</li><li>maximum execution time: 15 minutes</li><li>environment variables: 4KB</li><li>disk capacity in the function container in <code>/tmp</code>: 512 MB</li><li>concurrency executions: 1000</li><li>lambda function deployment size(zipped): 50MB</li><li>size of uncompressed deployment(code + dependencies): 250MB</li><li>can use the <code>/tmp</code> directory to load other files at startup</li></ul><h2 id="lambda-best-practices"><a class="markdownIt-Anchor" href="#lambda-best-practices"></a> lambda best practices</h2><ul><li>perform heavy duty work outside of your function handler<ul><li>connect to databases</li><li>initilize the SDK</li><li>pull in dependencies</li></ul></li><li>use environment variables for<ul><li>database connection sttrings, S3 buckets, etc…</li><li>passwords, sensitive values</li></ul></li><li>minimize your deployment package size to its runtime necessities<ul><li>break down the function</li><li>remember lambda limits</li><li>use Layers where necessary</li></ul></li><li>aviod using recursive code, never have a lambda function call itself</li></ul><h1 id="dynamodb"><a class="markdownIt-Anchor" href="#dynamodb"></a> DynamoDB</h1><h2 id="nosql-database"><a class="markdownIt-Anchor" href="#nosql-database"></a> NoSQL database</h2><ul><li>non-relational databases and are distributed</li><li>include MongoDB, DynamoDB…</li><li>do not support query joins (or just limited support)</li><li>all the data that is needed for a query is present in one row</li><li>don’t perform aggregations such as SUM, AVG…</li><li>scale horizontally</li><li>there is no right or wrong for NoSQL or SQL, they just require to model the data differently and think about user queries differently</li></ul><h2 id="amazon-dynamodb"><a class="markdownIt-Anchor" href="#amazon-dynamodb"></a> Amazon DynamoDB</h2><ul><li>fully managed, highly available with replication across multiple AZ</li><li>NoSQL database</li><li>scales to massive workloads, distributed database</li><li>millions of requests per second, trillions of row, 100s of TB of storage</li><li>fast and consistent in performance (low latency on retrieval)</li><li>integrated with IAM for security, authorization and administration</li><li>enables event driven programming with DynamoDB streams</li><li>low cost and auto scaling capabilities</li></ul><h2 id="basics"><a class="markdownIt-Anchor" href="#basics"></a> basics</h2><ul><li><p>DynamoDB is made of Tables</p></li><li><p>each table has a Primary Key (must be decided at creation time)</p></li><li><p>each table can have an infinite number of items</p></li><li><p>each item has attributes (can be added over time - can be null)</p></li><li><p>maximum size of an item is 400KB</p></li><li><p>data types supported are:</p><ul><li>scalar types: String, Number, Binary, Boolean, Null</li><li>Document types: List, Map</li><li>Set Types: String Set, Number Set, Binary Set</li></ul></li><li><p>Primary keys</p><ul><li>Partition Key (HASH)<ul><li>partition key must be unique for each item</li><li>partition key must be diverse so that the data is distributed</li></ul></li><li>Partition Key + Sort Key (HASH + RANGE)<ul><li>the combination must be unique for each item</li><li>data is grouped by partition key</li></ul></li></ul></li></ul><h2 id="read-write-capacity-modes"><a class="markdownIt-Anchor" href="#read-write-capacity-modes"></a> Read / Write capacity modes</h2><ul><li>control how you manage your table’s capacity</li><li>provisioned mode (default)<ul><li>you specify the number of reads/ writes per second</li><li>you need to plan capacity beforehand</li><li>pay for provisioned read / write capacity units</li></ul></li><li>on demand mode<ul><li>read / writes automatically scale up / down with your workloads</li><li>no capacity planning needed</li><li>pay for what you use, more expensive</li></ul></li><li>you can switch between different modes once every 24 hours</li></ul><h2 id="rw-capacity-modes-provisioned"><a class="markdownIt-Anchor" href="#rw-capacity-modes-provisioned"></a> R/W capacity modes - provisioned</h2><ul><li>table must have provisioned read an dwrite capacity units</li><li>read capacity units (RCU)</li><li>write capacity units</li><li>option to setup auto scaling of throughput to meet demand</li><li>throughput can be exceeded temporarily using brust capacity</li><li>if burst capacity has been consumed, you will get a <code>ProvisionedThroughpuutExceededException</code></li><li>it is then advised to do an exponential backoff retry</li></ul><h2 id="write-capacity-units-wcu"><a class="markdownIt-Anchor" href="#write-capacity-units-wcu"></a> Write Capacity units (WCU)</h2><ul><li>one WCU represents one write per second for an item up to 1KB in size</li><li>if the items are larget then 1 KB, more WCUs are consumed</li></ul><h2 id="strongly-consistent-read-vs-eventually-consistent-read"><a class="markdownIt-Anchor" href="#strongly-consistent-read-vs-eventually-consistent-read"></a> Strongly consistent read vs Eventually consistent read</h2><ul><li>Eventually consistent read (default)<ul><li>if we read just after a write, it is possible we will get some stale data because of replication</li></ul></li><li>Strongly consistent read<ul><li>if we read just after a write, we will get the correct data</li><li>set ConsistentRead parameter to True in API calls</li><li>consumes twice the RCU</li></ul></li></ul><h2 id="read-capacity-units-rcu"><a class="markdownIt-Anchor" href="#read-capacity-units-rcu"></a> Read capacity units (RCU)</h2><ul><li>one RCU represents one Strongly Consistent Read per second, or two Eventually consistent reads per second, for an item up to 4KB</li><li>if the items are larger than 4KB, more RCUs are consumed</li></ul><h2 id="paritions-internal"><a class="markdownIt-Anchor" href="#paritions-internal"></a> Paritions Internal</h2><ul><li>data is stored in partitions</li><li>partition keys go through a hashing algorithm to know to which partition they go to</li><li>WCUs and RCUs are spread evenly across partitions</li></ul><h2 id="throttling"><a class="markdownIt-Anchor" href="#throttling"></a> Throttling</h2><ul><li>if we exceed provisioned RCUs or WCUs, we get <code>ProvisionedThroughputExceededException</code></li><li>reasons<ul><li>hot keys: one partition key is being read too many times (popular item)</li><li>hot partitions</li><li>very large items, remember RCU and WCU depends on size of items</li></ul></li><li>solutions<ul><li>exponential backoff when exception is encountered</li><li>distribute partition keys as much as possible</li><li>if RCU issue, we can use DynamoDB Accelerator (DAX)</li></ul></li></ul><h2 id="on-demand"><a class="markdownIt-Anchor" href="#on-demand"></a> on demand</h2><ul><li>Read and writes automatically scale up and down with your workloads</li><li>no capacity planning needed</li><li>unlimited WCU and RCU, no throttle, more expensive</li><li>you are charged for reads and writes that you use in terms of RRU and WRU</li><li>read request units (RRU) - throughput for reads (same as RCU)</li><li>write request units (WRU) - throughput for writes (same as WCU)</li><li>2.5x more expensive than provisioned capacity</li><li>use cases: unknown workloads, unpredictable application traffic…</li></ul><h2 id="writing-data"><a class="markdownIt-Anchor" href="#writing-data"></a> writing data</h2><ul><li>PutItem<ul><li>creates a new item or fully replace an old item</li><li>consumers WCUs</li></ul></li><li>UpdateItem<ul><li>edits an existing item’s attributes or adds a new item if it doesn’t exist</li><li>can be used to implement Atomic Counters - a numeric attribute that is unconditionally incremented</li></ul></li><li>conditional writes<ul><li>accept a write / update / delete only if conditions are met, otherwise returns an error</li><li>helps with concurrent access to items</li><li>no performance impact</li></ul></li></ul><h2 id="reading-data"><a class="markdownIt-Anchor" href="#reading-data"></a> reading data</h2><ul><li>GetItem<ul><li>read based on primary key</li><li>primary key can be HASH or HASH + RANGE</li><li>eventually consistent read</li><li>option to use strongly consistent reads (more RCU - might take longer)</li><li>ProjectionExpression can be specified to retrieve only certain attributes</li></ul></li></ul><h2 id="reading-data-query"><a class="markdownIt-Anchor" href="#reading-data-query"></a> reading data - query</h2><ul><li>query returns items based on<ul><li>KeyConditionExpression<ul><li>partition key value - required</li><li>sort key value = optional</li></ul></li><li>FilterExpression<ul><li>additional filtering after the query operation (before data returned to you)</li><li>use only with non key attributes</li></ul></li></ul></li><li>returns<ul><li>the number of items specified in limit</li><li>or up to 1 MB of data</li></ul></li><li>ability to do pagination on the results</li><li>can query table, a local secondary index, or a global secondary index</li></ul><h2 id="reading-data-scan"><a class="markdownIt-Anchor" href="#reading-data-scan"></a> reading data - scan</h2><ul><li>scan the entire table and then filter out data (inefficient)</li><li>returns up to 1 MB of data - use pagination to keep on reading</li><li>consumes a lot of RCU</li><li>limit impact using Limit or reduce the size of the result and pause</li><li>for faster performance, use parallel scan<ul><li>multiple workers scan multiple data segments at the same time</li><li>increases the throughput and RCU consumed</li><li>limit the impact of parallel scans just like you would for Scans</li></ul></li><li>can use ProjectionExpression and FilterExpression</li><li>filtering will be done at the client side (e.g. in the browser)</li></ul><h2 id="deleting-data"><a class="markdownIt-Anchor" href="#deleting-data"></a> deleting data</h2><ul><li>DeleteItem<ul><li>delete an individual item</li><li>ability to perform a conditional delete</li></ul></li><li>DeleteTable<ul><li>delete a whole table and all its items</li><li>much quicker deletion than calling DeleteItem on all items</li></ul></li></ul><h2 id="batch-operations"><a class="markdownIt-Anchor" href="#batch-operations"></a> batch operations</h2><ul><li>allows you to save in latency by reducing the number of API calls</li><li>operations are done in parallel for better efficiency</li><li>part of a batch can fail, in which case we need to try again for the failed items</li><li>BatchWriteItem<ul><li>up to 25 PutItem and DeleteItem in one call</li><li>up to 16 MB of data written, up to 400KB of data per item</li><li>can’t update items</li></ul></li><li>BatchGetItem<ul><li>return items from one or more tables</li><li>up to 100 items, up to 16 MB of data</li><li>items are retrieved in parallel to minimize latency</li></ul></li></ul><h2 id="local-secondary-index-lsi"><a class="markdownIt-Anchor" href="#local-secondary-index-lsi"></a> Local Secondary Index (LSI)</h2><ul><li>alternative sort key for your table (use the same partition key)</li><li>the sort key consists of one scalar attribute</li><li>up to 5 local secondary indexes per table</li><li>must be defined at table creation time</li><li>attribute projections - can contain some or all the attributes of the base table</li></ul><h2 id="global-secondary-index-gsi"><a class="markdownIt-Anchor" href="#global-secondary-index-gsi"></a> Global secondary index (GSI)</h2><ul><li>alternative Primary key (HASH + HASH + RANGE) from the base table</li><li>speed up queries on non key attributes</li><li>the index key consists of scalar attributes</li><li>attribute projections - some or all the attributes of the base table</li><li>must provision RCUs and WCUs for the index</li><li>can be added / modified after table creation</li></ul><h2 id="indexes-and-throttling"><a class="markdownIt-Anchor" href="#indexes-and-throttling"></a> indexes and throttling</h2><ul><li>GSI<ul><li>if the writes are throttled on the GSI, then the main table will be throttled</li><li>even if the WCU on the main tables are fine</li><li>choose your GSI partition key carefully</li><li>assign your WCU capacity carefully</li></ul></li><li>LSI<ul><li>uses the WCUs and RCUs of the main table</li><li>no special throttling considerations</li></ul></li></ul><h2 id="optimistic-locking"><a class="markdownIt-Anchor" href="#optimistic-locking"></a> Optimistic locking</h2><ul><li>DynamoDB has a feature called Conditional Writes</li><li>a strategy to ensure an item hasn’t changed before you update / delete it</li><li>each item has an attribute that acts as a version number, and each update / delete request will change the value of the item, and also update the version number</li><li>if two request send at the same time, only one will succeed because the second request will not try to change the item because the version is different already.</li></ul><h2 id="dynamodb-dax"><a class="markdownIt-Anchor" href="#dynamodb-dax"></a> DynamoDB DAX</h2><ul><li>fully managed, highly available, seamless in memory cache for DynamoDB</li><li>microseconds latency for cached reads and queries</li><li>doesn’t require application logic modification</li><li>solves the hot key problem (too many reads)</li><li>5 minutes TTL for cache (default)</li><li>up to 10 nodes in the cluster</li><li>multi AZ</li><li>secure</li></ul><h3 id="dax-vs-elasticache"><a class="markdownIt-Anchor" href="#dax-vs-elasticache"></a> DAX vs ElastiCache</h3><ul><li>DAX is for individual object cache and simple query and scan</li><li>ElastiCache can store aggregation result and complex intermediate results</li></ul><h2 id="dynamodb-streams"><a class="markdownIt-Anchor" href="#dynamodb-streams"></a> DynamoDB Streams</h2><ul><li><p>ordered stream of item level modifications in a table</p></li><li><p>stream records can be</p><ul><li>sent to Kinesis Data Streams</li><li>read by AWS lambda</li><li>read by Kinesis Client Linrary applications</li></ul></li><li><p>data retention for up to 24 hours</p></li><li><p>use case</p><ul><li>react to changes in real time</li><li>analytics</li><li>insert into derivative tables</li><li>insert into ElasticSearch</li><li>implement cross region replication</li></ul></li><li><p>ability to choose the information that will be written to the stream</p><ul><li>KEYS_ONLY - only the key attributes of the modified item</li><li>NEW_IMAGE - the entire item, as it appears after it was modified</li><li>OLD_IMGAE - the entire item, as it appeared before it was modified</li><li>NEW_AND_OLD_IMAGES - both the new and old images of the item</li></ul></li><li><p>DynamoDB streams are made of shards, just like Kinesis Data Streams, so Kinesis KCL can be the consumer for DynamoDB Streams</p></li><li><p>you don’t need to provision shards, this is automated by AWS</p></li><li><p>records are not retroactively populated in a stream after enabling it</p></li></ul><h3 id="streams-and-lambda"><a class="markdownIt-Anchor" href="#streams-and-lambda"></a> Streams and lambda</h3><ul><li>you need to define an Event Source Mapping to read from DynamoDB streams</li><li>you need to ensure the lambda function has the appropriate permissions</li><li>your lambda function is invoked synchronously</li></ul><h2 id="dynamodb-ttl"><a class="markdownIt-Anchor" href="#dynamodb-ttl"></a> DynamoDB TTL</h2><ul><li>automatically delete items after an expiry timestamp</li><li>doesn’t consume any WCUs</li><li>the TTL attribute must be a number data type with Unix Epoch timestamp value</li><li>expired items deleted within 48 hours of expiration</li><li>expired items that haven’t been deleted, appears in reads/queries/scans (if you don’t want them, filter them out)</li><li>expired items are deleted from both LSIs and GSIs</li><li>a delete operation for each expired item enters the DynamoDB streams (can help recover expired items)</li><li>use cases: reduce stored data by keeping only current items, adhere to regulatory obligations, user sessions…</li></ul><h2 id="dynamodb-cli"><a class="markdownIt-Anchor" href="#dynamodb-cli"></a> DynamoDB CLI</h2><ul><li><code>--projection-expression</code>: one or more attributes to retrieve</li><li><code>--filter-expression</code>: filter items before returned to you</li><li>general CLI pagination options<ul><li><code>--page-size</code>: specify that CLI retrieves the full list of items but with a larger number of API calls instead of one API call</li><li><code>--max-items</code>: max number of items to show in the CLI (returns NextToken)</li><li><code>--starting-token</code>: specify the last NextToken to retrieve the next set of items</li></ul></li></ul><h2 id="dynamodb-transactions"><a class="markdownIt-Anchor" href="#dynamodb-transactions"></a> DynamoDB transactions</h2><ul><li>coordinated, all or nothing opeartions to multiple items across one or more tables</li><li>provides Atomicity, Consistency, Isolation, and Durability (ACID)</li><li>read modes - Eventual consistency, strong consistency, transactional</li><li>write modes - standard, transactional</li><li>consumers 2x WCUs and 2x RCUs</li><li>two operations<ul><li>TransactGetItems - one or more GetItem operations</li><li>TransactWriteItems - one or more PutItem, UpdateItem, DeleteItem operations</li></ul></li><li>use cases: financial transactions, managing orders, multi player games…</li></ul><h2 id="dynamodb-session-state-cache"><a class="markdownIt-Anchor" href="#dynamodb-session-state-cache"></a> DynamoDB Session State Cache</h2><ul><li>it is common to use DynamoDB to store session state</li><li>vs ElastiCache<ul><li>ElastiCache is in memory, but DynamoDB is serverless with auto scaling</li><li>both are key value pairs</li></ul></li><li>vs EFS<ul><li>EFS must be attached to EC2 instances as a network drive</li></ul></li><li>vs EBS and Instance store<ul><li>EBS and Instance store can only be used for local caching, not shared caching</li></ul></li><li>vs S3<ul><li>S3 is higher latency, and not meant for small objects</li></ul></li></ul><h2 id="dynamodb-security-and-other-features"><a class="markdownIt-Anchor" href="#dynamodb-security-and-other-features"></a> DynamoDB Security and other features</h2><ul><li>security<ul><li>VPC endpoints available to access DynamoDB without using the internet</li><li>access fully controled by IAM</li><li>encryption at rest using KMS and in transit using SSL/TLS</li></ul></li><li>backup and restore feature available<ul><li>point in time recovery (PITR) like RDS</li><li>no performance impact</li></ul></li><li>global tables<ul><li>multi region, multi active, fully replicated, high performance, need to enable DynamoDB streams first</li></ul></li><li>DynamoDB local<ul><li>develop and test apps locally without accessing the DynamoDB web service (without internet)</li></ul></li><li>AWS database migration service can be used to migrate to DynamoDB</li></ul><h3 id="fine-grained-access-control"><a class="markdownIt-Anchor" href="#fine-grained-access-control"></a> Fine-Grained access control</h3><ul><li>using web identity federation or cognito identity pools, each user gets AWS credentials</li><li>you can assign an IAM role to these users with a condition to limit their API access to DynamoDB</li><li>Leading Keys - limit row level access for users on the primary key</li><li>Attributes - limit specific attributes the user can see</li></ul><h1 id="api-gateway"><a class="markdownIt-Anchor" href="#api-gateway"></a> API Gateway</h1><h2 id="integrations-high-level"><a class="markdownIt-Anchor" href="#integrations-high-level"></a> Integrations high level</h2><ul><li>lambda function<ul><li>invoke lambda function</li><li>easy way to expose REST API backed by lambda</li></ul></li><li>HTTP<ul><li>expose HTTP endpoints in the backend</li><li>why? add rate limiting, caching, user authentications, API keys, etc…</li></ul></li><li>AWS service<ul><li>expose any API through the API Gateway</li><li>example: Step function workflow, post a message to SQS</li><li>why? add authentication, deploy publicly, rate control…</li></ul></li></ul><h2 id="endpoint-types"><a class="markdownIt-Anchor" href="#endpoint-types"></a> endpoint types</h2><ul><li>Edge-Optimized (default): for global clients<ul><li>requests are routed through the CloudFront Edge locations</li><li>the API Gateway still lives in only one region</li></ul></li><li>regional<ul><li>for clients within the same region</li><li>could manually combine with CloudFront (more control over the caching strategies and the distribution)</li></ul></li><li>private<ul><li>can only be accessed from your VPC using an interface VPC endpoint (ENI)</li><li>use a resource policy to define access</li></ul></li></ul><h2 id="deployment-stages"><a class="markdownIt-Anchor" href="#deployment-stages"></a> Deployment stages</h2><ul><li>making changes in the API Gateway does not mean they are effective</li><li>you need to make a deployment for them to be in effect</li><li>changes are deployed to Stages (as many as you want)</li><li>use the naming you like for stages (dev, test, prod)</li><li>each stage has its own configuration parameters</li><li>stages can be rolled back as a history of deployments is kept</li></ul><h3 id="stage-variables"><a class="markdownIt-Anchor" href="#stage-variables"></a> stage variables</h3><ul><li>stage variables are like environment variables for API Gateway</li><li>use them to change often changing configuration values</li><li>they can be used in<ul><li>lambda function ARN</li><li>HTTP endpoint</li><li>parameter mapping templates</li></ul></li><li>use cases:<ul><li>configure HTTP endpoints your stages talk to</li><li>pass configuration parameters to lambda through mapping templates</li></ul></li><li>stage variables are passed to the context object in lambda</li></ul><h3 id="stage-variables-with-lambda-aliases"><a class="markdownIt-Anchor" href="#stage-variables-with-lambda-aliases"></a> stage variables with lambda aliases</h3><ul><li>we can create a stage variable to indicate the corresponding lambda alias</li><li>our API gateway will automatically invoke the right lambda function</li></ul><h2 id="canary-deployment"><a class="markdownIt-Anchor" href="#canary-deployment"></a> canary deployment</h2><ul><li>possibility to enable canary deployments for any stage</li><li>choose the percentage of traffic the canary channel receives</li><li>metrics and logs are separate (for better monitoring)</li><li>possiblity to override stage variables for canary</li><li>this is Blue / Green deployment with lambda and API gateway</li></ul><h2 id="api-gateway-integration-types"><a class="markdownIt-Anchor" href="#api-gateway-integration-types"></a> API Gateway - Integration types</h2><ul><li>MOCK<ul><li>API Gateway returns a response without sending the request to the backend (for testing and dev purpose)</li></ul></li><li>HTTP / AWS<ul><li>you must configure both the integration request and integration response</li><li>setup data mapping using mapping templates for the request and response</li></ul></li><li>AWS_PROXY (lambda proxy)<ul><li>incoming request from the client is the input to lambda</li><li>the function is responsible for the logic of request / response</li><li>no mapping template, headers, query string parameters</li></ul></li><li>HTTP_PROXY<ul><li>no mapping template</li><li>the HTTP request is passed to the backend</li><li>the HTTP response from the backend is forwarded by API gateway</li></ul></li></ul><h3 id="mapping-template"><a class="markdownIt-Anchor" href="#mapping-template"></a> Mapping template</h3><ul><li>mapping templates can be used to modify request / response</li><li>rename and modify query string parameters</li><li>modify body content</li><li>add headers</li><li>uses Velocity template language</li><li>filter output results</li></ul><h3 id="mapping-template-json-to-xml-with-soap"><a class="markdownIt-Anchor" href="#mapping-template-json-to-xml-with-soap"></a> Mapping template: JSON to XML with SOAP</h3><ul><li>SOAP API are XML based, whereas REST API are JSON based</li><li>in this case, API gateway should<ul><li>extract data from the request: either path, payload or header</li><li>build SOAP message based on request data (mapping template)</li><li>call SOAP service and receive XML response</li><li>transform XML response to desired format and respond to the user</li></ul></li></ul><h2 id="api-gateway-swagger-open-api-spec"><a class="markdownIt-Anchor" href="#api-gateway-swagger-open-api-spec"></a> API Gateway Swagger / Open API spec</h2><ul><li>common way of defining REST APIs, using API defintion as code</li><li>import existing Swagger / OpenAPI 3.0 spec to API Gateway<ul><li>method</li><li>method request</li><li>integration request</li><li>method response</li><li>extensions for API Gateway and setup every single option</li></ul></li><li>can export current API as Swagger / OpenAPI spec</li><li>swagger can be written in YAML or JSON</li></ul><h2 id="caching-api-response"><a class="markdownIt-Anchor" href="#caching-api-response"></a> Caching API response</h2><ul><li>caching reduces the number of calls made to the backend</li><li>default TTL is 300 seconds</li><li>caches are defined per stage</li><li>possible to override cache settings per method</li><li>cache encryption option</li><li>cache capacity between 0.5 to 237 GB</li><li>cache is expensive, makes sense in production, may not make sense in dev and test</li></ul><h3 id="api-gateway-cache-invalidation"><a class="markdownIt-Anchor" href="#api-gateway-cache-invalidation"></a> API Gateway cache invalidation</h3><ul><li>able to flush the entire cache immediately</li><li>clients can invalidate the cache with header: <code>Cache-Control: max-age=0</code> (with proper IAM authorization)</li><li>if you don’t impose an InvalidateCache policy or choose the require authorization check box in the console, any client can invalidate the API cache, which is not good.</li></ul><h2 id="usage-plan-and-api-keys"><a class="markdownIt-Anchor" href="#usage-plan-and-api-keys"></a> Usage plan and API keys</h2><ul><li>if you want to make an API available as an offering to your customers</li><li>usage plan<ul><li>who can access one or more deployed API stages and methods</li><li>how much and how fast they can access them</li><li>uses API keys to identify API clients and meter access</li><li>configure throttling limits and quota limits that are enforced on individual client</li></ul></li><li>API keys<ul><li>alphanumberic string values to distribute to your customers</li><li>can use with usage plans to control access</li><li>throttling limits are applied to API keys</li><li>quotas limits is the overall number of maximum requests</li></ul></li></ul><h2 id="logging-and-tracing"><a class="markdownIt-Anchor" href="#logging-and-tracing"></a> logging and tracing</h2><ul><li>CloudWatch logs<ul><li>enable CloudWatch logging at the stage level</li><li>can override settings on a per API basis</li><li>log contains information about request / response body</li></ul></li><li>X-Ray<ul><li>enable tracing to get extra information about requests in API gateway</li><li>X-Ray API Gateway + Lambda gives you the full picture</li></ul></li></ul><h2 id="cloudwatch-metrics-2"><a class="markdownIt-Anchor" href="#cloudwatch-metrics-2"></a> CloudWatch metrics</h2><ul><li>metrics are by stage, possiblity to enable detailed metrics</li><li>CacheHitCount and CacheMissCount: efficiency of the cache</li><li>Count: the total number of API requests in a given period</li><li>IntegrationLatency: the time between when API Gateway relays a request to the backend and when receives a response from the backend</li><li>Latency: the time between when API gateway receives a request from a client and when it returns a response to the client, the latency includes the integration latency and other API gateway overhead</li><li>4xx Error (client side) and 5xx error (server side)</li></ul><h2 id="throttling-2"><a class="markdownIt-Anchor" href="#throttling-2"></a> throttling</h2><ul><li>account limit<ul><li>API gateway throttles requests at 10000 rps across all API</li><li>soft limit that can be increased upon request</li></ul></li><li>in case of throttling = 429 too many requests</li><li>can set stage limit and method limits to improve performance</li><li>or you can define usage plans to throttle per customer</li><li>just like lambda concurrency, one API that is overloaded, if not limited, can cause the other APIs to be throttled too.</li></ul><h2 id="cors-2"><a class="markdownIt-Anchor" href="#cors-2"></a> CORS</h2><ul><li>CORS must be enabled when you receive API calls from another domain</li><li>the OPTIONS pre flight request must contain the following headers<ul><li>Access-Control-Allow-Methods</li><li>Access-Control-Allow-Headers</li><li>Access-Control-Allow-Origin</li></ul></li><li>CORS can be enabled through the console</li></ul><h2 id="authentication-and-authorization"><a class="markdownIt-Anchor" href="#authentication-and-authorization"></a> Authentication and Authorization</h2><ul><li>IAM<ul><li>great for users already within your AWS accounts + resource policy for cross account</li></ul></li><li>Custom Authorizer<ul><li>great for third party tokens</li><li>very flexible in terms of what IAM policy is returned</li></ul></li><li>Cognito User Pool<ul><li>you manage your own user pool</li><li>no need to write any custom code</li><li>must implement authorization in the backend</li></ul></li></ul><h2 id="websocket-api"><a class="markdownIt-Anchor" href="#websocket-api"></a> WebSocket API</h2><ul><li>what is WebSocket<ul><li>two way interactive communication between a user’s browser and a server</li><li>server can push information to the client</li><li>this enables stateful application use cases</li></ul></li><li>WebSocket APIs are often used in real time applications such as chat applications, collaboration platforms, multiplayer games, and financial trading platforms</li><li>works with AWS services (lambda, DynamoDB) or HTTP endpoints</li></ul><h3 id="routing"><a class="markdownIt-Anchor" href="#routing"></a> Routing</h3><ul><li>incoming JSON messages are routed to different backend</li><li>if no routes =&gt; send to default</li><li>you request a route selection expression to select the field on JSON to route from</li><li>the result is evaluated against the route keys available in your API gateway</li><li>the route is then connceted to the backend you have setup through API gateway</li></ul><h2 id="architecture"><a class="markdownIt-Anchor" href="#architecture"></a> Architecture</h2><ul><li>create a single interface for all the microservices in your company</li><li>use API endpoints with various resources</li><li>apply a simple domain name and SSL certificates</li><li>can apply forwarding and transformation rules at the API gateway level</li></ul><h1 id="sam-serverless-application-model"><a class="markdownIt-Anchor" href="#sam-serverless-application-model"></a> SAM (serverless application model)</h1><ul><li>framework for developing and deploying serverless applications</li><li>all the configurations is YAML code</li><li>generate complex CloudFormation from simple SAM YAML file</li><li>supports anything from CLoudFormation</li><li>only two commmands to deploy to AWS</li><li>SAM can use CodeDeploy to deploy lambda functions</li><li>SAM can help you to run lambda, API gateway, DynamoDB locally</li></ul><h2 id="recipe"><a class="markdownIt-Anchor" href="#recipe"></a> Recipe</h2><ul><li>transform header indicates its SAM template<ul><li><code>Transform:</code></li></ul></li><li>write code<ul><li>AWS::Serverless::Function</li><li>AWS::Serverless::Api</li><li>AWS::Serverless::SimpleTable</li></ul></li><li>package and deploy<ul><li>aws cloudformation package / sam package</li><li>aws cloudformation deploy / sam deploy</li></ul></li></ul><h2 id="sam-policy-templates"><a class="markdownIt-Anchor" href="#sam-policy-templates"></a> SAM policy templates</h2><ul><li>list of templates to apply permissions to your lambda functions</li><li>important examples<ul><li>S3ReadPolicy: give read only permissions to objects in S3</li><li>SQSPollerPolicy: allows to poll an SQS queue</li><li>DynamoDBCrudPolicy: CRUD = create read update delete</li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">MyFunction:</span><br><span class="line">  Type: &#39;AWS::Serverless::Function&#39;</span><br><span class="line">  Properties:</span><br><span class="line">    CodeUri: xxxxx</span><br><span class="line">    Handler: xxxxxx</span><br><span class="line">    Runtime: xxxxxx</span><br><span class="line">    Policies:</span><br><span class="line">      - SQSPollerPolicy:</span><br><span class="line">        QueueName:</span><br><span class="line">          !GetAtt MyQueue.QueueName</span><br></pre></td></tr></table></figure><h2 id="sam-sumary"><a class="markdownIt-Anchor" href="#sam-sumary"></a> SAM Sumary</h2><ul><li>SAM is built on CloudFormation</li><li>SAM requires the Transform and Resources sections</li><li>commands to know<ul><li>sam build: fetch dependencies and create local deployment artifacts</li><li>sam package: package and upload to Amazon S3, generate CloudFormation template</li><li>sam deploy: deploy to CloudFormation</li></ul></li><li>SAM policy templates for easy IAM policy definition</li><li>SAM is integrated with CodeDeploy to do deploy to lambda aliases</li></ul><h2 id="serverless-application-repository-sar"><a class="markdownIt-Anchor" href="#serverless-application-repository-sar"></a> Serverless Application Repository (SAR)</h2><ul><li>managed repository for serverless applications</li><li>the applications are packaged using SAM</li><li>build and publish applications that can be re used by organizations<ul><li>can share publicly</li><li>can share with specific accounts</li></ul></li><li>this prevents duplicate work, and just go straight to publishing</li><li>application settings and behavior can be customized using Environment variables</li></ul><h1 id="cloud-development-kit-cdk"><a class="markdownIt-Anchor" href="#cloud-development-kit-cdk"></a> Cloud Development Kit (CDK)</h1><ul><li>define your cloud infrastructure using a familiar language</li><li>contains high level components called <code>constructs</code></li><li>the code is complied into a CloudFormation template (YAML / JSON)</li><li>you can therefore deploy infrastructure and application runtime code togther<ul><li>great for lambda functions</li><li>great for Docker Containers in ECS / EKS</li></ul></li></ul><h2 id="cdk-vs-sam"><a class="markdownIt-Anchor" href="#cdk-vs-sam"></a> CDK vs SAM</h2><ul><li>SAM<ul><li>serverless focused</li><li>write your template declaratively in JSON or YAML</li><li>great for quickly getting started with lambda</li><li>leverages CloudFormation</li></ul></li><li>CDK<ul><li>all aws services</li><li>write infra in a programming language</li><li>leverages CloudFormation</li></ul></li></ul><h1 id="cognito"><a class="markdownIt-Anchor" href="#cognito"></a> Cognito</h1><ul><li>we want to give our users an identity so that they can interact with our application</li><li>Cognito user pools<ul><li>sign in functionality for app users</li><li>integrate with API gateway and ALB</li></ul></li><li>Cognito Identity Pool (federated identity)<ul><li>provide AWS credentials to users so they can access AWS resources directly</li><li>integrate with Cognito user pools as an identity provider</li></ul></li><li>Cognito Sync<ul><li>Synchronize data from device to Cognito</li><li>is deprecated and replaced by AppSync</li></ul></li></ul><h2 id="cognito-user-pools"><a class="markdownIt-Anchor" href="#cognito-user-pools"></a> Cognito User Pools</h2><ul><li><p>create a serverless database of user for your web and mobile apps</p></li><li><p>simple login: username and password combination</p></li><li><p>password reset</p></li><li><p>email and phone number verification</p></li><li><p>federated identities: users from Facebook, Google, SAML…</p></li><li><p>feature: block users if their credentials are compromised elsewhere</p></li><li><p>login send back a JSON web token (JWT)</p></li><li><p>Cognito has a hosted authentication UI that you can add to your app to handle signup and signin workflows</p></li><li><p>using the hosted UI, you have a foundation for integration with social logins, OIDC or SAML</p></li><li><p>can customize with a custom logo and custom CSS</p></li></ul><h2 id="cognito-identity-pools"><a class="markdownIt-Anchor" href="#cognito-identity-pools"></a> Cognito Identity Pools</h2><ul><li>get identities for users so they obtain temporary AWS credentials</li><li>your identity pool can include<ul><li>public providers (login with Amazon, Facebook, Google, Apple)</li><li>users in an Amazon Cognito user pool</li><li>OpenID Connect Providers and SAML identity providers</li><li>developer authenticated identities</li><li>Cognito identity pools allow for unauthenticated (guest) access</li></ul></li><li>users can then access AWS service directly or through API gateway<ul><li>the IAM policies applied to the credentials are defined in Cognito</li><li>they can be customized based on the user_id for fine grained control</li></ul></li></ul><h3 id="iam-roles"><a class="markdownIt-Anchor" href="#iam-roles"></a> IAM roles</h3><ul><li>default IAM roles for authenticated and guest users</li><li>define rules to choose the role for each user based on the user’s ID</li><li>you can partition your users’ access using policy variables</li><li>IAM credentials are obtained by Cognito identity pools through STS</li><li>the roles must have a trust policy of Cognito identity pools</li></ul><h2 id="cognito-user-pools-vs-cognito-identity-pools"><a class="markdownIt-Anchor" href="#cognito-user-pools-vs-cognito-identity-pools"></a> Cognito User Pools vs Cognito Identity Pools</h2><ul><li>Cognito User Pool<ul><li>database of users for your web and mobile application</li><li>allows to federate logins through public social identity provider, OIDC, SAML…</li><li>can customize the hosted UI for authentication</li><li>has triggers with AWS lamdba during the authentication flow</li></ul></li><li>Cognito identity pools<ul><li>obtain AWS credentials for your users</li><li>users can login through public social, OIDC, SAML and Cognito User Pools</li><li>users can be unauthenticated</li><li>users are mapped to IAM roles and policies, can leverage policy variables</li></ul></li><li>CUP + CIP = manage users / password + access AWS services</li></ul><h2 id="cognito-sync"><a class="markdownIt-Anchor" href="#cognito-sync"></a> Cognito Sync</h2><ul><li>Deprecated - use AWS AppSync now</li><li>store preferences, configuration, state of app</li><li>cross device synchronization</li><li>offline capability</li><li>store data in datasets</li><li>push sync: silently notify across all devices when identity data changes</li><li>Cognito Stream: stream data from Cognito into Kinesis</li><li>Cognito Events: execute lambda functions in response to events</li></ul><h1 id="step-functions"><a class="markdownIt-Anchor" href="#step-functions"></a> Step Functions</h1><ul><li>model your workflows as state machines (one per workflow)<ul><li>order fulfillment, data processing</li><li>web applications, any workflow</li></ul></li><li>written in JSON</li><li>visualization of the workflow and the execution of the workflow, as well as history</li><li>start workflow with SDK call, API gateway, eventbridge</li></ul><h2 id="task-states"><a class="markdownIt-Anchor" href="#task-states"></a> task states</h2><ul><li>do some work in your state machine</li><li>invoke one service<ul><li>can invoke a lambda function</li><li>run an batch job</li><li>run an ECS task and wait for it to complete</li><li>insert an item from DynamoDB</li><li>publish message to SNS, SQS</li><li>launch another step function workflow</li></ul></li><li>run an activity<ul><li>EC2, Amazon ECS, on premises</li><li>activities poll the step functions for work</li><li>activities send result back to step functions</li></ul></li></ul><h2 id="states"><a class="markdownIt-Anchor" href="#states"></a> states</h2><ul><li>choice state: test for a condition to send to a branch</li><li>fail or succeed state: stop execution with failure or success</li><li>pass state: simply pass its input to its output or inject some fixed data, without performing work</li><li>wait state: provide a delay for a certain amount of time or until a specified time/date</li><li>Map state: dynamically iterate steps</li><li>parallel state: begin parallel branches of execution</li></ul><h2 id="error-handling"><a class="markdownIt-Anchor" href="#error-handling"></a> Error handling</h2><ul><li>any state can encounter runtime errors for various reasons<ul><li>state machine definition issues</li><li>task failtures</li><li>transient issues</li></ul></li><li>use <code>retry</code> and <code>catch</code> in the state machine to handle the errors instead of inside the application code</li><li>the state may report its own errors</li></ul><h3 id="retry"><a class="markdownIt-Anchor" href="#retry"></a> Retry</h3><ul><li>evaluated from top to bottom</li><li>ErrorEquals: match a specific kind of error</li><li>IntervalSeconds: initial delay before retrying</li><li>BackOffRate: multiple the delay after each retry</li><li>MaxAttempts: default to 3, set to 0 for never retried</li><li>When max attempts are reached, the <code>catch</code> kicks in</li></ul><h3 id="catch"><a class="markdownIt-Anchor" href="#catch"></a> Catch</h3><ul><li>evaluated from top to bottom</li><li>ErrorEquals: match a specific kind of error</li><li>Next: state to send to</li><li>ResultPath: a path that determines what input is sent to the state specified in the Next field</li></ul><h3 id="resultpath"><a class="markdownIt-Anchor" href="#resultpath"></a> ResultPath</h3><ul><li>include the error in the input</li></ul><h1 id="appsync"><a class="markdownIt-Anchor" href="#appsync"></a> AppSync</h1><ul><li>AppSync is a managed service that uses GraphQL</li><li>GraphQL makes it easy for applications to get exactly the data they needed</li><li>this includes combining data from one or more sources</li><li>retrieve data in real time with WebSocket or MQTT on WebSocket</li><li>for mobile apps: local data access and data Synchronization</li><li>it all starts with uploading one GraphQL schema</li></ul><h2 id="security-5"><a class="markdownIt-Anchor" href="#security-5"></a> Security</h2><ul><li>there are four ways you can authorize applications to interact with your AppSync GraphQL API<ul><li>API KEY</li><li>IAM</li><li>OPENID_CONNECT</li><li>COGNITO USER POOLS</li></ul></li><li>for custom domain and HTTPS, use CloudFront in front of AppSync</li></ul><h1 id="sts-security-token-service"><a class="markdownIt-Anchor" href="#sts-security-token-service"></a> STS (security Token service)</h1><ul><li>Allows to grant limited and temporary access to AWS resources</li><li>AssumeRole: assume roles within your account or cross account</li><li>AssumeRoleWithSAML: return credentials for users logged in with SAML</li><li>AssumeRoleWithWebIdentity<ul><li>return credentials for users logged with an IDP</li><li>AWS recommends against using this, and using Cognito User Pools instead</li></ul></li><li>GetSessionToken: For MFA, from a user or account root user</li><li>GetFederationToken: obtain temporary credentials for a federated user</li><li>GetCallerIdentity: return details about the IAM user or role used in the API call</li><li>DecodeAuthorizationMessage: decode error message when an AWS API is called</li></ul><h2 id="using-sts-to-assume-a-role"><a class="markdownIt-Anchor" href="#using-sts-to-assume-a-role"></a> using STS to assume a role</h2><ul><li>define an IAM role within your account or cross account</li><li>define which principals can access this IAM role</li><li>user STS to retrieve credentials and impersonate the IAM role you have access to</li><li>temporary credentials can be valid between 15 minutes to 1 hour</li></ul><h2 id="sts-with-mfa"><a class="markdownIt-Anchor" href="#sts-with-mfa"></a> STS with MFA</h2><ul><li>use GetSessionToken from STS</li><li>appropriate IAM policy using IAM conditions</li><li><code>aws:MultiFactorAuthPresent:true</code></li><li>GetSessionToken returns<ul><li>access ID</li><li>secret key</li><li>session token</li><li>expiration date</li></ul></li></ul><h1 id="advanced-iam"><a class="markdownIt-Anchor" href="#advanced-iam"></a> Advanced IAM</h1><h2 id="iam-policies-and-s3-bucket-policies"><a class="markdownIt-Anchor" href="#iam-policies-and-s3-bucket-policies"></a> IAM policies and S3 Bucket policies</h2><ul><li>IAM policies are attached to users, roles and groups</li><li>S3 bucket policies are attached to buckets</li><li>when evaluating if an IAM principal can perform an operation X on a bucket, the <code>union</code> of its assigned IAM policies and S3 bucket policies will be evaluated at the same time.</li></ul><h2 id="dynamic-policies-with-iam"><a class="markdownIt-Anchor" href="#dynamic-policies-with-iam"></a> Dynamic policies with IAM</h2><ul><li>how do you assign each user access to their own foler in S3 bucket?</li><li>create one dynamic policy with IAM</li><li>leverage the special policy variable <code>$&#123;aws:username&#125;</code></li></ul><h2 id="inline-vs-managed-policies"><a class="markdownIt-Anchor" href="#inline-vs-managed-policies"></a> inline vs managed policies</h2><ul><li>AWS managed policy<ul><li>maintained by AWS</li><li>good for power users and administrators</li><li>updated in case of new services and new APIs</li></ul></li><li>customer managed policy<ul><li>best practice, re usable, can be applied to many principals</li><li>version controlled + rollback, central change management</li></ul></li><li>inline<ul><li>strict one to one relationship between policy and principal</li><li>policy is deleted if you delete the IAM principal</li></ul></li></ul><h2 id="granting-a-user-permissions-to-pass-a-role-to-an-aws-service"><a class="markdownIt-Anchor" href="#granting-a-user-permissions-to-pass-a-role-to-an-aws-service"></a> granting a user permissions to pass a role to an AWS service</h2><ul><li>to configure many services, you must pass an IAM role to the service</li><li>the service will later assume the role and perform actions</li><li>for this, you need the IAM permission <code>iam:PassRole</code></li><li>it often comes with <code>iam:GetRole</code> to view the role being passed</li></ul><h3 id="can-a-role-be-passed-to-any-service"><a class="markdownIt-Anchor" href="#can-a-role-be-passed-to-any-service"></a> can a role be passed to any service?</h3><ul><li>no: roles can only be passed to what their trust allows</li><li>a trust policy for the role that allows the service to assume the role</li></ul><h2 id="directory-service-overview"><a class="markdownIt-Anchor" href="#directory-service-overview"></a> Directory service - overview</h2><ul><li>AWS managed Microsoft AD<ul><li>create your own AD in AWS, manage users locally, supports MFA</li><li>establish trust connections with your on permise AD</li></ul></li><li>AD connector<ul><li>directory gateway to redirect to on premises AD</li><li>users are managed on the on premises AD only</li></ul></li><li>Simple AD<ul><li>AD compatible managed directory on AWS</li><li>cannot be joined with on premises AD</li></ul></li></ul><h1 id="kms"><a class="markdownIt-Anchor" href="#kms"></a> KMS</h1><h2 id="encryption"><a class="markdownIt-Anchor" href="#encryption"></a> Encryption</h2><h3 id="encryption-in-flight"><a class="markdownIt-Anchor" href="#encryption-in-flight"></a> Encryption in flight</h3><ul><li>data is encrypted before sending and decrypted after receiving</li><li>SSL certificate help with encryption</li><li>encryption in flight ensures no MITM can happen</li></ul><h3 id="server-side-encryption-at-rest"><a class="markdownIt-Anchor" href="#server-side-encryption-at-rest"></a> server side encryption at rest</h3><ul><li>data is encrypted after being received by the server</li><li>data is decrypted before being sent</li><li>it is stored in an encrypted form thanks to a key</li><li>the encryption / decryption keys must be managed somewhere and the server must have access to it</li></ul><h3 id="client-side-encryption-2"><a class="markdownIt-Anchor" href="#client-side-encryption-2"></a> Client side encryption</h3><ul><li>data is encrypted by the client and never decrypted by the server</li><li>data will be decrypted by a receiving client</li><li>the server should not be able to decrypt the data</li><li>could leverage Envelop encryption</li></ul><h2 id="aws-kms"><a class="markdownIt-Anchor" href="#aws-kms"></a> AWS KMS</h2><ul><li>fully integrated with IAM for authorization</li><li>seamlessly integrated into<ul><li>EBS</li><li>S3</li><li>RedShift</li><li>RDS</li><li>SSM</li></ul></li><li>but you can also use CLI / SDK</li><li>the value in KMS is the CMK used to encrypt data can never be retrieved by user, and the CMK can be rotated for extra security</li><li>KMS can only help in encryping up to 4KB of data per call, if data &gt; 4KB, we need to use Envelope encryption</li><li>to give access to KMS to someone<ul><li>make sure the key policy allows the user</li><li>make sure the IAM policy allows the API calls</li></ul></li></ul><h2 id="cmk-types"><a class="markdownIt-Anchor" href="#cmk-types"></a> CMK Types</h2><ul><li>Symmetric<ul><li>first offering of KMS, single encryption key that is used to encrypt and decrypt</li><li>AWS services that are integrated with KMS use Symmetric CMKs</li><li>necessary for envelope encryption</li><li>you never get access to the key uncrypted (must call KMS API to use)</li></ul></li><li>Asymmetric<ul><li>public and private key pair</li><li>used for encrypt and decrypt</li><li>the public key is downloadable, but you can’t access the private key unencrypted</li><li>use case: encryption outside of AWS by users who can’t call the KMS API</li></ul></li></ul><h2 id="kms-key-policies"><a class="markdownIt-Anchor" href="#kms-key-policies"></a> KMS key policies</h2><ul><li>control access to KMS keys, similar to S3 bucket policies</li><li>difference: you cannot control access without them</li><li>default KMS key policy<ul><li>created if you don’t provide a specific key policy</li><li>compelete access to the key to the root user, which means all IAM users can access the key</li><li>gives access to the IAM policies to the KMS key</li></ul></li><li>custom KMS key policy<ul><li>define users, roles that can access the KMS key</li><li>define who can administer the key</li><li>helpful for cross account access of your KMS key</li></ul></li></ul><h3 id="copying-snapshots-across-accounts"><a class="markdownIt-Anchor" href="#copying-snapshots-across-accounts"></a> copying snapshots across accounts</h3><ul><li>create a snapshot, encrypted with your own CMK</li><li>attach a KMS key policy to authorize cross account access</li><li>share the encrypted snapshot</li><li>create a copy of the snapshot, encrypt it with a KMS key in your account</li><li>create a volume from the snapshot</li></ul><h2 id="envelope-encryption"><a class="markdownIt-Anchor" href="#envelope-encryption"></a> Envelope encryption</h2><ul><li>KMS encrypt API call has limit of 4kb</li><li>if you want to encrypt &gt; 4KB, we need to user envelope encryption</li><li>the main API that will help us is the <code>GenerateDataKey</code> API</li><li>steps<ul><li>Encryption<ol><li>call GenerateDataKey API to get the plaintext date key and encrypted data key (encrypted using your CMK)</li><li>encrypt the big file using the plaintext data key on your local machine (client side)</li><li>create an envelope includes the encrypted date key and the encrypted big file</li></ol></li><li>decryption<ol><li>call Decrypt API, send the encrypted data key to KMS to decrypt using your own CMK</li><li>plaintext data key will be returned</li><li>use the plaintext data key to decrypt your encrypted big file.</li></ol></li></ul></li></ul><h3 id="encryption-sdk"><a class="markdownIt-Anchor" href="#encryption-sdk"></a> Encryption SDK</h3><ul><li>the Encryption SDK implemented envelope encryption for us</li><li>the encryption SDK also exists as a CLI tool we can install</li><li>feature - data key caching<ul><li>re use data keys instead of creating new data keys for each encryption</li><li>helps with reducing the number of API calls to KMS with a security trade off</li></ul></li></ul><h2 id="kms-symmetric-api-summary"><a class="markdownIt-Anchor" href="#kms-symmetric-api-summary"></a> KMS symmetric - API summary</h2><ul><li>encrypt: up to 4KB</li><li>GenerateDataKey: generates a unique symmetric data key<ul><li>returns a plaintext copy of the data key</li><li>and a copy that is encrypted under the CMK that you specify</li></ul></li><li>decrypt: decrypt up to 4KB of data (including data encryption keys)</li><li>GenerateRamdom: returns a random byte string</li></ul><h2 id="quota-limits"><a class="markdownIt-Anchor" href="#quota-limits"></a> Quota limits</h2><ul><li>when you exceed a request quota, you get a <code>ThrottlingException</code></li><li>to respond, use exponential backoff</li><li>for crytographic operations, they share the same quota</li><li>this includes requests made by AWS on your behalf</li><li>for GenerateDataKey, consider using DEK caching from the encryption SDK</li><li>you can also request quotas increase through AWS support</li></ul><h2 id="sse-kms-deep-dive"><a class="markdownIt-Anchor" href="#sse-kms-deep-dive"></a> SSE-KMS deep dive</h2><ul><li>SSE-KMS leverages the GenerateDataKey and Decrypt KMS API calls</li><li>these KMS API calls will show up in CloudTrail, helpful for logging</li><li>to perform SSE-KMS, you need<ul><li>a KMS key policy that authorize the user / role (so we could use the key)</li><li>an IAM policy that authorizes access to KMS (so we could access the AWS KMS service)</li><li>otherwise you will get an access denied error</li></ul></li><li>S3 calls to KMS for SSE-KMS count against your KMS limits<ul><li>if throttling, try exponential backoff</li><li>or request an increase in KMS limits</li></ul></li></ul><h3 id="s3-bucket-policies-force-ssl"><a class="markdownIt-Anchor" href="#s3-bucket-policies-force-ssl"></a> S3 bucket policies - force SSL</h3><ul><li>to force SSL, create an S3 bucket policy with a DENY on the condition <code>aws:SecureTransport=false</code></li></ul><h3 id="s3-bucket-policy-force-encryption-of-sse-kms"><a class="markdownIt-Anchor" href="#s3-bucket-policy-force-encryption-of-sse-kms"></a> S3 bucket policy - force encryption of SSE-KMS</h3><ol><li>deny incorrect encryption header: make sure it includes <code>aws:kms</code></li><li>deny no encryption header to ensure objects are not uploaded un encrypted</li></ol><ul><li>we could also use S3 default encryption of SSE-KMS, in this case, we don’t need the second policy.</li></ul><h2 id="s3-bucket-key-for-sse-kms-encryption"><a class="markdownIt-Anchor" href="#s3-bucket-key-for-sse-kms-encryption"></a> S3 bucket key for SSE-KMS encryption</h2><ul><li>we could enable S3 bucket key to reduce the API calls to KMS directly</li><li>the key is used to encrypt kMS objects with new data keys using envelope encryption</li><li>you will see less KMS cloudtrail events</li></ul><h1 id="ssm-parameter-store"><a class="markdownIt-Anchor" href="#ssm-parameter-store"></a> SSM Parameter Store</h1><ul><li>secure storage for configuration and secrets</li><li>optional seamless encryption using KMS</li><li>serverless, scalable, durable, easy sdk</li><li>version tracking of configurations / secrets</li><li>configuration management using path and IAM</li><li>notifications with CloudWatch events</li><li>integration with CloudFormation</li></ul><h2 id="parameter-policies"><a class="markdownIt-Anchor" href="#parameter-policies"></a> Parameter policies</h2><ul><li>allow to assign a TTL to a parameter to force updating or deleting sensitive data</li><li>can assign multiple policies at a time</li></ul><h1 id="secrets-manager"><a class="markdownIt-Anchor" href="#secrets-manager"></a> Secrets Manager</h1><ul><li>Newer service, meant for storing secrets</li><li>capability to force rotation of secrets every X days</li><li>automate generation of secrets on rotation using lambda function</li><li>integration with RDS</li><li>secrets are encrypted using KMS</li><li>mostly meant for RDS integration</li></ul><h2 id="ssm-parameter-store-vs-secrets-manager"><a class="markdownIt-Anchor" href="#ssm-parameter-store-vs-secrets-manager"></a> SSM Parameter store vs secrets manager</h2><ul><li>secrets manager<ul><li>automatic rotation of secrets with lambda</li><li>lambda function is provided for RDS, Redshift…</li><li>KMS encryption is mandatory</li></ul></li><li>SSM parameter store<ul><li>simple API</li><li>no secret rotation (can be implemented using CloudWatch events and lambda)</li><li>KMS encryption is optional</li><li>can pull a secrets manager secrets using the SSM parameter Store API</li></ul></li></ul><h2 id="cloudwatch-logs-encryption"><a class="markdownIt-Anchor" href="#cloudwatch-logs-encryption"></a> CloudWatch logs - encryption</h2><ul><li>you can encrypt CloudWatch logs with KMS keys</li><li>encryption is enabled at the log group level, by associating a CMK with a log group, either when you create the log group or after it exists</li><li>you cannot associate a CMK with a log group using the CloudWatch console, have to use CLI</li><li>you must use the CloudWatch logs API<ul><li><code>associate-kms-key</code>: if the log group already exists</li><li><code>create-log-group</code>: if the log group doesn’t exist yet</li></ul></li></ul><h1 id="acm-aws-certificate-manager"><a class="markdownIt-Anchor" href="#acm-aws-certificate-manager"></a> ACM (AWS certificate manager)</h1><ul><li>provision, manage, and deploy SSL / TLS certificates</li><li>used to provide in flight encryption for websites</li><li>supports both public and private TLS certificates</li><li>free of charge for public TLS certificates</li><li>automatic TLS certificate renewal</li><li>integration with<ul><li>ELB</li><li>CloudFront</li><li>APIs on API Gateway</li></ul></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> AWS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS SAA Review</title>
      <link href="2021/08/09/AWS-SAA-Review/"/>
      <url>2021/08/09/AWS-SAA-Review/</url>
      
        <content type="html"><![CDATA[<h1 id="i-passed"><a class="markdownIt-Anchor" href="#i-passed"></a> I PASSED!</h1><p><img src="/../images/AWS-SAA-Review/AWSCertifiedSolutionsArchitectAssociateCertificate.png" alt="" /><br /><a href="https://www.credly.com/badges/58d1f023-d657-470e-a22e-fbe8ddf4124b?source=linked_in_profile">View My Certificate</a></p><h1 id="getting-started"><a class="markdownIt-Anchor" href="#getting-started"></a> Getting Started</h1><h2 id="aws-regions"><a class="markdownIt-Anchor" href="#aws-regions"></a> AWS Regions</h2><ul><li>AWS has regions all aroung the world</li><li>Names can be us-east-1, eu-west-3…</li><li>A region is a cluster of data centers</li><li>Most AWS services are regoin-scoped</li></ul><h2 id="how-to-choose-an-aws-region"><a class="markdownIt-Anchor" href="#how-to-choose-an-aws-region"></a> How to choose an AWS Region?</h2><ul><li>Compliance: with data governance and legal requirements, data never leaves a region without your explicit permission</li><li>Proximity to customers: reduced latency</li><li>Available services within a region: new services and new features aren’t available in every region</li><li>Pricing: pricing varies region to region and is transparent in the service pricing page</li></ul><h2 id="aws-availability-zones"><a class="markdownIt-Anchor" href="#aws-availability-zones"></a> AWS Availability Zones</h2><ul><li>Each region has many AZs example:<ul><li>ap-southeast-2a</li><li>ap-southeast-2b</li><li>ap-southeast-2c</li></ul></li><li>Each AZ is one or more discrete data centers with redundant power, networking and connectivity</li><li>they are separate from each other, so that they are isolated from disasters</li><li>they are connected with high bandwidth, ultra low latency networking</li></ul><h2 id="aws-points-of-presence-edge-locations"><a class="markdownIt-Anchor" href="#aws-points-of-presence-edge-locations"></a> AWS Points of Presence (Edge locations)</h2><ul><li>Content is delivered to end users with lower latency</li></ul><h1 id="iam-and-aws-cli"><a class="markdownIt-Anchor" href="#iam-and-aws-cli"></a> IAM and AWS CLI</h1><h2 id="iam"><a class="markdownIt-Anchor" href="#iam"></a> IAM</h2><ul><li>Identity and Access Management, Global service</li><li>Root Account: created by default, shouldn’t be used or shared</li><li>Users are people within your organization, and can be grouped</li><li>Groups only contain users, not other groups</li><li>Users don’t have to belong to a group, and user can belong to multiple groups</li></ul><h3 id="iam-permissions"><a class="markdownIt-Anchor" href="#iam-permissions"></a> IAM Permissions</h3><ul><li>Users or Groups can be assigned JSON documents called policies</li><li>These policies define the permissions of the users</li><li>In AWS you apply the least privilege principle, don’t give more permissions than a user needs</li></ul><h3 id="iam-policies-structure"><a class="markdownIt-Anchor" href="#iam-policies-structure"></a> IAM Policies Structure</h3><ul><li>Consist of<ul><li>Version: policy language version, always include ‘2012-10-17’</li><li>Id: an identifier for the policy (optional)</li><li>Statement: one or more individual statements (required)</li></ul></li><li>Statements consists of<ul><li>Sid: an identifier for the statement (optional)</li><li>Effect: whether the statement allows or denies access (Allow, Deny)</li><li>Principal: account/user/role to which this policy applied to</li><li>Action: list of actions this policy allows or denies</li><li>Resource: list of resources to which the actions applied to</li><li>Condition: conditions for when this policy is in effect (optional)</li></ul></li></ul><h3 id="how-can-users-access-aws"><a class="markdownIt-Anchor" href="#how-can-users-access-aws"></a> How can users access AWS?</h3><ol><li>AWS Management Console: protected by password + MFA</li><li>AWS Command Line Interface: protected by access keys</li><li>AWS SDK: for code, protected by access keys</li></ol><ul><li>Access key ID = username</li><li>Secret access key = password</li></ul><h3 id="iam-roles-for-services"><a class="markdownIt-Anchor" href="#iam-roles-for-services"></a> IAM Roles for services</h3><ul><li>Some AWS service will need to perform actions on your behalf</li><li>we will assign permissions to AWS services with IAM Roles</li><li>Common roles:<ul><li>EC2 instance roles</li><li>lambda function roles</li><li>roles for CloudFormation</li></ul></li></ul><h3 id="iam-security-tools"><a class="markdownIt-Anchor" href="#iam-security-tools"></a> IAM Security Tools</h3><ul><li>IAM credentials report (account-level)<ul><li>a report that lists all your account’s users and the status of their various credentials</li></ul></li><li>IAM Access Advisor (user-level)<ul><li>Access Advisor shows the service permissions granted to a user and when those services were last accessed</li><li>you can use this information to revise your policies</li></ul></li></ul><h3 id="iam-guidelines-and-best-practices"><a class="markdownIt-Anchor" href="#iam-guidelines-and-best-practices"></a> IAM Guidelines and Best practices</h3><ul><li>Don’t user root account except for AWS account setup</li><li>One physical user = one AWS user</li><li>assign users to groups and assign permissions to groups</li><li>create a strong password policy</li><li>use and enforce the use of MFA</li><li>create and use roles for giving permissions to AWS services</li><li>use access keys for CLI and SDK</li><li>Audit permissions of your account with the IAM Credential Report</li><li>Never share IAM users and access keys</li></ul><h1 id="ec2"><a class="markdownIt-Anchor" href="#ec2"></a> EC2</h1><ul><li>EC2 is one of the most popular of AWS offering</li><li>EC2 = Elastic Compute Cloud = Infrastructure as a Service</li><li>It mainly consists in the capability of<ul><li>Renting virtual machines (EC2)</li><li>Storing data on virtual drives (EBS)</li><li>Distributing load across machines (ELB)</li><li>Scaling the services using an auto-scaling group (ASG)</li></ul></li><li>Knowing EC2 is fundamental to understand how to Cloud works</li></ul><h2 id="ec2-instance-types-overview"><a class="markdownIt-Anchor" href="#ec2-instance-types-overview"></a> EC2 Instance Types - Overview</h2><ul><li>you can use different types of EC2 instances that are optimised for different use cases</li><li>e.g. m5.2xlarge<ul><li>m: instance class</li><li>5: generation</li><li>2xlarge: size within the instance class</li></ul></li></ul><h3 id="general-purpose"><a class="markdownIt-Anchor" href="#general-purpose"></a> General Purpose</h3><ul><li>Great for a diversity of workloads such as web servers or code repositories</li><li>Balance between<ul><li>Compute</li><li>Memory</li><li>Networking</li></ul></li></ul><h3 id="compute-optimized"><a class="markdownIt-Anchor" href="#compute-optimized"></a> Compute Optimized</h3><ul><li>Great for compute intensive tasks that require high performance processors<ul><li>Batch processing workloads</li><li>media transcoding</li><li>high performance web servers</li><li>high performance computing</li><li>scientific modeling and machine learning</li><li>dedicated gaming servers</li></ul></li></ul><h3 id="memory-optimized"><a class="markdownIt-Anchor" href="#memory-optimized"></a> Memory Optimized</h3><ul><li>Fast performance for workloads that process large data sets in memory</li><li>high performance, relational/non-relational databases</li><li>distributed web scale cache stores</li><li>in memory databases optimized for BI</li><li>applications performing real time processing of big unstructured data</li></ul><h3 id="storage-optimized"><a class="markdownIt-Anchor" href="#storage-optimized"></a> Storage Optimized</h3><ul><li>great for storage intensive tasks that require high, sequential read and write access to large data sets on local storage</li><li>high frequency online transaction processing systems</li><li>relational and NoSQL databases</li><li>cache for in memory databases</li><li>data warehousing applications</li><li>distributed file systems</li></ul><h2 id="security-groups"><a class="markdownIt-Anchor" href="#security-groups"></a> Security Groups</h2><ul><li>the fundamental of network security in AWS</li><li>they control how traffic is allowed into or out of our EC2 instance</li><li>security groups only contain allow rules</li><li>security groups rules can reference by IP or by security group (inbound/outbound rules)</li></ul><h3 id="good-to-know"><a class="markdownIt-Anchor" href="#good-to-know"></a> Good to know</h3><ul><li>security groups can be attached to multiple instances and one instance can have multiple security groups attach to it</li><li>security group are locked down to a region and VPC</li><li>security group live outside the EC2, if traffic is blocked, the EC2 instacne won’t see it (doesn’t know it tried to get in)</li><li>if your application is not accessible (time out), then its a security group issue</li><li>if your application gives a connection failed error, then its an application error or its not launched</li><li>all inbound traffic is blocked by default</li><li>all outbound traffic is authorized by default</li></ul><h2 id="classic-ports-to-know"><a class="markdownIt-Anchor" href="#classic-ports-to-know"></a> Classic Ports to know</h2><ul><li>22 = SSH (Secure Shell) - log into a Linux instance</li><li>21 = FTP (File Transfer Protocol) - upload files into a file share</li><li>22 = SFTP (Secure File Transfer Protocol) - upload files using SSH</li><li>80 = HTTP - access unsecured websites</li><li>443 = HTTPS - access secured websites</li><li>3389 = RDP (Remote Desktop Protocol) - log into a Windows instance</li></ul><h2 id="ec2-instances-purchasing-options"><a class="markdownIt-Anchor" href="#ec2-instances-purchasing-options"></a> EC2 Instances purchasing options</h2><ul><li>on-demand instance: short workload, predictable pricing</li><li>reserved, minimum 1 year:<ul><li>reserved instances: long workloads</li><li>convertible reserved instances: long workloads with flexible instances</li><li>scheduled reserved instances: example - every Thursday between 3 and 6 pm</li></ul></li><li>Spot instance: short workloads, cheap and can lose instances (less reliable)</li><li>dedicated hosts: book an entire physical server, control instance placement</li></ul><h3 id="ec2-on-demand"><a class="markdownIt-Anchor" href="#ec2-on-demand"></a> EC2 on demand</h3><ul><li><p>pay for what you use</p><ul><li>linux - billing per second, after the first minute</li><li>all other os - billing per hour</li></ul></li><li><p>has the highest cost but no upfront payment</p></li><li><p>no long-term commitment</p></li><li><p>recommended for short term and un-interrupted workloads, where you can’t predict how the application will behave.</p></li></ul><h3 id="ec2-reserved-instances"><a class="markdownIt-Anchor" href="#ec2-reserved-instances"></a> EC2 reserved instances</h3><ul><li>up to 75% discount compared to on demand</li><li>reservation period: 1 year or 3 year2</li><li>purchasing options: no upfront / partial upfront / all upfront</li><li>reserve a specific instance type</li><li>recommended for steady state usage applications (think database)</li></ul><h4 id="convertible-reserved-instance"><a class="markdownIt-Anchor" href="#convertible-reserved-instance"></a> Convertible reserved instance</h4><ul><li>can change the EC2 instance type</li><li>up to 54% discount</li></ul><h4 id="scheduled-reserved-instances"><a class="markdownIt-Anchor" href="#scheduled-reserved-instances"></a> scheduled reserved instances</h4><ul><li>launch within time window you reserve</li><li>when you require a fraction of day / week / month</li><li>still commitment over 1 to 3 years</li></ul><h3 id="ec2-spot-instance"><a class="markdownIt-Anchor" href="#ec2-spot-instance"></a> EC2 Spot instance</h3><ul><li><p>can get a discount of up to 90% compared to on demand</p></li><li><p>instances that you can lose at any point of time if your max price is less than the current spot price</p></li><li><p>the MOST cost efficient instances in AWS</p></li><li><p>useful for workloads that are resilient to failure</p></li><li><p>not suitable for critical jobs or databases</p></li></ul><h4 id="spot-instance-requests"><a class="markdownIt-Anchor" href="#spot-instance-requests"></a> Spot instance requests</h4><ul><li>define max spot price and get the instance while current spot price &lt; max<ul><li>the hourly spot price varies based on offer and capacity</li><li>if the current spot price &gt; your max price you can choose to stop or terminate your instance with a 2 minutes grace period</li></ul></li><li>other strategy: spot block<ul><li>block spot instance during a specified time frame (1 to 6 hours) without interruptions</li><li>in rare situations, the instance may be reclaimed</li></ul></li><li>cancel the spot instance request before terminate the spot instances</li></ul><h4 id="spot-fleets"><a class="markdownIt-Anchor" href="#spot-fleets"></a> Spot fleets</h4><ul><li>spot fleets = set of spot instances + (optional) on demand instances</li><li>the spot fleet will try to meet the target capacity with price constraints<ul><li>define possible launch pools: instance type, OS, AZ</li><li>can have multiple launch pools, so that the fleet can choose</li><li>spot fleet stops launching instnaces when reaching capacity or max cost</li></ul></li><li>strategies to allocate spot instances<ul><li>lowest price: from the pool with the lowest price (cost optimization, short workload)</li><li>diversified: distributed across all pools (great for availability, long workloads)</li><li>capacity optimized: pool with the optimal capacity for the number of instances</li></ul></li><li>spot fleets allow us to automatically request spot instance with the lowest price</li></ul><h3 id="ec2-dedicated-hosts"><a class="markdownIt-Anchor" href="#ec2-dedicated-hosts"></a> EC2 dedicated hosts</h3><ul><li><p>an Amazon EC2 dedicated host is a physical server with EC2 instance capacity fully dedicated to your use, dedicated hosts can help you address compliance requirements and reduce costs by allowing you to use your existing server-bound software licenses</p></li><li><p>allocated for your account for a 3 year period reservation</p></li><li><p>more expensive</p></li><li><p>useful for software that have complicated licensing model (BYOL - bring your own license)</p></li><li><p>or for companies that have strong regulatory or compliance needs</p></li></ul><h2 id="elastic-ip"><a class="markdownIt-Anchor" href="#elastic-ip"></a> Elastic IP</h2><ul><li><p>when you stop and then start an EC2 instance, it can change its public IP</p></li><li><p>if you need to have a fixed public IP for your instance, you need an Elastic IP</p></li><li><p>an Elastic IP is a public IPv4 IP you own as long as you don’t delete it</p></li><li><p>you can attach it to one instance at a time</p></li><li><p>with an Elastic IP, you can mask the failure of an instance or software by rapidly remapping the address to another instance in your account (not common)</p></li><li><p>you can only have 5 Elastic IP in your account</p></li><li><p>Overall, try to avoid using Elastic IP</p><ul><li>they often reflect poor architectrual decisions</li><li>instead, use a random public IP and register a DNS name to it</li><li>use a load balancer and don’t use a public IP</li></ul></li></ul><h2 id="placement-groups"><a class="markdownIt-Anchor" href="#placement-groups"></a> Placement Groups</h2><ul><li>Sometimes you want control over the EC2 instance placement strategy</li><li>when you create a placement group, you specify one of the following strategies for the group<ul><li>Cluster: clusters instances into a low latency group in a single AZ</li><li>Spread: spreads instances across underlying hardware (max 7 instances per group per AZ) - critical applications</li><li>partition: spreads instances across many different partitions (which rely on different sets of racks) within an AZ, Scales to 100 of EC2 instances per group (Hadoop, Cassandra, Kafka), the instances in a partition do not share racks with the instances in the other partitions, a partition failure can affect many EC2 but won’t affect other partitions</li></ul></li></ul><h2 id="elastic-network-interfaces-eni"><a class="markdownIt-Anchor" href="#elastic-network-interfaces-eni"></a> Elastic Network Interfaces (ENI)</h2><ul><li>logical component in a VPC that represents a virtual network card</li><li>the ENI can have the following attributes<ul><li>Primary private IPv4, one or more secondary IPv4</li><li>One Elastic IP per private IPv4</li><li>one public IPv4</li><li>one or more security groups</li><li>a MAC address</li></ul></li><li>you can create ENI independently and attach them on the fly on EC2 instances for failover</li><li>bound to a specific AZ</li></ul><h2 id="ec2-hibernate"><a class="markdownIt-Anchor" href="#ec2-hibernate"></a> EC2 Hibernate</h2><ul><li><p>Stop: the data on disk (EBS) is kept intact in the next start</p></li><li><p>Terminate: any EBS volums (root) also setup to be destroyed is lost</p></li><li><p>First start: the OS boots and the EC2 user data script is run</p></li><li><p>Following starts: the OS boots up</p></li><li><p>the your application starts, caches get warmed up and that can take time</p></li><li><p>Introducing EC2 Hibernate</p><ul><li>RAM state is preserved</li><li>the instance boot is much faster (the OS is not stopped / restarted)</li><li>under the hood: the RAM state is written to a file in the root EBS volume</li><li>the root EBS volume must be encrypted</li></ul></li><li><p>Use cases</p><ul><li>long running process</li><li>saving the RAM state</li><li>servcies that take time to initialize</li></ul></li></ul><h2 id="ec2-nitro"><a class="markdownIt-Anchor" href="#ec2-nitro"></a> EC2 Nitro</h2><ul><li>underlying platform for the next generation of EC2 instances</li><li>new virtualization technology</li><li>allows for better performance<ul><li>better networking options</li><li>Higher Speed EBS</li></ul></li><li>better underlying security</li></ul><h2 id="ec2-vcpu"><a class="markdownIt-Anchor" href="#ec2-vcpu"></a> EC2 vCPU</h2><ul><li>EC2 instance comes with a combination of RAM and vCPU</li><li>in some cases, you may want to change the vCPU options<ul><li>change the number of CPU cores</li><li>chagne the number of vCPUs (threads) per core</li></ul></li><li>only specified during instance launch</li></ul><h2 id="ec2-capacity-reservations"><a class="markdownIt-Anchor" href="#ec2-capacity-reservations"></a> EC2 capacity reservations</h2><ul><li>ensure you have EC2 capacity when needed</li><li>manual or planned end date for the reservation</li><li>no need for 1 or 3 year commitment</li><li>capacity access is immediate, you get billed as soon as it starts</li><li>combine with reserved instances and savings plans to do cost saving</li></ul><h2 id="ec2-ebs"><a class="markdownIt-Anchor" href="#ec2-ebs"></a> EC2 EBS</h2><ul><li>an EBS volume is a network drive you can attach to your instances while they run</li><li>it allows your instances to persist data, even after their termination</li><li>they can only be mounted to one instance at a time (in some cases, some EBS can be attached to multiple EC2 instances at same time)</li><li>they are bound to a specific AZ</li><li>think of them as a network USB stick</li></ul><h3 id="ebs-volume"><a class="markdownIt-Anchor" href="#ebs-volume"></a> EBS volume</h3><ul><li>its a network drive<ul><li>it uses the network to communicate the instance, which means there might be a bit of latency</li><li>it can be detached from an EC2 instance and attached to another one quickly</li></ul></li><li>its locked down to an AZ<ul><li>an EBS volume in us-east-1a cannot be attached to an instance in us-east-1b</li><li>to move a volume across, you first need to snapshot it</li></ul></li><li>have a provisioned capacity<ul><li>you get billed for all the provisioned capacity</li><li>you can increase the capacity of the drive over time</li></ul></li></ul><h3 id="ebs-volume-types"><a class="markdownIt-Anchor" href="#ebs-volume-types"></a> EBS volume types</h3><ul><li>gp2 / gp3: general purpose SSD<ul><li>gp3: newer generation, IOPS and throughput are independet</li><li>gp2: IOPS and throughput are linked</li></ul></li><li>io1 / io2: highest performance SSD</li><li>st1: low cost HDD, for throughput intensive workloads</li><li>sc1: lowest cost HDD</li><li>EBS volumes are characterized in Size / Throughput / IOPS</li></ul><h3 id="ebs-multi-attach-io1io2-family"><a class="markdownIt-Anchor" href="#ebs-multi-attach-io1io2-family"></a> EBS multi-attach - io1/io2 family</h3><ul><li>attach the same EBS volume to multiple EC2 instances in the same AZ</li><li>each instance has full read and write permissions to the volume</li><li>applications must manage concurrent write operations</li><li>must use a file system thta’s cluster-aware</li></ul><h3 id="ebs-encryption"><a class="markdownIt-Anchor" href="#ebs-encryption"></a> EBS encryption</h3><ul><li>when you create an encrypted EBS volume, you get the following<ul><li>data at rest is encrypted inside the volume</li><li>all the data in flight mobing between the instance and the volume is encrypted</li><li>all snapshots are encrypted</li><li>all volumes created from the snapshot are encryped</li></ul></li><li>encryption and decryption are handled transparently</li><li>encryption has a minimal impact on latency</li><li>EBS encryption leverages keys from KMS (AES-256)</li><li>copying an unencrypted snapshot allows encryption</li></ul><h3 id="ebs-raid"><a class="markdownIt-Anchor" href="#ebs-raid"></a> EBS RAID</h3><h4 id="raid-0"><a class="markdownIt-Anchor" href="#raid-0"></a> RAID 0</h4><ul><li>increase performance</li><li>combining 2 or more volumes and getting the total disk space and I/O</li><li>but if one disk fails, all the data is failed</li><li>using this, we can have a very big disk with a lot of IOPS</li></ul><h4 id="raid-1"><a class="markdownIt-Anchor" href="#raid-1"></a> RAID 1</h4><ul><li>increase fault tolerance</li><li>mirroring a volume to another</li><li>we have to send the data to two EBS volume at the same time (2 * network)</li></ul><h3 id="ebs-delete-on-termination"><a class="markdownIt-Anchor" href="#ebs-delete-on-termination"></a> EBS delete on termination</h3><ul><li>controls the EBS behaviour when an EC2 instance terminates<ul><li>by default, the root EBS volume is delete (attribute enabled)</li><li>by default, any other attached EBS volume is not deleted (attribute disabled)</li></ul></li><li>this can be controlled by the AWS console / CLI</li><li>use case: preseve root volume when instance is terminated (disable the attribute)</li></ul><h2 id="ebs-snapshots"><a class="markdownIt-Anchor" href="#ebs-snapshots"></a> EBS Snapshots</h2><ul><li>make a backup (snapshot) of your EBS volume at a point of time</li><li>not necessary to detach volume to do snapshot, but recommended</li><li>can copy snapshots across AZ or Region</li><li>can create volume from snapshot</li></ul><h2 id="efs-elastic-file-system"><a class="markdownIt-Anchor" href="#efs-elastic-file-system"></a> EFS - Elastic File System</h2><ul><li>Managed NFS (network file system) that can be mounted on many EC2</li><li>EFS works with EC2 instances in multi-AZ</li><li>highly avialble, scalable, expensive, pay per use</li><li>uses security group to control access to EFS</li><li>compatible with Linux based AMI (not Windows)</li><li>encryption at rest using KMS</li><li>to mount EFS to EC2, you need to add EC2 security group as a inbound rule in EFS security group</li></ul><h3 id="performance-and-storage-class"><a class="markdownIt-Anchor" href="#performance-and-storage-class"></a> Performance and Storage Class</h3><ul><li>Performance mode<ul><li>general purpose</li><li>MAX I/O</li></ul></li><li>Throughput mode<ul><li>bursting</li><li>provisioned</li></ul></li><li>Storage tiers<ul><li>standard</li><li>infrequent access, cost to retrieve files, lower price to store</li></ul></li></ul><h2 id="ami-overview"><a class="markdownIt-Anchor" href="#ami-overview"></a> AMI Overview</h2><ul><li>Amazon Machien Image</li><li>a customization of an EC2 instance<ul><li>you add your own software, configuration, operating system etc…</li><li>faster boot / configuration time because all your software is pre-packaged</li></ul></li><li>AMI are built for a specific region and can be copied across regions</li><li>you can launch EC2 instance from<ul><li>public AMI: provided by AWS</li><li>your own AMI: you make and maintain them yourself</li><li>AWS marketplace AMI: an AMI someone else made</li></ul></li></ul><h2 id="ec2-instance-store"><a class="markdownIt-Anchor" href="#ec2-instance-store"></a> EC2 instance store</h2><ul><li>EBS volumes are network drives with good but limited performance</li><li>if you need a high performance hardware disk, use EC2 instance store</li><li>better I/O performance</li><li>EC2 instance store lose their storage if they are stopped (ephemeral)</li><li>good for buffer / cache / scratch data / temporary content</li><li>risk of data loss if hardware fails</li><li>backups and replication are your responsibility</li></ul><h2 id="ec2-metadata"><a class="markdownIt-Anchor" href="#ec2-metadata"></a> EC2 Metadata</h2><ul><li>AWS EC2 instance metadata is powerful but one of the least known features to developers</li><li>it allows EC2 instance to learn about themselves without using an IAM role for that purpose</li><li>the URL is <code>http://169.254.169.254/latest/meta-data</code></li><li>you can retrieve the IAM role name from the metadata, but you CANNOT retrieve the IAM policy</li></ul><h1 id="elastic-load-balancer"><a class="markdownIt-Anchor" href="#elastic-load-balancer"></a> Elastic Load Balancer</h1><h2 id="what-is-load-balancing"><a class="markdownIt-Anchor" href="#what-is-load-balancing"></a> What is load balancing?</h2><ul><li>load balancers are servers that forward internet traffic to multiple servers (EC2 instances) downstream</li></ul><h2 id="why-use-a-load-balancer"><a class="markdownIt-Anchor" href="#why-use-a-load-balancer"></a> Why use a load balancer?</h2><ul><li><p>Spread load across multiple downstream instances</p></li><li><p>expose a single point of access (DNS) to your application</p></li><li><p>seamlessly handle failures of downstream instances</p></li><li><p>do regular health checks to your instances</p></li><li><p>provide SSL termination (HTTPS) for your websites</p></li><li><p>enforce stickness with cookies</p></li><li><p>high availability across zones</p></li><li><p>separate public traffic from private traffic</p></li><li><p>An ELB is a managed load balancer</p><ul><li>AWS guarantees that it will be working</li><li>AWS takes care of upgrades, maintenance, high availability</li><li>AWS provides only a few configuration knobs</li></ul></li><li><p>it costs less to setup your own load balancer but it will be a lot more effort on your end</p></li><li><p>it is integrated with many AWS offering / services</p></li></ul><h2 id="health-checks"><a class="markdownIt-Anchor" href="#health-checks"></a> Health Checks</h2><ul><li>Health Checks are crucial for load balancers</li><li>they enable the load balancer to know if instances it forwards traffic to are available to reply to requests</li><li>the health check is done on a port and a route (/health is common)</li><li>if the response is not 200, then the instance is unhealthy</li></ul><h2 id="classic-load-balanceers-v1"><a class="markdownIt-Anchor" href="#classic-load-balanceers-v1"></a> Classic Load Balanceers (v1)</h2><ul><li>supports TCP (layer 4), HTTP and HTTPS (layer 7)</li><li>health checks are TCP or HTTP based</li></ul><h2 id="application-load-balancer-v2"><a class="markdownIt-Anchor" href="#application-load-balancer-v2"></a> Application Load Balancer (v2)</h2><ul><li>Application load balancer is layer 7 (HTTP)</li><li>load balancing to multiple HTTP applications across machines (target groups)</li><li>load balancing to multiple applications on the same machine (containers)</li><li>support for HTTP/2 and WebSocket</li><li>Support redirects (from HTTP to HTTPS)</li><li>Routing tables to differnt target groups<ul><li>routing based on path in URL (<a href="http://example.com/users">example.com/users</a> &amp; <a href="http://example.com/posts">example.com/posts</a>)</li><li>routing based on hostname in URL (<a href="http://one.example.com">one.example.com</a> &amp; <a href="http://other.example.com">other.example.com</a>)</li><li>routing based on query string, headers (<a href="http://example.com/users?id=123&amp;other=false">example.com/users?id=123&amp;other=false</a>)</li></ul></li><li>ALB are a great fit for micro services and container based application (Docker and Amazon ECS)</li><li>Has a port mapping feature to redirect to a dynamic port in ECS</li><li>in comparison, we would need multiple CLB, one for each application</li></ul><h3 id="target-groups"><a class="markdownIt-Anchor" href="#target-groups"></a> Target Groups</h3><ul><li>EC2 instances can be managed by an Auto Scaling Group - HTTP</li><li>ECS tasks (managed by ECS itself) - HTTP</li><li>Lambda function - HTTP request is translated into a JSON event</li><li>IP addresses - must be private IPs</li><li>ALB can route to multiple target groups</li><li>health checks are at the target group level</li></ul><h2 id="network-load-balancer-v2"><a class="markdownIt-Anchor" href="#network-load-balancer-v2"></a> Network Load Balancer (v2)</h2><ul><li>network load balancer (layer 4)<ul><li>forward TCP and UDP traffic to your instance</li><li>handle millions of request per second</li><li>less latency ~ 100 ms (vs 400 ms for ALB)</li></ul></li><li>NLB has one static IP per AZ, and supports assigning Elastic IP (helpful for whitelisting specific IP)</li><li>NLB are used for extreme performance, TCP or UDP traffic</li><li>Not included in AWS free tier</li></ul><h2 id="sticky-sessions-session-affinity"><a class="markdownIt-Anchor" href="#sticky-sessions-session-affinity"></a> Sticky Sessions (Session Affinity)</h2><ul><li><p>it is possible to implement stickness so that the same client is always redirected to the same instance behind a load balancer</p></li><li><p>this works for CLB and ALB</p></li><li><p>the cookie used for stickness has an expiration date you control</p></li><li><p>use case: make sure the user doesn’t lost his session data</p></li><li><p>enabling stickness may bring imbalance to the load over the backend EC2 instances</p></li><li><p>Application based cookies</p><ul><li>custom cookie<ul><li>generated by the target</li><li>can include any custom attributes required by the application</li><li>cookie name must be specified individually for each target group</li><li>don’t use AWSALB, AWSALBAPP, AWSALBTG (reserved for use by the ELB)</li></ul></li><li>application cookie<ul><li>generated by the load balancer</li><li>cookie name is AWSALBAPP</li></ul></li></ul></li><li><p>Duration based cookie</p><ul><li>cookie generated by the load balancer</li><li>cookie name is AWSALB for ALB, AWSELB for CLB</li></ul></li></ul><h2 id="cross-zone-load-balancing"><a class="markdownIt-Anchor" href="#cross-zone-load-balancing"></a> Cross Zone Load Balancing</h2><ul><li>each load balancer instance distribute evenly across all registered instances in all AZ</li><li>ALB<ul><li>always on (can’t be disabled)</li><li>no charges for inter AZ data</li></ul></li><li>NLB<ul><li>disabled by default</li><li>you pay charges for inter AZ data if enabled</li></ul></li><li>CLB<ul><li>Through console =&gt; enabled by default</li><li>through CLI / API =&gt; disabled by default</li><li>no charges</li></ul></li></ul><h2 id="ssltls"><a class="markdownIt-Anchor" href="#ssltls"></a> SSL/TLS</h2><ul><li><p>an SSL certificate allows traffic between your clients and your load balancer to be encrypted in transit</p></li><li><p>SSL refers to Secure Sockets Layer, used to encrypt connections</p></li><li><p>TLS refers to Transport Layer Security, which is a newer version</p></li><li><p>TLS certificate are mainly used, but people still refer as SSL</p></li><li><p>public SSL certificates are issued by Certificate Authorities (CA)</p></li><li><p>SSL certificates have an expiration date and must be renewed</p></li><li><p>the load balancer uses an X.509 certificate (SSL/TLS server certificate)</p></li><li><p>you can manage certificates using ACM (AWS Certificate Manager)</p></li><li><p>You can create upload your own certificate</p></li><li><p>HTTPS listner</p><ul><li>you must specify a default certificate</li><li>you can add an optional list of certs to support multiple domains</li><li>clients can use SNI (Server Name Indication) to specify the host name they reach</li><li>ability to specify a security policy to support older version of SSL/TLS</li></ul></li></ul><h3 id="ssl-server-name-indication"><a class="markdownIt-Anchor" href="#ssl-server-name-indication"></a> SSL - Server Name Indication</h3><ul><li>SNI solves the problem of loading multiple SSL certificate onto one web server (to serve multiple website)</li><li>its newer protocol, and requires the client to indicate the hostname of the target server in the initial SSL handshake</li><li>the server will then find the correct certificate, or return the default one</li><li>Only works for ALB and NLB, CloudFront</li><li>doesn’t work for CLB</li></ul><h2 id="elb-connection-draining"><a class="markdownIt-Anchor" href="#elb-connection-draining"></a> ELB Connection Draining</h2><ul><li>Time to complete in-flight requests while the instance is de-registering or unhealthy</li><li>stops sending new requests to the instance which is de-registering</li><li>between 1 to 3600 seconds, default is 300 seconds</li><li>can be disabled (set to zero)</li><li>set to a low value if your requests are short</li></ul><h1 id="auto-scaling-group"><a class="markdownIt-Anchor" href="#auto-scaling-group"></a> Auto Scaling Group</h1><ul><li><p>in real life, the load on your websites and application can change</p></li><li><p>in the cloud, you can create and get rid of servers very quickly</p></li><li><p>the goal of an Auto Scaling Group is to</p><ul><li>scale out to match an increased load</li><li>scale in to match an decreased load</li><li>ensure we have a minimum and maximum number of machines running</li><li>automatically register new instances to a load balancer</li></ul></li></ul><h2 id="asg-attributes"><a class="markdownIt-Anchor" href="#asg-attributes"></a> ASG attributes</h2><ul><li>A launch configuration<ul><li>AMI + instance type</li><li>EC2 user data</li><li>EBS volumes</li><li>Security groups</li><li>SSH key pair</li></ul></li><li>min size / max size / initial capacity</li><li>network + subnets information</li><li>load balancer information</li><li>scaling policies</li></ul><h2 id="auto-scaling-alarms"><a class="markdownIt-Anchor" href="#auto-scaling-alarms"></a> Auto Scaling Alarms</h2><ul><li>it is possible to scale an ASG based on CloudWatch alarms</li><li>an alarm monitors a metric (such as average CPU)</li><li>metrics are computed for the overall ASG instances</li></ul><h2 id="auto-scaling-new-rules"><a class="markdownIt-Anchor" href="#auto-scaling-new-rules"></a> Auto Scaling New Rules</h2><ul><li>it is now possible to define better auto scaling rules that are directly managed by EC2<ul><li>target average CPU usage</li><li>number of requests on the ELB per instance</li><li>average network in</li><li>average network out</li></ul></li><li>these rules are easier to setup and can make more sense</li></ul><h2 id="auto-scaling-custom-metric"><a class="markdownIt-Anchor" href="#auto-scaling-custom-metric"></a> Auto Scaling Custom Metric</h2><ol><li>send custom metric from application on EC2 to CloudWatch</li><li>Create CloudWatch alarm to react to low / high values</li><li>use the CloudWatch alarm as the scaling policy for ASG</li></ol><h2 id="good-to-know-2"><a class="markdownIt-Anchor" href="#good-to-know-2"></a> Good to know</h2><ul><li>scaling policies can be on CPU, network… and can even be on custom metrics or based on a schedule</li><li>ASGs use launch configurations or launch templates</li><li>to update an ASG, you must provide a new launch configuration / launch template</li><li>IAM roles attached to an ASG will get assigned to EC2 instances</li><li>ASG are free, you pay for the underlying resources being launched</li><li>having instances under an ASG means that if they get terminated for whatever reason, the ASG will automatically create a new one as a replacement.</li><li>ASG can terminate instances marked as unhealthy by an ELB (and then replace them)</li></ul><h2 id="auto-scaling-groups-dynamic-scaling-policies"><a class="markdownIt-Anchor" href="#auto-scaling-groups-dynamic-scaling-policies"></a> Auto Scaling Groups - Dynamic Scaling Policies</h2><ul><li>target tracking scaling<ul><li>most simple and easy to setup</li><li>example: I want to average ASG CPU to stay at around 40%</li></ul></li><li>Simple / Step Scaling<ul><li>When a CloudWatch alarm is triggered (example: CPU &gt; 70%), then add 2 units</li><li>when a CloudWatch alarm is triggered (example: CPU &lt; 30%), then remove 1 unit</li></ul></li><li>Scheduled Actions<ul><li>anticipate a scaling based on known usage patterns</li><li>example: increase the min capacity to 10 at 5pm on Fridays</li></ul></li><li>predictive scaling<ul><li>continuously forecast load and schedule scaling ahead</li></ul></li></ul><h2 id="good-metrics-to-scale-on"><a class="markdownIt-Anchor" href="#good-metrics-to-scale-on"></a> Good metrics to scale on</h2><ul><li>CPU Utilization<ul><li>average CPU utilization across your instances</li></ul></li><li>Request Count Per Target<ul><li>to make sure the number of requests per EC2 instances is stable</li></ul></li><li>Average network in / out<ul><li>if your application is network bound (heavy downloads / uploads)</li></ul></li><li>Any custom metric that you push using CloudWatch</li></ul><h2 id="scaling-cooldowns"><a class="markdownIt-Anchor" href="#scaling-cooldowns"></a> Scaling Cooldowns</h2><ul><li>After a scaling activity happens, you are in the cooldown period (default 300 seconds)</li><li>during the cooldown period the ASG will not launch or terminate additional instances (to allow for metrics to stablize)</li><li>advice: use a ready to use AMI to reduce configuration time in order to be serving request faster and reduce the cooldown period</li></ul><h2 id="asg-default-termination-policy"><a class="markdownIt-Anchor" href="#asg-default-termination-policy"></a> ASG default termination policy</h2><ol><li>Find the AZ which has the most number of instances</li><li>if there are multiple instances in the AZ to choose from, delete the one with the oldest launch configuration</li></ol><ul><li>ASG tries to balance the number of instances across AZ by default</li></ul><h2 id="asg-lifecycle-hooks"><a class="markdownIt-Anchor" href="#asg-lifecycle-hooks"></a> ASG lifecycle hooks</h2><ul><li>by default as soon as an instance is launched in an ASG its inservice</li><li>you have the ability to perform extra steps before the instance goes in service (pending state)</li><li>you have the ability to perform extra actions before the instance is terminated (terminating state), like extract logs, tools etc…</li></ul><h2 id="asg-launch-template-vs-launch-configuration"><a class="markdownIt-Anchor" href="#asg-launch-template-vs-launch-configuration"></a> ASG launch template vs Launch configuration</h2><ul><li>both<ul><li>ID of the AMI, the instance type, a key pair, security groups, and the other parameters that you use to launch EC2 instances</li></ul></li><li>Launch Configuration<ul><li>must be re-created every time</li></ul></li><li>launch template<ul><li>can have multiple versions</li><li>create parameters subsets (partial configuration for re-use and inheritance)</li><li>provision using both on demand and stop instances</li><li>can use T2 unlimited burst feature</li><li>recommended by AWS going forward</li></ul></li></ul><h1 id="rds"><a class="markdownIt-Anchor" href="#rds"></a> RDS</h1><ul><li>RDS stands for relational database service</li><li>its a managed DB service for DB use SQL as a query language</li><li>it allows you to create databases in the cloud that are managed by AWS<ul><li>Postgres</li><li>MySQL</li><li>MariaDB</li><li>Oracle</li><li>Microsoft SQL Server</li><li>Aurora (AWS Proprietary database)</li></ul></li></ul><p>Advantage over using RDS vs deploying DB on EC2</p><ul><li>RDS is a managed service</li><li>automated provisioning, OS patching</li><li>continuous backups and restore to specific timestamp (point in time restore)</li><li>monitoring dashboards</li><li>read replicas for improved read performance</li><li>multi AZ setup for DR (Disaster Recovery)</li><li>maintenance windows for upgrades</li><li>scaling capability (vertical or horizontal)</li><li>storage backed by EBS</li><li>but you can’t SSH into your RDS instance (its managed by AWS)</li></ul><h2 id="rds-backups"><a class="markdownIt-Anchor" href="#rds-backups"></a> RDS backups</h2><ul><li>backups are automatically enabled in RDS</li><li>automatically backups<ul><li>daily full backup of the database (during the maintenance windows)</li><li>transaction logs are backed up by RDS every 5 minutes</li><li>ability to restore to any point in time (from oldest backup to 5 minutes ago)</li><li>7 days retention (can be increased to 35 days)</li></ul></li><li>DB snapshots<ul><li>manually triggered by the user</li><li>retention of backup for as long as you want</li></ul></li></ul><h2 id="rds-storage-auto-scaling"><a class="markdownIt-Anchor" href="#rds-storage-auto-scaling"></a> RDS storage auto scaling</h2><ul><li>helps you increase storage on your RDS DB instance dynamically</li><li>when RDS detects you are running out of free database storage, it scales automatically</li><li>avoid manually scaling your database storage</li><li>you have to set maximum storeage threshold (maximum limit for DB storage)</li><li>automatically modify storage if<ul><li>free storage is less than 10% of allocated storage</li><li>low storage lasts at least 5 minuts</li><li>6 hours have passed since last modification</li></ul></li><li>useful for applications with unpredicatable workloads</li><li>supports all RDS database engines (MariaDB, MySQL, PostgreSQL, SQL server, Oracle)</li></ul><h2 id="read-replicas-for-read-scalability"><a class="markdownIt-Anchor" href="#read-replicas-for-read-scalability"></a> Read Replicas for read scalability</h2><ul><li>up to 5 read replicas<ul><li>within AZ</li><li>cross AZ</li><li>cross region</li></ul></li><li>replication is ASYNC, so reads are eventually consisent, possible to read old data</li><li>replicas can be promoted to their own DB</li><li>applications must update the connection string to leverage read replicas</li></ul><h3 id="read-replicas-use-case"><a class="markdownIt-Anchor" href="#read-replicas-use-case"></a> Read replicas - use case</h3><ul><li>you have a production database that is taking on normal load</li><li>you want to run a reporting application to run some analytics</li><li>you create a read replica to run the new workload there</li><li>the production application is unaffected</li><li>read replicas are used for SELECT only kind of operations (not DELETE, INSERT, UPDATE)</li></ul><h3 id="network-cost"><a class="markdownIt-Anchor" href="#network-cost"></a> Network cost</h3><ul><li>in AWS there is a network cost when data goes from one AZ to another</li><li>for RDS read replicas within the same region, you don’t pay that fee</li><li>for read replicas across regions, you need to pay</li></ul><h3 id="multi-az-disaster-recovery"><a class="markdownIt-Anchor" href="#multi-az-disaster-recovery"></a> Multi AZ disaster recovery</h3><ul><li>SYNC replication</li><li>one DNS name - automatic app failaover to standby</li><li>increase availability</li><li>failover in case of loss of AZ, loss of network, instance or storage failure</li><li>no manual intervention in apps</li><li>not used for scaling (not handle traffic, only take over when master RDS fail)</li><li>NOTE: the read replicas can be setup as Multi AZ for disaster recovery</li></ul><h2 id="rds-from-single-az-to-multi-az"><a class="markdownIt-Anchor" href="#rds-from-single-az-to-multi-az"></a> RDS - from single AZ to multi AZ</h2><ul><li>zero downtime operation (no need to stop the DB)</li><li>just click on modify for the database</li><li>the following happens internally<ul><li>a snapshot is taken</li><li>a new DB is restored from the snapshot in a new AZ</li><li>synchronization is established between the two databases</li></ul></li></ul><h2 id="rds-security-encryption"><a class="markdownIt-Anchor" href="#rds-security-encryption"></a> RDS security - encryption</h2><ul><li>at rest<ul><li>possibility to encrypt the master and read replicas with AWS KMS - AES-256 encryption</li><li>encryption has to be defined at launch time</li><li>if the master is not encrypted, the read replica cannot be encrypted</li><li>Transparent Data Encryption (TDE) available for Oracle and SQL server</li></ul></li><li>in flight encryption<ul><li>SSL certificate to encrypt data to RDS in flight</li><li>provide SSL options with trust certificate when connecting to database</li></ul></li></ul><h3 id="encryption-operations"><a class="markdownIt-Anchor" href="#encryption-operations"></a> Encryption operations</h3><ul><li>Encrypting RDS backups<ul><li>snapshots of un-encrypted RDS databases are un-encrypted</li><li>snapshots of encrypted RDS database are encrypted</li><li>can copy a snapshot into an encrypted one</li></ul></li><li>to encrypt an un-encrypted RDS database<ul><li>create a snapshot of the un-encrypted database</li><li>copy the snapshot and enable encryption for the snapshot</li><li>restore the database from the encrypted snapshot</li><li>migrate applications to the new database and delete the old database</li></ul></li></ul><h2 id="rds-security-network-and-iam"><a class="markdownIt-Anchor" href="#rds-security-network-and-iam"></a> RDS security - network and IAM</h2><ul><li>network security<ul><li>RDS database are usually deployed within a private subnet, not in a public one</li><li>RDS security works by leveraging security groups (the same concept as for EC2 instances) - it controls which IP / security group can communicate with RDS</li></ul></li><li>access management<ul><li>IAM policies help control who can manage AWS RDS (through the RDS API)</li><li>traditional username and password can be used to login into the database</li><li>IAM based authentication can be used to login into RDS for MySQL and PostgreSQL</li></ul></li></ul><h3 id="rds-iam-authentication"><a class="markdownIt-Anchor" href="#rds-iam-authentication"></a> RDS - IAM authentication</h3><ul><li>IAM database authentication works with MySQL and PostgreSQL</li><li>you don’t need a password, just an authentication token obtained through IAM and RDS API calls</li><li>auth token has a lifetime of 15 minutes</li><li>benefits<ul><li>network in / out must be encrypted using SSL</li><li>IAM to centainly manage users instead of DB</li><li>can leverage IAM roles and EC2 instance profiles for easy integration</li></ul></li></ul><h1 id="amazon-aurora"><a class="markdownIt-Anchor" href="#amazon-aurora"></a> Amazon Aurora</h1><ul><li>Aurora is a proprietary technology from AWS (not open sourced)</li><li>Postgres and MySQL are both supported as Aurora DB (that means your drivers will work as if Aurora was a Postgres or MySQL database)</li><li>Aurora is AWS cloud optimized and claims 5x performance improvement over MySQL on RDS, over 3x performance of Postgres on RDS</li><li>Aurora storage automatically grows from 10 GB to 64 TB</li><li>Aurora can have 15 replicas while MySQL has up to 5, and the replication process is faster</li><li>failover in Aurora is instantaneous</li><li>Aurora costs more then RDS (20% more), but is more efficient</li></ul><h2 id="aurora-high-availability-and-read-scaling"><a class="markdownIt-Anchor" href="#aurora-high-availability-and-read-scaling"></a> Aurora High Availability and Read Scaling</h2><ul><li>6 copies of your data across 3 AZ<ul><li>4 copies out of 6 needed for writes</li><li>3 copies out of 6 needed for reads</li><li>self healing with peer to peer replication</li><li>storage is striped across 100s of volumes</li></ul></li><li>one Aurora instance takes writes (master)</li><li>automated failover for master in less than 30 seconds</li><li>master + up to 15 Aurora read replicas serve reads</li><li>support for cross region replication</li></ul><h2 id="aurora-custom-endpoints"><a class="markdownIt-Anchor" href="#aurora-custom-endpoints"></a> Aurora - Custom Endpoints</h2><ul><li>define a subset of Aurora instances as a custom endpoint</li><li>example: run analytical queries on specific replicas</li><li>the reader endpoint is generally not used after defining custom endpoints</li></ul><h2 id="aurora-serverless"><a class="markdownIt-Anchor" href="#aurora-serverless"></a> Aurora serverless</h2><ul><li>automated database instantiation and auto scaling based on actual usage</li><li>good for infrequent intermittent or unpredictable workloads</li><li>no capacity planning needed</li><li>pay per second, can be more cost effective</li></ul><h2 id="aurora-multi-master"><a class="markdownIt-Anchor" href="#aurora-multi-master"></a> Aurora Multi-Master</h2><ul><li>in case you want immediate failover for write node (HA)</li><li>every node does Read and write - vs - promoting a read replica as the new master (faster failover)</li></ul><h1 id="amazon-elasticache"><a class="markdownIt-Anchor" href="#amazon-elasticache"></a> Amazon ElastiCache</h1><ul><li>the same way RDS is to get managed relational databases</li><li>elastiCache is to get managed Redis or Memcached</li><li>caches are in memory databases with really high performance, low latency</li><li>helps reduce load off databases for read intensive workloads</li><li>helps make your application stateless</li><li>AWS takes care of OS maintenance / patching, optimization, setup, configuration, monitoring, failure recovery and backups</li><li>using ElastiCache involves heavy application code changes</li></ul><h2 id="db-cache"><a class="markdownIt-Anchor" href="#db-cache"></a> DB Cache</h2><ul><li>applications queries ElastiCache, if not available, get from RDS and store in ElastiCache</li><li>htlps relieve load in RDS</li><li>Cache must have an invalidation strategy to make sure only the most current data is used in there (LRU, LFU)</li></ul><h2 id="user-session-store"><a class="markdownIt-Anchor" href="#user-session-store"></a> User session store</h2><ul><li>user logs into any of the application</li><li>the application wrties the session data into ElastiCache</li><li>the user hits another instance of our application</li><li>the instance retrieve the session data and the user is already logged in</li></ul><h2 id="redis"><a class="markdownIt-Anchor" href="#redis"></a> Redis</h2><ul><li>Multi AZ witi auto faliover</li><li>read replicas to scale reads and have High Availability</li><li>data durability using AOF persistence</li><li>backup and restore features</li></ul><h2 id="memcached"><a class="markdownIt-Anchor" href="#memcached"></a> Memcached</h2><ul><li>multi-node for partitioning of data (sharding)</li><li>no high availability (replication)</li><li>non persistent</li><li>no backup and restore</li><li>multi-threaded architecture</li></ul><h2 id="patterns-for-elasticache"><a class="markdownIt-Anchor" href="#patterns-for-elasticache"></a> Patterns for ElastiCache</h2><ul><li>Lazy loading<ul><li>all the read data is cached, data can become stale in cache</li></ul></li><li>write through<ul><li>adds or update data in the cache when written to a DB (no stale data)</li></ul></li><li>session store:<ul><li>store temporary session data in a cache (using TTL features)</li></ul></li></ul><h2 id="reids-use-case"><a class="markdownIt-Anchor" href="#reids-use-case"></a> Reids use case</h2><ul><li>Gaming leaderboard</li><li>Redis Sorted sets guarantee both uniqueness and element ordering</li><li>each time a new element added, its ranked in real time, then added in correct order</li></ul><h1 id="route-53"><a class="markdownIt-Anchor" href="#route-53"></a> Route 53</h1><ul><li>route 53 is a managed DNS (domain name system)</li><li>DNS is a collection of rules and records which helps clients understand how to reach a server through its domain name</li><li>in AWS, the most common records are<ul><li>A: hostname =&gt; IPv4</li><li>AAAA: hostname =&gt; IPv6</li><li>CNAME: hostname =&gt; hostname</li><li>Alias: hostname =&gt; AWS resource</li></ul></li></ul><h2 id="overview"><a class="markdownIt-Anchor" href="#overview"></a> Overview</h2><ul><li>route 53 can use<ul><li>public domain names you own</li><li>private domain names that can be resolved by your instances in your VPCs</li></ul></li><li>Route 53 has advanced features such as<ul><li>load balancing (through DNS, also called client load balancing)</li><li>health checks</li><li>routing policy: simple, failover, geolocation, latency, weighted…</li></ul></li><li>you pay $0.5 per month per hosted zone</li></ul><ol><li>user will first send DNS request (<a href="http://myapp.mydomain.com">http://myapp.mydomain.com</a>) to route 53 asking for IP address</li><li>route 53 will response will the ip address of that DNS and a TTL</li><li>user browser will then send the HTTP request to the correct IP to reach the server</li><li>next time when the user send DNS request, if the last request is not expire (check the TTL), browser will directly go to the last saved IP address, save traffic for route 53</li></ol><h2 id="cname-vs-alias"><a class="markdownIt-Anchor" href="#cname-vs-alias"></a> CNAME vs Alias</h2><ul><li>AWS resource (load balancer, cloudfront…) expose an AWS hostname and you want <a href="http://myapp.mydomain.com">myapp.mydomain.com</a></li><li>CNAME<ul><li>points a hostname to any other hostname</li><li>only for non root domain (<a href="http://something.mydomain.com">something.mydomain.com</a>)</li></ul></li><li>Alias<ul><li>points a hostname to an AWS resource</li><li>works for root domain and non root domain (<a href="http://mydomain.com">mydomain.com</a>)</li><li>free of charge</li><li>native health check</li></ul></li></ul><h2 id="simple-routing-policy"><a class="markdownIt-Anchor" href="#simple-routing-policy"></a> Simple Routing policy</h2><ul><li>use when you need to redirect to a single resource</li><li>you can’t attach health checks to simple routing policy</li><li>if multiple values (IP addresses) are returned, a random one is chosen by the client (client side load balancing)</li></ul><h2 id="weighted-routing-policy"><a class="markdownIt-Anchor" href="#weighted-routing-policy"></a> Weighted routing policy</h2><ul><li>control the percentage of the requests that go to specific endpoint</li><li>helpful to test percentage of traffic on new app version for example</li><li>helpful to split traffic between two regions</li><li>can be associated with health checks</li><li>but on the client side the browser is not aware that it has multiple weighted endpoints in the backend</li></ul><h2 id="latency-routing-policy"><a class="markdownIt-Anchor" href="#latency-routing-policy"></a> Latency routing policy</h2><ul><li>redirect to the server that has the least latency close to user</li><li>super helpful when latency of users is a priority</li><li>latency is evaluated in terms of user to designated AWS region</li><li>Germany may be redirected to the US (if that’s the lowest latency)</li></ul><h2 id="route-53-health-checks"><a class="markdownIt-Anchor" href="#route-53-health-checks"></a> Route 53 health checks</h2><ul><li>have X health checks failed =&gt; unhealthy (default 3)</li><li>have X health checks passed =&gt; healthy (default 3)</li><li>default health checks interval : 30 seconds (can set to 10 seconds with higher cost)</li><li>about 15 health checkers will the the endpoint health in the background (from different regions)<ul><li>one request every 2 seconds on average (30 / 15)</li><li>can have HTTP, TCP, and HTTPS health checks (no SSL verification)</li><li>possible to integrate health check with CloudWatch</li></ul></li><li>health checks can be linked to route 53 DNS queries</li></ul><h2 id="geolocation-routing-policy"><a class="markdownIt-Anchor" href="#geolocation-routing-policy"></a> GeoLocation routing policy</h2><ul><li>different from latency based</li><li>this is routing based on user location</li><li>here we specify traffic from the UK should go to this specific IP</li><li>should create a default policy (in case there is no match on location)</li></ul><h2 id="geoproximity-routing-policy"><a class="markdownIt-Anchor" href="#geoproximity-routing-policy"></a> Geoproximity routing policy</h2><ul><li>route traffic to your resources based on the geographic location of users and resources</li><li>ability to shift more traffic to resources based on the defined bias</li><li>to change the size of the geographic region, specify bias values<ul><li>to expand (1 to 99) - more traffic to the resources</li><li>to shrink (-1 to -99) - less traffic to the resources</li></ul></li><li>resources can be<ul><li>AWS resources (specify AWS region)</li><li>non-AWS resources (specify latitude and longitude)</li></ul></li><li>you must use route 53 traffic flow (advanced) to use this feature</li></ul><h2 id="multi-value-routing-policy"><a class="markdownIt-Anchor" href="#multi-value-routing-policy"></a> Multi value routing policy</h2><ul><li>use when routing traffic to multiple resources</li><li>want to associate a route 53 health checks with records</li><li>up to 8 healthy records are returned for each multi value query</li><li>multi value is not a substitute for having an ELB</li><li>client browser will randomly choose a healthy record from returned records (client side fault tolerance)</li></ul><h2 id="route-53-as-a-registrar"><a class="markdownIt-Anchor" href="#route-53-as-a-registrar"></a> Route 53 as a Registrar</h2><ul><li><p>a domain name registrar is an organization that manages the reservation of internet domain names</p><ul><li>GoDaddy</li><li>Google Domains</li></ul></li><li><p>Domain registrar != DNS</p></li><li><p>if you buy your domain on 3rd party website, you can still use route 53</p></li></ul><ol><li>create a hosted zone in route 53</li><li>update NS records on 3rd party website to use route 53 name servers (all 4 of them)</li></ol><h1 id="classic-solutions-architecture"><a class="markdownIt-Anchor" href="#classic-solutions-architecture"></a> Classic Solutions Architecture</h1><h2 id="stateful-app-with-shopping-cart"><a class="markdownIt-Anchor" href="#stateful-app-with-shopping-cart"></a> Stateful App with shopping cart</h2><ul><li>ELB sticky sessions</li><li>web clients for storing cookies and making our web app stateless</li><li>ElastiCache<ul><li>for storing sessions (alternative: DynamoDB)</li><li>for caching data from RDS</li><li>Multi AZ</li></ul></li><li>RDS<ul><li>for storing user data</li><li>read replicas for scaling reads</li><li>multi AZ for disaster recovery</li></ul></li><li>tight security with security groups referencing each other</li></ul><h2 id="instantiating-applications-quickly"><a class="markdownIt-Anchor" href="#instantiating-applications-quickly"></a> Instantiating Applications Quickly</h2><ul><li>EC2 instances<ul><li>use a golden AMI: install your applications, OS dependencies, beforehand and launch your EC2 instance from the golden AMI</li><li>bootstrap using user data: for dynamic configuration, use User Data scripts</li><li>Hybrid: mix golden AMI and User Data (Elastic Beanstalk)</li></ul></li><li>RDS databases<ul><li>restore from a snapshot: the database will have schemas and data ready</li></ul></li><li>EBS volume:<ul><li>restore from a snapshot, the disk will already be formatted and have data</li></ul></li></ul><h1 id="beanstalk"><a class="markdownIt-Anchor" href="#beanstalk"></a> Beanstalk</h1><h2 id="developer-problems-on-aws"><a class="markdownIt-Anchor" href="#developer-problems-on-aws"></a> Developer problems on AWS</h2><ul><li><p>managing infrastructure</p></li><li><p>deploying code</p></li><li><p>configuring all the databases, load balancers, etc…</p></li><li><p>scaling concerns</p></li><li><p>most web apps have the same architecture (ALB + ASG)</p></li><li><p>all the developers want is for their code to run</p></li><li><p>possibly, consistently across different applications and environments</p></li></ul><h2 id="elastic-beanstalk-overview"><a class="markdownIt-Anchor" href="#elastic-beanstalk-overview"></a> Elastic Beanstalk - overview</h2><ul><li>Elastic Beanstalk is a developer centric view of deploying an application on AWS</li><li>it uses all the component’s we have seen before: EC2, ASG, ELB, RDS…</li><li>managed service<ul><li>automatically handles capacity provisioning, load balancing, scaling, application health monitoring, instance configuration…</li><li>just the application code is the responsiblity of the developer</li></ul></li><li>we still have full control over the configuration</li><li>Beanstalk is free but you pay for the underlying instances</li></ul><h2 id="elastic-beanstalk-components"><a class="markdownIt-Anchor" href="#elastic-beanstalk-components"></a> Elastic Beanstalk - components</h2><ul><li>application<ul><li>collectioin of Elastic Beanstalk components (environments, versions, configurations…)</li></ul></li><li>application version<ul><li>an iteration of your application code</li></ul></li><li>environment<ul><li>collection of AWS resources running an application version (only one application version at a time)</li><li>Tiers<ul><li>web server environment tier</li><li>worker environment tier</li></ul></li><li>you can create multiple environments (dev, test, prod…)</li></ul></li></ul><h1 id="s3"><a class="markdownIt-Anchor" href="#s3"></a> S3</h1><h2 id="buckets"><a class="markdownIt-Anchor" href="#buckets"></a> Buckets</h2><ul><li>Amazon S3 allows people to store objects in buckets</li><li>buckets must have a globally unique name</li><li>buckets are defined at the region level</li><li>naming convention<ul><li>No uppercase</li><li>no underscore</li><li>3-63 characters long</li><li>not an ip</li><li>must start with lowercase letter or number</li></ul></li></ul><h2 id="objects"><a class="markdownIt-Anchor" href="#objects"></a> Objects</h2><ul><li><p>objects (files) have a key</p></li><li><p>the key is the FULL path</p><ul><li>s3:&quot;//my-bucket/my_folder/another_folder/my_file.txt</li><li>key is: my_folder/another_folder/my_file.txt</li><li>prefix is: my_folder/another_folder/</li><li>object name is: my_file.txt</li></ul></li><li><p>there is no conecpt of directories within buckets</p></li><li><p>just keys with very long names that contain slashes</p></li><li><p>object values are the content of the body</p><ul><li>max object size is 5TB</li><li>if uploading more than 5GB, must use multi-part upload</li></ul></li><li><p>metadata (list of text key / value pairs, system or user metadata)</p></li><li><p>Tags (Unicode key / value pair - up to 10) - useful for security / lifecycle</p></li><li><p>Version ID (if versioning is enabled)</p></li></ul><h2 id="versioning"><a class="markdownIt-Anchor" href="#versioning"></a> Versioning</h2><ul><li>you can version your files in Amazon S3</li><li>it is enabled at the bucket level</li><li>same key overwrite will increment the version</li><li>it is best pratice to version your buckets<ul><li>protect against unintended deletes (ability to restore a version)</li><li>easy roll back to previous version</li></ul></li><li>notes<ul><li>any file that is not versioned prior to enabling versioning will have version <code>null</code></li><li>suspending versioning does not delete the previous versions</li></ul></li></ul><h2 id="encryption-for-objects"><a class="markdownIt-Anchor" href="#encryption-for-objects"></a> Encryption for objects</h2><ol><li>SSE-S3: encrypts S3 object using keys handled and managed by AWS</li><li>SSE-KMS: leverage AWS KMS service to manage encryption keys</li><li>SSE-C: when you want to manage your own encryption keys</li><li>client side encryption</li></ol><ul><li>it is important to understand which ones are adapted to which situation for the exam</li></ul><h3 id="s3-default-encryption"><a class="markdownIt-Anchor" href="#s3-default-encryption"></a> S3 Default Encryption</h3><ul><li>one way to force encryption is to use a bucket policy and refuse any API call to PUT an S3 object without encryption headers</li><li>another way is to use the default encryption option in S3</li><li>note: bucket policies are evaluated before default encryption<ul><li>e.g. if you have a bucket policy to reject all un-encrypted files from being upload to S3, then you can’t upload un-encrypted file even if you have the default encryption enabled.</li></ul></li></ul><h3 id="sse-c"><a class="markdownIt-Anchor" href="#sse-c"></a> SSE-C</h3><ul><li>Amazon S3 does not store the encryption key you provide</li><li>HTTPS must be used (because you need to send the key in the request)</li><li>Encryption key must provided in HTTP headers, for every request</li></ul><h3 id="client-side-encryption"><a class="markdownIt-Anchor" href="#client-side-encryption"></a> Client side encryption</h3><ul><li>client library such as the Amazon S3 Encryption client</li><li>clients must encrypt the data themselves before sending to S3</li><li>clients must decrypt the data themselves when retrieving the data from S3</li><li>customer fully manages the keys and encryption cycle</li></ul><h3 id="encryption-in-transit-ssltls"><a class="markdownIt-Anchor" href="#encryption-in-transit-ssltls"></a> Encryption in transit (SSL/TLS)</h3><ul><li>Amazon S3 exposes<ul><li>HTTP endpoint, non encrypted</li><li>HTTPS endpoint, encryption in flight</li></ul></li><li>You are free to use the endpoint you want, but HTTPS is recommended</li><li>most clients would use the HTTPS endpoint by default</li><li>HTTPS is mandatory for SSE-C (because you need to send the key in the request)</li></ul><h2 id="security"><a class="markdownIt-Anchor" href="#security"></a> Security</h2><ul><li><p>User based</p><ul><li>IAM policies: which API calls should be allowed for a specific user from IAM console</li></ul></li><li><p>Resource based</p><ul><li>bucket policies: bucket wide rules from the S3 console - allows cross account</li><li>Object ACL: finer grain</li><li>Bucket ACL: less common</li></ul></li><li><p>Note: an IAM principal can access an S3 object if</p><ul><li>the user IAM permissions allow it OR the resource policy ALLOW it</li><li>AND there is no explicit DENY</li></ul></li><li><p>JSON based policies</p><ul><li>Resources: buckets and objects</li><li>Actions: Set of API to Allow or Deny</li><li>Effect: Allow / Deny</li><li>Principal: the account or user to apply the policy to</li></ul></li><li><p>use S3 bucket for policy to</p><ul><li>Grant public access to the bucket</li><li>Force objects to be encrypted at upload</li><li>Grant access to another account (cross account)</li></ul></li></ul><h2 id="cors"><a class="markdownIt-Anchor" href="#cors"></a> CORS</h2><ul><li>An origin is a scheme, host, and port</li><li>CORS means Cross-Origin Resource Sharing</li><li>Web browser based machanism to allow requests to other origins while visiting the main origin</li><li>the requests won’t be fulfilled unless the other origin allows for the requests, using CORS Headers (<code>Access-Control-Allow-Origin</code>)</li><li>if a client does a cross-origin request on our S3 bucket, we need to enable the correct CORS headers</li><li>you can allow for a specific origin or * for all origins</li></ul><h2 id="s3-access-logs"><a class="markdownIt-Anchor" href="#s3-access-logs"></a> S3 Access logs</h2><ul><li>for audit purpose, you may want to log all access to S3 buckets</li><li>any request made to S3, from any account, authorized or denied, will be logged into another S3 bucket</li><li>that data can be analyzed using data analysis tools later (Amazon Athena)</li></ul><h2 id="s3-replication-cross-region-or-same-region"><a class="markdownIt-Anchor" href="#s3-replication-cross-region-or-same-region"></a> S3 Replication (Cross-Region or Same Region)</h2><ul><li><p>Must enable versioning in source and destination</p></li><li><p>cross region replication</p></li><li><p>same region replication</p></li><li><p>buckets can be in different accounts</p></li><li><p>copying is asynchronous</p></li><li><p>must give proper IAM permissions to S3</p></li><li><p>After activating, only new objects are replicated (existing objects will not be replicated)</p></li><li><p>For DELETE operations</p><ul><li>can replicate delete markers from source to target (optional setting)</li><li>deletions with a version ID are not replicated (to avoid malicious deletes)</li></ul></li><li><p>there is not chaining of replication</p><ul><li>if bucket one has replicatio into bucket two, which has replicatioin into bucket three</li><li>then objects created in bucket one are not replicated to bucket three</li></ul></li></ul><h2 id="s3-pre-signed-url"><a class="markdownIt-Anchor" href="#s3-pre-signed-url"></a> S3 Pre-signed URL</h2><ul><li>can generate pre-signed URLs using SDK or CLI</li><li>valid for a default of 3600 seconds</li><li>users given a pre-signed URL inherit the permissions of the person who generated the URL for GET / PUT</li></ul><h2 id="s3-storage-class"><a class="markdownIt-Anchor" href="#s3-storage-class"></a> S3 Storage Class</h2><h3 id="standard-general-purpose"><a class="markdownIt-Anchor" href="#standard-general-purpose"></a> Standard - General Purpose</h3><ul><li>High durability of objects across multiple AZ</li><li>99.99% availability over a given year</li><li>sustain 2 concurrent facility failure</li><li>use case: big data analytics, mobile and gaming applications, content distribution…</li></ul><h3 id="standard-ia"><a class="markdownIt-Anchor" href="#standard-ia"></a> Standard - IA</h3><ul><li>suitable for data that is less frequently accessed, but requires rapid access when needed</li><li>99.9% availability</li><li>low cost compared to GP</li><li>use cases: as a data store for disater recovery, backups</li></ul><h3 id="one-zone-ia"><a class="markdownIt-Anchor" href="#one-zone-ia"></a> One Zone - IA</h3><ul><li>Same as IA but data is stored in a single AZ</li><li>99.5% availability</li><li>low latency and high throughput performance</li><li>supports SSL for data at transit and encryption at rest</li><li>low cost compared to IA</li><li>use cases: storing secondary backup copies of on-premise data, or storing data you can re-create</li></ul><h3 id="intelligent-tiering"><a class="markdownIt-Anchor" href="#intelligent-tiering"></a> Intelligent Tiering</h3><ul><li>same low latency and high throughput performance of S3 standard</li><li>small monthly monitoring and auto-tiering fee</li><li>automatically moves objects between two access tiers based on changing access patterns</li><li>resilient against events that impact an entire AZ</li></ul><h3 id="amazon-glacier"><a class="markdownIt-Anchor" href="#amazon-glacier"></a> Amazon Glacier</h3><ul><li>low cost object storage meant for archiving / backup</li><li>data is retained for the longer term (10+ years)</li><li>alternative to on-premise magnetic tape storage</li><li>cost per storage per month + retrieval cost</li><li>each item in glacier is called archive</li><li>archives are stored in Vaults</li></ul><h3 id="amazon-glacier-and-glacier-deep-archive"><a class="markdownIt-Anchor" href="#amazon-glacier-and-glacier-deep-archive"></a> Amazon Glacier and Glacier Deep Archive</h3><ul><li>Amazon Glacier - 3 retrieval options<ul><li>expedited (1 to 5 minues)</li><li>standard (3 to 5 hours)</li><li>bulk (5 to 12 hours)</li><li>minimum storage duration of 90 days</li></ul></li><li>Amazon Glacier Deep Archive<ul><li>Standard (12 hours)</li><li>Bulk (48 hours)</li><li>Minimum storage duration of 180 days</li></ul></li></ul><h2 id="s3-lifecycle-rules"><a class="markdownIt-Anchor" href="#s3-lifecycle-rules"></a> S3 Lifecycle Rules</h2><ul><li>Transition actions<ul><li>it defines when objects are transitioned to another storage class</li><li>e.g. move objects to Standard IA class 60 days after creation</li><li>e.g. move to Glacier for archiving after 6 months</li></ul></li><li>Expiration actions<ul><li>configure to expire (delete) after some time</li><li>e.g. access log files can be set to delete after a 365 days</li><li>e.g. can be used to delete old versions of files (if versioning is enabled)</li><li>e.g. can be used to delete incomplete multi-part uploads</li></ul></li></ul><h3 id="s3-analytics-storage-class-analysis"><a class="markdownIt-Anchor" href="#s3-analytics-storage-class-analysis"></a> S3 Analytics - Storage Class Analysis</h3><ul><li>You can setup S3 analytics to help determine when to transit objects from Standard to Standard IA</li><li>does not work for One Zone - IA or Glacier</li></ul><h2 id="s3-select-and-glacier-select"><a class="markdownIt-Anchor" href="#s3-select-and-glacier-select"></a> S3 Select and Glacier Select</h2><ul><li>retrieve less data using SQL by performing server side filtering</li><li>can filter by rows and columns</li><li>less network transfer, less CPU cost client-side</li></ul><h2 id="s3-event-notifications"><a class="markdownIt-Anchor" href="#s3-event-notifications"></a> S3 Event notifications</h2><ul><li>can create as many events as desired<ul><li>SNS</li><li>SQS</li><li>Lambda function</li></ul></li><li>S3 event notifications typically deliver events in seconds but can sometimes take a minute or longer</li><li>if two writes are made to a single non-versioned object at the same time, it is possible that only a single event notification will be sent</li><li>if you want to ensure that an event notification is sent for every successful write, you can enable versioning on your bucket.</li><li>Your S3 bucket needs to have permission to send message to SQS queue</li></ul><h2 id="s3-requester-pays"><a class="markdownIt-Anchor" href="#s3-requester-pays"></a> S3 Requester Pays</h2><ul><li>in general, bucket owners pay for all S3 storage and data transfer costs associated with their buckets</li><li>with Requester Pays buckets, the requester instead of the bucket owner pays the cost of the request and the data download from the bucket</li><li>helpful when you want to share large datasets with other accounts</li><li>the requester must be authenticated in AWS (cannot be anonymous)</li></ul><h2 id="glacier-vault-lock"><a class="markdownIt-Anchor" href="#glacier-vault-lock"></a> Glacier Vault Lock</h2><ul><li>Adopt a WORM (Write Once Read Many) model</li><li>lock the policy for future edits (can no longer be changed)</li><li>helpful for compliance and data retention</li></ul><h2 id="s3-object-lock-versioning-must-be-enabled"><a class="markdownIt-Anchor" href="#s3-object-lock-versioning-must-be-enabled"></a> S3 Object Lock (versioning must be enabled)</h2><ul><li>adopt a WORM (Write Once Read Many) model</li><li>block an object version deletion for a specified amount of time</li><li>object retention<ul><li>retention period: specifies a fixed period</li><li>legal hold: same protection, no expiry date</li></ul></li><li>Modes<ul><li>Governance mode: users can’t overwrite or delete an object version or alter its lock settings unless they have special permissions</li><li>Compliance mode: a protected object version can’t be overwritten or deleted by any user, including the root user. When an object is locked in compliance mode, its retention mode can’t be changed and its retention period can’t be shortened.</li></ul></li></ul><h1 id="aws-athena"><a class="markdownIt-Anchor" href="#aws-athena"></a> AWS Athena</h1><ul><li>serverless service to perform analytics directly against S3 files</li><li>uses SQL language to query the files</li><li>has a JDBC / ODBC driver (for BI tools)</li><li>charged per query and amount of data scanned</li><li>supports CSV, JSON, ORC, Avro, and Parquet (built on Presto)</li><li>use cases: BI / Analytics / reporting / Logs / CloudTrail trails etc…</li></ul><h1 id="aws-cloudfront"><a class="markdownIt-Anchor" href="#aws-cloudfront"></a> AWS CloudFront</h1><ul><li>CDN</li><li>improves read performance, content is cached at the edge loctions</li><li>216 point of presence globally (edge locations)</li><li>DDoS protection, integration with Shield, AWS web application firewall</li><li>can expose external HTTPS and can talk to internal HTTPS backends</li></ul><h2 id="origins"><a class="markdownIt-Anchor" href="#origins"></a> Origins</h2><ul><li>S3 bucket<ul><li>for distributing files and caching them at the edge</li><li>enahnced security with CloudFront OAI (Origin Access Identity), this can block access directly to S3</li><li>CloudFront can be used as an ingress (to upload files to S3)</li></ul></li><li>Custom Origin (HTTP)<ul><li>Application Load Balancer</li><li>EC2 instance</li><li>S3 Website (must first enable the bucket as a static S3 website)</li><li>Any HTTP backend you want</li></ul></li></ul><h3 id="cloudfront-vs-s3-cross-region-replication"><a class="markdownIt-Anchor" href="#cloudfront-vs-s3-cross-region-replication"></a> CloudFront vs S3 Cross Region Replication</h3><ul><li>CloudFront<ul><li>Global Edge Network</li><li>files are cached for a TTL</li><li>great for static content that must be available everywhere, maybe outdated for a while</li></ul></li><li>S3 Cross Region Replication<ul><li>must be setup for each region you want replication to happen</li><li>files are updated in near real time</li><li>read only</li><li>great for dynamic content that needs to be available at low latency in few regions</li></ul></li></ul><h2 id="cloudfront-signed-url-signed-cookies"><a class="markdownIt-Anchor" href="#cloudfront-signed-url-signed-cookies"></a> CloudFront Signed URL / Signed Cookies</h2><ul><li>you want to distribute paid share content to premium users over the world</li><li>we can use CloudFront Signed URL / Cookie, we attach a policy with<ul><li>includes URL expiration</li><li>includes IP ranges to access the data from</li><li>Trusted Signers (which AWS accounts can create signed URLs)</li></ul></li><li>Signed URL: access to individual files (one signed URL per file)</li><li>Signed Cookies: access to multiple files (one signed Cookie for many files)</li></ul><h3 id="process"><a class="markdownIt-Anchor" href="#process"></a> Process</h3><ol><li>user authenticate and authorized to the application</li><li>the application send request to CloudFront to generate Signed URL / Cookie</li><li>the application send the signed URL / Cookie back to user</li><li>user use the signed URL / Cookie to access the file in CloudFront</li><li>CloudFront fetch the file from S3 to the user</li></ol><h3 id="cloudfront-signed-url-vs-s3-pre-signed-url"><a class="markdownIt-Anchor" href="#cloudfront-signed-url-vs-s3-pre-signed-url"></a> CloudFront Signed URL vs S3 Pre-signed URL</h3><ul><li>CloudFront Signed URL<ul><li>Allow access to a path, no matter the origin</li><li>account wide key pair, only the root can manage it</li><li>can filter by IP, path, date, expiration</li><li>can leverage caching features</li></ul></li><li>S3 Pre-signed URL<ul><li>issue a request as the person who pre-signed the URL</li><li>uses the IAM key of the signing IAM principal</li><li>limited lifetime</li></ul></li></ul><h2 id="cloudfront-price-class"><a class="markdownIt-Anchor" href="#cloudfront-price-class"></a> CloudFront - Price Class</h2><ul><li>You can reduce the number of edge locations for cost reduction</li><li>3 price classes<ul><li>price class all: all regions</li><li>price class 200: most regions, but excludes the most expensive regions</li><li>price class 100: only the least expensive regions</li></ul></li></ul><h2 id="cloudfront-multiple-origins"><a class="markdownIt-Anchor" href="#cloudfront-multiple-origins"></a> CloudFront - Multiple Origins</h2><ul><li>to route to different kind of origins based on the content type</li><li>e.g. one origin is from ALB and another origin is from S3 bucket</li></ul><h3 id="based-on-the-path-pattern"><a class="markdownIt-Anchor" href="#based-on-the-path-pattern"></a> Based on the path pattern</h3><ul><li><code>/images/*</code></li><li><code>/api/*</code></li><li><code>/*</code></li></ul><h2 id="cloudfront-origin-groups"><a class="markdownIt-Anchor" href="#cloudfront-origin-groups"></a> CloudFront - Origin Groups</h2><ul><li>to increase high availability and do failover</li><li>Origin Groups: one primary and one secondary origin</li><li>if the primary origin fails, the second one is used (CloudFront will send the same request to the secondary origin)</li></ul><h2 id="cloudfront-field-level-encryption"><a class="markdownIt-Anchor" href="#cloudfront-field-level-encryption"></a> CloudFront - Field Level Encryption</h2><ul><li>protect user sensitive information through application stack</li><li>adds an additional layer of security along with HTTPS</li><li>sensitive information encrypted at the edge close to the user</li><li>uses asymmetric encryption (public private key pair)</li><li>usage<ol><li>client send sensitive information to the edge location</li><li>edge location use public key to encrypt the information</li><li>edge location send encrypted information to CloudFront</li><li>CloudFront send information all the way to (CloudFront =&gt; ALB =&gt; Web Servers) Web server</li><li>Web server uses the private key to decrypt the information</li></ol></li></ul><h1 id="aws-global-accelerator"><a class="markdownIt-Anchor" href="#aws-global-accelerator"></a> AWS Global Accelerator</h1><h2 id="global-users-for-our-application"><a class="markdownIt-Anchor" href="#global-users-for-our-application"></a> Global users for our application</h2><ul><li>you have deployed an application and have global users who want to access it directly</li><li>they go over the public internet, which can add a lot of latency due to many hops</li><li>we wish to go as fast as possible through AWS network to minimize latency</li></ul><h2 id="unicast-ip-vs-anycast-ip"><a class="markdownIt-Anchor" href="#unicast-ip-vs-anycast-ip"></a> Unicast IP vs Anycast IP</h2><ul><li>Unicast IP<ul><li>one server holds one IP address</li></ul></li><li>Anycast IP<ul><li>all servers hold the same IP address and the client is routed to the nearest one</li></ul></li></ul><h2 id="aws-global-accelerator-2"><a class="markdownIt-Anchor" href="#aws-global-accelerator-2"></a> AWS Global Accelerator</h2><ul><li>leverage the AWS internal network to route to your application</li><li>2 Anycast IP are created for your application</li><li>the Anycast IP send traffic directly to Edge locations</li><li>the edge locations send the traffic to your application (through AWS private network)</li></ul><h2 id="global-accelerator-vs-cloudfront"><a class="markdownIt-Anchor" href="#global-accelerator-vs-cloudfront"></a> Global Accelerator vs CloudFront</h2><ul><li><p>they both use the AWS global network and its edge locations around the world</p></li><li><p>both services integrate with AWS shield for DDoS protection</p></li><li><p>CloutFront</p><ul><li>improves performance for both cacheable content (images / videos)</li><li>Dynamic content (such as API acceleration and dynamic site delivery)</li><li>content is served at the edge location</li></ul></li><li><p>Global Accelerator</p><ul><li>improves performance for a wide range of applications over TCP or UDP</li><li>proxying packets at the edge to applications running in one or more AWS regions</li><li>good fit for non-HTTP use cases: such as gaming (UDP), IoT (MQTT) or Voice Over IP</li><li>good for HTTP use cases that require static IP (if use Route 53 Geo location, client browser will cache the IP address and redirect user to the old IP for a TTL)</li><li>good for HTTP use cases that require deterministic, fast regional failover</li></ul></li></ul><h1 id="aws-snow-family"><a class="markdownIt-Anchor" href="#aws-snow-family"></a> AWS Snow Family</h1><ul><li>Highly-secure, portable devices to collect and process data at the edge, and migrate data into and out of AWS</li></ul><h2 id="snowball-edge-for-data-transfers"><a class="markdownIt-Anchor" href="#snowball-edge-for-data-transfers"></a> Snowball Edge (for data transfers)</h2><ul><li>physical data transport solution</li><li>alternative to moving data over the network</li><li>pay per data transfer job</li><li>provide block storage and Amazon S3 compatible object storage</li><li>Snowball Edge Storage Optimzied</li><li>Snowball Edge Compute Optimized</li></ul><h2 id="snowcore"><a class="markdownIt-Anchor" href="#snowcore"></a> Snowcore</h2><ul><li>small, portable computing, anywhere, rugged and secure, withstands harsh environements</li><li>light, 2.1 kg</li><li>device used for edge computing, storage, and data transfer</li><li>8 TB usable storage</li><li>must provide your own battery and cables</li><li>can be sent back to AWS offline, or connect it to internet and use AWS datasync to send data</li></ul><h2 id="snowmobile"><a class="markdownIt-Anchor" href="#snowmobile"></a> Snowmobile</h2><ul><li>transfer exabytes of data (1 EB = 1000 PB = 1,000,000 TB)</li><li>each snowmobile has 100 PB of capacity</li><li>high security</li><li>better than snowball if you transfer more then 10 PB</li></ul><h2 id="edge-computing"><a class="markdownIt-Anchor" href="#edge-computing"></a> Edge computing</h2><ul><li>process data while its being created on an edge location<ul><li>A truck on the road, a ship on the sea, a mining station underground (no internet access)</li></ul></li><li>these locations may have<ul><li>limited / no internet access</li><li>limited / no easy access to computing power</li></ul></li><li>we setup a snowball / snowcone device to do edge computing</li><li>eventually we can ship back the device to AWS</li></ul><h2 id="aws-opshub"><a class="markdownIt-Anchor" href="#aws-opshub"></a> AWS OpsHub</h2><ul><li>Historically, to use Snow Family devices, you need a CLI</li><li>today, you can use AWS OpsHub (a software you install on your computer / laptop) to manage your snow family devices<ul><li>unlocking and configuring single or clustered devices</li><li>transferring files</li><li>launching and managing instances running on Snow family devices</li><li>monitor device metrics (storage capacity, active instances)</li><li>launch compatible AWS services on your devices</li></ul></li></ul><h3 id="snowball-into-glacier"><a class="markdownIt-Anchor" href="#snowball-into-glacier"></a> Snowball into Glacier</h3><ul><li>Snowball cannot import to Glacier directly</li><li>you must use Amazon S3 first, in combination with an S3 lifecycle policy</li></ul><h1 id="aws-storage-gateway"><a class="markdownIt-Anchor" href="#aws-storage-gateway"></a> AWS Storage Gateway</h1><ul><li>Bridge between on-premises data and cloud data in S3</li><li>use cases: disaster recovery, backup and restore, tiered storage</li></ul><h2 id="file-gateway"><a class="markdownIt-Anchor" href="#file-gateway"></a> File Gateway</h2><ul><li>configured S3 buckets are accessible using the NFS and SMB protocol</li><li>supports S3 standard, S3 IA, S3 One Zone IA</li><li>bucket access using IAM roles for each File Gateway</li><li>most recently used ata is cached in the file Gateway</li><li>can be mounted on many servers</li><li>integrated with AD (Active Directory) for user authentication</li></ul><ol><li>On-premises server communicate with File Gateway (optionally with Authentication)</li><li>File Gateway communicate with S3 buckets</li></ol><h2 id="volume-gateway"><a class="markdownIt-Anchor" href="#volume-gateway"></a> Volume Gateway</h2><ul><li>block storage using iSCSI protocol backed by S3</li><li>backed by EBS snapshot which can help restore on-premises volumes</li><li>cached volumes: low latency access to most recent data</li><li>stored volumes: entire dataset is on premises, scheduled backups to S3</li></ul><ol><li>On-premises server communicate with Volume Gateway using iSCSI protocol</li><li>Volume Gateway communicate with S3 bucket to create EBS snapshots</li></ol><ul><li>Volume Gateway is often used as data backup</li></ul><h2 id="tape-gateway"><a class="markdownIt-Anchor" href="#tape-gateway"></a> Tape Gateway</h2><ul><li>some companies have backup processes using physical tapes</li><li>with tape gateway, companies use the same processes but, in the cloud</li><li>Virtual Tape Library (VTL) backed by Amazon S3 and Glacier</li><li>backup data using existing tape-based processes</li></ul><h2 id="storage-gateway-hardware-appliance"><a class="markdownIt-Anchor" href="#storage-gateway-hardware-appliance"></a> Storage Gateway - Hardware appliance</h2><ul><li>if you don’t have on-premises virtual server, you can buy from Amazon</li></ul><h1 id="aws-fsx"><a class="markdownIt-Anchor" href="#aws-fsx"></a> AWS FSx</h1><h2 id="aws-fsx-for-windows"><a class="markdownIt-Anchor" href="#aws-fsx-for-windows"></a> AWS FSx for Windows</h2><ul><li>EFS is a shared POSIX system for Linux system</li><li>FSx is a fully managed Windows file system share drive</li><li>supports SMB protocol and Windows NTFS</li><li>Microsoft Active Directory integration, ACLs, user quotas</li><li>can be accessed from your on-premises infrastructure</li><li>can be configured to be Multi-AZ</li><li>data is backed up daily to S3</li></ul><h2 id="amazon-fsx-for-lustre"><a class="markdownIt-Anchor" href="#amazon-fsx-for-lustre"></a> Amazon FSx for Lustre</h2><ul><li>Lustre is a type of parallel distributed file system, for large scale computing</li><li>the name Lustre is derived from Linux and Cluster</li><li>Machine Learning, High Performance Computing</li><li>Video processing, Financial Modeling and Electronic Design Automation</li><li>Seamless integration with S3</li><li>can be used from on-premises servers</li></ul><h3 id="fsx-file-system-deployment-options"><a class="markdownIt-Anchor" href="#fsx-file-system-deployment-options"></a> FSx File System Deployment Options</h3><ul><li>Scratch file system<ul><li>temporary storage</li><li>data is not replicated</li><li>high burst</li><li>usage: short-term processing, optimize costs</li></ul></li><li>Persistent File System<ul><li>long-term storage</li><li>data is replicated within same AZ</li><li>replace failed files within minutes</li><li>usage: long-term processing, sensitive data</li></ul></li></ul><h1 id="aws-transfer-family"><a class="markdownIt-Anchor" href="#aws-transfer-family"></a> AWS Transfer Family</h1><ul><li>a fully managed service for file transfers into and out of Amazon S3 or Amazon EFS using the FTP protocol</li><li>supported protocols<ul><li>AWS Transfer for FTP (File Transfer Protocol)</li><li>AWS Transfer for FTPS (File Transfer Protocol over SSL)</li><li>AWS Transfer for SFTP (Secure File Transfer Protocol)</li></ul></li><li>Managed infrastructure, scalable, reliable, highly available</li><li>pay per provisioned endpoint per hour + data transfers in GB</li><li>store and manage users’ credentials within the services</li><li>integrate with existing authentication systems (Microsoft Active Directory, LDAP, Okta…)</li></ul><h1 id="aws-storage-comparison"><a class="markdownIt-Anchor" href="#aws-storage-comparison"></a> AWS Storage Comparison</h1><ul><li>S3: Object Storage<ul><li>S3 is going to be an object storage, it’s going to be serverless, you don’t have to prove incapacity ahead of time. It has some deep integration with so many database services.</li></ul></li><li>Glacier: Object Archival<ul><li>Glacier is going to be for object archival. So this is when we want to store objects for a long period of time. Retrieve it very very rarely, and when we retrieve these objects, they’re going to be taking a lot of time to get back to us because they are archived.</li></ul></li><li>EFS: Network File System for Linux instances, POSIX file system<ul><li>EFS is Elastic File System, and this is a network file system for Linux instances. It is a POSIX file system so that means for Linux again. And it is accessible from all your EC2 instances at once. So it is something that is going to be shared and across AZ.</li></ul></li><li>FSx for Windows: Network File System for Windows servers<ul><li>FSx for Windows is the same thing as EFS, but for Windows. So it’s a network file system for your Windows servers.</li></ul></li><li>FSx for Lustre: High performance computing Linux file system<ul><li>FSx for Lustre is Linux and cluster, so it’s for High Performance Computing Linux file system. This is where you’re going to do your HPC running. You only have insanely high IOPS, insanely big capacity. And it has integration with S3 in the back end.</li></ul></li><li>EBS volume: network storage for one EC2 instance at a time<ul><li>EBS volumes is your network storage for one EC2 instance at a time only. And it is bound to a specific availability zone that you create it in. And in case you wanted to change the AZ, you will need to create a snapshot, move that snapshot over, and create a volume from it.</li></ul></li><li>Instance Storage: physical storage for your EC2 instance (high IOPS)<ul><li>Instance Storage is going to be physical storage for your EC2 instance. And so, because it’s attached from the hardware, then it’s going to have a much higher IOPS than EBS. EBS volumes, as we remember, it is up to 16,000 IOPS or 64,000 IOPS for io1. But for Instance Storage, because it is physically attached to your EC2 instance, you can get, for some, millions of IOPS. Um, it’s going to be very high. But the risk is that if your EC2 instance goes down, then you will lose that storage permanently.</li></ul></li><li>Storage Gateway: file gateway, volume gateway, tape gateway<ul><li>Storage Gateway is going to be transporting files from on premise to AWS. So we have File Gateway, Volume Gateway for cache and stored, and Tape Gateway. Each with their use cases.</li></ul></li><li>Snowball / Snowmobile: to move large amount of data to the cloud, physically<ul><li>And then finally, Snowball/Snowmobile to move large amount of data to the cloud physically into S3.</li></ul></li><li>database: for specific workloads, usually with indexing and querying</li></ul><h1 id="amazon-sqs-simple-queuing-service"><a class="markdownIt-Anchor" href="#amazon-sqs-simple-queuing-service"></a> Amazon SQS (Simple Queuing Service)</h1><ul><li>Fully managed service, used to decouple applications</li><li>attributes<ul><li>unlimited throughput, unlimited number of messages in queue</li><li>default retention of messages: 4 days, to maximum 14 days</li><li>low latency</li><li>limitation of 256KB per message sent</li></ul></li><li>can have duplicate messages (at least once delivery, occasionally)</li><li>can have out of order message (best effort ordering)</li></ul><h2 id="producing-messages"><a class="markdownIt-Anchor" href="#producing-messages"></a> Producing Messages</h2><ul><li>Produced to SQS using the SDK (SendMessage API)</li><li>the message is persisted in SQS until a concumer deletes it</li></ul><h2 id="consuming-messages"><a class="markdownIt-Anchor" href="#consuming-messages"></a> Consuming Messages</h2><ul><li>consumers (running on EC2 instances, servers, or AWS lambda)</li><li>Poll SQS for messages (receive up to 10 message at a time)</li><li>process the messages (example: insert the message into an RDS database)</li><li>delete the messages using the DeleteMessage API</li></ul><h2 id="multiple-ec2-instances-consumers"><a class="markdownIt-Anchor" href="#multiple-ec2-instances-consumers"></a> Multiple EC2 instances consumers</h2><ul><li>consumers receive and process messages in parallel</li><li>at least once delivery (another consumer will receive the message if the first consumer didn’t process it fast enough)</li><li>best-effort message ordering</li><li>consumers delete messages after processing them</li><li>we can scale consumers horizontally to improve throughput of processing</li></ul><h2 id="sqs-with-auto-scaling-group"><a class="markdownIt-Anchor" href="#sqs-with-auto-scaling-group"></a> SQS with Auto Scaling Group</h2><ol><li>CloudWatch is monitoring the SQS length</li><li>if SQS length is too long, CloudWatch will trigger an alarm</li><li>Auto Scaling group will increase the number of EC2 instances if the alarm is triggered</li></ol><h2 id="sqs-security"><a class="markdownIt-Anchor" href="#sqs-security"></a> SQS Security</h2><ul><li>encryption<ul><li>in flight encryption using HTTPS API</li><li>at rest encryption using KMS keys</li><li>client side encryption if the client wants to perform encryption / decryption itself</li></ul></li><li>Access control: IAM policies to regulate access to the SQS API</li><li>SQS access policies (similar to S3 bucket policies)</li></ul><h2 id="sqs-queue-access-policy"><a class="markdownIt-Anchor" href="#sqs-queue-access-policy"></a> SQS Queue Access Policy</h2><ul><li>Cross Account Access<ul><li>if other accounts want to poll message from the SQS queue, we could add policy to the SQS specify which account and allow it to call receiveMessage API</li></ul></li><li>publish S3 event notifications to SQS queue<ol><li>we upload an object to a S3 bucket</li><li>S3 bucket triggered an event message to be sent to SQS queue</li></ol><ul><li>we need to add a policy to SQS queue allowing the bucket to call SendMessage API to the queue</li></ul></li></ul><h2 id="sqs-message-visibility-timeout"><a class="markdownIt-Anchor" href="#sqs-message-visibility-timeout"></a> SQS - Message Visibility Timeout</h2><ul><li><p>after a message is polled by a consumer, it becomes invisible to other consumers</p></li><li><p>by default, the message visibility timeout is 30 seconds</p></li><li><p>that means the message has 30 seconds to be processed and deleted from the queue</p></li><li><p>after the message visibility timeout is over, the message is visible in SQS for other consumers to receive</p></li><li><p>if a message is not processed within the visiblity timeout, it will be processed again by other consumers</p></li><li><p>a consumer could call the ChangeMessageVisibility API to get more time</p></li><li><p>if visibility timeout is high (hours), and consumer crashes, re-processing will take time</p></li><li><p>if visibility timeout is too low (seconds), we may get duplicates</p></li></ul><h2 id="sqs-dead-letter-queue"><a class="markdownIt-Anchor" href="#sqs-dead-letter-queue"></a> SQS - Dead Letter Queue</h2><ul><li>if a consumer fails to process a message within the visibility timeout, the message goes back to the queue</li><li>we can set a threshold of how many times a message can go back to the queue</li><li>after the MaximumReceives threshold is exceeded, the message goes into a dead letter queue (DLQ)</li><li>useful for debugging</li><li>make sure to process the messages in the DLQ before they expire</li><li>good to set a retention of 14 days in the DLQ</li></ul><h2 id="sqs-request-response-systems"><a class="markdownIt-Anchor" href="#sqs-request-response-systems"></a> SQS - Request - Response Systems</h2><ol><li>producer send request with the reply-to queue ID to the Request queue</li><li>responders receive the request from the Request queue and process it</li><li>after processing, responders send the response to the corrent Response queue using the queue ID in the request</li></ol><ul><li>to implement this pattern: use the SQS Temporary Queue Client</li><li>it leverages virtual queues instead of creating / deleting SQS queues (cost effective)</li></ul><h2 id="sqs-delay-queue"><a class="markdownIt-Anchor" href="#sqs-delay-queue"></a> SQS - Delay Queue</h2><ul><li>delay a message (consumers don’t see it immediately) up to 15 minutes</li><li>default is 0 seconds (message is avaialble right away)</li><li>can set a default at queue level</li><li>can override the default on send using the DelaySeconds parameter</li></ul><h2 id="sqs-fifo-queue"><a class="markdownIt-Anchor" href="#sqs-fifo-queue"></a> SQS - FIFO queue</h2><ul><li>Frist In First Out</li><li>limited throughput</li><li>exactly once send capability (by removing duplicates), the message that failed to be processed will be insert at the end of the queue</li><li>messages are processed in order by the consumer</li></ul><h1 id="amazon-sns"><a class="markdownIt-Anchor" href="#amazon-sns"></a> Amazon SNS</h1><ul><li>the event producer only sends message to one SNS topic</li><li>as many event receivers (subscriptions) as we want to listen to the SNS topic notifications</li><li>each subscriber to the topic will get all the messages (note: new feature to filter messages)</li><li>subscribers can be<ul><li>SQS</li><li>HTTP / HTTPS</li><li>lambda</li><li>Emails</li><li>SMS messages</li><li>Mobile notifications</li></ul></li></ul><h2 id="sns-integrates-with-a-lot-of-aws-services"><a class="markdownIt-Anchor" href="#sns-integrates-with-a-lot-of-aws-services"></a> SNS integrates with a lot of AWS services</h2><ul><li>many AWS services can send data directly to SNS for notifications</li><li>CloudWatch (for alarms)</li><li>Auto Scaling Groups notifications</li><li>Amazon S3 (on bucket events)</li><li>CloudFormation (upon state changes =&gt; failed to build etc…)</li><li>etc…</li></ul><h2 id="how-to-publish"><a class="markdownIt-Anchor" href="#how-to-publish"></a> How to publish</h2><ul><li>topic publish (using SDK)<ul><li>create a topic</li><li>create a subscription</li><li>publish to the topic</li></ul></li><li>direct publish (for mobile apps SDK)<ul><li>create a platform application</li><li>create a platform endpoint</li><li>publish to the platform endpoint</li><li>works with Google GCM, Apple APNS, Amazon ADM…</li></ul></li></ul><h2 id="security-2"><a class="markdownIt-Anchor" href="#security-2"></a> Security</h2><ul><li>Encryption<ul><li>in flight encryption using HTTPS / API</li><li>at rest encryption using KMS keys</li><li>Client side encryption if the client wants to perform encryption / decryption itself</li></ul></li><li>Access Control: IAM policies to regulate access to the SNS API</li><li>SNS access policies (similar to S3 bucket policies)<ul><li>useful for cross account access to SNS topics</li><li>useful for allowing other services (S3…) to write to an SNS topic</li></ul></li></ul><h2 id="sns-sqs-fan-out"><a class="markdownIt-Anchor" href="#sns-sqs-fan-out"></a> SNS + SQS: Fan Out</h2><ul><li>Push once in SNS, receive in all SQS queues that are subscribers</li><li>fully decoupled, no data loss</li><li>SQS allows for: data persistence, delayed processing and retries of work</li><li>ability to add more SQS subscribers over time</li><li>make sure your SQS queue access policy allows for SNS to write</li></ul><h3 id="eg-s3-events-to-multiple-queues-or-lambda-functions"><a class="markdownIt-Anchor" href="#eg-s3-events-to-multiple-queues-or-lambda-functions"></a> e.g. S3 Events to multiple queues or lambda functions</h3><ul><li>if you want to send the same S3 event to many SQS queues, or optionally lambda functions, use fan out pattern</li></ul><h2 id="sns-fifo-topic"><a class="markdownIt-Anchor" href="#sns-fifo-topic"></a> SNS FIFO topic</h2><ul><li>similar features as SQS FIFO<ul><li>ordering by message group ID (all messages in the same group are ordered)</li><li>deduplication using a deduplication ID or Content Based Deduplication</li></ul></li><li>can only have SQS FIFO queue as subscribers</li><li>limited throughput (same throughput as SQS FIFO)</li></ul><h2 id="message-filtering"><a class="markdownIt-Anchor" href="#message-filtering"></a> Message Filtering</h2><ul><li>JSON policy used to filter messages sent to SNS topic’s subscriptions</li><li>if a subscription doesn’t have a filter policy, it receives every message</li></ul><h1 id="aws-kinesis"><a class="markdownIt-Anchor" href="#aws-kinesis"></a> AWS Kinesis</h1><ul><li>make it easy to collect, process and analyze streaming data in real time</li><li>ingest real time data such as application logs, Metrics, website clickstreams, IoT telemetry data…</li></ul><h2 id="kinesis-data-streams"><a class="markdownIt-Anchor" href="#kinesis-data-streams"></a> Kinesis Data Streams</h2><ul><li>billing is per shard provisioned, can have as many shards as you want</li><li>retention between 1 day (default) to 365 days</li><li>ability to reprocess (replay) data</li><li>once data is inserted in Kinesis, it can’t be deleted (immutability)</li><li>data that shares the same partition goes to the same shard (ordering)</li><li>producers: AWS SDK, Kinesis Producer Library (KPL), Kinesis Agent</li><li>consumers:<ul><li>write your own: Kinesis Client Library (KCL), AWS SDK</li><li>managed: AWS Lambda, Kinesis Data Firehose, Kinesis Data Analytics</li></ul></li></ul><h2 id="kinesis-firehose"><a class="markdownIt-Anchor" href="#kinesis-firehose"></a> Kinesis Firehose</h2><ul><li>fully managed service, no administration, automatic scaling, serverless<ul><li>AWS redshift / Amazon S3 / ElasticSearch</li></ul></li><li>pay for data going through firehose</li><li>near real time<ul><li>60 seconds latency minimum for non full batches</li><li>or minimum 32 MB of data at a time</li></ul></li><li>supports many data formats, conversions, transformations, compression</li><li>supports custom data transformations, using AWS Lambda</li><li>can send failed or all data to a backup S3 bucket</li></ul><table><thead><tr><th>Kinesis Data Streams</th><th>Kinesis Data Firehos</th></tr></thead><tbody><tr><td>Streaming service for ingest at scale</td><td>load streaming data into S3 / redshift / ES / Thrid party / custom HTTP</td></tr><tr><td>write custom code (producer, consumer)</td><td>fully managed</td></tr><tr><td>real time (~200ms)</td><td>near real time (buffer time min 60 seconds)</td></tr><tr><td>manage scaling (shard splitting / merging)</td><td>automatic scaling</td></tr><tr><td>data storage for 1 to 365 days</td><td>no data storage</td></tr><tr><td>support replay capability</td><td>doesn’t support replay capability</td></tr></tbody></table><h2 id="kinesis-data-analytics-sql-application"><a class="markdownIt-Anchor" href="#kinesis-data-analytics-sql-application"></a> Kinesis Data Analytics (SQL application)</h2><ul><li>perform real time analytics on Kinesis Streams using SQL</li><li>fully managed, no servers to provision</li><li>automatic scaling</li><li>real time analytics</li><li>pay for actual consumtion rate</li><li>can create streams out of the real time queries</li><li>use cases<ul><li>time series analytics</li><li>real time dashboards</li><li>real time metrics</li></ul></li></ul><h2 id="kinesis-vs-sqs-ordering"><a class="markdownIt-Anchor" href="#kinesis-vs-sqs-ordering"></a> Kinesis vs SQS ordering</h2><ul><li>let’s assume we have 100 trucks, 5 Kinesis shards, 1 SQS FIFO</li><li>Kinesis data streams<ul><li>on average you will have 20 trucks per shard</li><li>trucks will have their data ordered within each shard</li><li>the maximum amount of consumer in parallel we can have is 5</li><li>can receive up to 5MB/s of data</li></ul></li><li>SQS FIFO<ul><li>you only have one SQS FIFO queue</li><li>you will have 100 group ID</li><li>you can have up to 100 consumers (due to the 100 group ID)</li><li>you have up to 300 messages per second (or 3000 if using batching)</li><li>better to use if you have a dynamic number of consumers</li></ul></li></ul><table><thead><tr><th>SQS</th><th>SNS</th><th>Kinesis</th></tr></thead><tbody><tr><td>consumer pull data</td><td>push data to many subscribers</td><td>standard: pull data (2MB per shard), enhanced-fan out: push data (2MB per shard per consumer)</td></tr><tr><td>data is deleted after being consumed</td><td>data is not persisted (lost if not delivered)</td><td>possibility to replay data</td></tr><tr><td>can have as many workers as we want</td><td>up to 12,500,000 subscribers</td><td>-</td></tr><tr><td>no need to provision throughput</td><td>no need to provision throughput</td><td>must provision throughput</td></tr><tr><td>ordering guearantees only on FIFO queues</td><td>FIFO capability for SQS FIFO</td><td>ordering at shard level</td></tr><tr><td>individual message delay capability</td><td>integrates with SQS for fan out architecture pattern</td><td>data expires after X days</td></tr><tr><td>-</td><td>-</td><td>meant for real time big data analytics and ETL</td></tr></tbody></table><h2 id="amazon-mq"><a class="markdownIt-Anchor" href="#amazon-mq"></a> Amazon MQ</h2><ul><li>SQS, SNS are cloud native serviecs, and they are using proprietary protocols from AWS</li><li>traditional applications running from on-premises may use open protocols such as MQTT, AMQP, STOMP, OpenWire, WSS</li><li>when migrating to the cloud, instead of re-engineering the application to use SQS, SNS, we can use Amazon MQ</li></ul><h1 id="container"><a class="markdownIt-Anchor" href="#container"></a> Container</h1><h2 id="docker"><a class="markdownIt-Anchor" href="#docker"></a> Docker</h2><ul><li>Docker is a software development platform to deploy apps</li><li>apps are packaged in containers that can be run on any OS</li><li>apps run the same, regardless of where they are run<ul><li>any machine</li><li>no compatibility issues</li><li>predictable behavior</li><li>less work</li><li>easier to maintain and deploy</li><li>works with any language, any OS, any techonology</li></ul></li></ul><h2 id="where-are-docker-images-stored"><a class="markdownIt-Anchor" href="#where-are-docker-images-stored"></a> Where are Docker images stored</h2><ul><li>Docker images are stored in Docker repositories</li><li>public: Docker hub: <a href="https://hub.docker.com/">https://hub.docker.com/</a></li><li>private: Amazon ECR (Elastic Container Registry)</li><li>Public: Amazon ECR public</li></ul><h2 id="docker-containers-management"><a class="markdownIt-Anchor" href="#docker-containers-management"></a> Docker Containers Management</h2><ul><li>to manage containers, we need a container managemenet platform<ul><li>ECS (Amazon’s own container platform)</li><li>Fargate: Amazon’s own serverless container platform</li><li>EKS: Amazon’s managed Kubernetes (open source)</li></ul></li></ul><h2 id="ecs-elastic-container-service"><a class="markdownIt-Anchor" href="#ecs-elastic-container-service"></a> ECS (Elastic Container Service)</h2><ul><li>Launch Docker containers on AWS</li><li>you must provision and maintain the infrastructrue (the EC2 instance)</li><li>AWS takes care of starting and stopping the containers</li><li>has integrations with the Application Load Balancer</li><li>ECS agent will be installed on the EC2 instances for ECS to know who to manage</li></ul><h2 id="fargate"><a class="markdownIt-Anchor" href="#fargate"></a> Fargate</h2><ul><li>launch Docker containers on AWS</li><li>you do not provision the infrastructure (no EC2 instances to manage)</li><li>serverless offering</li><li>AWS just runs containers for you based on the CPU / RAM you need</li><li>for each container in Fargate it needs an ENI for the public to access it</li></ul><h2 id="iam-roles-for-ecs-tasks"><a class="markdownIt-Anchor" href="#iam-roles-for-ecs-tasks"></a> IAM roles for ECS tasks</h2><ul><li>EC2 instance profile<ul><li>used by the ECS agent</li><li>makes API calls to ECS service</li><li>send container logs to CloudWatch logs</li><li>pull docker image from ECR</li><li>reference sensitive data in Secret Manager or SSM Parameter store</li></ul></li><li>ECS task role<ul><li>allow each task to have a specific role</li><li>use different roles for the different ECS services you run</li><li>task role is defined in the task definition</li></ul></li></ul><h2 id="ecs-data-volumes-efs-file-systems"><a class="markdownIt-Anchor" href="#ecs-data-volumes-efs-file-systems"></a> ECS data volumes - EFS file systems</h2><ul><li>works for both EC2 tasks and Fargate tasks</li><li>ability to mount EFS volumes onto tasks</li><li>tasks launched in any AZ will be able to share the same data in the EFS volume</li><li>Fargate + EFS = serverless  + data storage without managing servers</li><li>use case: persistent multi-AZ shared storage for your containers</li></ul><h2 id="load-balancing-for-ec2-launch-type"><a class="markdownIt-Anchor" href="#load-balancing-for-ec2-launch-type"></a> Load Balancing for EC2 Launch type</h2><ul><li>we get a dynamic port mapping</li><li>the ALB supports finding the right port on your EC2 instances</li><li>you must allow on the EC2 instnace’s security group any port from the ALB security group</li></ul><h2 id="load-balancing-for-fargate"><a class="markdownIt-Anchor" href="#load-balancing-for-fargate"></a> Load Balancing for Fargate</h2><ul><li>each task has a unique IP (because of ENI)</li><li>you must allow on the ENI’s security group the task port from the ALB security group</li></ul><h2 id="event-bridge"><a class="markdownIt-Anchor" href="#event-bridge"></a> Event Bridge</h2><ol><li>user upload object to S3</li><li>S3 triggers event to Amazon Event Bridge</li><li>Event Bridge triggers the container task to run</li><li>the task will have the role to access S3 and DynamoDB</li><li>task will get the object from S3 and save it to DynamoDB</li></ol><h2 id="ecs-rolling-updates"><a class="markdownIt-Anchor" href="#ecs-rolling-updates"></a> ECS Rolling updates</h2><ul><li>when updating from v1 to v2, we can control how many tasks can be started and stopped, and in which order, by specifying the minimum and maximum healthy percent</li></ul><h2 id="ecr-elastic-container-registry"><a class="markdownIt-Anchor" href="#ecr-elastic-container-registry"></a> ECR (Elastic Container Registry)</h2><ul><li>store, manage and deploy containers on AWS, pay for what you use</li><li>fully integrated with ECS and IAM for security, backed by Amazon S3</li><li>supports image vulnerability scanning, version, tag, image lifecycle</li><li>but if we wanted to automate the whole process, we could be using a CICD, so Continuous Integration Continuous Deployment platform and for example, CodeBuild could help us with this to automate building a Docker image and then pushing it onto Amazon ECR to finally trigger an ECS update.</li></ul><h2 id="eks-elastic-kubernetes-service"><a class="markdownIt-Anchor" href="#eks-elastic-kubernetes-service"></a> EKS (Elastic Kubernetes Service)</h2><ul><li>it is a way to launch managed Kubernetes clusters on AWS</li><li>Kubernetes is an open source system for automatic deployment, scaling and management of containerized application</li><li>it is an alternative to ECS, similar goal but different API</li><li>EKS supports<ul><li>EC2 if you want to deploy worker nodes</li><li>Fargate to deploy serverless containers</li></ul></li><li>use case: if your company is already using Kunernetes on-premises or in another cloud, and wants to migrate to AWS using Kubernetes</li><li>Kubernetes is cloud agnostic (can be used in any cloud, Azure, GCP…)</li></ul><h1 id="serverless"><a class="markdownIt-Anchor" href="#serverless"></a> Serverless</h1><ul><li>serverless is a new paradigm in which the developers don’t have to manage servers anymore</li><li>Serverless was pioneered by AWS lambda but now also includes anything that’s managed: database, messaging, storage</li><li>serverless does not mean there are no servers, it means that you just don’t need to manage / provision / see them</li></ul><h2 id="lambda"><a class="markdownIt-Anchor" href="#lambda"></a> Lambda</h2><ul><li>easy pricing<ul><li>pay per request and compute time</li></ul></li><li>integrated with the whole AWS suite of services</li><li>integrated with many programming languages<ul><li>Node.js</li><li>Python</li><li>Java</li><li>C# (.NET Core)</li><li>Golang</li><li>C# / Powershell</li><li>Ruby</li><li>Lambda container image<ul><li>the container image must implement the lambda runtime API</li><li>ECS / Fargate is perferred for running arbitrary Docker images</li></ul></li></ul></li><li>easy monitoring through AWS CloudWatch</li><li>easy to get more resources per functions</li></ul><h3 id="lambda-limits"><a class="markdownIt-Anchor" href="#lambda-limits"></a> Lambda Limits</h3><ul><li>Execution<ul><li>Memory allocation: 128MB - 10GB (64 MB increments)</li><li>Maximum execution time: 15 minutes</li><li>Environment variables (4 KB)</li><li>disk capacity in the function container (in /tmp): 512 MB</li><li>concurrency executions: 1000 (can be increased)</li></ul></li><li>Deployment<ul><li>lambda function deployment size (compressed zip): 50 MB</li><li>size of uncompressed deployment (code + dependencies): 250 MB</li><li>can use the /tmp directory to load other files at startup</li><li>size of environment variables: 4KB</li></ul></li></ul><h3 id="lambdaedge"><a class="markdownIt-Anchor" href="#lambdaedge"></a> Lambda@Edge</h3><ul><li><p>you have deployed a CDN using CloudFront</p></li><li><p>what if you wanted to run a global AWS lambda alongside?</p></li><li><p>or how to implement request filtering before reaching your application?</p></li><li><p>for this, you can use Lambda@Edge</p><ul><li>build more responsive applications</li><li>you don’t manage servers, lambda is deployed globally</li><li>customize the CDN content</li><li>pay only for what you use</li></ul></li><li><p>you can use lambda to change CloudFront requests and responses</p><ul><li>after cloudfront receives a request from a viewer (viewer request)</li><li>before cloudfront forwards the request to the origin (origin request)</li><li>after cloudfront receives the response from the origin (origin response)</li><li>before cloudfront forwards the response to the viewer (viewer response)</li></ul></li><li><p>you can also generate responses to viewers without ever sending the request to the origin</p></li></ul><h2 id="dynamodb"><a class="markdownIt-Anchor" href="#dynamodb"></a> DynamoDB</h2><ul><li>fully managed, hgihly available with replication across 3 AZ</li><li>NoSQL database, not a relational database</li><li>scales to massive workloads, distributed database</li><li>millions of requests per seconds, trillions of row, 100s of TB of storage</li><li>fast and consistent in performance (low latency on retrieval)</li><li>integrated with IAM for security, authorization and administration</li><li>enables event driven programming with DynamoDB streams</li><li>low cost and auto scaling capabilities</li></ul><h3 id="dynamodb-basics"><a class="markdownIt-Anchor" href="#dynamodb-basics"></a> DynamoDB - basics</h3><ul><li>DynamoDB is made of tables</li><li>each table has a primary key (must be decided at creation time)</li><li>each table can have an infinite number of items (rows)</li><li>each item has attributes (can be added over time - can be null)</li><li>maximum size of a item is 400KB</li><li>data types supported are<ul><li>Scalar Type: string, number, binary, booelan, null</li><li>Document type: list, map</li><li>set types: string set, number set, binary set</li></ul></li></ul><h3 id="provisioned-throughput"><a class="markdownIt-Anchor" href="#provisioned-throughput"></a> Provisioned Throughput</h3><ul><li>table must have provisioned read and write capacity units</li><li>read capacity units (RCU), throughput for reads<ul><li>1 RCU = 1 strongly consistent read of 4 KB per second</li><li>1 RCU = 2 eventually consistent read of 4 KB per second</li></ul></li><li>write capacity units (WCU), throughput for writes<ul><li>1 WCU = 1 write of 1 KB per second</li></ul></li><li>option to setup auto scaling of throughput to meet demand</li><li>throughput can be exceeded temporarily using burst credit</li><li>if burst credit are empty, you will get a ProvisionedThroughputExeception</li><li>it is then advised to do an exponential back off retry</li></ul><h3 id="dynamodb-dax"><a class="markdownIt-Anchor" href="#dynamodb-dax"></a> DynamoDB - DAX</h3><ul><li>DynamoDB accelerator</li><li>seamless cache for DynamoDB, no application re-write</li><li>writes go through DAX to DynamoDB</li><li>micro second latency for cached reads and queries</li><li>solves the Hot Key problem (too many reads)</li><li>5 minutes TTL for cache by default</li><li>up to 10 nodes in the cluster</li><li>multi AZ (3 nodes minumum recommended for production)</li><li>secure (encryption at rest with KMS, VPC, IAM, CloudTrail…)</li></ul><h3 id="dynamodb-streams"><a class="markdownIt-Anchor" href="#dynamodb-streams"></a> DynamoDB Streams</h3><ul><li>changes in DynamoDB (create, update, delete) can end up in a DynamoDB stream</li><li>this stream can be read by AWS lambda and we can then do<ul><li>react to changes in real time (welcome email to new users)</li><li>analytics</li><li>create derivative tables/ views</li><li>insert into elasticSearch</li></ul></li><li>cloud implement cross region replication using Streams</li><li>Stream has 24 hours of data retention</li></ul><h3 id="transactions-new-from-nov-2018"><a class="markdownIt-Anchor" href="#transactions-new-from-nov-2018"></a> Transactions (new from Nov 2018)</h3><ul><li>all or nothing type of operations</li><li>coordinated insert, update and delete across multiple tables</li><li>include up to 10 unique items or up to 4MB of data</li></ul><h3 id="on-demand-new-from-nov-2018"><a class="markdownIt-Anchor" href="#on-demand-new-from-nov-2018"></a> On Demand (new from Nov 2018)</h3><ul><li>no capacity planning needed (WCU / RCU) - scales automatically</li><li>2.5x more expensive than provisioned capacity</li><li>helpful when spikes are un-predicatable or the application is very low throughput</li></ul><h3 id="dynamodb-security-and-other-features"><a class="markdownIt-Anchor" href="#dynamodb-security-and-other-features"></a> DynamoDB - Security and other features</h3><ul><li>Security<ul><li>VPC endpoints available to access DynamoDB without internet</li><li>access fully controlled by IAM</li><li>encryption at rest using KMS</li><li>encryption in transit using SSL / TLS</li></ul></li><li>backup and restore feature available<ul><li>point in time restore like RDS</li><li>no performance impact</li></ul></li><li>Global Tables (cross region replication)<ul><li>multi region, fully replicated, high performance</li><li>active active replication (data will be replicated to other tables no matter which table gets the data first)</li><li>must enable DynamoDB Streams</li><li>useful for low latency, Disater Recovery purposes</li></ul></li><li>Amazon DMS (Data Migration Service) can be used to migrate to DynamoDB (from Mongo, Oracle, MySQL, S3, etc…)</li><li>you can launch a local DynamoDB on your computer for development purposes</li></ul><h2 id="api-gateway"><a class="markdownIt-Anchor" href="#api-gateway"></a> API Gateway</h2><ul><li>AWS lambda + API gateway</li><li>support for the webSocket Protocol</li><li>handle API versioning</li><li>handle different environments (dev, test, prod)</li><li>handle security (authentication, authorization)</li><li>create API keys, handle request throttling</li><li>Swagger / Open API import to quickly define APIs</li><li>Transform and validate requests and responses</li><li>generate SDK and API specifications</li><li>cache API responses</li></ul><h3 id="api-gateway-endpoint-types"><a class="markdownIt-Anchor" href="#api-gateway-endpoint-types"></a> API Gateway - Endpoint Types</h3><ul><li>Edge Optimized (default): for global clients<ul><li>requests are routed through the CloudFront edge locations (improves latency)</li><li>the API gateway still lives in only one region</li></ul></li><li>Regional<ul><li>for clients within the same region</li><li>could manually combine with CloudFront (more control over the caching strategies and the distribution)</li></ul></li><li>private<ul><li>can only by accessed from your VPC using an interface VPC endpoint (ENI)</li><li>use a resource policy to define access</li></ul></li></ul><h3 id="security-3"><a class="markdownIt-Anchor" href="#security-3"></a> Security</h3><h4 id="iam-permissions-2"><a class="markdownIt-Anchor" href="#iam-permissions-2"></a> IAM Permissions</h4><ul><li>create an IAM policy authorization and attach to User / Role</li><li>API gateway verfies IAM permissions passed by the calling application</li><li>good to provide access within your own infrastructure</li><li>leverage Sig v4 capability where IAM credential are in headers</li></ul><h4 id="lambda-authorizer"><a class="markdownIt-Anchor" href="#lambda-authorizer"></a> Lambda authorizer</h4><ul><li>users AWS lambda to validate the token in header being passed</li><li>option to cache result of authentication</li><li>helps to use OAuth / SAML / third party type of authentication</li><li>lamdba (authorizer) must return an IAM policy for the user</li></ul><h4 id="cognito-user-pools"><a class="markdownIt-Anchor" href="#cognito-user-pools"></a> Cognito User Pools</h4><ul><li>cognito fully manages user lifecycle</li><li>API gateway verifies identity automatically from AWS cognito</li><li>no custom implementation required</li><li>Cognito only helps with authentication, not authorization</li></ul><h2 id="aws-cognito"><a class="markdownIt-Anchor" href="#aws-cognito"></a> AWS Cognito</h2><ul><li>we want to give our users an identity so that they can interact with our application</li></ul><h3 id="aws-cognito-user-pools"><a class="markdownIt-Anchor" href="#aws-cognito-user-pools"></a> AWS Cognito User Pools</h3><ul><li>create a serverless database of user for your mobile apps</li><li>simple login: username or email  / password combination</li><li>possibility to verify emails / phone numbers and add MFA</li><li>can enable federated identities (Facebook, Google, SAML…)</li><li>sends back a JSON web tokens (JWT)</li><li>can be integrated with API gateway for authentication</li></ul><h3 id="aws-cognito-federated-identity-pools"><a class="markdownIt-Anchor" href="#aws-cognito-federated-identity-pools"></a> AWS Cognito - Federated Identity Pools</h3><ul><li>goal<ul><li>provide direct access to AWS resources from the client side</li></ul></li><li>How<ul><li>login to federated identity provider - or remain anonymous</li><li>get temporary AWS credentials back from the federated identity pool</li><li>these credentials come with a pre-defined IAM policy stating their permissions</li></ul></li><li>example<ul><li>provide (temporary) access to write to S3 bucket using Facebook login</li></ul></li></ul><h3 id="aws-cognito-sync"><a class="markdownIt-Anchor" href="#aws-cognito-sync"></a> AWS Cognito Sync</h3><ul><li>deprecated - use AWS AppSync now</li><li>store preferneces, configuration, state of app</li><li>cross device synchronization</li><li>offline capability (synchronization when back online)</li><li>requires federated identity pool in Cognito</li><li>store data in datasets</li></ul><h2 id="aws-sam-serverless-application-model"><a class="markdownIt-Anchor" href="#aws-sam-serverless-application-model"></a> AWS SAM - Serverless Application Model</h2><ul><li>framework for developing and deploying serverless applications</li><li>all the configurations is YAML code<ul><li>lambda functions</li><li>DynamoDB tables</li><li>API Gateway</li><li>Cognito User Pool</li></ul></li><li>SAM can help you to run Lambda, API Gateway, DynamoDB locally</li><li>SAM can use CodeDeploy to deploy lambda functions</li></ul><h1 id="databases-comparison"><a class="markdownIt-Anchor" href="#databases-comparison"></a> Databases Comparison</h1><h2 id="rds-2"><a class="markdownIt-Anchor" href="#rds-2"></a> RDS</h2><ul><li>managed postgreSQL / MySQL / Oracle / SQL server</li><li>must provision an EC2 instance and EBS volume type and size</li><li>support for read replicas and multi AZ</li><li>security through IAM, security groups, KMS, SSL in transit</li><li>backup / snapshot / point in time restore</li><li>managed and scheduled maintenance</li><li>monitoring through CloudWatch</li><li>use case: store relational datasets (RDBMS / OLTP (online transactional processing)), perform SQL queries, transactional inserts / update / delete is available</li></ul><h2 id="aurora"><a class="markdownIt-Anchor" href="#aurora"></a> Aurora</h2><ul><li>compatible API for PostgreSQL / MySQL</li><li>Data is held in 6 replicas, 3 AZ</li><li>auto healing capability</li><li>multi AZ, auto scaling read replicas</li><li>read replicas can be global</li><li>Aurora database can be global for DR or latency purpose</li><li>define EC2 instance type for Aurora instances</li><li>same security / monitoring / maintenance features as RDS</li><li>Aurora Serverless - for unpredicatble / intermittent workloads</li><li>Aurora multi-master - for continuous write failover</li><li>no need to provision</li><li>use case: same as RDS, but with less maintenance / more flexibility / more performance</li></ul><h2 id="elasticcache"><a class="markdownIt-Anchor" href="#elasticcache"></a> ElasticCache</h2><ul><li>managed Redis / Memcached (similar offering as RDS, but for caches)</li><li>in memory data store, sub-millisecond latency</li><li>must provision an EC2 instance type</li><li>support for Clustering (Redis), and Multi AZ, read replicas (sharding)</li><li>security through IAM, security groups, KMS, Redis Auth</li><li>backup / snapshot / point in time restore</li><li>managed and scheduled maintenance</li><li>monitoring through CloudWatch</li><li>use case: key value store, frequent reads, less writes, cache results for DB queries, store session data for websites, cannot use SQL</li></ul><h2 id="dynamodb-2"><a class="markdownIt-Anchor" href="#dynamodb-2"></a> DynamoDB</h2><ul><li>AWS proprietary technology, managed NoSQL database</li><li>serverless, provisioned capacity, auto scaling, on demand capacity</li><li>can replace ElastiCache as a key value store</li><li>highly available, multi AZ by default, read and writes are decoupled, DAX for read cache</li><li>reads can be eventually consistent (occasional old data) or strongly consistent (always latest data)</li><li>security, authentication and authorization is done through IAM</li><li>DynamoDB Streams to integrate with AWS lambda</li><li>backup and restore feature, global table feature</li><li>monitoring through CloudWatch</li><li>can only query on primay key, sort key, or indexes</li><li>use case: serverless applications development, distributed serverless cache, doesn’t have SQL query language available, has transactions capability from Nov 2018</li></ul><h2 id="s3-2"><a class="markdownIt-Anchor" href="#s3-2"></a> S3</h2><ul><li>great for big objects, not so great for small objects (because of latency)</li><li>serverless, scales infinitely, max object size is 5TB</li><li>strong consistency</li><li>Tiers: S3 standard, S3 IA, S3 One Zone IA, Glacier, for backups</li><li>features: versioning, encryption, cross region replication etc…</li><li>security: IAM, bucket policy, ACL</li><li>encryption: SSE-S3, SSE-KMS, SSE-C, client side encryption, SSL in transit</li><li>use case: static files, key value store for big files, website hosting</li></ul><h2 id="athena"><a class="markdownIt-Anchor" href="#athena"></a> Athena</h2><ul><li>fully serverless query engine with SQL capabilities</li><li>used to query data in S3</li><li>pay per query</li><li>output results back to S3</li><li>secured through IAM</li><li>use case: one time SQL queries, serverless queries on S3, log analytics</li></ul><h2 id="redshift"><a class="markdownIt-Anchor" href="#redshift"></a> RedShift</h2><ul><li><p>Redshift is based on PostgreSQL, but it is not used for OLTP</p></li><li><p>its OLAP - online analytical processing (analytics and data warehousing)</p></li><li><p>Columnar storage of data (instead of row based)</p></li><li><p>massively parallel query execution</p></li><li><p>pay as you go based on the instances provisioned</p></li><li><p>has a SQL interface for performing the queries</p></li><li><p>BI tools such as AWS quicksight or Tableau integrate with it</p></li><li><p>data is loaded from S3 / DynamoDB, DMS, other DBs</p></li><li><p>from 1 node to 128 nodes, up to 160 GB of space per node</p></li><li><p>leader node: for query planning, results aggregation</p></li><li><p>compute node: for performing the queries, send results to leader</p></li><li><p>Redshift Spectrum: perform queries directly against S3 (no need to load)</p></li><li><p>backup and restore, security VPC / IAM / KMS, monitoring</p></li><li><p>Redshift enhanced VPC routing: COPY / UNLOAD goes through VPC</p></li></ul><h3 id="snapshots-dr"><a class="markdownIt-Anchor" href="#snapshots-dr"></a> Snapshots / DR</h3><ul><li>Redshift has no multi AZ mode</li><li>snapshots are point in time backups of a cluster, stored internally in S3</li><li>snapshots are incremental (only what has changed is saved)</li><li>you can restore a snapshot into a new cluster</li><li>automated: every 8 hours, every 5 GB, or on schedule, set retention</li><li>manual: snapshot is retained until you delete it</li><li>you can configure Amazon Redshift to automatically copy snapshots (automated or manual) of a cluster to another AWS region</li></ul><h3 id="redshift-specturm"><a class="markdownIt-Anchor" href="#redshift-specturm"></a> Redshift Specturm</h3><ul><li>query data that is already in S3 without loading it</li><li>must have a Redshift cluster available to start the query</li><li>the query is then submitted to thousands of Redshift Spectrum nodes</li><li>data doesn’t need to be loaded into Redshift first</li></ul><h2 id="aws-glue"><a class="markdownIt-Anchor" href="#aws-glue"></a> AWS Glue</h2><ul><li>managed extract, transform, and load (ETL) service</li><li>useful to prepare and transform data for analytics</li><li>fully serverless service</li></ul><h3 id="glue-data-catalog"><a class="markdownIt-Anchor" href="#glue-data-catalog"></a> Glue Data Catalog</h3><ul><li>Glue data catalog: catalog of datasets (metadata)</li><li>S3 =&gt; AWS Glue Data Crawler =&gt; AWS Glue Data Catalog =&gt; Amazon Athena</li></ul><h2 id="neptune"><a class="markdownIt-Anchor" href="#neptune"></a> Neptune</h2><ul><li>fully managed graph database</li><li>when do we use graphs?<ul><li>high relationship data</li><li>social networking: users friends with users, replied to comment on post of user and likes other comments</li><li>knowledge graphs (Wikipedia)</li></ul></li><li>highly available across 3 AZ, with up to 15 read replicas</li><li>point in time recovery, continuous backup to Amazon S3</li><li>support for KMS encryption at rest + HTTPS</li></ul><h2 id="elasticsearch"><a class="markdownIt-Anchor" href="#elasticsearch"></a> ElasticSearch</h2><ul><li>example: in dynamoDB, you can only find by primary key or indexes</li><li>with ElasticSearch you can search any field, even partially matches</li><li>it is common to use ElasticSearch as a complement to another database</li><li>ElasticSearch also has some usage for Big Data applications</li><li>you can provision a cluster of instances</li><li>built in integrations: Amazon Kinesis data Firehose, SSL and VPC</li><li>comes with Kibana (visulization) and Logstash (log ingestion) - ELK stack</li></ul><h1 id="aws-cloudwatch"><a class="markdownIt-Anchor" href="#aws-cloudwatch"></a> AWS CloudWatch</h1><h2 id="cloudwatch-metrics"><a class="markdownIt-Anchor" href="#cloudwatch-metrics"></a> CloudWatch Metrics</h2><ul><li>CloudWatch provides metrics for every servcies in AWS</li><li>Metric is a variable to monitor (CPU Utilization, Network In…)</li><li>metrics belong to namespaces</li><li>dimension is an attribute of a metric (instance id, environment, etc…)</li><li>up to 10 dimensions per metric</li><li>metrics have timestamps</li><li>can create CloudWatch dashboards of metrics</li></ul><h2 id="ec2-detailed-monitoring"><a class="markdownIt-Anchor" href="#ec2-detailed-monitoring"></a> EC2 Detailed monitoring</h2><ul><li>EC2 instance metrics have metrics every 5 minutes</li><li>with detailed monitoring (for a cost), you get data every 1 minute</li><li>use detailed monitoring if you want to scale faster for your ASG</li><li>the AWS free tier allows us to have 10 detailed monitoring metrics</li><li>Note: EC2 memory usage is by default not pushed (must be pushed from inside the instance as a custom metric)</li></ul><h2 id="cloudwatch-custom-metrics"><a class="markdownIt-Anchor" href="#cloudwatch-custom-metrics"></a> CloudWatch Custom Metrics</h2><ul><li>possiblity to define and send your own custom metrics to CloudWatch</li><li>example: memory usage, disk space, number of logged in users…</li><li>use API call PutMetricData</li><li>ability to use dimensions (attributes) to segment metrics<ul><li><a href="http://instance.id">instance.id</a></li><li><a href="http://environment.name">environment.name</a></li></ul></li><li>metric resolution (StorageResolution API parameter - two possible values)<ul><li>Standard: 1 minute</li><li>high resolution: 1 / 5 / 10 / 30 seconds - higher cost</li></ul></li><li>important: accepts metric data points two weeks in the past and two hours in the future (make sure to configure your EC2 instance time correctly)</li></ul><h2 id="cloudwatch-dashboards"><a class="markdownIt-Anchor" href="#cloudwatch-dashboards"></a> CloudWatch Dashboards</h2><ul><li>great way to setup custom dashboards for quick access to key metrics and alarms</li><li>dashboards are global</li><li>dashboards can include graphs from different AWS accounts and regions</li><li>you can change the time zone and time range of the dashboards</li><li>you can setup automatic refresh (10s, 1m, 2m, 5m, 15m)</li><li>dashboards can be shared with people who don’t have an AWS account (public, email address…)</li><li>pricing<ul><li>3 dashboards (up to 50 metrics) for free</li><li>$3 dollar / dashboard / month after</li></ul></li></ul><h2 id="cloudwatch-logs"><a class="markdownIt-Anchor" href="#cloudwatch-logs"></a> CloudWatch Logs</h2><ul><li><p>applications can send logs to CloudWatch using the SDK</p></li><li><p>CloudWatch can collect log from</p><ul><li>elastic beanstalk: collection of log from application</li><li>ECS: collection from containers</li><li>AWS lambda: collection from function logs</li><li>VPC flow logs: VPC specific logs</li><li>API Gateway</li><li>CloudTrail based on filter</li><li>CloudWatch log agents: for example on EC2 machines</li><li>Route53: log DNS queries</li></ul></li><li><p>CloudWatch Logs can go to</p><ul><li>batch exporter to S3 for archival</li><li>Stream to ElasticSearch cluster for further analytics</li></ul></li><li><p>Logs storage architecture</p><ul><li>log groups: arbitrary name, usually representing an application</li><li>log stream: instances within application / log files / containers</li></ul></li><li><p>can define log expiration policies (never expire, 30 days, etc…)</p></li><li><p>using the AWS CLI we can tail CloudWatch logs</p></li><li><p>to send logs to CloudWatch, make sure IAM permissions are correct</p></li><li><p>security: encryption of logs using KMS at the group level</p></li></ul><h2 id="cloudwatch-logs-for-ec2"><a class="markdownIt-Anchor" href="#cloudwatch-logs-for-ec2"></a> CloudWatch Logs for EC2</h2><ul><li>by default, no logs from your EC2 machine will go to CloudWatch</li><li>you need to run a CloudWatch agent on EC2 to push the log files you want</li><li>make sure IAM permissions are correct</li><li>the CloudWatch log agent can be setup on-premises too</li></ul><h3 id="cloudwatch-logs-agent-vs-unified-agent"><a class="markdownIt-Anchor" href="#cloudwatch-logs-agent-vs-unified-agent"></a> CloudWatch Logs Agent vs Unified Agent</h3><ul><li>CloudWatch Logs Agent<ul><li>old version of the agent</li><li>can only send to CloudWatch logs</li></ul></li><li>CloudWatch unified agent<ul><li>collect additional system-level metrics such as RAM, processors,etc…</li><li>collect logs to send to CloudWatch logs</li><li>centralized configuration using SSM Parameter Store</li></ul></li></ul><h2 id="cloudwatch-alarms"><a class="markdownIt-Anchor" href="#cloudwatch-alarms"></a> CloudWatch Alarms</h2><ul><li>Alarms are used to trigger notifications for any metric</li><li>various options (sampling, percentage, max, min, etc…)</li><li>alarm status<ul><li>OK</li><li>INSUFFICIENT_DATA</li><li>ALARM</li></ul></li><li>period<ul><li>length of time in seconds to evaluate the metric</li><li>high resolution custom metrics: 10 / 30 or multiples of 60 seconds</li></ul></li></ul><h3 id="alarm-targets"><a class="markdownIt-Anchor" href="#alarm-targets"></a> Alarm Targets</h3><ul><li>Stop, terminate, reboot or recover an EC2 instance</li><li>trigger auto scaling action</li><li>send notification to SNS (from which you can do pretty much anything)</li></ul><h3 id="ec2-instance-recovery"><a class="markdownIt-Anchor" href="#ec2-instance-recovery"></a> EC2 instance recovery</h3><ul><li>status check<ul><li>instance status = check the EC2 VM</li><li>system status = check the underlying hardware</li></ul></li><li>recovery<ul><li>same private, public, elastic IP, metadata, placement group</li></ul></li></ul><h3 id="cloudwatch-alarm-good-to-know"><a class="markdownIt-Anchor" href="#cloudwatch-alarm-good-to-know"></a> CloudWatch Alarm: good to know</h3><ul><li>alarms can be created based on CloudWatch Logs Metrics Filters</li><li>to test alarms and notifications, set the alarm state to alarm using CLI</li></ul><h2 id="cloudwatch-events"><a class="markdownIt-Anchor" href="#cloudwatch-events"></a> CloudWatch Events</h2><ul><li>event pattern: intercept events from AWS services (sources)<ul><li>example soruces: EC2 instance start, codebuild failure, S3 trsuted advisor</li><li>can intercept any API call with CloudTrail integration</li></ul></li><li>schedule or Cron (example: create an event every 4 hours)</li><li>A JSON payload is created from the event and passed to a target<ul><li>compute: lambda, batch, ECS task</li><li>integration: SQS, SNS, Kinesis data streams, Kinesis data firehose</li><li>Orchestration: step functions, codepipeline, codebuild</li><li>maintenance: SSM, EC2 actions</li></ul></li></ul><h2 id="amazon-eventbridge"><a class="markdownIt-Anchor" href="#amazon-eventbridge"></a> Amazon EventBridge</h2><ul><li><p>eventbridge is the next evolution of CloudWatch Events</p></li><li><p>default event bus: generated by AWS services (CloudWatch events)</p></li><li><p>partner event bus: receive events from SaaS service or applications</p></li><li><p>custom event buses: for your own applications</p></li><li><p>event buses can be accessed by other AWS accounts</p></li><li><p>Rules: how to process the events (similar to CloudWatch Events)</p></li><li><p>Amazon EventBridge builds upon and extends CloudWatch events</p></li><li><p>it uses the same service API and endpoint, and the same underlying service infrastructure</p></li><li><p>eventbridge allows extension to add event buses for your custom applications and your thrid party SaaS apps</p></li><li><p>event bridge has the schema registry capability</p></li><li><p>eventbridge has a different name to mark the new capabilities</p></li><li><p>over time, the CloudWatch events name will be replaced with eventbridge</p></li></ul><h2 id="aws-cloudtrail"><a class="markdownIt-Anchor" href="#aws-cloudtrail"></a> AWS CloudTrail</h2><ul><li>provides governance, compliancen and audit for your AWS account</li><li>CloudTrail is enabled by default</li><li>get an history of events / API calls made within your AWS account by<ul><li>console</li><li>SDK</li><li>CLI</li><li>AWS Service</li></ul></li><li>can put logs from CloudTrail into CloudWatch logs or S3</li><li>a trail can be applied to all regions (default) or a single region</li><li>if a resource is deleted in AWS, investigate CloudTrail first</li></ul><h2 id="cloudtrail-insights"><a class="markdownIt-Anchor" href="#cloudtrail-insights"></a> CloudTrail Insights</h2><ul><li>enable CloudTrail insights to detect unusual activity in your account<ul><li>inaccurate resource provisioning</li><li>hitting service limits</li><li>bursts of AWS IAM actions</li><li>gaps in periodic maintenance activity</li></ul></li><li>CloudTrail insights analyzes normal management events to create a baseline</li><li>and then continuously analyzes write events to detect unusual patterns<ul><li>anomalies appear in the CloudTrail console</li><li>event is sent to Amazon S3</li><li>an eventbridge event is generated (for automation needs)</li></ul></li></ul><h3 id="cloudtrail-events-retention"><a class="markdownIt-Anchor" href="#cloudtrail-events-retention"></a> CloudTrail Events retention</h3><ul><li>events are stored for 90 days in CloudTrail</li><li>to keep events beyond this period, log them to S3 and use Athena</li></ul><h1 id="aws-config"><a class="markdownIt-Anchor" href="#aws-config"></a> AWS Config</h1><ul><li>helps with auditing and recording compliance of your AWS resources</li><li>helps record configurations and changes over time</li><li>questions that can be solved by AWS Config<ul><li>is there unrestricted SSH access to my security groups</li><li>do my buckets have any public access</li><li>how has my ALB configuration changed over time</li></ul></li><li>you can receive alerts (SNS notifications) for any changes</li><li>AWS Config is a per-region service</li><li>can be aggregated across regions and accounts</li></ul><h2 id="config-rules-remediations"><a class="markdownIt-Anchor" href="#config-rules-remediations"></a> Config Rules - remediations</h2><ul><li>automate remediation of non-compliant resources using SSM automation documents</li><li>use AWS-managed automation documents or create custom automation documents<ul><li>tip: you can create custom automation documents that invokes lambda function</li></ul></li><li>you can set remediation retries if the resource is still non-compliant after auto-remediation</li></ul><h2 id="config-rules-notifications"><a class="markdownIt-Anchor" href="#config-rules-notifications"></a> Config Rules - notifications</h2><ul><li>use eventbridge to trigger notifications when AWS resources are non-compliant</li><li>ability to send configuration changes and compliance state notifications to SNS (all events - use SNS filtering or filter at client-side)</li></ul><h2 id="cloudwatch-vs-cloudtrail-vs-config"><a class="markdownIt-Anchor" href="#cloudwatch-vs-cloudtrail-vs-config"></a> CloudWatch vs CloudTrail vs Config</h2><ul><li>CloudWatch<ul><li>performance monitoring (metrics, CPU, network, etc…) and dashboards</li><li>event and alerting</li><li>log aggregation and analysis</li></ul></li><li>CloudTrail<ul><li>record API calls made within your account by everyone</li><li>can define trails for specific resources</li><li>global service</li></ul></li><li>Config<ul><li>record configuration changes</li><li>evaluate resources against comliance rules</li><li>get timeline of changes and compliance</li></ul></li></ul><h3 id="example-for-an-elastic-load-balancer"><a class="markdownIt-Anchor" href="#example-for-an-elastic-load-balancer"></a> Example for an Elastic Load Balancer</h3><ul><li>CloudWatch<ul><li>monitoring incoming connections metric</li><li>visualize error codes as a percentage over time</li><li>make a dashboard to get an idea of your load balancer performance</li></ul></li><li>CloudTrail<ul><li>track who made any changes to the load balancer with API calls</li></ul></li><li>Config<ul><li>trakc security group rules for the load balancer</li><li>track configuration changes for the load balancer</li><li>ensure an SSL certificate is always assigned to the load balancer (compliance)</li></ul></li></ul><h1 id="aws-sts-security-token-service"><a class="markdownIt-Anchor" href="#aws-sts-security-token-service"></a> AWS STS (Security Token Service)</h1><ul><li>allows to grant limited and temporary access to AWS resources</li><li>token is valid for up to one hour (must be refreshed)</li><li>AssumeRole<ul><li>within your own account: for enhanced security</li><li>cross account access: assume role in target account for perform actions there</li></ul></li><li>AssumeRoleWithSAML<ul><li>return credentials for users logged with SAML</li></ul></li><li>AssumeRoleWithWebIdentity<ul><li>return credentials for users logged with an IDP (facebook, google…)</li><li>AWS recommends against using this, and using Cognito instead</li></ul></li><li>GetSessionToken<ul><li>for MFA, from a user or AWS account root user</li></ul></li></ul><ol><li>define an IAM role within your account or cross-account</li><li>define which principals can access this IAM role</li><li>use AWS STS to retrieve credentials and impersonate the IAM role you have access to (AssumeRole API)</li><li>temporary credentials can be valid between 15 minutes to 1 hour</li></ol><h2 id="identity-federation-in-aws"><a class="markdownIt-Anchor" href="#identity-federation-in-aws"></a> Identity Federation in AWS</h2><ul><li>federation lets users outside of AWS to assume temporary role for accessing AWS resources</li><li>these users assume identity provided access role</li><li>federations can have many flavors<ul><li>SAML</li><li>Custom Identity Broker</li><li>Amazon Cognito</li><li>Single Sign On</li><li>Non-SAML with AWS Microsoft AD</li></ul></li><li>using federation, you don’t need to create IAM users (user management is outside of AWS)</li></ul><h2 id="saml-20-federation"><a class="markdownIt-Anchor" href="#saml-20-federation"></a> SAML 2.0 Federation</h2><ul><li>needs to setup a trust between AWS IAM and SAML (both ways)</li><li>SAML enables web based, cross domain SSO</li><li>uses the STS API: AssumeRoleWithSAML</li><li>note federation through SAML is the old way of doing things</li><li>Amazon SSO federation is the new managed and simpler way</li></ul><h2 id="aws-directory-services"><a class="markdownIt-Anchor" href="#aws-directory-services"></a> AWS Directory Services</h2><ul><li>AWS Managed Microsoft AD<ul><li>create your own AD in AWS, manage users locally, supports MFA</li><li>establish trust connections with your on-premises AD</li></ul></li><li>AD Connector<ul><li>Directory Gateway (proxy) to redirect to on-premises AD</li><li>users are managed on the on-premises AD (not on AWS)</li></ul></li><li>Simple AD<ul><li>AD compatible managed directory on AWS</li><li>cannot be joined with on-premises AD (users managed on AWS only)</li></ul></li></ul><h2 id="aws-organizations"><a class="markdownIt-Anchor" href="#aws-organizations"></a> AWS Organizations</h2><ul><li>global service</li><li>allows to manage multiple AWS accounts</li><li>the main account is the master account - you can’t change it</li><li>other accounts are member accounts</li><li>member accounts can only be part of one organization</li><li>consolidated billing across all accounts - single payment method</li><li>pricing benefits from aggregated usage</li><li>API is available to automate AWS account creation</li></ul><h3 id="multi-account-strategies"><a class="markdownIt-Anchor" href="#multi-account-strategies"></a> Multi account strategies</h3><ul><li>create accounts per department, per cost center, per dev/test/prod, based on regulatory restrictions (using SCP), for better resource isolation, to have separate per-account service limits, isolated account for logging</li><li>multi account vs one account multi VPC</li><li>use tagging standards for billing purposes</li><li>enable CloudTrail on all accounts, send logs to central S3 account</li><li>send CloudWatch logs to central logging account</li><li>establish cross account roles for admin purpose</li></ul><h3 id="service-control-policies-scp"><a class="markdownIt-Anchor" href="#service-control-policies-scp"></a> Service Control Policies (SCP)</h3><ul><li>whitelist or blacklist IAM actions</li><li>applied at the OU or Account level</li><li>does not apply to the master account</li><li>SCP is applied to all the users and roles of the account, including Root</li><li>the SCP does not affect service linked roles<ul><li>service linked roles enable other AWS services to integrate with AWS organizations and can’t be restricted by SCPs</li></ul></li><li>SCP must have an explicit Allow (does not allow anything by default)</li><li>use cases<ul><li>restrict access to certain services (for example: can’t use EMR)</li><li>enforce PCI compliance by explicitly disabling services</li></ul></li></ul><h3 id="aws-organization-moving-accounts"><a class="markdownIt-Anchor" href="#aws-organization-moving-accounts"></a> AWS Organization - moving accounts</h3><ul><li>to migrate accounts from one organization to another<ul><li>remove the member account from the old organization</li><li>send an invite to the new organization</li><li>accept the invite to the new organization from the member account</li></ul></li><li>if you want the master account of the old organization to also join the new organization<ul><li>remove the member accounts from the organization using the procedure above</li><li>delete the old organization</li><li>repeat the process above to invite the old master account to the new org</li></ul></li></ul><h1 id="iam-advanced"><a class="markdownIt-Anchor" href="#iam-advanced"></a> IAM Advanced</h1><h2 id="iam-for-s3"><a class="markdownIt-Anchor" href="#iam-for-s3"></a> IAM for S3</h2><ul><li>ListBucket permission applies to<ul><li><code>arn:aws:s3:::test</code></li><li>bucket level permission</li></ul></li><li>GetObject, PutObject, DeleteObject applies to<ul><li><code>arn:aws:s3:::test/*</code></li><li>object level permission</li></ul></li></ul><h2 id="iam-roles-vs-resource-based-policies"><a class="markdownIt-Anchor" href="#iam-roles-vs-resource-based-policies"></a> IAM Roles vs Resource Based Policies</h2><ul><li>when you assume a role (user, application or service), you give up your original permissions and take the permissions assigned to the role</li><li>when using a resource based policy, the principal doesn’t have to give up his permissions</li></ul><h2 id="iam-permission-boundaries"><a class="markdownIt-Anchor" href="#iam-permission-boundaries"></a> IAM permission boundaries</h2><ul><li>IAM permission boundaries are supported for users and roles (not groups)</li><li>advanced feature to use a managed policy to set the maximum permissions an IAM entity can get</li><li>if a user has been assigned a permission boundary so that it can only access S3, then no matter what permission policies it has, it can only access to S3, nothing else.</li></ul><h2 id="aws-resource-access-manager-ram"><a class="markdownIt-Anchor" href="#aws-resource-access-manager-ram"></a> AWS Resource Access Manager (RAM)</h2><ul><li>share AWS resources that you own with other AWS accounts</li><li>share with any account or within your organization</li><li>avoid resource duplication</li><li>VPC subnets<ul><li>allow to have all the resources launched in the same subnets</li><li>must be from the same AWS organization</li><li>cannot share security groups and default VPC</li><li>participants can manage their own resources in there</li><li>participants can’t view, modify, delete resources that belong to other participants or the owner</li></ul></li><li>AWS transit gateway</li><li>route53 resolver rules</li><li>license manager configurations</li></ul><h2 id="aws-sso"><a class="markdownIt-Anchor" href="#aws-sso"></a> AWS SSO</h2><ul><li>centrally manage single sign on to access multiple accounts and third party business applications</li><li>integrated with AWS organizations</li><li>support SAML 2.0 markup</li><li>integration with on-premises active directory</li><li>centralized permissioin management</li><li>centralized auditing with CloudTrail</li></ul><h1 id="aws-security"><a class="markdownIt-Anchor" href="#aws-security"></a> AWS Security</h1><h2 id="encryption-in-flight-ssl"><a class="markdownIt-Anchor" href="#encryption-in-flight-ssl"></a> Encryption in flight (SSL)</h2><ul><li>data is encrypted before sending and decrypted after receiving</li><li>SSL certificate help with encryption (HTTPS)</li><li>encryption in flight ensures no MITM (man in the middle) attach can happen</li></ul><h2 id="server-side-encryption-at-rest"><a class="markdownIt-Anchor" href="#server-side-encryption-at-rest"></a> Server side encryption at rest</h2><ul><li>data is encrypted after being received by the server</li><li>data is decrypted before being sent</li><li>it is stored in an encrypted form thanks to a key (usually a data key)</li><li>the encryption / decryption keys must be managed somewhere and the server must have access to it</li></ul><h2 id="client-side-encryption-2"><a class="markdownIt-Anchor" href="#client-side-encryption-2"></a> Client side encryption</h2><ul><li>data is encrypted by the client and never decrypted by the server</li><li>data will be decrypted by a receiving client</li><li>the server should not be able to decrypt the data</li></ul><h2 id="aws-kms-key-management-service"><a class="markdownIt-Anchor" href="#aws-kms-key-management-service"></a> AWS KMS (key management service)</h2><ul><li>anytime you hear encryption for an AWS service, it is most likely KMS</li><li>easy way to control access to your data, AWS manages keys for us</li><li>fully integrated with IAM authorization</li><li>seamlessly integrated into<ul><li>EBS</li><li>S3</li><li>Redshift</li><li>RDS</li><li>SSM</li></ul></li><li>but you can also use the CLI / SDK</li></ul><h3 id="kms-customer-master-key-cmk-types"><a class="markdownIt-Anchor" href="#kms-customer-master-key-cmk-types"></a> KMS - Customer Master Key (CMK) Types</h3><ul><li>Symmetric (AES-256)<ul><li>first offering of KMS, single encryption key that is used to encrypt and decrypt</li><li>AWS services that are integrated with KMS use Symmetric CMKs</li><li>you never get access to the key unencrypted (must call KMS API to use)</li></ul></li><li>Asymmetric (RSA and ECC key pairs)<ul><li>public (Encrypt) and private (decrypt) key</li><li>used for encrypt / decrypt, or sign / verify operations</li><li>the public key ios downloadable, but you can’t access the private key unencrypted</li><li>use case: encryption outside of AWS by users who can’t call the KMS API</li></ul></li></ul><h3 id="pricing"><a class="markdownIt-Anchor" href="#pricing"></a> Pricing</h3><ul><li>able to fully manage the keys and policies<ul><li>create</li><li>rotation policies</li><li>disable</li><li>enable</li></ul></li><li>able to audit key usage (using CloudTrail)</li><li>3 types of customer master keys (CMK)<ul><li>AWS managed service default CMK: free</li><li>user keys created in KMS: $1 / month</li><li>user keys imported (must be 256-bit symmetric key): $1 / month</li></ul></li><li>plus pay for API call to KMS</li></ul><h3 id="kms-101"><a class="markdownIt-Anchor" href="#kms-101"></a> KMS 101</h3><ul><li>anytime you need to share sensitive information, use KMS<ul><li>database passwords</li><li>credentials to external service</li><li>private key of SSL certificates</li></ul></li><li>the value in KMS is that the CMK used to encrypt data can never be retrieved by the user, and the CMK can be rotated for extra security</li><li>never ever store your secrets in plaintext, especially in your code</li><li>encrypted secrets can be stored in the code / environment variables</li><li>KMS can only help in encrypting up to 4 KB of data per call</li><li>if data &gt; 4KB, use envelope encryption</li></ul><h3 id="kms-key-policies"><a class="markdownIt-Anchor" href="#kms-key-policies"></a> KMS key policies</h3><ul><li>control access to KMS keys, similar to S3 bucket policies</li><li>different: you cannot control access without them</li><li>default KMS key policy<ul><li>created if you don’t provide a specific KMS key policy</li><li>complete access to the key to the root user = entire AWS account</li><li>the root user can administer the key and all IAM accounts can use the key</li><li>gives access to the IAM policies to the KMS key</li></ul></li><li>custom KMS key policy<ul><li>define users, roles that can access the KMS key</li><li>define who can administer the key</li><li>useful for cross-account access of your KMS key</li></ul></li></ul><h3 id="kms-automatic-key-rotation"><a class="markdownIt-Anchor" href="#kms-automatic-key-rotation"></a> KMS Automatic Key Rotation</h3><ul><li>for Costumer managed CMK (not AWS managed CMK)</li><li>if enabled: automatic key rotation heppens every 1 year</li><li>previous key is kept active so you can decrypt old data</li><li>new key has the same CMK ID (only the backing key is changed)</li></ul><h2 id="ssm-parameter-store"><a class="markdownIt-Anchor" href="#ssm-parameter-store"></a> SSM Parameter Store</h2><ul><li>secure storage for configuration and secrets</li><li>optional seamless encryption using KMS</li><li>serverless, scalable, durable, easy SDK</li><li>version tracking of configurations / secrets</li><li>configuration management using path and IAM</li><li>notifications with CloudWatch events</li><li>integration with CloudFormation</li></ul><h2 id="aws-secrets-manager"><a class="markdownIt-Anchor" href="#aws-secrets-manager"></a> AWS Secrets Manager</h2><ul><li>newer service, meant for storing secrets</li><li>capability to force rotation of secrets every X days</li><li>automate generation of secrets on rotation (uses lambda)</li><li>integration with Amazon RDS</li><li>secrets are encrypted using KMS</li></ul><h2 id="cloudhsm"><a class="markdownIt-Anchor" href="#cloudhsm"></a> CloudHSM</h2><ul><li>AWS provisions encryption hardware</li><li>dedicated hardware (HSM = Hardware Security Module)</li><li>you manage your own encryption keys entirely (not AWS)</li><li>HSM device is tamper resistant</li><li>supports both symmetric and asymmetric encryption (SSL/TLS keys)</li><li>no free tier available</li><li>must use the CloudHSM client software</li><li>refshift support CloudHSM for database encryption and key management</li><li>good option to use with SSE-C encryption</li></ul><h2 id="aws-shield"><a class="markdownIt-Anchor" href="#aws-shield"></a> AWS Shield</h2><ul><li>AWS shield standard<ul><li>free service that is activated for every AWS customer</li><li>provides protection from attacks such as SYN/UDP floods, reflection attacks and other layer 3 / layer 4 attacks</li></ul></li><li>AWS Shield Advanced<ul><li>optional DDoS mitigation service ($3000 per month per organization)</li><li>protect against more sophisticated attack on EC2, ELB, CloudFront, Global Accelerator, Route53</li></ul></li></ul><h2 id="aws-waf-web-application-firewall"><a class="markdownIt-Anchor" href="#aws-waf-web-application-firewall"></a> AWS WAF (Web Application Firewall)</h2><ul><li>protects your web applications from common web exploits (layer 7)</li><li>layer 7 is HTTP (vs layer 4 is TCP)</li><li>deploy on Application Load Balancer, API Gateway, CloudFront</li><li>define web ACL<ul><li>rules can include: IP addresses, HTTP headers, HTTP body, URI strings</li><li>protects from common attack - SQL injection and cross-site scripting (XSS)</li><li>size constraints, geo-match</li><li>rate based rules (to count occurrences of events) - for DDoS protection</li></ul></li></ul><h2 id="aws-guardduty"><a class="markdownIt-Anchor" href="#aws-guardduty"></a> AWS GuardDuty</h2><ul><li>intelligent threat discovery to protect AWS account</li><li>uses machine learning algorithms, anomaly detection, third party data</li><li>one click to enable (30 days trial), no need to install software</li><li>input data includes<ul><li>CloudTrail log: unusual API calls, unauthorized deployments</li><li>VPC flow logs: unusual internal traffic, unusual IP addresses</li><li>DNS logs: compromised EC2 instances sending encoded data within DNS queries</li></ul></li><li>can setup CloudWatch event rules to be notified in case of findings</li><li>CloudWatch events rules can target AWS lambda or SNS</li><li>can protect against CryptoCurrency attacks</li></ul><h2 id="aws-inspector"><a class="markdownIt-Anchor" href="#aws-inspector"></a> AWS Inspector</h2><ul><li>automated security assessments for EC2 instances</li><li>analyze the running OS against known vulnerabilities</li><li>analyze against unintended network accessibility</li><li>AWS Inspector agent must be installed on OS in EC2 instances</li><li>after the assessment, you get a report with a list of vulnerabilities</li><li>possibilitiy to send notifications to SNS</li></ul><h2 id="aws-macie"><a class="markdownIt-Anchor" href="#aws-macie"></a> AWS Macie</h2><ul><li>Amazon Macie is a fully managed data security and data privacy service that uses machine learning and pattern matching to discover and protect your sensitive data in AWS</li><li>Macie helps identify and alert you to sensitive data, such as personally identifiable information (PII)</li></ul><h1 id="aws-vpc"><a class="markdownIt-Anchor" href="#aws-vpc"></a> AWS VPC</h1><h2 id="understanding-cidr-classless-inter-domain-routing-ipv4"><a class="markdownIt-Anchor" href="#understanding-cidr-classless-inter-domain-routing-ipv4"></a> Understanding CIDR (Classless Inter-Domain Routing) - IPv4</h2><ul><li><p>CIDR are used for security groups rules, or AWS networking in general</p></li><li><p>they help to define an IP address range</p></li><li><p>a CIDR has two components</p><ul><li>the base IP</li><li>the subnet mask</li></ul></li><li><p>the base IP represents an IP contained in the range</p></li><li><p>the subnet masks defines how many bits can change in the IP</p></li><li><p>the subnet masks basically allows part of the underlying IP to get additional next values from the base IP</p><ul><li><code>/32</code> allow for 1 IP = <code>2^0</code></li><li><code>/31</code> allow for 1 IP = <code>2^1</code></li><li><code>/30</code> allow for 1 IP = <code>2^2</code></li><li><code>/29</code> allow for 1 IP = <code>2^3</code></li><li><code>/28</code> allow for 1 IP = <code>2^4</code></li><li><code>/27</code> allow for 1 IP = <code>2^5</code></li><li><code>/26</code> allow for 1 IP = <code>2^6</code></li><li><code>/25</code> allow for 1 IP = <code>2^7</code></li><li><code>/24</code> allow for 1 IP = <code>2^8</code></li><li><code>/16</code> allow for 1 IP = <code>2^16</code></li><li><code>/0</code> allow for 1 IP = <code>2^32</code></li></ul></li><li><p>quick memo</p><ul><li><code>/32</code> - no IP number can change</li><li><code>/24</code> - last IP number can change</li><li><code>/16</code> - last IP two numbers can change</li><li><code>/8</code> - last IP 3 numbers can change</li><li><code>/0</code> - all IP numbers can change</li></ul></li></ul><h2 id="private-vs-public-ip-allowed-ranges"><a class="markdownIt-Anchor" href="#private-vs-public-ip-allowed-ranges"></a> Private vs public IP allowed ranges</h2><ul><li>the internet assigned number authority established certain blocks of IPv4 addresses for the use of private (LAN) and public addresses</li><li>private IP can only allow certain values<ul><li>10.0.0.0 - 10.255.255.255 (in big networks)</li><li>172.16.0.0 - 172.31.255.255 (default AWS one)</li><li>192.168.0.0 - 192.168.255.255 (home networks)</li></ul></li><li>all the rest of the IP on the internet are public IP</li></ul><h2 id="default-vpc-walkthrough"><a class="markdownIt-Anchor" href="#default-vpc-walkthrough"></a> Default VPC walkthrough</h2><ul><li>all new accounts have a default VPC</li><li>new instances are launched into default VPC if no subnet is specified</li><li>default VPC have internet connectivity and all instances have public IP</li><li>we also get a public and private DNS name</li></ul><h2 id="vpc-in-aws-ipv4"><a class="markdownIt-Anchor" href="#vpc-in-aws-ipv4"></a> VPC in AWS - IPv4</h2><ul><li>you can have multiple VPCs in a region (max 5 per region)</li><li>max CIDR per VPC is 5, for each CIDR<ul><li>min size is <code>/28</code> = 16 IP addresses</li><li>max size is <code>/16</code> = 65536 IP addresses</li></ul></li><li>because VPC is private, only the private IP ranges are allowed</li><li>your VPC CIDR should not overlap with your other networks</li></ul><h2 id="subnets-ipv4"><a class="markdownIt-Anchor" href="#subnets-ipv4"></a> Subnets - IPv4</h2><ul><li>AWS reserves 5 IPs addresses (first 4 and last 1 IP address) in each subnet</li><li>these 5 IPs are not available for use and cannot be assigned to an instance</li><li>if CIDR block is 10.0.0.0/24, reserved IP are<ul><li>10.0.0.1: network address</li><li>10.0.0.2: reserved by AWS for the VPC router</li><li>10.0.0.3: reserved by AWS for mapping to Amazon provided DNS</li><li>10.0.0.4: reserved by AWS for future use</li><li>10.0.0.255: network broadcast address, AWS does not support broadcast in a VPC, therefore the address is reserved</li></ul></li><li>exam tip<ul><li>if you need 29 IP addresses for EC2 instances, you can’t choose a subnet of size /27 (32 IPs)</li><li>you need at least 64 IP, subnet size /26 (<code>64 - 5 &gt; 29</code>, but <code>32 - 5 &lt;= 29</code>)</li></ul></li></ul><h2 id="internet-gateways"><a class="markdownIt-Anchor" href="#internet-gateways"></a> Internet Gateways</h2><ul><li>internet gateways helps our VPC instances connect with the internet</li><li>it scales horizontally and is HA and redundant</li><li>must be created separately from VPC</li><li>one VPC can only be attached to one IGW and vice versa</li><li>internet gateway is also a NAT for the instances that have a public IPv4</li><li>internet gateways on their own do not allow internet access</li><li>route tables must also be edited</li></ul><p>If you launch an EC2 instance, to give the instance public internet, you need to edit the route table.</p><ol><li>associate route table to the subnet</li><li>add a rule in route table, so that when instance is trying to access a public IP, it will route the traffic to the internet gateway</li></ol><p>For instances in private subnet, if they were to access it through the internet gateway, they would also be accessible from the internet (not we want). So we need NAT</p><h2 id="nat-instances-network-address-translation"><a class="markdownIt-Anchor" href="#nat-instances-network-address-translation"></a> NAT instances - network address translation</h2><ul><li>allows instances in the private subnets to connect to the internet</li><li>must be launched in a public subnet</li><li>must disable EC2 flag: source / destination check</li><li>must have elastic IP attached to it</li><li>route table must be configured to route traffic from private subnets to NAT instance</li></ul><p>NAT instance will then route traffic to the internet gateway because of the route table rules.</p><p><img src="/../images/AWS-SAA-Review/1.png" alt="" /></p><h2 id="nat-gateway"><a class="markdownIt-Anchor" href="#nat-gateway"></a> NAT Gateway</h2><ul><li>AWS managed NAT, higher bandwidth, better availability, no admin needed</li><li>pay by the hour for usage and bandwidth</li><li>NAT is created in a specified AZ, uses an EIP</li><li>cannot be used by an instance in the subnet (only from the other subnets)</li><li>requires an IGW (private subnet -&gt; NAT -&gt; IGW)</li><li>no security group to manage / required</li></ul><h3 id="nat-gateway-with-ha"><a class="markdownIt-Anchor" href="#nat-gateway-with-ha"></a> NAT Gateway with HA</h3><ul><li>NAT gateway is resilient within a single AZ</li><li>must create multiple NAT gateway in multiple AZ for fault-tolerance</li><li>there is no cross AZ failover needed because if an AZ goes down it doesn’t need NAT</li></ul><h2 id="dns-resolution-in-vpc"><a class="markdownIt-Anchor" href="#dns-resolution-in-vpc"></a> DNS Resolution in VPC</h2><ul><li>enableDnsSupport (DNS Resolution settings)<ul><li>default is True</li><li>helps decide if DNS resolution is supported for the VPC</li><li>if True, queries the AWS DNS server at 169.254.169.253</li></ul></li><li>enableDnsHostname (DNS Hostname setting)<ul><li>False by default for newly created VPC</li><li>True by default for default VPC</li><li>won’t do anything unless enableDnsSupport is True</li><li>if True, assign public hostname to EC2 instance if it has a public</li></ul></li><li>if you use custom DNS domain names in a private zone in Route 53, you must set both these attributes to true</li></ul><h2 id="network-acls-and-security-group"><a class="markdownIt-Anchor" href="#network-acls-and-security-group"></a> Network ACLs and Security Group</h2><ul><li><p>Security group is the firewall of EC2 Instances.</p></li><li><p>Network ACL is the firewall of the VPC Subnets.</p></li><li><p>Security groups are tied to an instance whereas Network ACLs are tied to the subnet.</p></li><li><p>Network ACLs are applicable at the subnet level, so any instance in the subnet with an associated NACL will follow rules of NACL. That’s not the case with security groups, security groups has to be assigned explicitly to the instance.</p></li><li><p>This means any instances within the subnet group gets the rule applied. With Security group, you have to manually assign a security group to the instances.</p></li><li><p>Security groups are stateful: This means any changes applied to an incoming rule will be automatically applied to the outgoing rule. e.g. If you allow an incoming port 80, the outgoing port 80 will be automatically opened.</p></li><li><p>Network ACLs are stateless: This means any changes applied to an incoming rule will not be applied to the outgoing rule. e.g. If you allow an incoming port 80, you would also need to apply the rule for outgoing traffic.</p></li></ul><h3 id="rules-allow-or-deny"><a class="markdownIt-Anchor" href="#rules-allow-or-deny"></a> Rules: Allow or Deny</h3><ul><li>Security group support allow rules only (by default all rules are denied). e.g. You cannot deny a certain IP address from establishing a connection.</li><li>Network ACL support allow and deny rules. By deny rules, you could explicitly deny a certain IP address to establish a connection example: Block IP address 123.201.57.39 from establishing a connection to an EC2 Instance.</li></ul><p><img src="/../images/AWS-SAA-Review/2.png" alt="" /></p><table><thead><tr><th>Security Group</th><th>Network ACL</th></tr></thead><tbody><tr><td>Operates at the instance level</td><td>Operates at the subnet level</td></tr><tr><td>supports allow rules only</td><td>supports allow rules and deny rules</td></tr><tr><td>is stateful: return traffic is automatically allowed, regardless of any rules</td><td>is stateless: return traffic must be explicity allowed by rules</td></tr><tr><td>we evaluate all rules before deciding whether to allow traffic</td><td>we proces rules in number order when deciding whether to allow traffic</td></tr><tr><td>applies to an instance only if someone specifies the security group when launching the instance, or associates the security group with the instance later on</td><td>automatically applies to all instances in the subnets it’s associated with (therefore, you don’t have to rely on users to specify the security group)</td></tr></tbody></table><h2 id="vpc-peering"><a class="markdownIt-Anchor" href="#vpc-peering"></a> VPC Peering</h2><ul><li>connect 2 VPCs, privately using AWS network</li><li>make them behave as if they were in the same network</li><li>must not have overlapping CIDR</li><li>VPC peering connection is not transitive (must be established for each VPC that need to communicate with one another)<br />e.g. if we connect VPC A to VPC B and also connect VPC B to VPC C, this doesn’t mean VPC A is connected to VPC C.</li><li>you can do VPC peering with another AWS account</li><li>you must update route tables in each VPC’s subnets to ensure instances can communicate</li></ul><h3 id="vpc-peering-good-to-know"><a class="markdownIt-Anchor" href="#vpc-peering-good-to-know"></a> VPC Peering - good to know</h3><ul><li>VPC peering can work inter region, cross account</li><li>you can reference a security group of a peered VPC (work cross account)</li></ul><h2 id="vpc-endpoint"><a class="markdownIt-Anchor" href="#vpc-endpoint"></a> VPC Endpoint</h2><ul><li>endpoints allow you to connect to AWS services using a private network instead of the public www network</li><li>they scale horizontally and are redundant</li><li>they remove the need of IGW, NAT, etc… to access AWS services</li><li>interface<ul><li>provisions an ENI (private IP address) as an entry point (must attach security group) - most AWS services</li></ul></li><li>gateway<ul><li>provisions a target and must be used in a route table - S3 and DynamoDB</li></ul></li></ul><h2 id="flow-logs"><a class="markdownIt-Anchor" href="#flow-logs"></a> Flow Logs</h2><ul><li>capture information about IP traffic going into your interfaces<ul><li>VPC flow logs (includes the other two)</li><li>subnet flow logs</li><li>elastic network interface flow logs</li></ul></li><li>helps to monitor and troubleshoot connectivity issues</li><li>flow logs data can go to S3 / CloudWatch Logs</li><li>captures network information from AWS managed interfaces too: ELB, RDS, ElastiCache, Redshift, WorkSpaces</li></ul><h2 id="bastion-hosts"><a class="markdownIt-Anchor" href="#bastion-hosts"></a> Bastion Hosts</h2><ul><li>we can use a Bastion Host to SSH into our private instances</li><li>the bastion is in the public subnet which is then connected to all other private subnets</li><li>Bastion Host security group must be tightened</li><li>exam tip: make sure the bastion host only has port 22 traffic from the IP you need. not from the security groups of your other instances</li></ul><h2 id="site-to-site-vpn"><a class="markdownIt-Anchor" href="#site-to-site-vpn"></a> Site to Site VPN</h2><ul><li>Virtual Private Gateway<ul><li>VPN concentrator on the AWS side of the VPN connection</li><li>VGW (VPC Gateway) is created and attached to the VPC from which you want to create the Site-to-Site VPN connection</li></ul></li><li>Customer Gateway<ul><li>software application or physical device on customer side of the VPN connection</li><li>ip address<ul><li>use static, internet-routable IP address for your customer gateway device</li><li>if behind a CGW (Cloud Gateway) behind a NAT, use the public IP address of the NAT</li></ul></li></ul></li></ul><h2 id="direct-connect-dx"><a class="markdownIt-Anchor" href="#direct-connect-dx"></a> Direct Connect (DX)</h2><ul><li>provides a dedicated private connection from a remote network to your VPC</li><li>dedicated connection must be setup between your data center and AWS direct connect locations</li><li>you need to setup a Virtual Private Gateway on your VPC</li><li>access public resources (S3), and private (EC2) on same connection</li><li>use cases<ul><li>increase bandwidth throughput: working with large data sets - lower cost</li><li>more consistent network experience - applications using real time data feeds</li><li>hybrid environments (on premises + cloud)</li></ul></li><li>supports both IPv4 and IPv6</li></ul><h3 id="direct-connect-gateway"><a class="markdownIt-Anchor" href="#direct-connect-gateway"></a> Direct connect gateway</h3><ul><li>if you want to setup a direct connect to one or more VPC in many different regions (same account), you must use a direct connect gateway</li></ul><h3 id="connection-types"><a class="markdownIt-Anchor" href="#connection-types"></a> Connection types</h3><ul><li>dedicated connections<ul><li>1 Gbps and 10 Gbps capacity</li><li>physical ethernet port dedicated to a customer</li><li>request made to AWS first, then completed by AWS direct connetion partners</li></ul></li><li>hosted connections<ul><li>50 Mbps, 500 Mbps to 10 Gbps</li><li>connection requests are made via AWS direct connect partners</li><li>capacity can be added or removed on demand</li><li>1,2,5,10 Gbps available at select AWS direct connect partners</li></ul></li><li>lead times are often longer than 1 month to establish a new connection</li></ul><h3 id="encryption"><a class="markdownIt-Anchor" href="#encryption"></a> Encryption</h3><ul><li>data in transit is not encrypted but is private</li><li>AWS direct connect + VPN provides an IPsec-encrypted private connection</li><li>good for an extra level of security, but slightly more complex to put in place</li></ul><h3 id="resiliency"><a class="markdownIt-Anchor" href="#resiliency"></a> Resiliency</h3><ul><li>High resiliency for critical workloads<ul><li>one connection at multiple locations</li></ul></li><li>maximum resiliency for critical workloads<ul><li>maximum resilience is achieved by separate connections</li><li>terminating on separate devices in more than one location</li></ul></li></ul><h2 id="egress-outgoing-only-internet-gateway"><a class="markdownIt-Anchor" href="#egress-outgoing-only-internet-gateway"></a> Egress (outgoing) only internet gateway</h2><ul><li>Egress only internet gateway is for IPv6 only</li><li>similar function as a NAT, but a NAT is for IPv4</li><li>good to know: IPv6 are all public addresses</li><li>therefore all our instances with IPv6 are publicly accessible</li><li>Egress only internet gateway gives our IPv6 instances access to the internet, but they won’t be directly reachable by the internet</li><li>after creating an Egress only internet gateway, edit the route tables</li></ul><h2 id="aws-private-link-vpc-endpoint-service"><a class="markdownIt-Anchor" href="#aws-private-link-vpc-endpoint-service"></a> AWS Private Link - VPC Endpoint Service</h2><h3 id="how-to-expose-services-in-your-vpc-to-other-vpcs"><a class="markdownIt-Anchor" href="#how-to-expose-services-in-your-vpc-to-other-vpcs"></a> How to expose services in your VPC to other VPCs?</h3><ul><li>Option1: make it public<ul><li>goes through the public www</li><li>tough to manage access</li></ul></li><li>Option2: VPC peering<ul><li>must create many peering relations (peering relation is one-to-one)</li><li>opens the whole network(maybe you just want one of your services to be exposed, not the whole VPC)</li></ul></li></ul><h3 id="aws-private-link"><a class="markdownIt-Anchor" href="#aws-private-link"></a> AWS Private Link</h3><ul><li>most secure and scalable way to expose a service to 1000s of VPCs</li><li>does not require VPC peering, internet gateway, NAT, route tables</li><li>requires a network load balancer (service VPC) and ENI (customer VPC)<ul><li>customer VPC =&gt; ENI =&gt; private link =&gt; NLB =&gt; service VPC</li></ul></li><li>if the NLB is in multiple AZ, and the ENI in multiple AZ, the solution is fault tolerant</li></ul><p><img src="/../images/AWS-SAA-Review/3.png" alt="" /></p><h2 id="ec2-classic-and-aws-classiclink-deprecated"><a class="markdownIt-Anchor" href="#ec2-classic-and-aws-classiclink-deprecated"></a> EC2 Classic and AWS ClassicLink (deprecated)</h2><ul><li>EC2 classic: instances run in a single network shared with other customers</li><li>Amazon VPC: your instances run logically isolated to your AWS account</li><li>classLink: allows you to link EC2 instances to a VPC in your account<ul><li>must associate a security group</li><li>enables communication using private IPv4 addresses</li><li>removes the need to make use of public IPv4 addresses or Elastic IP addresses</li></ul></li><li>Likely to be distractors at the exam</li></ul><h2 id="aws-vpn-cloudhub"><a class="markdownIt-Anchor" href="#aws-vpn-cloudhub"></a> AWS VPN Cloudhub</h2><ul><li>provide secure communication between sites, if you have multiple VPN connections</li><li>low cost hub-and-spoke model for primary or secondary network connectivity between locations</li><li>it is a VPN connection so it goes over the public internet</li></ul><h2 id="transit-gateway"><a class="markdownIt-Anchor" href="#transit-gateway"></a> Transit Gateway</h2><ul><li>for having transitive peering between thousands of VPCs and on premises, hub-and-spoke(star) connection</li><li>regional resource, can work cross-region</li><li>share cross account using Resource Access Manager (RAM)</li><li>you can peer transit gateway across regions</li><li>route tables: limit which VPC can talk with other VPC</li><li>works with direct connect gateway, VPN connections</li><li>supports IP multicast (not supported by any other AWS service)</li><li>share direct connect between multiple accounts<ul><li>VPCs =&gt; transite gateway -&gt; direct connect gateway =&gt; AWS direct connect endpoint =&gt; customer router</li></ul></li></ul><h3 id="transit-gateway-site-to-site-vpc-ecmp"><a class="markdownIt-Anchor" href="#transit-gateway-site-to-site-vpc-ecmp"></a> Transit Gateway: site-to-site VPC ECMP</h3><ul><li>ECMP = equal cost multi path routing</li><li>routing strategy to allow to forward a packet over multiple best path</li><li>use case: create multiple site-to-site VPN connections to increase the bandwidth of your connection to AWS</li></ul><h2 id="vpc-summary"><a class="markdownIt-Anchor" href="#vpc-summary"></a> VPC Summary</h2><p><img src="/../images/AWS-SAA-Review/4.png" alt="" /></p><ul><li>CIDR: IP range</li><li>VPC: Virtual Private Cloud =&gt; we define a list of IPv4 or IPv6 CIDR</li><li>Subnets: Tied to an AZ, we define a CIDR for a subnet</li><li>Internet gateway: at the VPC level, provide internet access</li><li>Route table: must be edited to add routes from subnets to the IGW, VPC peering connections, VPC endpoints, etc…</li><li>NAT Instances: gives internet access to the instances in private subsnets, old, must be setup in a public subnet, disable source / destination check flag</li><li>NAT gateway: managed by AWS, provides scalable internet access to private instances, IPv4 only</li><li>Private DNS + route 53: enable DNS resolution + DNS hostnames (VPC)</li><li>NACL: stateless, subnet rules for inbound and outbound, don’t forget ephemeral ports</li><li>Security groups: stateful, operate at the EC2 instance level</li><li>VPC Peering: connect two VPC with non overlapping CIDR, non transitive</li><li>VPC endpoints: provide private access to AWS services (S3, DynamoDB, CloudFormation, SSM) within VPC, no need to go through internet gateway</li><li>Bastion Host: public instance to SSH into, that has SSH connectivity to instances in private subnets</li><li>Site to Site VPN: setup a customer gateway on Data center, a Virtual Private Gateway on VPC, and site to site VPN over public internet</li><li>Direct Connect: setup a virtual private gateway on VPC, and establish a direct private connection to an AWS direct connection location</li><li>Direct Connect Gateway: setup a direct connect to many VPC in different regions</li><li>internet gateway Egress: like a NAT gateway, but for IPv6</li><li>Private Link / VPC endpoint services<ul><li>connect services privately from your service VPC to customers VPC</li><li>doesn’t need VPC peering, public internet, NAT gateway, route tables</li><li>must be used with network load balancer and ENI</li></ul></li><li>ClassicLInk: connect EC2 classic instances privately to your VPC</li><li>VPC Cloudhub: hun and spoke VPN model to connect your sites</li><li>Transit gateway: transitive peering connections for VPC, VPN and DX</li></ul><h2 id="networking-cost-in-aws"><a class="markdownIt-Anchor" href="#networking-cost-in-aws"></a> Networking cost in AWS</h2><p><img src="/../images/AWS-SAA-Review/5.png" alt="" /></p><ul><li>use private IP instead of public IP for good savings and better network performance</li><li>use same AZ for maximum savings (at the cost of HA)</li></ul><p><img src="/../images/AWS-SAA-Review/6.png" alt="" /></p><p><img src="/../images/AWS-SAA-Review/7.png" alt="" /></p><p><img src="/../images/AWS-SAA-Review/8.png" alt="" /></p><h2 id="ipv6-for-vpc"><a class="markdownIt-Anchor" href="#ipv6-for-vpc"></a> IPv6 for VPC</h2><ul><li>IPv4 cannot be disabled for your VPC and subnets</li><li>you can enable IPv6 to operate in dual-stack mode</li><li>your EC2 instance would get at least a private internal IPv4 and a public IPv6</li><li>they can communicate using either IPv4 or IPv6</li></ul><h3 id="ipv6-troubleshooting"><a class="markdownIt-Anchor" href="#ipv6-troubleshooting"></a> IPv6 Troubleshooting</h3><ul><li>if you cannot launch an instance in your subnet<ul><li>it is not because it cannot acquire an IPv6 (the space is very large)</li><li>it is because there are no available IPv4 in your subnet</li></ul></li><li>solution: create a new IPv4 CIDR in your subnet</li></ul><h1 id="disaster-recovery-overview"><a class="markdownIt-Anchor" href="#disaster-recovery-overview"></a> Disaster Recovery Overview</h1><ul><li>any event that has a negative impact on a company’s business continuity or finances is a disaster</li><li>disaster recovery is about preparing for and recovering from a disaster</li><li>what kind of disaster recovery<ul><li>on premises =&gt; on premises: tranditional DR, very expensive</li><li>on premises =&gt; AWS Cloud: hybrid recovery</li><li>AWS Cloud Region A =&gt; AWS Cloud Region B</li></ul></li><li>need to define 2 terms<ul><li>RPO: recovery point objective</li><li>RTO: recovery time objective</li></ul></li></ul><p><img src="/../images/AWS-SAA-Review/9.png" alt="" /></p><h2 id="backup-and-restore-high-rpo"><a class="markdownIt-Anchor" href="#backup-and-restore-high-rpo"></a> Backup and restore (High RPO)</h2><ul><li>needs more time to recover</li></ul><h2 id="pilot-light"><a class="markdownIt-Anchor" href="#pilot-light"></a> Pilot Light</h2><ul><li>a small version of the app is always running in the cloud</li><li>useful for the critical core (pilot light)</li><li>very similar to backup and restore</li><li>faster than backup and restore as critical systems are already up</li></ul><h2 id="warm-standby"><a class="markdownIt-Anchor" href="#warm-standby"></a> Warm Standby</h2><ul><li>full system is up and running but at minimum size</li><li>upon disaster, we can scale up to production load</li></ul><h2 id="multi-site-hot-site-approach"><a class="markdownIt-Anchor" href="#multi-site-hot-site-approach"></a> Multi Site / Hot Site Approach</h2><ul><li>very low RTO (minutes or seconds) - very expensive</li><li>full production scale is running AWS and on premises</li></ul><h2 id="disaster-recovery-tips"><a class="markdownIt-Anchor" href="#disaster-recovery-tips"></a> Disaster Recovery Tips</h2><ul><li>backup<ul><li>EBS snapshots, RDS automated backups / snapshots, etc…</li><li>regular pushes to S3 / S3 IA / Glacier, Lifecycle policy, cross region replication</li><li>from on premises: snowball or storage gateway</li></ul></li><li>HA<ul><li>use route 53 to migrate DNS over from region to region</li><li>RDS multi AZ, elastiCache multi AZ, EFS, S3</li><li>site to site VPN as a recovery from direct connect</li></ul></li><li>replication<ul><li>RDS replication, AWS Aurora + global databases</li><li>database replication from on premises to RDS</li><li>storage gateway</li></ul></li><li>automation<ul><li>cloudFormation / elastic beanstalk to re-create a whole new environment</li><li>recover / reboot EC2 instance with cloudwatch if alarms fails</li><li>AWS lambda functions for customized automations</li></ul></li><li>chans<ul><li>Netflix has a simian-army randomly terminating EC2</li></ul></li></ul><h1 id="dms-database-migration-service"><a class="markdownIt-Anchor" href="#dms-database-migration-service"></a> DMS - Database Migration Service</h1><ul><li>quickly and securely migrate databases to AWS, resilient, self healing</li><li>the source database remains available during the migration</li><li>supports<ul><li>homogeneous migrations: Oracle to Oracle</li><li>Heterogeneous: Microsoft SQL server to Aurora</li></ul></li><li>continuous Data replication using CDC</li><li>you must create an EC2 instance to perform the replication tasks</li></ul><h2 id="aws-schema-conversion-tool-sct"><a class="markdownIt-Anchor" href="#aws-schema-conversion-tool-sct"></a> AWS Schema Conversion Tool (SCT)</h2><ul><li>convert your database’s schema from one engine to another</li><li>example OLTP: sql server or Oracle =&gt; MySQL, PostgreSQL, Aurora</li><li>example OLAP: Teradata or Oracle =&gt; Amazon Redshift</li><li>you do not need to use SCT if you are migrating the same DB engine<ul><li>on premise postgreSQL =&gt; RDS postgreSQL</li><li>the DB engine is still PostgreSQL (RDS is just a platform)</li></ul></li></ul><h2 id="on-premises-strategy-with-aws"><a class="markdownIt-Anchor" href="#on-premises-strategy-with-aws"></a> On Premises Strategy with AWS</h2><ul><li>ability to download Amazon Linux 2 AMI as a VM<ul><li>use VMWare, KVM, VirtualBox to run VM</li></ul></li><li>VM import / Export<ul><li>migrate existing applications into EC2</li><li>create a DR repository strategy for your on premises VMs</li><li>can export abck the VMs from EC2 to on premises</li></ul></li><li>AWS application discovery services<ul><li>gather information about your on premises server to plan a migration</li><li>server utilization and dependency mappings</li><li>track with AWS migration hub</li></ul></li><li>AWS database migration server (DMS)<ul><li>replicate on premise =&gt; AWS</li><li>AWS =&gt; AWS</li><li>AWS =&gt; on premises</li></ul></li><li>AWS server migration service (SMS)<ul><li>incremental replication of on premises live servers to AWS</li></ul></li></ul><h2 id="aws-datasync"><a class="markdownIt-Anchor" href="#aws-datasync"></a> AWS DataSync</h2><ul><li>move large amount of data from on premise to AWS</li><li>can synchronize to: Amazon S3  (any storage class, including Glacier), Amazon EFS, FSx for Windows</li><li>move data from your NAS or file system via NFS or SMB</li><li>replication tasks can be scheduled hourly, daily or weekly</li><li>leverage the DataSync agent to connect to your systems</li><li>can setup a bandwidth limit</li></ul><h2 id="aws-backup"><a class="markdownIt-Anchor" href="#aws-backup"></a> AWS Backup</h2><ul><li>fully managed service</li><li>centrally manage and automate backups across AWS services</li><li>no need to create custom scripts and manual processes</li><li>supported services<ul><li>FSx</li><li>EFS</li><li>DynamoDB</li><li>EC2</li><li>EBS</li><li>RDS</li><li>Aurora</li><li>AWS storage gateway (volume gateway)</li></ul></li><li>supports cross region backups</li><li>supports cross account backups</li><li>supports PITR (point in time recovery) for supported services</li><li>on demand and scheduled backups</li><li>tag based backup policies</li><li>you create backup policies known as Backup Plans<ul><li>backup frequency</li><li>backup window</li><li>transition to cold storage</li><li>retention period</li></ul></li></ul><h1 id="more-solution-architectures"><a class="markdownIt-Anchor" href="#more-solution-architectures"></a> More Solution Architectures</h1><h2 id="compute-and-networking"><a class="markdownIt-Anchor" href="#compute-and-networking"></a> Compute and Networking</h2><ul><li>EC2 enhanced networking (SR-IOV)<ul><li>higher bandwidth, higher PPS (packet per second), lower latency</li><li>option1: Elastic Network Adapter (ENA) up to 100 Gbps</li><li>option2: Intel, up to 10 Gbps, legacy</li></ul></li><li>Elastic Fabric Adapter (EFA)<ul><li>improved ENA for HPC, only works for Linux</li><li>great for inter node communications, tightly coupled networks</li><li>leverages message passing interface (MPI) standard</li><li>bypasses the underlying linux OS to provide low latency, reliable transport</li></ul></li></ul><h2 id="cloudformation"><a class="markdownIt-Anchor" href="#cloudformation"></a> CloudFormation</h2><ul><li>a declarative way of outlining your AWS infrastructure, for any resources</li><li>for example, within a CloudFormation template, you say<ul><li>I want a security group</li><li>2 EC2 instances using this security group</li><li>2 Elastic IPs for these EC2 machines</li><li>1 S3 bucket</li><li>a load balancer in front of these machines</li></ul></li><li>then cloudformation creates those for you, in the right order, with the exact configuration that you specify</li><li>templates have to be uploaded in S3 and then referenced in CloudFormation</li><li>to update a template, we can’t edit previous ones, we have to re-upload a new version of the template to AWS</li><li>stacks are identified by a name</li><li>deleting a stack deletes every single artifact that was created by CloudFormation</li></ul><h3 id="deploying-cloudformation-templates"><a class="markdownIt-Anchor" href="#deploying-cloudformation-templates"></a> Deploying CloudFormation templates</h3><ul><li>manual way<ul><li>editing templates in the CloudFormation designer</li><li>using the console to input parameters, etc…</li></ul></li><li>automated way<ul><li>editing templates in a YAML file</li><li>using the AWS CLI to deploy the templates</li><li>recommended way when you fully want to automate your flow</li></ul></li></ul><h3 id="cloudformation-stacksets"><a class="markdownIt-Anchor" href="#cloudformation-stacksets"></a> CloudFormation - stacksets</h3><ul><li>create, update, or delete stacks across multiple accounts and regions with a single operation</li><li>administrator account to create stacksets</li><li>trusted accounts to create, update, delete stack instances from stacksets</li><li>when you update a stackset, all associated stack instances are updated throughout all accounts and regions</li></ul><h2 id="aws-step-functions"><a class="markdownIt-Anchor" href="#aws-step-functions"></a> AWS Step Functions</h2><ul><li>build serverless visual workflow to orchestrate your lambda functions</li><li>represent flow as a JSON state machine</li><li>features: sequence, parallel, conditions, timeouts, error handling</li><li>can also integrate with EC2, ECS, on premise servers, API gateway</li><li>possiblity to implement human approval feature</li></ul><h2 id="aws-swf-simple-workflow-service"><a class="markdownIt-Anchor" href="#aws-swf-simple-workflow-service"></a> AWS SWF - simple workflow service</h2><ul><li>coordinate work amongst applications</li><li>code runs on EC2</li><li>concept of activity step and decision step</li><li>has built in human intervention step</li><li>step function is recommended to be used for new applications, except<ul><li>if you need external signals to intervene in the processes</li><li>if you need child processes that return values to parent processes</li></ul></li></ul><h2 id="amazon-emr"><a class="markdownIt-Anchor" href="#amazon-emr"></a> Amazon EMR</h2><ul><li>EMR stands for Elastic Map Reduce</li><li>EMR helps creating Hadoop clusters (big data) to analyze and process vast amount of data</li><li>the clusters can be made of hundreds of EC2 instances</li><li>also supports Apache Spark, HBase, Presto, Flink</li><li>EMR takes care of all the provisioning and configuration</li><li>auto scaling and integrated with Spot instances</li><li>use cases: data processing, machine learning, web indexing, big data</li></ul><h2 id="aws-opsworks"><a class="markdownIt-Anchor" href="#aws-opsworks"></a> AWS Opsworks</h2><ul><li><p>Chef and Puppet help you perform server configuration automatically, or repetitive actions</p></li><li><p>they work great with EC2 and on premises VM</p></li><li><p>AWS Opsworks = managed Chef and Puppet</p></li><li><p>it is an alternative to AWS SSM</p></li><li><p>they help with managing configuration as code</p></li><li><p>helps in having consistent deployments</p></li><li><p>works with Linux and Windows</p></li></ul><h2 id="aws-elastic-transcoder"><a class="markdownIt-Anchor" href="#aws-elastic-transcoder"></a> AWS Elastic Transcoder</h2><ul><li>convert media files (video + music) stored in S3 into various formats for tablets, PC, smartphone, TV etc…</li><li>features: bit rate optimization, thumbnail, watermarks, captions, DRM, progressive download, encryption</li><li>4 components<ul><li>jobs: what does the work of the transcoder</li><li>pipeline: queue that manages the transcoding job</li><li>presets: template for converting media from one format to another</li><li>notifications: SNS for exmaple</li></ul></li><li>pay for what you use, scales automatically, fully managed</li></ul><h2 id="aws-workspaces"><a class="markdownIt-Anchor" href="#aws-workspaces"></a> AWS WorkSpaces</h2><ul><li>managed, secure cloud desktop</li><li>great to eliminate management of on premise VDI (virtual desktop infrastructure)</li><li>on demand, pay per by usage</li><li>secure, encrypted, network isolation</li><li>integrated with Microsoft active directory</li></ul><h2 id="aws-appsync"><a class="markdownIt-Anchor" href="#aws-appsync"></a> AWS AppSync</h2><ul><li>store and sync data across mobile and web apps in real time</li><li>makes use of GraphQL (mobile technology from Facebook)</li><li>client code can be generated automatically</li><li>integrations with DynamoDB</li><li>real time subscriptions</li></ul><h2 id="cost-explorer"><a class="markdownIt-Anchor" href="#cost-explorer"></a> Cost Explorer</h2><ul><li>visualize, understand and manage your AWS costs and usage over time</li><li>create custom reports that analyze cost and usage data</li><li>analyze your data at a high level, total costs and usage across all accounts</li><li>choose an optimal savings plan</li><li>forecast usage up to 12 months based on previous usage</li></ul><h2 id="cheatsheet"><a class="markdownIt-Anchor" href="#cheatsheet"></a> CheatSheet</h2><ul><li><p>CodeCommit: service where you can store your code. Similar service is GitHub</p></li><li><p>CodeBuild: build and testing service in your CICD pipelines</p></li><li><p>CodeDeploy: deploy the packaged code onto EC2 and AWS Lambda</p></li><li><p>CodePipeline: orchestrate the actions of your CICD pipelines (build stages, manual approvals, many deploys, etc)</p></li><li><p>CloudFormation: Infrastructure as Code for AWS. Declarative way to manage, create and update resources.</p></li><li><p>ECS (Elastic Container Service): Docker container management system on AWS. Helps with creating micro-services.</p></li><li><p>ECR (Elastic Container Registry): Docker images repository on AWS. Docker Images can be pushed and pulled from there</p></li><li><p>Step Functions: Orchestrate / Coordinate Lambda functions and ECS containers into a workflow</p></li><li><p>SWF (Simple Workflow Service): Old way of orchestrating a big workflow.</p></li><li><p>EMR (Elastic Map Reduce): Big Data / Hadoop / Spark clusters on AWS, deployed on EC2 for you</p></li><li><p>Glue: ETL (Extract Transform Load) service on AWS</p></li><li><p>OpsWorks: managed Chef &amp; Puppet on AWS</p></li><li><p>ElasticTranscoder: managed media (video, music) converter service into various optimized formats</p></li><li><p>Organizations: hierarchy and centralized management of multiple AWS accounts</p></li><li><p>Workspaces: Virtual Desktop on Demand in the Cloud. Replaces traditional on-premise VDI infrastructure</p></li><li><p>AppSync: GraphQL as a service on AWS</p></li><li><p>SSO (Single Sign On): One login managed by AWS to log in to various business SAML 2.0-compatible applications (office 365 etc)</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> AWS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Denodo Data Virtualization</title>
      <link href="2021/08/02/Denodo-Data-Virtualization/"/>
      <url>2021/08/02/Denodo-Data-Virtualization/</url>
      
        <content type="html"><![CDATA[<h1 id="data-virtualization"><a class="markdownIt-Anchor" href="#data-virtualization"></a> Data Virtualization</h1><p>Data Virtualization is a logical layer which</p><ul><li>Delivers business data in real time to consuming applications or business users</li><li>Integrates data from disparate sources, locations, and formats, without replicating the data</li><li>Enables faster access to all data, less replication and cost, and more agility to change</li></ul><ol><li>Connects: to disparate data sources</li><li>Combines: related data into views</li><li>Consume: in business applications</li></ol><h2 id="pillars-of-data-virtualization"><a class="markdownIt-Anchor" href="#pillars-of-data-virtualization"></a> Pillars of Data Virtualization</h2><ol><li>Universal Data Access: hides the complexity of underlying data sources</li><li>Unified Virtual Data Layer: Common virtual canonical business model</li><li>Universal Data Publishing: multiple publishing interfaces and access patterns</li><li>Unified Data Governance: Central point for data governance</li><li>Agile High Performance: Multiple delivery process to meet different SLA(Service Level Agreement)'s</li></ol><h2 id="data-integration-strategies"><a class="markdownIt-Anchor" href="#data-integration-strategies"></a> Data Integration Strategies</h2><p>Data silos make it challenging for business users to access and analyze all of the available data within an organization. To bring the data together, companies typically use</p><ol><li>Extract, Transform, and Load processes (ETL)</li></ol><ul><li>copy the data from different silos and move it to a central location (e.g. Data Warehouse)</li></ul><ol start="2"><li>Enterprise Service Buses (ESB)</li></ol><ul><li>establish a communication system for applications, enabling them to share information</li></ul><ol start="3"><li>Data Virtualization (DV)</li></ol><ul><li>reate real time, integrated views of data in data silos, and makes them available to applications, analysts and business users</li></ul><h3 id="etl"><a class="markdownIt-Anchor" href="#etl"></a> ETL</h3><ul><li>In an ETL process the data is extracted from a source, transformed and loaded into another data system</li><li>Pros and Cons<ul><li>(Pro) ETL processes are efficient and effective at moving data in bulk</li><li>(Con) Moving data to another system means that a new repository must be maintained</li><li>(Con) ETL processes are not collaborative, the end-users must wait until the data is ready</li></ul></li></ul><h3 id="esb"><a class="markdownIt-Anchor" href="#esb"></a> ESB</h3><ul><li>Pros<ul><li>Applications are decoupled</li><li>They can be used for orchestrate business logic using message flows</li></ul></li><li>Cons<ul><li>ESBs are sutable only for operational use cases that involve small result sets</li><li>Queries are static, can only be scheduled and restricted to one source at a time.</li></ul></li></ul><h3 id="data-virtualization-2"><a class="markdownIt-Anchor" href="#data-virtualization-2"></a> Data Virtualization</h3><p>Data virtualization supports a wide variety of sources and targets, which makes it an ideal data integration strategy to complement ETL processes and ESBs</p><ul><li>for ETL<ul><li>Seamlessly connecting on-premises and cloud components</li><li>real-time integration of disparate data sources</li></ul></li><li>for ESB<ul><li>The ESB can connect to the data virtualization layer to access external sources that cannot be easily added to the ESB</li></ul></li></ul><h1 id="donodo-platform-architecture"><a class="markdownIt-Anchor" href="#donodo-platform-architecture"></a> Donodo Platform Architecture</h1><p>Denodo platform comes with the various in-built components as follows</p><ul><li>Virtual Dataport: it is the core component, the data virtualization server</li><li>Data catalog: a self-service data discovery tool</li><li>Scheduler: it is used for scheduling and executing batch jobs</li><li>Solution Manager: it provides cantralized management of all the servers</li></ul><h2 id="virtual-dataport"><a class="markdownIt-Anchor" href="#virtual-dataport"></a> Virtual Dataport</h2><p>Virtual Dataport enables business applications to process a series of distributed and heterogeneous data sources, as if the data were contained in a large virtual database</p><ul><li>it acts as a mediator that provides a structured and unified view of the data contained in all the data sources included in the system</li></ul><h2 id="data-catalog"><a class="markdownIt-Anchor" href="#data-catalog"></a> Data Catalog</h2><p>help business users, data scientists to discover the data assets that are available through the Denodo platform</p><ul><li>it promotes self-service and discovery capabilities for business users, enabling them to explore both data and metadata in a single web fronend tool</li><li>with this tool, the end user will be able to access a graphical representation of the business entities and associations, as well as the data linage and tree view information</li><li>it includes reporting capabilities and export options (CSV, excel, Tableau etc…)</li></ul><p>Data catalog is designed to provide organizations with three core benefits</p><ul><li>Enterprise-wide directory of datasets available for consumption from a business friendly web interface<ul><li>fast business decisions by enabling a much more rapid and comprehensive understanding and access to all enterprise data and metadata</li></ul></li><li>Governed self service BI/Analytics and data consumption that is still owned and maintained by IT</li><li>Significant IT time, resource and cost reduction</li></ul><h2 id="denodo-scheduler"><a class="markdownIt-Anchor" href="#denodo-scheduler"></a> Denodo Scheduler</h2><ul><li>exporting data to a database or files such as Tableau Data Export, delimited files, CSVs, flat files, MS Excel</li><li>Indexing data to enable google-like keyword searches on content</li><li>Cache loading</li><li>Periodical management tasks such as data statistic gathering, looking for changes in sources, etc…</li></ul><p>Denodo Scheduler enables a hybrid, DV to ETL pattern</p><ul><li>Jobs can be scheduled for a specific time and can have dependencies of other jobs</li><li>Detailed execution reports that can be sent by email</li><li>Support for data extraction from sources with limited query capabilities</li><li>Persistent jobs and Transparent retries in the event of failure</li><li>Possiblity of parallel execution of the different queries involved in the same job</li></ul><h2 id="denode-solution-manager"><a class="markdownIt-Anchor" href="#denode-solution-manager"></a> Denode Solution Manager</h2><ul><li>easy promotion of new metadata to different environments in multi-location architectures with different clusters from a centralized web UI</li><li>it provides automated lifecycle management capabilities, DevOps tasks are greatly simplified and gaining the agility</li><li>it’s centralized web UI allows a simpler and more efficient management of deployments, streamlining continuous delivery strategies.</li></ul><h1 id="denodo-platform-tools-and-applications"><a class="markdownIt-Anchor" href="#denodo-platform-tools-and-applications"></a> Denodo platform tools and applications</h1><h2 id="denode-platform-control-center"><a class="markdownIt-Anchor" href="#denode-platform-control-center"></a> Denode platform control center</h2><p>Allow to start and stop all the Denodo platform servers and its tools</p><ul><li>it allows configuring some additional functions</li><li>it can be launched either by<ul><li>selecting the shortcuts created during the installatioin</li><li>Or by executing the denodo_platform.sh script from the bin folder of the Denodo platform installation</li></ul></li></ul><h2 id="web-design-studio"><a class="markdownIt-Anchor" href="#web-design-studio"></a> Web design studio</h2><p>A web based tool, aimed for developers to develop the Virtual DataPort elements</p><ul><li>Web design studio can be started<ul><li>from the Denodo platform control center</li><li>by executing the designstudio_startup.sh script from the bin folder</li></ul></li><li>it can be accessed using the URL: <a href="http://localhost:9090/denodo-design-studio">http://localhost:9090/denodo-design-studio</a></li><li>currently, it does not support configuring the administration options</li></ul><h2 id="data-catalog-2"><a class="markdownIt-Anchor" href="#data-catalog-2"></a> Data Catalog</h2><p>A web based self service tool, aimed for business users to query and serach the organization data</p><ul><li>they can generate new knowledge and can take better decisions</li><li>data catalog can be started, either from<ul><li>the Denodo platform control center</li><li>by executing the datacatalog_startup.sh script from the bin folder of the Denodo platform installation</li></ul></li><li>the default URL is: <a href="http://localhost:9090/denodo-data-catalog">http://localhost:9090/denodo-data-catalog</a></li><li>this tool is not included in Denodo Standard 8.0 version</li></ul><h2 id="scheduler-aministration-tool"><a class="markdownIt-Anchor" href="#scheduler-aministration-tool"></a> Scheduler Aministration Tool</h2><p>A web tool, used to connect to the scheduler server for creating and managing the scheduler jobs</p><ul><li>scheduler administartion tool can be started, either using<ul><li>the Denodo platform control center</li><li>executing the scheduler_webadmin_startup.sh script from the bin folder of the Denodo platform installation</li></ul></li><li>the default URL to launch the tool is: <a href="http://localhost:9090/webadmin/denodo-scheduler-admin">http://localhost:9090/webadmin/denodo-scheduler-admin</a></li></ul><h2 id="solution-manager-administration-tool"><a class="markdownIt-Anchor" href="#solution-manager-administration-tool"></a> Solution Manager Administration Tool</h2><p>A web tool, used to connect to the Solution Manager and License Manager Servers</p><ul><li>it provides an unified access to all the web applications of the Denodo platform<ul><li>Data Catalog</li><li>Web Design Studio</li><li>Diagnostics and Monitoring tool</li><li>Scheduler web administration tool</li></ul></li><li>The Solution Manager Administration Tool can be started, either by<ul><li>Using the Denodo Solution Manager Control center</li><li>Using the solutionmanagerwebtool_startup.sh script from the bin folder of the Solution Manager installation</li></ul></li><li>the default URL to launch the Solution Manager Administration tool<ul><li><a href="http://localhost:9090/solution-manager-web-tool">http://localhost:9090/solution-manager-web-tool</a></li></ul></li></ul><h2 id="diagnostics-and-monitoring-tool"><a class="markdownIt-Anchor" href="#diagnostics-and-monitoring-tool"></a> Diagnostics and Monitoring tool</h2><p>A web tool, aimed for both developers and administrators who wants to</p><ul><li>monitor the current state of a server, a cluster or an environment</li><li>diagnose the past state of a server to identify the cause of a problem</li><li>diagnostics and monitoring tool can be started, either using<ul><li>The Denodo platform control center</li><li>by executing the diagnosticmonitoringtool_startup.sh script</li></ul></li><li>default URL: <a href="http://localhost:9090/diagnostic-monitoring-tool">http://localhost:9090/diagnostic-monitoring-tool</a></li></ul><h2 id="southbound-connectors"><a class="markdownIt-Anchor" href="#southbound-connectors"></a> Southbound Connectors</h2><p>Specialized connectors to access specific data repositories or applications to retrieve their schema and data</p><ul><li>these connectors are configurable by using a virtual editor or SQL like commands that are part of the Denodo platform</li><li>it helps in creating data sources to retrieve data from a repository of data in the Denodo platform<ul><li>E.g. a relational database, a REST or SOAP web service, a MS Excel file, etc…</li></ul></li></ul><h2 id="data-model"><a class="markdownIt-Anchor" href="#data-model"></a> Data Model</h2><p>The Derived views are created over base views to combine the data from different sources or to apply any kind of transformations</p><ul><li>Denodo platform offers graphical drag and drop tool for modeling the derived views</li><li>it used extended relational algebra for data combination and transformation.</li></ul><h2 id="northbound-connectors"><a class="markdownIt-Anchor" href="#northbound-connectors"></a> Northbound Connectors</h2><p>One of the essential capabilities of Data Virtualization is about the different access mechanisms provided to the consumers, these access mechanisms are called Northbound Connectors</p><ul><li>Denodo platform offers flexible delivery options to suit all type of users and application at almost no cost</li><li>if facilitates the creation of a single point of access and interaction with the underlying data source and abstracted views in a standard way</li></ul><h1 id="denodo-platform-security"><a class="markdownIt-Anchor" href="#denodo-platform-security"></a> Denodo Platform Security</h1><h2 id="data-in-transit"><a class="markdownIt-Anchor" href="#data-in-transit"></a> Data in Transit</h2><p>When users access data from Denodo Platform the data is moving</p><ul><li>Data moves through the network<ul><li>From the data sources to Denodo</li><li>From Denodo to the final users and consuming applications</li></ul></li><li>This is referred as Security in Transit</li><li>To ensure that the data is well protected and secure, it is possible to encrypt the connection</li></ul><p>Data in transit refers to all communications between the Denodo Platform and Data sources, between data consumers and Denodo Platform</p><ul><li>it can be secured through TLS at the connection level<ul><li>Denodo supports TLS 1.2 or 1.3</li><li>TLS configuration is automatized via a Denodo TLS configurator script</li></ul></li></ul><p>Any encrpytion algorithm supported by the default Java Cryptography Providers of the Denodo Platform JRE (Java 11) can be used</p><ul><li>Strongest ciphers can be enabled installing Java Cryptography Extension (JCE), unlimited strength jurisdiction policy files</li><li>when full encryption at the transport level is not required<ul><li>Denodo’s build-in functions for encryption/decryption can be selectively applied to sensitive fields to prevent unauthorized access.</li></ul></li></ul><h2 id="data-in-rest"><a class="markdownIt-Anchor" href="#data-in-rest"></a> Data in Rest</h2><p>Denodo Platform stores some opeartional data in a relational database and hard drive, these data are called as Data at Rest</p><ul><li>Metadata of the various Denodo Platform components and elements<ul><li>Data sources, views, stored procedures, web serviees</li><li>sensitive information on the configuration of the server</li></ul></li><li>Data cached in a relational database</li><li>data swapped to disk during query execution</li></ul><p>The Data at Rest can be secured by Denodo as follows</p><ul><li>Metadata: sensitive information are stored encrypted/hashed in the metadata repository<ul><li>Additiionally, you can enable Transparent Data Encryption to encrypt the database</li></ul></li><li>Cached Data: Denodo will transparently leverage any encryption mechanism available in the selected cache system<ul><li>For example, Orable Transparent Data Encryption</li></ul></li><li>Swapped Data: encrypt the swap folder by using OS file system encryption</li></ul><h2 id="authentication-protocols"><a class="markdownIt-Anchor" href="#authentication-protocols"></a> Authentication Protocols</h2><p>Used to publish data to consuming application</p><ul><li>standard username/password security mechanism</li><li>Kerberos support</li><li>HTTP-based authentication pass-through for the OData interface</li><li>Web service security with HTTPS, HTTP basic/Digest, SAML 2.0, OAuth 2.0, HTTP SPNEGO and WS-Security protocols</li><li>OAuth 2.0 in JDBC, ODBC connections is also available</li></ul><p>Denodo also offers different alternatives to integrate with identity, authentication and authorization services</p><ul><li>Denodo built-in security</li><li>Integration with external entitlement services (LDAP/AD)</li><li>Single sign on using OAuth, and SAML</li><li>Integration with external custom entitlement service with specific security policies</li></ul><h1 id="performance"><a class="markdownIt-Anchor" href="#performance"></a> Performance</h1><h2 id="static-optimization"><a class="markdownIt-Anchor" href="#static-optimization"></a> Static Optimization</h2><p>The Denodo Optimizer analyzes the query and simplify it by rewriting it to improve the performance</p><ul><li>it focuses on maximize query delegation to the data sources</li><li>it applies by default for all the queries</li><li>it minimizes the network traffic</li><li>it reduces the data volume that needs to be processed in the virtual layer</li><li>it applies one or more simplifications to the same query</li></ul><h1 id="connecting-and-combining-data-with-denodo"><a class="markdownIt-Anchor" href="#connecting-and-combining-data-with-denodo"></a> Connecting and combining Data with Denodo</h1><p>Denodo platform allows to add remote databases as sources</p><ul><li>the recommended way to connect to databases is always using the JDBC data source<ul><li>JDBC is an acronym referred to Java Database Connectivity</li><li>JDBC defines an API for the Java Programming language to access to any database using a suitable driver</li></ul></li></ul><p>Denodo platform supports out-the-box a wide variety of databases</p><ul><li>relational databases<ul><li>oracle, MS server, PostgreSQL, MySQL, Amazon Aurora, Azure SQL, Apache Derby</li></ul></li><li>Data Warehouses<ul><li>Snowflake, Amazon Redshift, Azure SQL Data Warehouse, Google BigQuery, SAP HANA, Teradata, Yellowbrick</li></ul></li><li>Interactive Query Services<ul><li>Hive, Impala, Amazon Athena, Presto, Spark SQL</li></ul></li></ul><p>By default, Denodo platform does not include some supported JDBC drivers, although it includes the adapter</p><ul><li>When a driver is not provided by Denodo, the .jar files of the driver must be uploaded to Virtual Dataport server using the Administration tool</li><li>Import option in the File &gt; Extensioin Management &gt; Libraries</li></ul><p>When Denodo does not include an specific adapter for a data source</p><ul><li>if possible, select a similar adapter<ul><li>for example, to connect to MySQL 6.0, the adapter MySQL 5 can be selected</li></ul></li><li>if there are not similar adapters, the generic adapter can be used</li><li>in both cases the driver must be provided and uploaded to the server</li></ul><h2 id="import-a-sql-query"><a class="markdownIt-Anchor" href="#import-a-sql-query"></a> Import a SQL Query</h2><p>Instead of using a table as the source for a base view, it is possible to generate a view from a SQL query</p><ul><li>the query will be sent to the database without modifications<ul><li>but Denodo platform may delegate to the source a bigger query over the given sentence, for example, when delegating conditions</li></ul></li><li>this new view will inherit its internal schema from the meta information associated to the query results</li></ul><p>This is useful in several scenarios</p><ul><li>using specific syntax to the accessed database that cannot be replicated in virtual dataport<ul><li>for example, using a function that is not available in virutal dataport</li></ul></li><li>situations when an exact query is needed<ul><li>for example, complex queries already created instead of duplicting them in Denodo</li><li>using queries that have been optimized for the specific database being accessed.</li></ul></li></ul><h2 id="import-stored-procedures"><a class="markdownIt-Anchor" href="#import-stored-procedures"></a> Import Stored Procedures</h2><p>Base views can be created graphically over stored procedure of the following databases</p><ul><li>IBM DB2, MS SQL Server and Oracle</li></ul><p>If the procedure has one or more cursors, one of the following options can be selected</p><ul><li>Stream output at the specified cursor<ul><li>the data that is returned by the cursor is flattened</li></ul></li><li>do not stream cursor parameters<ul><li>the data returned by the cursor will be in an array</li></ul></li></ul><h2 id="querying-views-from-execution-panel"><a class="markdownIt-Anchor" href="#querying-views-from-execution-panel"></a> Querying views from Execution Panel</h2><p>Virtual Dataport is able to import data coming from different systems and with different structure and format</p><ul><li>to retrieve data form a source, some elements are created in Denodo<ul><li>A data source representing a repository of data</li><li>base views repreesnting entities in the source</li><li>these base views can be executed in virtual dataport</li></ul></li></ul><h2 id="basic-derived-views"><a class="markdownIt-Anchor" href="#basic-derived-views"></a> Basic Derived Views</h2><p>Derived Views are new views created over other Denodo Views</p><ul><li>A derived view is another element in the virtual dataport catalog<ul><li>it may then appear in the FROM clause of any VQL query and may be used as a base for constructing new views or queries</li></ul></li><li>THe cache may be used on a derived view, and user privileges can be defined</li></ul><h2 id="functions"><a class="markdownIt-Anchor" href="#functions"></a> Functions</h2><p>Functions are used to generate new attributes in the schema of a view</p><ul><li>a function is defined as an identifier and a list of arguments that can be constants, fields or other functions<ul><li>e.g. len(‘this function gets the length of this text’)</li></ul></li></ul><p>All virtual dataport functions can be browsed by using CTRL + SPACE in the</p><ul><li>Specify WHERE expression tab of the execution panel</li><li>in the field expression dialog available while defining new fields for views</li></ul><p>Custom functions allow users to extend the set of functions available in Virtual dataport</p><ul><li>they are used in the same way as every other function</li></ul><p>Implemented as JAVA classes included in a JAR file that is added to the Virtual Dataport</p><ul><li>functions have to be stateless</li><li>each function has to have a unique name and a different JAVA class</li><li>different functions can be grouped in a single JAR file</li></ul><h2 id="union-views"><a class="markdownIt-Anchor" href="#union-views"></a> Union Views</h2><p>A union view allows the tuples from various input views to be output as a single view</p><ul><li>in standard relational algebra, union operation implies<ul><li>all the relations must have the same schema</li></ul></li><li>extended union all is also used<ul><li>whenever any of the input relations has an attribute that is not present in the others, it is added to the resulting view.</li></ul></li></ul><p>When creating a view, more than just a UNION operation is performed</p><ul><li>some of the operations are performed through intermediate projection operations automatically added by virtual dataport<ul><li>e.g. changing the name of the view, deleting fields</li></ul></li><li>other intermediate opeartions can be added manually<ul><li>where conditions tab</li><li>group by tab</li></ul></li><li>all the operations performed are shown in the tree view screen</li></ul><h2 id="jsonxml-data-source"><a class="markdownIt-Anchor" href="#jsonxml-data-source"></a> JSON/XML data source</h2><p>Virtual Dataport allows to import data from XML or JSON</p><ul><li>these formats are often used for transmitting structured data over a network connection</li><li>these data sources allows Denodo platform to connect to RESTful web services<ul><li>connecting to a resource URI which returns a response with a payload formatted in XML or JSON (google APIs, Twitter etc…)</li></ul></li></ul><p>For JSON data source</p><ul><li>a tuple root can be selected<ul><li>/JSONFile is the default option</li><li>modify it when it is needed to access only a part of the document rather than the entirety of it.</li></ul></li></ul><p>For XML date sources</p><ul><li>there are two options to create base views<ul><li>do not stream output, the base view will return a single compound value aggregating all the document information</li><li>stream output at the specified level: it does not require the entire document to be realized in memory before processing it<ul><li>the contents will be split into different tuples</li></ul></li></ul></li></ul><h2 id="web-service-data-source"><a class="markdownIt-Anchor" href="#web-service-data-source"></a> Web service data source</h2><p>A web service is a software system designed to support interoperable machine-to-machine interaction over a network</p><ul><li>virtual dataport can use a SOAP web service as a data source and performs queries over it by invoking its operations<ul><li>in a web service source, the fields of the query are the input parameters of the web service operation</li></ul></li></ul><h2 id="join-types"><a class="markdownIt-Anchor" href="#join-types"></a> Join Types</h2><p>A join view allows the relational algebra operation with the same name to be executed on a series of input views</p><ul><li>it combines records from two or more views by using values common to each</li><li>INNER JOIN (default)</li><li>LEFT OUTER JOIN</li><li>RIGHT OUTER JOIN</li><li>FULL OUTER JOIN</li><li>CROSS JOIN<ul><li>each row from the first relation is combined with each row from the second one, this join returns the Cartesian product of the sets of rows from the joined tables</li></ul></li></ul><h3 id="join-execution-methods"><a class="markdownIt-Anchor" href="#join-execution-methods"></a> Join Execution Methods</h3><p>Depending on the join type and the selected order, the user can define different join execution methods</p><ul><li>Merge</li><li>Hash</li><li>Nested</li><li>Nested Parallel<br />If the join execution method is not set, design studio will try to calculate the best query plan and all the queries against the join view will follow this plan</li></ul><h3 id="merge"><a class="markdownIt-Anchor" href="#merge"></a> Merge</h3><p>This join method requires the input data to be ordered by the join attributes, this can be achieved as follows</p><ul><li>when the data source allows opeartions, virtual dataport will automatically request the data ordered<ul><li>if it does not allow sorting operations, the ORDERBY clause can be used in the underlying views to sort the data in the required order</li></ul></li><li>the collation of both sources must be the same</li><li>if the data source returns directly the data in the appropriate order<ul><li>the base view options allow administrators to specify it using the ‘Fields by which the data is sorted in the source’ field</li></ul></li><li>data sources are queried in parallel, ordered by the join conditiion and the non-matching data are discarded</li><li>when valid, this strategy is usually the most efficient one and uses less memory than the others</li></ul><h3 id="hash"><a class="markdownIt-Anchor" href="#hash"></a> Hash</h3><p>Creates an in-memory hash table:</p><ul><li>for each different join attribute values on the right side, it will insert a key-value pair into the hash table</li><li>the left side tuples that match these values will be in the final join view output</li></ul><p>This is the most efficient join method when</p><ul><li>the input views that cannot be ordered or are large or the query latency times for the data sources are high<ul><li>minimizes the sub-queries to the sources</li></ul></li></ul><h3 id="nested"><a class="markdownIt-Anchor" href="#nested"></a> Nested</h3><p>Obtains data from one input view, then for each record obtained a subquery is executed in the other view using the join conditions</p><ul><li>if the second view comes from a relational data source, virtual dataport will optimize the process by running a single subquery that retrieves all the matching data from the second source<ul><li>if the amount of values obtained from the left side view of the join exceed a certain value (200 default), the server will group the queries to obtain the data from the rigih-side</li></ul></li><li>A nested join is a good option when the right side returns a lot of tuples and the left side only returns a few</li></ul><h3 id="nested-parallel"><a class="markdownIt-Anchor" href="#nested-parallel"></a> Nested Parallel</h3><p>Same as Nested but this method executes the sub queries in parallel</p><ul><li>an additional parameter allows to specify the maximum number of subqueries launched in parallel</li><li>if the second data source is of JDBC/ODBC type, the use of NESTED PARALLEL is usually unnecessary and less efficient, NESTED option must be used</li></ul><h1 id="compound-types-and-flatten-operation"><a class="markdownIt-Anchor" href="#compound-types-and-flatten-operation"></a> Compound Types and Flatten Operation</h1><p>Denodo virtual dataport supports modeling data types with a complex structure using the types register and array</p><ul><li>an element of the type array can be considered a subview and an array type always has an associated register type that acts like the schema of the subview it is modeling</li></ul><p>Sometimes it is desirable to flatten a compound field that contains an array of registers</p><ul><li>typical in XML and web service data sources</li></ul><p>Flattening a register</p><ul><li>every register element will be a new field on the derived view output</li><li>every array elemenet will be a new row</li></ul><p>it is possible to perform the inverse operation of faltten to create array or register elements from several fields</p><ul><li>this can be done using the NEST or REGISTER functions</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Data Virtualization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TIBCO Data Virtualization</title>
      <link href="2021/07/28/TIBCO-Data-Virtualization/"/>
      <url>2021/07/28/TIBCO-Data-Virtualization/</url>
      
        <content type="html"><![CDATA[<h1 id="virtual-views"><a class="markdownIt-Anchor" href="#virtual-views"></a> Virtual Views</h1><ul><li>Virtual Data Table</li><li>Defined by SQL and TDV Metadata</li><li>Contains SQL SELECT and any ANSI-Standard SQL</li><li>Often federate data from multiple physical sources</li><li>Encapsulate business meaning</li><li>Hide complexity</li><li>Enable re-use</li></ul><h2 id="views"><a class="markdownIt-Anchor" href="#views"></a> Views</h2><ul><li>Created graphically on Model and Grid tabs</li><li>Created Manually on SQL tab<ul><li>Graphical tabs will be removed</li><li>Graphical tabs can be re-created in most cases</li><li>Graphical tabs are not requried</li></ul></li><li>Move freely between graphical and manual modes</li></ul><h1 id="custom-functions"><a class="markdownIt-Anchor" href="#custom-functions"></a> Custom Functions</h1><ul><li><p>User-defined SQL construct</p></li><li><p>Accept parameters, return a single scalar output</p></li><li><p>May be used in SELECT or WHERE clause</p></li><li><p>Example: SELECT UPPER(column_name) AS column_name_upper</p></li><li><p>TDV custom functions created by promoting SQL scripts or custom Java procedures</p></li><li><p>Encapsulate business functionality specific to your enterprice</p></li><li><p>Enable re-use across many projects and many data sources</p></li><li><p>Any script or procedure that outputs a single scalar can be promoted to a Custom Function</p></li></ul><h1 id="layered-development"><a class="markdownIt-Anchor" href="#layered-development"></a> Layered Development</h1><ul><li>Enhance the development process but does not reduce performance at run time</li><li>Enables reuse of virtual resources within and across projects</li><li>Layers are flexible</li></ul><h2 id="physical-layer"><a class="markdownIt-Anchor" href="#physical-layer"></a> Physical Layer</h2><ul><li>Abstract away the physical characteristics of the data on individual data sources</li><li>We generally build virtual views that are almost identical to the underlying physical data structures</li></ul><h2 id="business-layer"><a class="markdownIt-Anchor" href="#business-layer"></a> Business Layer</h2><ul><li>Building coarse-grained data resources that have some important enterprise wide meaning and might be used by many different projects</li></ul><h2 id="application-layer"><a class="markdownIt-Anchor" href="#application-layer"></a> Application Layer</h2><ul><li>Tailor the business layer resources to meet the needs of individual projects</li></ul><h1 id="publishing-virtual-databases"><a class="markdownIt-Anchor" href="#publishing-virtual-databases"></a> Publishing Virtual Databases</h1><ul><li><p>Makes TDV resources accessible to authorized consumers</p></li><li><p>Accessible as a Database via JDBC, ODBC, <a href="http://ADO.NET">ADO.NET</a>, OData</p></li><li><p>Accessible as Web Services via REST, SOAP</p></li><li><p>Many resource types may be published</p></li><li><p>You can create as many Virtual Databases as you like</p></li><li><p>Catelogs and Schemas are optional, However, Catelogs are required for ODBC clients</p></li><li><p>Changes are automatically propagated to published resources</p></li></ul><h1 id="publishing-web-services"><a class="markdownIt-Anchor" href="#publishing-web-services"></a> Publishing Web Services</h1><ul><li><p>we could publish procedures as Web Services</p></li><li><p>In most cases, it is not good practice to publish entire database tables as Web Services, because there might be hundreds of millions of rows, and web services over HTTP are generally not aimed at such use cases</p></li><li><p>Stored procedures however, can accept input parameters which can be used to filter results, therefore, a common practice is to wrap a view within a stored procedure using one or more input parameters that force the data consumer to filter data requests</p></li><li><p>Changes are automatically propagated to published resources</p></li></ul><h1 id="relational-data-source-connections"><a class="markdownIt-Anchor" href="#relational-data-source-connections"></a> Relational Data Source Connections</h1><ul><li><p>Specify connection details</p><ul><li>Host, port, database name, user ID, password</li></ul></li><li><p>Introspect the data source and gather matadata</p><ul><li>Catalogs, schemas, tables, columns, etc…</li></ul></li><li><p>Accept and respond to queries</p></li><li><p>Handle insert, update, and delete transactions</p></li><li><p>Execute stored procedures</p></li><li><p>Expose database artifacts for use in virtual views</p></li><li><p>Understand capabilities of physical databases</p></li><li><p>A JDBC Driveer .jar is required</p><ul><li>TDV is permitted to bundle some drivers</li><li>other drivers must be downloaded and installed<ul><li>This is a one-time process</li></ul></li></ul></li><li><p>Copy the driver into the appropriate TDV driver</p><ul><li>TDV restart is required</li></ul></li></ul><h1 id="rest-clients"><a class="markdownIt-Anchor" href="#rest-clients"></a> REST Clients</h1><ul><li>Uniform interface to web resources<ul><li>Based on URIs</li><li>Manipulate textual represntations of web resources</li><li>Based on HTTP verbs (GET, POST, DELETE, UPDATE)</li><li>Human-readable and self-describing</li></ul></li><li>Stateless</li><li>Contract-free</li></ul><h2 id="automate-authentication-process"><a class="markdownIt-Anchor" href="#automate-authentication-process"></a> Automate Authentication Process</h2><ul><li>Soap UI</li><li>cURL</li><li>Chrome Advanced REST Client</li></ul><h1 id="sql-script"><a class="markdownIt-Anchor" href="#sql-script"></a> SQL Script</h1><ul><li><p>ANSI-SQL-compliant Scripting language</p></li><li><p>Enables procedural logic, including</p><ul><li>Conditional execution</li><li>Looping</li><li>Pipelining</li><li>Exception handling</li><li>Etc…</li></ul></li><li><p>Procedural logic</p></li><li><p>Parameter-driven processing</p></li><li><p>Calls to system procedures and custom procedures</p></li><li><p>Exception handling and logging</p></li><li><p>Scripts can call other resources, including</p><ul><li>Other scripts</li><li>Java procedures</li><li>Packaged queries</li><li>TDV procedure library</li></ul></li></ul><h1 id="xslt-and-streaming-transformations"><a class="markdownIt-Anchor" href="#xslt-and-streaming-transformations"></a> XSLT and Streaming Transformations</h1><ul><li><p>XSLT Transformations</p><ul><li>Extensible Stylesheet Language Transformations</li><li>Industry-standard transformation language</li><li>In DV, most commonly used for flattening XML</li></ul></li><li><p>Streaming Transformations</p><ul><li>Similar to XSLT Editor</li><li>Useful for large data sets</li></ul></li><li><p>Relational data structures provide a common format for data federation</p></li><li><p>Hierarchical XML structures must be flattened in order to participate in data federation projects</p></li></ul><h1 id="procedure-joins"><a class="markdownIt-Anchor" href="#procedure-joins"></a> Procedure Joins</h1><ul><li><p>A special type of join between a View and a Stored Procedure</p></li><li><p>Stored Procedure is executed once per View row - for unique values only</p></li><li><p>Data from the View row provides input parameters to the Procedure</p></li><li><p>Results from all executions are aggregated and then used for the join</p></li><li><p>Augment View data</p><ul><li>Complex calculations</li><li>Procedural logic</li><li>External data in non-standard format</li></ul></li></ul><h1 id="triggers"><a class="markdownIt-Anchor" href="#triggers"></a> Triggers</h1><ul><li><p>Execute based on</p><ul><li>Time parameters</li><li>System events</li><li>User-defined events</li><li>JMS messages</li></ul></li><li><p>Actions include</p><ul><li>Send email</li><li>Execute a procedure</li><li>Gather statistics</li><li>Re-introspect</li></ul></li><li><p>Notify adminstrators of important TDV conditions</p></li><li><p>Provide automated response to important TDV conditions</p></li><li><p>Automate common maintenance tasks</p></li><li><p>Enable developers to execute multiple asynchronous actions</p></li></ul><h1 id="tdv-rights"><a class="markdownIt-Anchor" href="#tdv-rights"></a> TDV Rights</h1><ul><li><p>System-wide capabilities, including</p><ul><li>Tools, such as Studio</li><li>Administration, such as config, status, and users</li><li>Access to resources, such as Views and Procedures</li></ul></li><li><p>Rights may be assigned to</p><ul><li>Groups</li><li>Users</li></ul></li><li><p>During development</p><ul><li>Prevent unauthorized users from accessing developer tools and resources</li><li>Enable developers to access needed resources</li></ul></li><li><p>During ongoing operation</p><ul><li>Enable System Administrators to limit access to operational controls</li></ul></li></ul><h1 id="soap-data-sources"><a class="markdownIt-Anchor" href="#soap-data-sources"></a> SOAP Data Sources</h1><ul><li>Enable TDV to introspect SOAP based web services</li><li>Responses can be transformed, federated and published</li><li>Access to data on internet or intranet</li><li>Commonly-used API for enterprise applications</li></ul><h1 id="cache-index-management"><a class="markdownIt-Anchor" href="#cache-index-management"></a> Cache Index Management</h1><ul><li><p>Indexes can improve Cache read times for</p><ul><li>Views and Procedures</li><li>Single-Table, Multi-Table</li><li>Full and inCremental Refreshes</li></ul></li><li><p>Index Management helps</p><ul><li>Reduce cache refresh time</li><li>reduce index create/update time</li></ul></li><li><p>Manually-Indexes Cache</p></li><li><p>Single-Table Cache</p></li><li><p>Multi-Table Cache</p></li></ul><h1 id="caching-multi-table"><a class="markdownIt-Anchor" href="#caching-multi-table"></a> Caching Multi Table</h1><ul><li><p>Materialized Views or Procedures</p></li><li><p>Wide range of relational database targets</p></li><li><p>Simple or highly abstract</p></li><li><p>Automatic refresh on configurable schedule</p></li><li><p>Cache data held:</p><ul><li>In a relational database - contrasts with file cache</li><li>On multiple tables - contrasts with single-table cache</li></ul></li><li><p>Useful when</p><ul><li>Response time trumps latency</li><li>A physical data source has restricted access</li><li>Efficient use of indexes is desirable (*)</li></ul></li></ul><p>A specific benefit of multi table caching is that it provides physical separation of cache versions which means indexes on a cache are more efficient.</p><p>Single table caches use a cache key column to maintain logical separation of current and previous cache versions, data rows representing the previous expired version are not deleted until all transactions using the old version have completed, this means the old and new cache data may exist simultaneously in a cache for a period of time. TDV will use the appropriate cache key to ensure that correct data is always returned. However, database indexes built on cache columns may be inefficient because they will contain extraneous rows.</p><p>Multi-table cache avoids this issue and enables indexes to be as efficient as possible, but it takes more space.</p><h1 id="caching-single-table"><a class="markdownIt-Anchor" href="#caching-single-table"></a> Caching Single Table</h1><ul><li><p>Materialized Views or Procedures</p></li><li><p>Wide range of relational database targets</p></li><li><p>Simple or highly abstract</p></li><li><p>Automatic refresh on configurable schedule</p></li><li><p>Cache data held:</p><ul><li>In a relational database - contrasts with file cache</li><li>On multiple tables - contrasts with single-table cache</li></ul></li><li><p>Useful when</p><ul><li>Response time trumps latency</li><li>A physical data source has restricted access</li></ul></li></ul><h1 id="caching-policies"><a class="markdownIt-Anchor" href="#caching-policies"></a> Caching Policies</h1><p>All or nothing</p><ul><li><p>Define cache refresh/expiration schedules for groups of resources</p></li><li><p>Maintain consistency across multiple cached resources</p></li><li><p>Enhance cache performance when dependencies are present</p></li><li><p>Not supported for incremental caching</p></li><li><p>Enhance data consistency across multiple caches</p></li><li><p>Ensure accuracy and efficiency with dependent caches</p></li><li><p>Cache policy can mix single-table and multi-table caching</p></li></ul><h1 id="caching-incremental-pull-based"><a class="markdownIt-Anchor" href="#caching-incremental-pull-based"></a> Caching Incremental Pull Based</h1><ul><li><p>Initial - full load</p></li><li><p>Subsequent refreshes - changes only</p></li><li><p>useful when</p><ul><li>Cached data set is large</li><li>full refresh is time-consuming</li></ul></li></ul><h1 id="caching-stored-procedures"><a class="markdownIt-Anchor" href="#caching-stored-procedures"></a> Caching Stored Procedures</h1><ul><li><p>Cache resutls for stored procedure ‘Variants’</p><ul><li>Each variant cached upon first use</li><li>Number of cached variants is configurable<ul><li>Default is 32, max is 99999999</li><li>when limit is reached, LRU variant is purged</li></ul></li><li>All input parameters must be scalars</li></ul></li><li><p>Performance improvements for</p><ul><li>Long-running procedures, external web services</li><li>highly repetitive, high-concurrency procedures</li><li>Unreliable data source connections</li></ul></li></ul><h1 id="cors-operations"><a class="markdownIt-Anchor" href="#cors-operations"></a> CORS operations</h1><ul><li>Cross-Origin Resource Sharing</li><li>HTTP security standard for scripts and other operations</li><li>Applies to script operations like XMLHttpRequest</li><li>Servers may permit or deny CORS requests</li><li>Does not apply to simple request like <code>&lt;img&gt;</code> src</li><li>Requests(GET HEAD POST) execute in one step</li><li>other requests must be pre-flighted using OPTIONS</li><li>Customers serve HTML template pages from a web server in one domain and then populate these pages with REST resources from served from a TDV instance</li></ul><h1 id="custom-datasource-adapters"><a class="markdownIt-Anchor" href="#custom-datasource-adapters"></a> Custom Datasource Adapters</h1><ul><li>New datasource adapters created by reconfiguring a template based on an existing adapter</li><li>No coding required</li><li>The template may be a product-specific datasource, or a generic JDBC datasource</li></ul><p>Three Common use cases</p><ul><li>Settings changes on a supported datasource</li><li>custom functionality in a supported datasource</li><li>connectivity to a datasource not supported by TDV out of the box</li></ul><h1 id="custom-java-procedure-cjp"><a class="markdownIt-Anchor" href="#custom-java-procedure-cjp"></a> Custom Java Procedure (CJP)</h1><ul><li>An API that enables Java code to interact with TDV</li><li>TDV provides a set of interfaces to be implemented</li><li>The CJP is installed as a data source in TDV</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Data Virtualization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL and Database Design</title>
      <link href="2021/07/23/MySQL-and-Database-Design/"/>
      <url>2021/07/23/MySQL-and-Database-Design/</url>
      
        <content type="html"><![CDATA[<h1 id="data-definition-language"><a class="markdownIt-Anchor" href="#data-definition-language"></a> Data Definition Language</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">SHOW DATABASES;</span><br><span class="line"></span><br><span class="line">CREATE DATABASE Test;</span><br><span class="line"></span><br><span class="line">USE Test;</span><br><span class="line"></span><br><span class="line">SHOW TABLES;</span><br><span class="line"></span><br><span class="line">DROP DATABASE Test;</span><br></pre></td></tr></table></figure><h2 id="data-types"><a class="markdownIt-Anchor" href="#data-types"></a> Data Types</h2><ul><li>INT: Whole numbers</li><li>FLOAT(M, D): Decimal numbers (approximate)<ul><li>M: length</li><li>D: length after the decimal point</li><li>allow rounding, e.g. for FLOAT(3,1), number 6.25 will be rounded up to 6.3</li></ul></li><li>DECIMAL(M, D): Decimal numbers (percise)</li><li>CHAR(N): Fixed length character</li><li>VARCHAR(N): Varying length character</li><li>ENUM(‘M’, ‘F’): Value form a defined list</li><li>BOOLEAN: True or False values</li><li>DATE: Date (YYYY-MM-DD)</li><li>DATETIME: Date and time (YYYY-MM-DD HH-mm-SS)</li><li>TIME: Time (HHH-mm-SS), can be larger than 24 hours</li><li>YEAR: Year (YYYY)</li></ul><h2 id="primary-and-foreign-keys"><a class="markdownIt-Anchor" href="#primary-and-foreign-keys"></a> Primary and Foreign keys</h2><h3 id="primay-key"><a class="markdownIt-Anchor" href="#primay-key"></a> Primay Key</h3><ul><li>A primay key is a column, or set of columns, which uniquely identifies a record within a table</li><li>A primay key must be unique</li><li>A primay key cannot be NULL</li><li>A table can only have one primary key</li></ul><h3 id="foreign-key"><a class="markdownIt-Anchor" href="#foreign-key"></a> Foreign Key</h3><ul><li>A foreign key is used to link two tables together</li><li>A foreign key is a column whose values match the values of another tables primay key column</li><li>The table with the primary key is called the reference, or parent table and the table with the foreign key is called the child table</li><li>A table can have multiple foreign keys</li></ul><h2 id="sql-queries"><a class="markdownIt-Anchor" href="#sql-queries"></a> SQL Queries</h2><h3 id="create-table"><a class="markdownIt-Anchor" href="#create-table"></a> Create Table</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE products (</span><br><span class="line">id INT AUTO_INCREMENT PRIMARY KEY,</span><br><span class="line">  name VARCHAR(30),</span><br><span class="line">  price DECIMAL(3, 2)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">CREATE TABLE customers (</span><br><span class="line">id INT AUTO_INCREMENT PRIMARY KEY,</span><br><span class="line">  first_name VARCHAR(30),</span><br><span class="line">  last_name VARCHAR(30),</span><br><span class="line">  gender ENUM(&#39;F&#39;, &#39;M&#39;),</span><br><span class="line">  phone_number VARCHAR(11)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">CREATE TABLE orders (</span><br><span class="line">id INT AUTO_INCREMENT PRIMARY KEY,</span><br><span class="line">  product_id INT,</span><br><span class="line">  customer_id INT,</span><br><span class="line">  order_time DATETIME,</span><br><span class="line">  FOREIGN KEY (product_id) REFERENCES products(id),</span><br><span class="line">  FOREIGN KEY (customer_id) REFERENCES customers(id)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><h3 id="alter-table"><a class="markdownIt-Anchor" href="#alter-table"></a> Alter Table</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"># 1. show details of a table</span><br><span class="line">DESCRIBE &lt;tablename&gt;;</span><br><span class="line"></span><br><span class="line"># 2. add column to table</span><br><span class="line">ALTER TABLE products</span><br><span class="line">ADD COLUMN coffee_origin VARCHAR(30);</span><br><span class="line"></span><br><span class="line"># 3. delete column from table</span><br><span class="line">ALTER TABLE prodcuts</span><br><span class="line">DROP COLUMN coffee_origin;</span><br><span class="line"></span><br><span class="line"># 4. add primary key to table</span><br><span class="line">ALTER TABLE &lt;tablename&gt;</span><br><span class="line">ADD PRIMARY KEY (columnname);</span><br><span class="line"></span><br><span class="line"># 5. delete primary key from table</span><br><span class="line">ALTER TABLE &lt;tablename&gt;</span><br><span class="line">DROP PRIMARY KEY;</span><br><span class="line"></span><br><span class="line"># 6. make up a constraint name when you add foreign key</span><br><span class="line">ALTER TABLE &lt;tablename&gt;</span><br><span class="line">ADD CONSTRAINT &lt;constraintname&gt;</span><br><span class="line">FOREIGN KEY (&lt;columnname&gt;) REFERENCES &lt;tablename&gt;(&lt;columnname&gt;);</span><br><span class="line"></span><br><span class="line"># example</span><br><span class="line">ALTER TABLE people</span><br><span class="line">ADD CONSTRAINT FK_PeopleAddress</span><br><span class="line">FOREIGN KEY (address_id) REFERENCES addresses(id);</span><br><span class="line"></span><br><span class="line"># 7. delete foreign key from table</span><br><span class="line">ALTER TABLE &lt;tablename&gt;</span><br><span class="line">DROP FOREIGN KEY &lt;constraintname&gt;;</span><br><span class="line"></span><br><span class="line"># example</span><br><span class="line">ALTER TABLE people</span><br><span class="line">DROP FOREIGN KEY FK_PeopleAddress;</span><br><span class="line"></span><br><span class="line"># 8. add constraint to table</span><br><span class="line">ALTER TABLE &lt;tablename&gt;</span><br><span class="line">ADD CONSTRAINT &lt;constraintname&gt; UNIQUE (&lt;columnname&gt;);</span><br><span class="line"></span><br><span class="line"># example</span><br><span class="line">ALTER TABLE pets</span><br><span class="line">ADD CONSTRAINT u_species UNIQUE (species);</span><br><span class="line"></span><br><span class="line"># 9. delete constraint from table</span><br><span class="line">ALTER TABLE &lt;tablename&gt;</span><br><span class="line">DROP INDEX &lt;constraintname&gt;;</span><br><span class="line"></span><br><span class="line"># example</span><br><span class="line">ALTER TABLE pets</span><br><span class="line">DROP INDEX u_species;</span><br><span class="line"></span><br><span class="line"># 10. change column name, using back ticks for column names, you can change the data type at the same time too.</span><br><span class="line">ALTER TABLE &lt;tablename&gt;</span><br><span class="line">CHANGE &#96;old_column_name&#96; &#96;new_column_name&#96; &lt;data type&gt;</span><br><span class="line"></span><br><span class="line"># example</span><br><span class="line">ALTER TABLE pets</span><br><span class="line">CHANGE &#96;species&#96; &#96;animal_type&#96; VARCHAR(20);</span><br><span class="line"></span><br><span class="line"># 11. change a column data type</span><br><span class="line">ALTER TABLE &lt;tablename&gt;</span><br><span class="line">MODIFY &lt;columnname&gt; &lt;date type&gt;</span><br><span class="line"></span><br><span class="line"># example</span><br><span class="line">ALTER TABLE addresses</span><br><span class="line">MODIFY city VARCHAR(30);</span><br></pre></td></tr></table></figure><h3 id="delete-table"><a class="markdownIt-Anchor" href="#delete-table"></a> Delete Table</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DROP TABLE products;</span><br></pre></td></tr></table></figure><h3 id="delete-all-data-from-table"><a class="markdownIt-Anchor" href="#delete-all-data-from-table"></a> Delete All Data from Table</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TRUNCATE TABLE products;</span><br></pre></td></tr></table></figure><h1 id="data-manipulation-language"><a class="markdownIt-Anchor" href="#data-manipulation-language"></a> Data Manipulation Language</h1><h2 id="insert"><a class="markdownIt-Anchor" href="#insert"></a> Insert</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO &lt;tablename&gt; (&lt;column1&gt;, &lt;column2&gt;, &lt;column3&gt;)</span><br><span class="line">VALUES (&#39;value1&#39;, &#39;value2&#39;, &#39;value3&#39;);</span><br><span class="line"></span><br><span class="line"># example</span><br><span class="line">INSERT INTO products (name, price, coffee_origin)</span><br><span class="line">VALUES (&#39;Espresso&#39;, 2.50, &#39;Brazil&#39;);</span><br></pre></td></tr></table></figure><h2 id="update"><a class="markdownIt-Anchor" href="#update"></a> Update</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">UPDATE &lt;tablename&gt;</span><br><span class="line">SET &lt;columnname&gt; &#x3D; &#39;value&#39;</span><br><span class="line">WHERE &lt;columnname&gt; &#x3D; &#39;value&#39;;</span><br><span class="line"></span><br><span class="line"># example</span><br><span class="line">UPDATE products</span><br><span class="line">SET coffee_origin &#x3D; &#39;Sri Lanka&#39;</span><br><span class="line">WHERE id &#x3D; 7;</span><br><span class="line"></span><br><span class="line"># set safe update to false so we can use other columns (not just primary key) in WHERE clause to update values</span><br><span class="line">SET SQL_SAFE_UPDATES&#x3D;0;</span><br></pre></td></tr></table></figure><h2 id="delete"><a class="markdownIt-Anchor" href="#delete"></a> Delete</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DELETE FROM people</span><br><span class="line">WHERE name &#x3D; &#39;John&#39;;</span><br><span class="line"></span><br><span class="line"># delete all rows in a table, just don&#39;t add the WHERE clause</span><br><span class="line">DELETE FROM people;</span><br></pre></td></tr></table></figure><h1 id="selecting-from-a-table"><a class="markdownIt-Anchor" href="#selecting-from-a-table"></a> Selecting from a table</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">SELECT &lt;columnname&gt; FROM &lt;tablename&gt;</span><br><span class="line">WHERE &lt;columnname&gt; &#x3D; &lt;value&gt; </span><br><span class="line">AND &lt;columnname&gt; &#x3D; &lt;value&gt;</span><br><span class="line">OR &lt;columnname&gt; &#x3D; &lt;value&gt;;</span><br><span class="line"></span><br><span class="line">SELECT * FROM customers</span><br><span class="line">WHERE last_name IN (&#39;Taylor&#39;, &#39;Bluth&#39;, &#39;Armstrong&#39;);</span><br><span class="line"></span><br><span class="line">SELECT * FROM orders</span><br><span class="line">WHERE order_time BETWEEN &#39;2017-01-01&#39; AND &#39;2017-01-07&#39;;</span><br><span class="line"></span><br><span class="line"># select all customers whos last name starts with &#39;W&#39;</span><br><span class="line">SELECT * FROM customers</span><br><span class="line">WHERE last_name LIKE &#39;W%&#39;;</span><br><span class="line"></span><br><span class="line">SELECT * FROM products</span><br><span class="line">ORDER BY price ASC;</span><br><span class="line"></span><br><span class="line">SELECT * FROM products</span><br><span class="line">ORDER BY price DESC;</span><br><span class="line"></span><br><span class="line">SELECT DISTINCT * FROM products;</span><br><span class="line"></span><br><span class="line"># list 5 rows start at 6th row</span><br><span class="line">SELECT * FROM customers</span><br><span class="line">LIMIT 5 OFFSET 5;</span><br><span class="line"></span><br><span class="line"># name alias</span><br><span class="line">SELECT name as coffee, price, coffee_origin as country</span><br><span class="line">FROM products;</span><br></pre></td></tr></table></figure><h1 id="select-from-multiple-tables"><a class="markdownIt-Anchor" href="#select-from-multiple-tables"></a> Select From Multiple Tables</h1><h2 id="what-is-a-join"><a class="markdownIt-Anchor" href="#what-is-a-join"></a> What is a join</h2><ul><li>Joins allow you to retrieve data from multiple tables in a single select statement</li><li>To join two tables there needs to be a related column between them</li><li>There are many different kinds of join</li></ul><h2 id="inner-join"><a class="markdownIt-Anchor" href="#inner-join"></a> INNER JOIN</h2><ul><li>Will retrieve data only when there is matching values in both values</li></ul><h2 id="left-join"><a class="markdownIt-Anchor" href="#left-join"></a> LEFT JOIN</h2><ul><li>Will retrieve all data from the left table and matching rows from the right table</li></ul><h2 id="right-join"><a class="markdownIt-Anchor" href="#right-join"></a> RIGHT JOIN</h2><ul><li>Will retrieve all data from the right table and matching rows from the left table</li></ul><h3 id="there-is-no-full-join-in-mysql"><a class="markdownIt-Anchor" href="#there-is-no-full-join-in-mysql"></a> There is no FULL JOIN in MySQL</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">SELECT products.name, orders.order_time FROM orders</span><br><span class="line">INNER JOIN products ON orders.product_id &#x3D; products.id;</span><br><span class="line"></span><br><span class="line"># with table alias</span><br><span class="line">SELECT p.name, o.order_time FROM orders o</span><br><span class="line">JOIN products p ON o.product_id &#x3D; p.id;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SELECT o.id, o.order_time, c.phone_number, c.last_name</span><br><span class="line">FROM orders o</span><br><span class="line">LEFT JOIN customers c ON o.customer_id &#x3D; c.id</span><br><span class="line">ORDER BY o.order_time</span><br><span class="line">LIMIT 10;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Join multiple tables</span><br><span class="line">SELECT p.name, p.price, c.first_name, c.last_name, o.order_time</span><br><span class="line">FROM products p</span><br><span class="line">JOIN orders o ON p.id &#x3D; o.product_id</span><br><span class="line">JOIN customers c ON c.id &#x3D; o.customer_id;</span><br></pre></td></tr></table></figure><h1 id="database-design"><a class="markdownIt-Anchor" href="#database-design"></a> Database Design</h1><h2 id="normalization"><a class="markdownIt-Anchor" href="#normalization"></a> Normalization</h2><ul><li>Normalization is the process of efficiently organizing data in a database</li><li>To eliminate redundant data</li><li>To only store related data in a table</li><li>Reduce storage space</li><li>Reduce insert, update and deletion anomalies</li><li>Improve query performance</li></ul><h2 id="first-normal-form"><a class="markdownIt-Anchor" href="#first-normal-form"></a> First Normal Form</h2><p>Tables are in first normal form if</p><ul><li>No repeated rows of data</li><li>Columns only contain a single value</li><li>Table has a primary key</li></ul><h2 id="second-normal-form"><a class="markdownIt-Anchor" href="#second-normal-form"></a> Second Normal Form</h2><p>Tables are in second normal form if</p><ul><li>They conform to first normal form</li><li>Every column that is not a primary key of the table is dependent on the whole of the primary key</li></ul><h2 id="third-normal-form"><a class="markdownIt-Anchor" href="#third-normal-form"></a> Third Normal Form</h2><p>Tables are in third normal form if</p><ul><li>They conform to second normal form</li><li>Every column that is not a primary key is only dependent on the whole of the primary key (they can’t dependent on other columns than primary key)</li></ul><h2 id="relationships"><a class="markdownIt-Anchor" href="#relationships"></a> Relationships</h2><p>Tables are related through primary and foreign keys</p><h2 id="one-to-one"><a class="markdownIt-Anchor" href="#one-to-one"></a> One to One</h2><ul><li>Where a key to one table appears no more than once as the key in another table and vice versa</li></ul><h2 id="one-to-many"><a class="markdownIt-Anchor" href="#one-to-many"></a> One to Many</h2><ul><li>Where a primary key of one table can be in multiple rows of a foreign key column of another table</li></ul><h2 id="many-to-many"><a class="markdownIt-Anchor" href="#many-to-many"></a> Many to Many</h2><ul><li>Where two tables can have many instances of each other</li></ul><h2 id="constraints"><a class="markdownIt-Anchor" href="#constraints"></a> Constraints</h2><ul><li>NOT NULL: a column can’t contain any null values</li><li>UNIQUE: a column can’t contain any duplicate values of data</li><li>PRIMARY KEY: a column that uniquely identifies each row of data</li><li>FOREIGN KEY: a column which is related to a primary key in another table</li><li>CHECK: controls the values that can be inserted into a column</li><li>DEFAULT: if no values is inserted into a column, you can set a default value</li></ul><h1 id="aggregate-functions"><a class="markdownIt-Anchor" href="#aggregate-functions"></a> Aggregate Functions</h1><ul><li>Perform a calculations on data within a column and returns one result row</li><li>Can use GROUP BY clauses to group the results by one or more columns</li><li>Can use a HAVING clause in a similar way to a WHERE clause in a SELECT statement to filter the resutls set.</li></ul><h1 id="subqueries"><a class="markdownIt-Anchor" href="#subqueries"></a> Subqueries</h1><ul><li>Can be used in a SELECT, INSERT, UPDATE or DELETE query</li><li>The nested query can be in the WHERE clause or the FROM</li><li>Two types of subquery<ul><li>Non-correlated</li><li>Correlated</li></ul></li></ul><h2 id="non-correlated-subquery"><a class="markdownIt-Anchor" href="#non-correlated-subquery"></a> Non-correlated subquery</h2><ul><li>The inner query can run independently of the outer query</li><li>Inner query runs first and produces a result set, which is then used by the outer query</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">SELECT id, start_time FROM screenings</span><br><span class="line">WHERE film_id IN</span><br><span class="line">(</span><br><span class="line">  SELECT id FROM films</span><br><span class="line">  WHERE length_min &gt; 120</span><br><span class="line">);</span><br></pre></td></tr></table></figure><h2 id="correlated-subquery"><a class="markdownIt-Anchor" href="#correlated-subquery"></a> Correlated subquery</h2><ul><li>The inner query can’t run independently of the outer query</li><li>The inner query runs for every row in the outer query</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">SELECT screening_id, customer_id, </span><br><span class="line">(</span><br><span class="line">  SELECT COUNT(seat_id)</span><br><span class="line">  FROM reserved_seat WHERE booking_id &#x3D; b.id</span><br><span class="line">)</span><br><span class="line">FROM bookings b;</span><br></pre></td></tr></table></figure><h1 id="sql-functions"><a class="markdownIt-Anchor" href="#sql-functions"></a> SQL Functions</h1><ul><li>Functions are stored programs which can be passed parameters and return a value</li><li>we have already seen some MySQL functions - aggregate functions</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Data Modeling Fundamentals</title>
      <link href="2021/07/20/Data-Modeling-Fundamentals/"/>
      <url>2021/07/20/Data-Modeling-Fundamentals/</url>
      
        <content type="html"><![CDATA[<h1 id="what-is-data-model"><a class="markdownIt-Anchor" href="#what-is-data-model"></a> What is Data Model?</h1><p>Unlike a real database or a real big data environment in the real world, the data model doesn’t have data in it. It is a representation of what that data actually is in the real world. It provides us with a great deal of insight into a lot of the characteristics and rules that apply to our data.</p><ul><li>Major data subjects</li><li>Attributes of data subjects</li><li>Relationships among data subjects</li><li>Business rules for our data</li></ul><h2 id="value-of-a-data-model"><a class="markdownIt-Anchor" href="#value-of-a-data-model"></a> Value of a data model</h2><ul><li>Abstraction from database implementation specifics</li><li>Helps even with relational databases</li><li>Even more valuable with ‘non-intuitive’ data implementations</li></ul><h1 id="basic-data-modeling-concepts-and-terminology"><a class="markdownIt-Anchor" href="#basic-data-modeling-concepts-and-terminology"></a> Basic Data Modeling Concepts and Terminology</h1><h2 id="data-subjects"><a class="markdownIt-Anchor" href="#data-subjects"></a> Data Subjects</h2><ul><li>Commonly called ‘entities’</li><li>Some methodologies use ‘objects’ or ‘classes’</li><li>Somewhat analogous to a database table</li><li>Think it as something that exists</li></ul><h2 id="attributes"><a class="markdownIt-Anchor" href="#attributes"></a> Attributes</h2><ul><li>Analogous to a database column</li><li>Think ‘field’</li><li>Attributes typically associated with entities (subjects)</li><li>Attribute types often shared across multiple entities</li></ul><h2 id="relationship-among-data-subjects"><a class="markdownIt-Anchor" href="#relationship-among-data-subjects"></a> Relationship among Data Subjects</h2><h2 id="business-rules-for-data"><a class="markdownIt-Anchor" href="#business-rules-for-data"></a> Business Rules for data</h2><ul><li>Cardinality</li><li>Mandatory or optional relationships</li><li>Permissible attribute values (including NULLs)</li><li>Data change dynamics (when a row is deleted, other rows in other tables will be deleted too)</li></ul><h1 id="compare-transactional-data-modeling-to-analytical-data-modeling"><a class="markdownIt-Anchor" href="#compare-transactional-data-modeling-to-analytical-data-modeling"></a> Compare Transactional Data Modeling to Analytical Data Modeling</h1><table><thead><tr><th></th><th>Transactional</th><th>Analytical</th></tr></thead><tbody><tr><td>Conceptual Level</td><td>mirror real world</td><td>dimensional</td></tr><tr><td>Logical level (relationsl)</td><td>data normalization rules with deliverate denormalization</td><td>fact and dimension tables in accordance with best practices</td></tr><tr><td>Logical level (non-relational)</td><td>NoSQL, OODBMS constructs</td><td>cubes, columnar databases</td></tr><tr><td>Physical level</td><td>blocks/tracks, MPP distribution</td><td>blocks/trakcs, MPP distribution, AWS buckets, HDFS NameNodes and DataNodes</td></tr></tbody></table><h1 id="the-building-blocks-of-data-modeling"><a class="markdownIt-Anchor" href="#the-building-blocks-of-data-modeling"></a> The Building Blocks of Data Modeling</h1><h2 id="entities"><a class="markdownIt-Anchor" href="#entities"></a> Entities</h2><p>Think it as\</p><ul><li>the real-world subject.</li><li>collection of attributes (fields)</li></ul><h3 id="representing-entities-in-a-model"><a class="markdownIt-Anchor" href="#representing-entities-in-a-model"></a> Representing entities in a model</h3><ul><li>Classic ER modeling: square, squared-off (not round) corners</li><li>Crow’s foot notation</li></ul><h2 id="attributes-2"><a class="markdownIt-Anchor" href="#attributes-2"></a> Attributes</h2><p>Field, the details of an entity</p><ul><li>Represented by a circle</li></ul><h3 id="attributes-have-descriptions-and-rules"><a class="markdownIt-Anchor" href="#attributes-have-descriptions-and-rules"></a> Attributes have descriptions and rules</h3><ul><li>Data types and sizes</li><li>Whether NULL values allowed</li><li>Permissible values</li></ul><h3 id="attribute-domains"><a class="markdownIt-Anchor" href="#attribute-domains"></a> Attribute domains</h3><ul><li>Reuseable general classes of descriptions</li><li>Applied to selective attributes that fit the domain</li><li>Supported by some data modeling software tools</li><li>Example: Valid Business Date is between 1/1/1980 and 21/31/2199, attribute not only have type DATE but also have domain ‘Valid Business Date’</li></ul><h3 id="multi-valued-attribute-mva"><a class="markdownIt-Anchor" href="#multi-valued-attribute-mva"></a> Multi-valued attribute (MVA)</h3><ul><li><p>More than one possible values for each instance</p></li><li><p>Example: a student could have more than one email addresses</p></li><li><p>represented by double circles</p></li><li><p>Modeling software often doesn’t permit MVAs in crow’s foot notation</p></li><li><p>MVAs is one of the two most obvious differentiators between conceptual and logical modeling</p></li><li><p>the other is many-to-many relationships vs database intersection tables</p></li></ul><h2 id="hierarchies-for-the-entities"><a class="markdownIt-Anchor" href="#hierarchies-for-the-entities"></a> Hierarchies for the Entities</h2><ul><li>A special type of relationship</li><li>Two or more entities that have a lot in common but also at least a little bit different</li><li>Parent and Child entities</li><li>Concept of inheritance</li><li>Hierarchies can be inclusive (the item can be in both child entities) or exclusive (the item can be in only one child entity)</li></ul><h2 id="constraints-for-your-attributes"><a class="markdownIt-Anchor" href="#constraints-for-your-attributes"></a> Constraints for your Attributes</h2><ul><li>Data types and sizes</li><li>Whether NULL values allowed</li><li>Permissible values<ul><li>Range of values (can only be the value inside a range)</li><li>List of values (enum, can only be one of the values in the list)</li></ul></li></ul><h2 id="strong-and-weak-entities"><a class="markdownIt-Anchor" href="#strong-and-weak-entities"></a> Strong and Weak entities</h2><p>Think instead in terms of dependencies</p><ul><li><p>Independent entities</p></li><li><p>Dependent entities</p><ul><li>Identification dependency</li><li>Existence dependency</li></ul></li><li><p>Strong entity exists on its own terms</p><ul><li>exists independent of any other entity</li><li>does not require any other entity instances to help identify its own instances</li></ul></li><li><p>Weak entity needs some help</p><ul><li>to identify specific instance of that entity</li><li>can’t exist without an instance of another entity</li><li>or both</li></ul></li></ul><h2 id="relationships"><a class="markdownIt-Anchor" href="#relationships"></a> Relationships</h2><ul><li><p>Classic ER notation: a diamond shape</p></li><li><p>Crow’s foot notation: a stright line</p></li><li><p>Multiple relationships between two entities</p></li><li><p>Recursive relationship involving just one entitiy</p></li><li><p>Ternary (three-entity) relationships</p></li><li><p>Relationships that seem like entities</p></li></ul><h2 id="cardinalities"><a class="markdownIt-Anchor" href="#cardinalities"></a> Cardinalities</h2><p>The number of something</p><ul><li>Each relationship has two cardinalities<ul><li>Maximum cardinality</li><li>Minimum cardinality</li></ul></li><li>Representing cardinality in various notations<ul><li>Classic ER</li><li>Crow’s foot</li></ul></li></ul><h3 id="maximum-cardinality"><a class="markdownIt-Anchor" href="#maximum-cardinality"></a> Maximum Cardinality</h3><ul><li>The maximum number of instances of both sides of a relationship</li><li>typical values: 1 or M</li><li>Can also be a specific numeric value</li></ul><h3 id="11-relationship"><a class="markdownIt-Anchor" href="#11-relationship"></a> 1:1 relationship</h3><ul><li>An instance from each side of a relationship is related to exactly 1 instance from the other side</li><li>Business rules:<ul><li>a university has exactly 1 president</li><li>a person can only be president of 1 university</li></ul></li></ul><h3 id="1m-relationship"><a class="markdownIt-Anchor" href="#1m-relationship"></a> 1:M relationship</h3><ul><li>An instance from one side of a relationship is related to 1 or more instances from the other side</li><li>Business rules:<ul><li>A faculty member can advise many students</li><li>A student is advised by only one faculty member</li></ul></li></ul><h3 id="mm-relationship"><a class="markdownIt-Anchor" href="#mm-relationship"></a> M:M relationship</h3><ul><li>Any instance from either side of the relationship can be associated with one or many instances from the other side</li><li>Business rules:<ul><li>A student can enroll in 1 or many classes</li><li>A class can enroll 1 or many students</li></ul></li></ul><h3 id="specific-number-of-max-cardinality"><a class="markdownIt-Anchor" href="#specific-number-of-max-cardinality"></a> Specific number of max cardinality</h3><ul><li>An instance from one side of a relationship can be related to at most some number from the other side</li><li>can be one-directional or bi-directional</li><li>One-directional 1 to (some number)</li><li>Bi-directional (some number) to (some number)</li></ul><p>Example</p><ol><li>A student can take no more than 7 classes in one semester, a class can have many students. (7:M)</li><li>A student can take no more than 7 classes and any class can enroll up to but no more than 300 students (7:300)</li></ol><h3 id="minimum-cardinality"><a class="markdownIt-Anchor" href="#minimum-cardinality"></a> Minimum Cardinality</h3><p>3 possible value for minimum cardinality</p><ul><li><p>0: optional/partial participation</p></li><li><p>1: mandatory/total participation</p></li><li><p>n: some explicit number of minimum instances</p><ul><li>A full-time lecturer must teach at least 6 classes</li></ul></li><li><p>Difficult to represent explicit numbers with 0 | 1 notation for minimum cardinality</p></li><li><p>Number pairs</p></li><li><p>Left: min cardinality, right: max cardinality</p></li></ul><p><img src="/../images/Data-Modeling-Fundamentals/1.png" alt="Cardinality" /></p><ul><li>An active student must enroll in at least 1 but up to many courses</li><li>A course can have many students but could possibly have zero students</li></ul><h2 id="normalization"><a class="markdownIt-Anchor" href="#normalization"></a> Normalization</h2><h3 id="1st-normal-form"><a class="markdownIt-Anchor" href="#1st-normal-form"></a> 1st Normal Form</h3><ul><li>Every row (tuple) must be unique</li><li>No repeating groups</li><li>MVAs is a violation of 1st NF</li></ul><h3 id="2nd-normal-form"><a class="markdownIt-Anchor" href="#2nd-normal-form"></a> 2nd Normal Form</h3><ul><li>Must be in 1st NF</li><li>No Partial key dependencies</li><li>must have single-column primary key</li></ul><h3 id="3rd-normal-form"><a class="markdownIt-Anchor" href="#3rd-normal-form"></a> 3rd Normal Form</h3><ul><li>Must be in 2NF</li><li>No non-key dependencies</li><li>All attributes are dependent on the primary key</li></ul><p>The key, the whole key, nothing but the key.</p><p>At the conceptual level, there is no real issues violating normalization. We address the issues at logicl level. Then, sometimes we deliverately violate the normalization at the physical level to improve performance based on real situations.</p><h2 id="conceptual-level-to-logical-level"><a class="markdownIt-Anchor" href="#conceptual-level-to-logical-level"></a> Conceptual level to logical level</h2><h3 id="addressing-normalization-violations"><a class="markdownIt-Anchor" href="#addressing-normalization-violations"></a> Addressing normalization violations</h3><ul><li>1NF violations: move offending data to separate table</li><li>2NF violations: partial key dependencies, move offending attribute to correct entity</li><li>3NF violations: non-key dependencies, same as 2NF, move attribute the correct place</li></ul><h3 id="transform-many-to-many-relationships"><a class="markdownIt-Anchor" href="#transform-many-to-many-relationships"></a> Transform many-to-many relationships</h3><ul><li>Add intersection entity to your model</li><li>Also referred to as associative entity</li><li>Purpose: decompose M:M relationship into multiple semantically equivalent relationships</li></ul><h1 id="software-for-data-modeling"><a class="markdownIt-Anchor" href="#software-for-data-modeling"></a> Software for Data Modeling</h1><p>Advantages of data modeling tools</p><ul><li>Enforcement of methodology, technique, and notation rules</li><li>Automated or semi-automated forward and reverse engineering</li></ul><h2 id="options-available"><a class="markdownIt-Anchor" href="#options-available"></a> Options available</h2><ol><li>Microsoft Visio</li><li>CA ERwin</li><li>ER/Studio Data Architect</li><li><a href="https://dbmstools.com/categories/data-modeling-tools">https://dbmstools.com/categories/data-modeling-tools</a></li></ol><h3 id="microsoft-visio"><a class="markdownIt-Anchor" href="#microsoft-visio"></a> Microsoft Visio</h3><ul><li>From guided drawing templates to semantically aware models<ul><li>Business process models</li><li>Data models</li></ul></li><li>Multi-functioned drawing tool</li><li>Close alignment with Microsoft SQL server</li><li>Widely used</li></ul><h3 id="ca-erwin"><a class="markdownIt-Anchor" href="#ca-erwin"></a> CA ERwin</h3><ul><li>One of the oldest data modeling tools still being used</li><li>Rich capabilities for forward and reverse engineering</li></ul><h3 id="erstudio-data-architect"><a class="markdownIt-Anchor" href="#erstudio-data-architect"></a> ER/Studio Data Architect</h3><ul><li>Another old timer that still is a market leader</li><li>Rich feature set including dimensional modeling (for analytical)</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Data </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Data Warehouse</title>
      <link href="2021/07/20/Data-Warehouse/"/>
      <url>2021/07/20/Data-Warehouse/</url>
      
        <content type="html"><![CDATA[<h1 id="what-is-business-intelligence"><a class="markdownIt-Anchor" href="#what-is-business-intelligence"></a> What is Business Intelligence?</h1><p>BI is the act of transforming raw/operational data into useful information for business analysis</p><h2 id="how-does-it-work"><a class="markdownIt-Anchor" href="#how-does-it-work"></a> How Does it Work?</h2><ol><li>BI based on Data Warehouse technology extracts information from a company’s operational systems</li><li>The data is transformed (cleaned and integrated), and loaded into Data Warehouse</li><li>Since this data is credible, it is used for business insights.</li></ol><h2 id="why-data-warehouse"><a class="markdownIt-Anchor" href="#why-data-warehouse"></a> Why Data Warehouse?</h2><ol><li>Data collected from various sources and stored in various databases (Oracle, SQL server, MySQL…) cannot be directly visualized</li><li>The data first needs to be integrated and then processed before visualization takes place.</li></ol><h1 id="what-is-data-warehouseing"><a class="markdownIt-Anchor" href="#what-is-data-warehouseing"></a> What is Data Warehouseing?</h1><ol><li>A central location where consolidated data from multiple locations (databases) are stored</li><li>DWH is maintained separately from an organization’s operational database. (DWH is another copy)</li><li>End uses access it whenever any information is needed.</li><li>Data Warehouse is not loaded every time new data is added to databases.</li></ol><h2 id="what-are-the-advantages-of-a-data-warehouse"><a class="markdownIt-Anchor" href="#what-are-the-advantages-of-a-data-warehouse"></a> What are The Advantages of a Data Warehouse?</h2><ol><li>Strategic questions can be answered by studying trends (from past data).</li><li>Data Warehousing is faster and more accurate</li><li>Data Warehouse is not a product that a company can go and purchase, it needs to be designed and depends entirely on the company’s requirement.</li></ol><p>End User<br />=&gt; Take the data from opeartional systems<br />=&gt; Integrate the data from multiple sources<br />=&gt; Standardize the data and remove inconsistencies<br />=&gt; Store the data in format suitable for easy access<br />=&gt; Return result to end user</p><h2 id="properties-of-a-data-warehouse"><a class="markdownIt-Anchor" href="#properties-of-a-data-warehouse"></a> Properties of a Data Warehouse</h2><p>A Data Warehouse is a subject-oriented, integrated, time-variant and non-volatile collection of data in support of managemnet’s decision-making process</p><ol><li>Subject-oriendted: Data is categorized and stored by business subject rather than by application. (data in data warehouse are suitable for business requirements)</li><li>Integrated: Data on a given subject is collected from disparate sources and stored in a single place</li><li>Time-variant: Data is stored as a series of snapshots, each representing a period of time</li><li>Non-volatile: Typically data in the data warehouse is not updated or deleted</li></ol><h1 id="key-terminologies-related-to-dwh-architechture"><a class="markdownIt-Anchor" href="#key-terminologies-related-to-dwh-architechture"></a> Key Terminologies Related to DWH Architechture</h1><h2 id="oltp-online-transaction-processing-vs-olap-online-analytical-processing"><a class="markdownIt-Anchor" href="#oltp-online-transaction-processing-vs-olap-online-analytical-processing"></a> OLTP (Online Transaction Processing) vs OLAP (Online Analytical Processing)</h2><table><thead><tr><th>Relational Database (OLTP)</th><th>Analytical Data Warehouse (OLAP)</th></tr></thead><tbody><tr><td>Contains current data</td><td>Contains historical data</td></tr><tr><td>Useful in running the business</td><td>Useful in analyzing the business</td></tr><tr><td>Based on Entity Relationship Model</td><td>Based on Star, Snowflake and Fact Constellation Schema</td></tr><tr><td>Provides primitive and highly detailed data</td><td>Provides summarized and consolidated data</td></tr><tr><td>Used for writing data into the database</td><td>Used for reading data from data warehouse</td></tr><tr><td>Database size ranges from 100MB to 1GB</td><td>Data warehouse size ranges from 100GB to 1TB</td></tr><tr><td>Fast, provides high performance</td><td>Highly flexible, but not fast</td></tr><tr><td>Number of records accessed is in tens</td><td>Number of records accessed is in millions</td></tr><tr><td>Example: All bank transactions made by a customer</td><td>Example: Bank transactions made by a customer at a particular time</td></tr></tbody></table><h3 id="oltp-examples"><a class="markdownIt-Anchor" href="#oltp-examples"></a> OLTP Examples:</h3><ol><li>A supermarket server which records every single product purchased at that market</li><li>A back server which records every time a transaction is made for a particular account</li><li>A railway reservation server which records the transactions of a passenger</li></ol><h3 id="olap-examples"><a class="markdownIt-Anchor" href="#olap-examples"></a> OLAP Examples:</h3><ol><li>Bank manager wants to know how many customers are utilizing the ATM of his branch. Based on this he may take a call whether to continue with the ATM or relocate it.</li><li>An insurance company wants to know the number of policies each agent has sold. This will help in better performance management of agents.</li></ol><h2 id="etl"><a class="markdownIt-Anchor" href="#etl"></a> ETL</h2><p>ETL is the process of extracting the data from various sources, transforming this data to meet your requirement and then loading it into a target data warehouse. (Tools: Talend, Informatica…)</p><h2 id="data-mart"><a class="markdownIt-Anchor" href="#data-mart"></a> Data Mart</h2><ol><li>Data mart is a smaller version of the data warehouse which deals with a single subject.</li><li>Data mart are focused on one area, hence, they draw data from a limited number of sources</li><li>Time taken to build data marts is very less compared to the time taken to build a data warehouse</li></ol><table><thead><tr><th>Data Warehouse</th><th>Data Marts</th></tr></thead><tbody><tr><td>Enterprise wide data</td><td>Department wide data</td></tr><tr><td>Multiple subject areas</td><td>Single subject data</td></tr><tr><td>Multiple data sources</td><td>Limited data sources</td></tr><tr><td>Occupies large memory</td><td>Occupies limited memory</td></tr><tr><td>Longer time to implement</td><td>Shorter time to implement</td></tr></tbody></table><h3 id="types-of-data-mart"><a class="markdownIt-Anchor" href="#types-of-data-mart"></a> Types of Data Mart</h3><ul><li>Dependent Data Mart</li></ul><ol><li>The Data is first extracted from the OLTP systems and them populated in the central DWH</li><li>From the DWH, the data travels to the Data Mart</li></ol><ul><li>Independent Data Mart</li></ul><ol><li>The data is directly received from the source system</li><li>This is suitable for small organizations or small groups within an organization</li></ol><ul><li>Hybrid Data Mart</li></ul><ol><li>The data is fed both from OLTP systems as well as the Data Warehouse</li></ol><h2 id="metadata"><a class="markdownIt-Anchor" href="#metadata"></a> Metadata</h2><ol><li>Metadata is defined as data about data</li><li>Matadata in a DWH defines the source data. (Flat file, Relational Database and other objects)</li><li>Matadata is used to define which table is source and target, and which concept is used to build business logic called transformation to the actual output.</li></ol><h1 id="dwh-architecture"><a class="markdownIt-Anchor" href="#dwh-architecture"></a> DWH Architecture</h1><p><img src="/../images/Data-Warehouse/1.png" alt="DWH Architecture" /></p>]]></content>
      
      
      
        <tags>
            
            <tag> Data </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Introduction to Azure</title>
      <link href="2021/06/03/Introduction-to-Azure/"/>
      <url>2021/06/03/Introduction-to-Azure/</url>
      
        <content type="html"><![CDATA[<h2 id="documentation"><a class="markdownIt-Anchor" href="#documentation"></a> Documentation</h2><ul><li>Best documentation in the world</li></ul><h2 id="azure-interaction-experiences"><a class="markdownIt-Anchor" href="#azure-interaction-experiences"></a> Azure Interaction Experiences</h2><ul><li>Portal</li><li>CLI</li><li>VS Code</li><li>Visual Studio</li></ul><h2 id="enablement"><a class="markdownIt-Anchor" href="#enablement"></a> Enablement</h2><ul><li>Getting certified</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Azure </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Scrum Master Notes</title>
      <link href="2021/06/03/Scrum-Master-Notes/"/>
      <url>2021/06/03/Scrum-Master-Notes/</url>
      
        <content type="html"><![CDATA[<h2 id="sprint-overview"><a class="markdownIt-Anchor" href="#sprint-overview"></a> Sprint Overview</h2><h3 id="roles"><a class="markdownIt-Anchor" href="#roles"></a> Roles</h3><ol><li>Product Owner - The voice of customer, responosible for the Product Backlog</li><li>Scrum Master - Servant Leader, responsible for ensuring the team is fully functional and productive</li><li>Scrum Team - self-organising and self-managing, responsible for the outcomes of the sprint</li></ol><h3 id="ceremonies-meetings"><a class="markdownIt-Anchor" href="#ceremonies-meetings"></a> Ceremonies (meetings)</h3><ol><li>Sprint Planning</li><li>Daily Scrum (stand up) - daily updates</li><li>Sprint Retro - reflective look back</li><li>Sprint Review - demo to product owner and customer and give feedback</li></ol><h3 id="artefacts"><a class="markdownIt-Anchor" href="#artefacts"></a> Artefacts</h3><ol><li>Product Backlog - list of objectives need to be done to deliver the product. Product Owner is responsible for the Product Backlog, decides what should be in it</li><li>Sprint Backlog - list of tasks for the current sprint, Scrum Team move tasks from Product Backlog to the Sprint Backlog and only focus on these tasks for the sprint</li><li>Scrum Board - visible to client, tasks for the day</li><li>Burndown Chart - visible to client, tasks for the day</li><li>Sprint Delivery - Tasks finished at the end of the sprint, should be the same as Product Backlog if nothing had gone wrong</li></ol><h3 id="non-core-roles"><a class="markdownIt-Anchor" href="#non-core-roles"></a> Non Core Roles</h3><ul><li>Stakeholders</li><li>Scrum Guidance Body</li><li>Vendors</li></ul><h2 id="ceremonies"><a class="markdownIt-Anchor" href="#ceremonies"></a> Ceremonies</h2><h3 id="sprint-planning"><a class="markdownIt-Anchor" href="#sprint-planning"></a> Sprint Planning</h3><ul><li>Agreeing and committing to what tasks will be done in the next sprint, move tasks from Product Backlog to Sprint Backlog</li></ul><h3 id="daily-stand-up"><a class="markdownIt-Anchor" href="#daily-stand-up"></a> Daily Stand Up</h3><ul><li>The team provides short and concise progress updates daily</li></ul><h3 id="sprint-review-showcase"><a class="markdownIt-Anchor" href="#sprint-review-showcase"></a> Sprint Review / Showcase</h3><ul><li>Allows stakeholders to assess progress and re-prioritise Product Backlog if necessary</li></ul><h3 id="sprint-retro"><a class="markdownIt-Anchor" href="#sprint-retro"></a> Sprint Retro</h3><ul><li>Where performance inefficiencies are discussed and opportunities for improvement are identified.</li><li>What went well, what didn’t go well, what can we start / stop doing (for scrum team itself)</li></ul><h2 id="non-official-ceremonies"><a class="markdownIt-Anchor" href="#non-official-ceremonies"></a> Non Official Ceremonies</h2><h3 id="release-planning"><a class="markdownIt-Anchor" href="#release-planning"></a> Release Planning</h3><ul><li>Identifying and communicating how often a solution will be released and what features will be included</li></ul><h3 id="elaboration"><a class="markdownIt-Anchor" href="#elaboration"></a> Elaboration</h3><ul><li>Ask questions and understand the problem in Backlog</li></ul><h3 id="backlog-grooming"><a class="markdownIt-Anchor" href="#backlog-grooming"></a> Backlog Grooming</h3><ul><li>Review and redefinition of existing tasks</li></ul><h3 id="backlog-prioritisation"><a class="markdownIt-Anchor" href="#backlog-prioritisation"></a> Backlog Prioritisation</h3><ul><li>Prioritise the Backlog tasks</li></ul><h3 id="risk-review-sessions"><a class="markdownIt-Anchor" href="#risk-review-sessions"></a> Risk Review Sessions</h3><h2 id="scrum-artifacts"><a class="markdownIt-Anchor" href="#scrum-artifacts"></a> Scrum Artifacts</h2><h3 id="prodcut-backlog"><a class="markdownIt-Anchor" href="#prodcut-backlog"></a> Prodcut Backlog</h3><ul><li>List of tasks within the project</li></ul><h3 id="sprint-backlog"><a class="markdownIt-Anchor" href="#sprint-backlog"></a> Sprint Backlog</h3><ul><li>List of tasks to be done within the next sprint</li></ul><h3 id="scrum-board-and-burndown-chart"><a class="markdownIt-Anchor" href="#scrum-board-and-burndown-chart"></a> Scrum Board and Burndown Chart</h3><ul><li>Tracking progress and commmunications in an open and visual way</li></ul><h2 id="scrum-principles"><a class="markdownIt-Anchor" href="#scrum-principles"></a> Scrum Principles</h2><h3 id="empriical-process-control"><a class="markdownIt-Anchor" href="#empriical-process-control"></a> Empriical Process Control</h3><ul><li>making decisions based on observation and experimentation rather than detailed upfront planning</li><li>Transparency, Allows all components to be observed by everyone</li><li>Inspection, Monitoring in place to ensure deliverables conform to stated requirements</li><li>Adaption, Lessons learn through transparency and inspection used to improve performance</li></ul><h3 id="self-organisation"><a class="markdownIt-Anchor" href="#self-organisation"></a> Self Organisation</h3><ul><li>Deliver greater value</li><li>Team buy-in and shared ownership</li><li>Higher levels of motivation</li><li>Innovative and creative environment</li></ul><h3 id="collaboration"><a class="markdownIt-Anchor" href="#collaboration"></a> Collaboration</h3><ul><li>Awareness, be aware of each other’s work</li><li>Articulation, paritition work into units</li><li>Appropriation, adapting technology to one’s own situation</li></ul><h3 id="value-based-prioritisation"><a class="markdownIt-Anchor" href="#value-based-prioritisation"></a> Value Based Prioritisation</h3><ul><li>Delivering value to the customer on an early and continuous basis</li><li>Methods used: Paried Comoparison, KANO, MoSCoW (Must, Should, Could, Won’t), 100 point comparison</li></ul><h3 id="timeboxing"><a class="markdownIt-Anchor" href="#timeboxing"></a> Timeboxing</h3><ul><li>The rhythm to which stakeholders work / contribute</li></ul><h3 id="iterative-development"><a class="markdownIt-Anchor" href="#iterative-development"></a> Iterative Development</h3><ul><li>Deliver value throughout the project, incorporating change as part of the process, adapt to the changing requirements</li></ul><h2 id="scrum-aspects"><a class="markdownIt-Anchor" href="#scrum-aspects"></a> Scrum Aspects</h2><h3 id="business-justification"><a class="markdownIt-Anchor" href="#business-justification"></a> Business Justification</h3><ul><li>based on the concept of value-driven delivery</li></ul><h3 id="quality"><a class="markdownIt-Anchor" href="#quality"></a> Quality</h3><ul><li>Definition of done, a set of rules that are applicable to all user stories</li><li>Ways of working, a set of guidelines that make up a social contract between the Scrum Team</li></ul><h3 id="change"><a class="markdownIt-Anchor" href="#change"></a> Change</h3><ul><li>Adapt of change, it is inevitable</li></ul><h3 id="risk"><a class="markdownIt-Anchor" href="#risk"></a> Risk</h3><ul><li>Need to be identified and mitigated early, they are inevitable</li></ul><h2 id="scrum-phases"><a class="markdownIt-Anchor" href="#scrum-phases"></a> Scrum Phases</h2><h3 id="initiate"><a class="markdownIt-Anchor" href="#initiate"></a> Initiate</h3><ul><li>The Initiate phase includes the processes related to initiation of a project – these are all pre-sprint activities such as<br />forming of the Scrum Core Team, identification of stakeholder, development of high level requirements (epics), creation<br />of the Prioritised Product Backlog and release planning.</li></ul><h3 id="plan-and-estimate"><a class="markdownIt-Anchor" href="#plan-and-estimate"></a> Plan and Estimate</h3><ul><li>This phase consists of processes related to planning and estimating tasks for the upcoming Sprint (Sprint Backlog).<br />These activities happen during the Sprint Planning Meeting.</li></ul><h3 id="implement"><a class="markdownIt-Anchor" href="#implement"></a> Implement</h3><ul><li>Implementation is related to the execution of the tasks and activities to create a project’s products. These activities<br />include creating the various deliverables, conducting Daily Stand Up Meetings, and grooming (i.e., reviewing, fine-tuning,<br />and regularly updating) the Product Backlog at regular intervals.</li></ul><h3 id="review-and-retrospect"><a class="markdownIt-Anchor" href="#review-and-retrospect"></a> Review and Retrospect</h3><ul><li>This phase is concerned with reviewing the deliverables and the work that has been done during the sprint (Sprint<br />Review Meeting) for acceptance and determining ways to improve the practices and methods used to do project work<br />and for incorporation into future sprints (Retrospect Sprint Meeting).</li></ul><h3 id="release"><a class="markdownIt-Anchor" href="#release"></a> Release</h3><ul><li>The release phase is focused on delivering/shipping the Accepted Deliverables to the customer and identifying,<br />documenting, and internalising the lessons learned during the project.</li></ul><h2 id="writing-a-user-story"><a class="markdownIt-Anchor" href="#writing-a-user-story"></a> Writing a User Story</h2><ul><li>User Stories will allow the Product Owner, Stakeholders and the Scrum Team to discuss, prioritise and deliver requirements and features</li><li>As a <code>Role</code>, I want to <code>Perform an action</code>, so I can <code>achieve an objective</code></li><li>Epic, Feature, Story</li><li>story delivers business value</li></ul><h3 id="user-story-estimate"><a class="markdownIt-Anchor" href="#user-story-estimate"></a> User Story Estimate</h3><ul><li>story points</li></ul><h3 id="acceptance-criteria"><a class="markdownIt-Anchor" href="#acceptance-criteria"></a> Acceptance Criteria</h3><ul><li>Conditions that developers and testers will use to complete the stories</li><li>the story will need to satisfy acceptance criteria to be considered complete</li></ul><h2 id="scrum-of-scrums"><a class="markdownIt-Anchor" href="#scrum-of-scrums"></a> Scrum of Scrums</h2><ul><li>Chief Product Owner</li><li>Chief Scrum Master</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Scrum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git cheatsheet</title>
      <link href="2021/06/02/git-cheatsheet/"/>
      <url>2021/06/02/git-cheatsheet/</url>
      
        <content type="html"><![CDATA[<h1 id="common-git-commands"><a class="markdownIt-Anchor" href="#common-git-commands"></a> Common git commands</h1><h2 id="make-directory-a-git-repository"><a class="markdownIt-Anchor" href="#make-directory-a-git-repository"></a> make directory a git repository</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git init</span><br></pre></td></tr></table></figure><h2 id="adds-files-in-the-to-the-staging-area-for-git"><a class="markdownIt-Anchor" href="#adds-files-in-the-to-the-staging-area-for-git"></a> Adds files in the to the staging area for Git.</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git add &lt;file or directory name&gt;</span><br></pre></td></tr></table></figure><h1 id="adding-a-commit-with-message"><a class="markdownIt-Anchor" href="#adding-a-commit-with-message"></a> Adding a commit with message</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git commit -m &quot;Commit message&quot;</span><br></pre></td></tr></table></figure><h2 id="current-state-of-the-repository"><a class="markdownIt-Anchor" href="#current-state-of-the-repository"></a> current state of the repository</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git status</span><br></pre></td></tr></table></figure><h2 id="create-a-new-branch"><a class="markdownIt-Anchor" href="#create-a-new-branch"></a> Create a new branch</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch &lt;branch name&gt;</span><br></pre></td></tr></table></figure><h2 id="checkout-an-existing-branch"><a class="markdownIt-Anchor" href="#checkout-an-existing-branch"></a> Checkout an existing branch</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout &lt;branch name&gt;</span><br></pre></td></tr></table></figure><h2 id="merge-changes-into-current-branch"><a class="markdownIt-Anchor" href="#merge-changes-into-current-branch"></a> Merge changes into current branch</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git merge &lt;branch name&gt;</span><br></pre></td></tr></table></figure><h2 id="add-remote-repository"><a class="markdownIt-Anchor" href="#add-remote-repository"></a> Add remote repository</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git remote &lt;command&gt; &lt;remote_name&gt; &lt;remote_URL&gt;</span><br><span class="line"></span><br><span class="line"># connect remote repo to the local repo, the remote repo has name origin, followed by its URL</span><br><span class="line">git remote add origin git@account_name.git.beanstalkapp.com:&#x2F;acccount_name&#x2F;repository_name.git</span><br></pre></td></tr></table></figure><h2 id="get-the-latest-version-of-a-repository"><a class="markdownIt-Anchor" href="#get-the-latest-version-of-a-repository"></a> get the latest version of a repository</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git pull &lt;branch_name&gt; &lt;remote_URL&#x2F;remote_name&gt;</span><br></pre></td></tr></table></figure><h2 id="sends-local-commits-to-the-remote-repository"><a class="markdownIt-Anchor" href="#sends-local-commits-to-the-remote-repository"></a> Sends local commits to the remote repository</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># push local commits to a remote repo</span><br><span class="line">git push &lt;remote_URL&#x2F;remote_name&gt; &lt;branch&gt;</span><br><span class="line"></span><br><span class="line"># push local branch MASTER to remote repo ORIGIN, </span><br><span class="line">git push origin master</span><br><span class="line"></span><br><span class="line"># push all local branches to remote repo</span><br><span class="line">git push -all origin</span><br><span class="line"></span><br><span class="line"># -u flag will keep track all pushes so next time you can just use git push</span><br><span class="line">git push -u origin master</span><br></pre></td></tr></table></figure><h2 id="show-the-chronological-commit-history-for-a-repository"><a class="markdownIt-Anchor" href="#show-the-chronological-commit-history-for-a-repository"></a> show the chronological commit history for a repository</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git log</span><br></pre></td></tr></table></figure><h2 id="make-a-copy-to-another-remote-repo"><a class="markdownIt-Anchor" href="#make-a-copy-to-another-remote-repo"></a> make a copy to another remote repo</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git fork</span><br></pre></td></tr></table></figure><h2 id="make-a-copy-from-a-remote-repo-to-the-a-local-repo"><a class="markdownIt-Anchor" href="#make-a-copy-from-a-remote-repo-to-the-a-local-repo"></a> make a copy from a remote repo to the a local repo</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone</span><br></pre></td></tr></table></figure><h2 id="temporarily-save-local-changes-before-pulling-from-remote-repo-local-changes-are-not-ready-for-commit"><a class="markdownIt-Anchor" href="#temporarily-save-local-changes-before-pulling-from-remote-repo-local-changes-are-not-ready-for-commit"></a> Temporarily save local changes before pulling from remote repo (local changes are not ready for commit)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># stash basically has the same logic as commit, git will just save the changes in different places so it will not appear in your commit history</span><br><span class="line">git stash save</span><br></pre></td></tr></table></figure><h2 id="reapply-local-changes-after-pulling"><a class="markdownIt-Anchor" href="#reapply-local-changes-after-pulling"></a> Reapply local changes after pulling</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git stash pop</span><br></pre></td></tr></table></figure><h2 id="change-the-starting-poing-of-a-branch"><a class="markdownIt-Anchor" href="#change-the-starting-poing-of-a-branch"></a> change the starting poing of a branch</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># this is make the commit history looks cleaner. But will cause problems when working with others because when you do it, your branch&#39;s starting poing is different to others and becomes a different branch</span><br><span class="line">git rebase</span><br></pre></td></tr></table></figure><h2 id="git-squash"><a class="markdownIt-Anchor" href="#git-squash"></a> git squash</h2><p>combine multiple commits into one commit, make the commit history looks cleaner</p>]]></content>
      
      
      
        <tags>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TCP/IP</title>
      <link href="2021/05/26/TCP-IP/"/>
      <url>2021/05/26/TCP-IP/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
        <tags>
            
            <tag> TCP/IP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C# LINQ</title>
      <link href="2021/04/20/C-LINQ/"/>
      <url>2021/04/20/C-LINQ/</url>
      
        <content type="html"><![CDATA[<h2 id="linq"><a class="markdownIt-Anchor" href="#linq"></a> LINQ</h2><ul><li>SQL-like syntax in C# and Visual Basic</li><li>Query any type of collection (<code>IEnumerable&lt;T&gt;</code>)</li><li>Query external data sources (xml, databases, JSON, CSV)</li></ul><h3 id="sql-query-vs-linq-query-syntax"><a class="markdownIt-Anchor" href="#sql-query-vs-linq-query-syntax"></a> SQL Query vs LINQ Query Syntax</h3><table><thead><tr><th>SQL</th><th>LINQ</th></tr></thead><tbody><tr><td>SELECT * FROM Products</td><td>FROM prod IN Products SELECT prod</td></tr><tr><td>SELECT Name FROM Products</td><td>FROM prod in Products SELECT <a href="http://prod.Name">prod.Name</a></td></tr><tr><td>SELECT * FROM Products WHERE ListPrice &gt; 10</td><td>FROM prod in Products WHERE prod.ListPrice &gt; 10 SELECT prod</td></tr></tbody></table><h3 id="two-linq-syntaxes"><a class="markdownIt-Anchor" href="#two-linq-syntaxes"></a> Two LINQ Syntaxes</h3><table><thead><tr><th>Query</th><th>Method</th></tr></thead><tbody><tr><td>FROM prod in Products SELECT prod</td><td>Products.Select(prod =&gt; prod)</td></tr><tr><td>FROM prod in Products SELECT <a href="http://prod.Name">prod.Name</a></td><td>Products.Select(prod =&gt; <a href="http://prod.Name">prod.Name</a>)</td></tr><tr><td>FROM prod in Products WHERE prod.ListPrice &gt; 10 SELECT prod</td><td>Products.Where(prod =&gt; prod.ListPrice &gt; 10).Select(prod =&gt; prod)</td></tr></tbody></table><h3 id="linq-operations"><a class="markdownIt-Anchor" href="#linq-operations"></a> LINQ Operations</h3><ul><li>Select</li><li>Projection (Change shape, select only certain properties from an object)</li><li>Order (ascending/descending)</li><li>Get an Element (find, first, last, single)</li><li>Filter (where)</li><li>Iteration/Partioning (foreach, skip, take)</li><li>Quantify (any, all, contains)</li><li>Set Comparison (equal, except, intersection)</li><li>Set Operations (union, concat)</li><li>Joining (inner joins, outer joins)</li><li>Grouping (groupby, subquery, groupjoin)</li><li>Distinct Sets (distinct)</li><li>Aggregation (count, sum, min, max, average)</li></ul><h2 id="select-and-order-operations"><a class="markdownIt-Anchor" href="#select-and-order-operations"></a> Select and Order Operations</h2><h3 id="projection-only-select-specific-columns-from-an-object"><a class="markdownIt-Anchor" href="#projection-only-select-specific-columns-from-an-object"></a> Projection (only select specific columns from an object)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">if (UseQuerySyntax)</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Query Syntax</span><br><span class="line">    Products &#x3D; (from prod in Products</span><br><span class="line">                select new Product</span><br><span class="line">                &#123;</span><br><span class="line">                    ProductID &#x3D; prod.ProductID,</span><br><span class="line">                    Name &#x3D; prod.Name,</span><br><span class="line">                    Size &#x3D; prod.Size,</span><br><span class="line">                &#125;).ToList();</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Method Syntax</span><br><span class="line">    Products &#x3D; Products.Select(prod &#x3D;&gt; new Product</span><br><span class="line">    &#123;</span><br><span class="line">        ProductID &#x3D; prod.ProductID,</span><br><span class="line">        Name &#x3D; prod.Name,</span><br><span class="line">        Size &#x3D; prod.Size</span><br><span class="line">    &#125;).ToList();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="projection-with-anonymous-class"><a class="markdownIt-Anchor" href="#projection-with-anonymous-class"></a> Projection with Anonymous Class</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">if (UseQuerySyntax)</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Query Syntax</span><br><span class="line">    var products &#x3D; (from prod in Products</span><br><span class="line">                    select new</span><br><span class="line">                    &#123;</span><br><span class="line">                        Identifier &#x3D; prod.ProductID,</span><br><span class="line">                        ProductName &#x3D; prod.Name,</span><br><span class="line">                        ProductSize &#x3D; prod.Size</span><br><span class="line">                    &#125;);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; Loop through anonymous class</span><br><span class="line">    foreach (var prod in products)</span><br><span class="line">    &#123;</span><br><span class="line">        sb.AppendLine($&quot;Product ID: &#123;prod.Identifier&#125;&quot;);</span><br><span class="line">        sb.AppendLine($&quot;   Product Name: &#123;prod.ProductName&#125;&quot;);</span><br><span class="line">        sb.AppendLine($&quot;   Product Size: &#123;prod.ProductSize&#125;&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Method Syntax</span><br><span class="line">    var products &#x3D; Products.Select(prod &#x3D;&gt; new</span><br><span class="line">    &#123;</span><br><span class="line">        Identifier &#x3D; prod.ProductID,</span><br><span class="line">        ProductName &#x3D; prod.Name,</span><br><span class="line">        ProductSize &#x3D; prod.Size</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; Loop through anonymous class</span><br><span class="line">    foreach (var prod in products)</span><br><span class="line">    &#123;</span><br><span class="line">        sb.AppendLine($&quot;Product ID: &#123;prod.Identifier&#125;&quot;);</span><br><span class="line">        sb.AppendLine($&quot;   Product Name: &#123;prod.ProductName&#125;&quot;);</span><br><span class="line">        sb.AppendLine($&quot;   Product Size: &#123;prod.ProductSize&#125;&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="ordering-data"><a class="markdownIt-Anchor" href="#ordering-data"></a> Ordering Data</h3><p>When using Method Syntax to order data, the .Select() method is optional when you are simply selecting the complete object as the return value</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">public void OrderBy()</span><br><span class="line">&#123;</span><br><span class="line">    if (UseQuerySyntax)</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; Query Syntax</span><br><span class="line">        Products &#x3D; (from prod in Products orderby prod.Name select prod).ToList();</span><br><span class="line">    &#125;</span><br><span class="line">    else</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; Method Syntax</span><br><span class="line">        Products &#x3D; Products.OrderBy(prod &#x3D;&gt; prod.Name).ToList();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ResultText &#x3D; $&quot;Total Products: &#123;Products.Count&#125;&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>Order by Descending</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">public void OrderByDescending()</span><br><span class="line">&#123;</span><br><span class="line">    if (UseQuerySyntax)</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; Query Syntax</span><br><span class="line">        Products &#x3D; (from prod in Products orderby prod.Name descending select prod).ToList();</span><br><span class="line">    &#125;</span><br><span class="line">    else</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; Method Syntax</span><br><span class="line">        Products &#x3D; Products.OrderByDescending(prod &#x3D;&gt; prod.Name).ToList();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ResultText &#x3D; $&quot;Total Products: &#123;Products.Count&#125;&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="order-by-two-fields"><a class="markdownIt-Anchor" href="#order-by-two-fields"></a> Order by Two Fields</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">public void OrderByTwoFields()</span><br><span class="line">&#123;</span><br><span class="line">    if (UseQuerySyntax)</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; Query Syntax</span><br><span class="line">        Products &#x3D; (from prod in Products orderby prod.Color descending, prod.Name).ToList();</span><br><span class="line">    &#125;</span><br><span class="line">    else</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; Method Syntax</span><br><span class="line">        Products &#x3D; Products.OrderByDescending(prod &#x3D;&gt; prod.Color).ThenBy(prod &#x3D;&gt; prod.Name).ToList();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ResultText &#x3D; $&quot;Total Products: &#123;Products.Count&#125;&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="extract-multiple-or-single-elements"><a class="markdownIt-Anchor" href="#extract-multiple-or-single-elements"></a> Extract Multiple or Single Elements</h2><h3 id="where-expression"><a class="markdownIt-Anchor" href="#where-expression"></a> Where Expression</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">public void WhereExpression()</span><br><span class="line">&#123;</span><br><span class="line">    string search &#x3D; &quot;L&quot;;</span><br><span class="line"></span><br><span class="line">    if (UseQuerySyntax)</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; Query Syntax</span><br><span class="line">        Products &#x3D; (from prod in Products where prod.Name.StartsWith(search) select prod).ToList();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    else</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; Method Syntax</span><br><span class="line">        Products &#x3D; Products.Where(prod &#x3D;&gt; prod.Name.StartsWith(search)).ToList();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ResultText &#x3D; $&quot;Total Products: &#123;Products.Count&#125;&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>Where with multiple fields</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">public void WhereTwoFields()</span><br><span class="line">&#123;</span><br><span class="line">    string search &#x3D; &quot;L&quot;;</span><br><span class="line">    decimal cost &#x3D; 100;</span><br><span class="line"></span><br><span class="line">    if (UseQuerySyntax)</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; Query Syntax</span><br><span class="line">        Products &#x3D; (from prod in Products where prod.Name.StartsWith(search) &amp;&amp; prod.StandardCost &gt; cost).ToList();</span><br><span class="line">    &#125;</span><br><span class="line">    else</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; Method Syntax</span><br><span class="line">        Products &#x3D; Products.Where(prod &#x3D;&gt; prod.Name.StartsWith(search) &amp;&amp; prod.StandardCost &gt; cost).ToList();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ResultText &#x3D; $&quot;Total Products: &#123;Products.Count&#125;&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>Using Custom Extension Method</li></ul><h3 id="extension-method"><a class="markdownIt-Anchor" href="#extension-method"></a> Extension Method</h3><p>Extension methods enable you to “add” methods to existing types without creating a new derived type, recompiling, or otherwise modifying the original type. Extension methods are static methods, but they’re called as if they were instance methods on the extended type.</p><p>The most common extension methods are the LINQ standard query operators that add query functionality to the existing <code>System.Collections.IEnumerable</code> and <code>System.Collections.Generic.IEnumerable&lt;T&gt;</code> types.</p><p>Extension methods are defined as <code>static</code> methods but are called by using instance method syntax. Their first parameter specifies which type the method operates on. The parameter is preceded by the <code>this</code> modifier.</p><p>Extension method is just a static method under the hood.</p><p>In the example, the result of <code>(from prod in Products select prod)</code> is an <code>IEnumerable&lt;Product&gt;</code> which is why <code>ByColor()</code> can be applied to this</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">public static IEnumerable&lt;Product&gt; ByColor(</span><br><span class="line">    this IEnumerable&lt;Product&gt; query, string color)</span><br><span class="line">&#123;</span><br><span class="line">    return query.Where(prod &#x3D;&gt; prod.Color &#x3D;&#x3D; color);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if (UseQuerySyntax)</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Query Syntax</span><br><span class="line">    Products &#x3D; (from prod in Products select prod).ByColor(search).ToList();</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Method Syntax</span><br><span class="line">    Products &#x3D; Products.ByColor(search).ToList();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="select-a-single-item"><a class="markdownIt-Anchor" href="#select-a-single-item"></a> Select a Single Item</h3><ul><li>First, will throw an Exception if item not found.</li><li>Last, same as First</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">try</span><br><span class="line">&#123;</span><br><span class="line">    if (UseQuerySyntax)</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; Query Syntax</span><br><span class="line">        value &#x3D; (from prod in Products select prod).First(prod &#x3D;&gt; prod.Color &#x3D;&#x3D; search);</span><br><span class="line">    &#125;</span><br><span class="line">    else</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; Method Syntax</span><br><span class="line">        value &#x3D; Products.First(prod &#x3D;&gt; prod.Color &#x3D;&#x3D; search);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ResultText &#x3D; $&quot;Found: &#123;value&#125;&quot;;</span><br><span class="line">&#125;</span><br><span class="line">catch</span><br><span class="line">&#123;</span><br><span class="line">    ResultText &#x3D; &quot;Not Found&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>FirstOrDefault, value will be null if item not found, will not throw an Exception</li><li>LastOrDefault, same as FirstOrDefault</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">if (UseQuerySyntax)</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Query Syntax</span><br><span class="line">    value &#x3D; (from prod in Products select prod).First(prod &#x3D;&gt; prod.Color &#x3D;&#x3D; search);</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Method Syntax</span><br><span class="line">    value &#x3D; Products.First(prod &#x3D;&gt; prod.Color &#x3D;&#x3D; search);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if (value &#x3D;&#x3D; null)</span><br><span class="line">&#123;</span><br><span class="line">    ResultText &#x3D; &quot;Not Found&quot;;</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">&#123;</span><br><span class="line">    ResultText &#x3D; $&quot;Found: &#123;value&#125;&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>Single, will throw an Exception if item not found or multiple items found.</li></ul><p>Single is supposed to be used to found a unique item, like primary key. The Exception thrown if multiple items are found is InvalidOperationException.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">try</span><br><span class="line">&#123;</span><br><span class="line">    if (UseQuerySyntax)</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; Query Syntax</span><br><span class="line">        value &#x3D; (from prod in Products select prod).Single(prod &#x3D;&gt; prod.ProductID &#x3D;&#x3D; search);</span><br><span class="line">    &#125;</span><br><span class="line">    else</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; Method Syntax</span><br><span class="line">        value &#x3D; Products.Single(prod &#x3D;&gt; prod.ProductID &#x3D;&#x3D; search);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ResultText &#x3D; $&quot;Found: &#123;value&#125;&quot;;</span><br><span class="line">&#125;</span><br><span class="line">catch</span><br><span class="line">&#123;</span><br><span class="line">    ResultText &#x3D; &quot;Not Found, or multiple elements found&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>SingleOrDefault, value will be NULL if no item found, but will still throw an Exception if multiple items found.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">try</span><br><span class="line">&#123;</span><br><span class="line">    if (UseQuerySyntax)</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; Query Syntax</span><br><span class="line">        value &#x3D; (from prod in Products select prod).SingleOrDefault(prod &#x3D;&gt; prod.ProductID &#x3D;&#x3D; search);</span><br><span class="line">    &#125;</span><br><span class="line">    else</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; Method Syntax</span><br><span class="line">        value &#x3D; Products.SingleOrDefault(prod &#x3D;&gt; prod.ProductID &#x3D;&#x3D; search);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if (value &#x3D;&#x3D; null)</span><br><span class="line">    &#123;</span><br><span class="line">        ResultText &#x3D; &quot;Not Found&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">    else</span><br><span class="line">    &#123;</span><br><span class="line">        ResultText &#x3D; $&quot;Found: &#123;value&#125;&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">catch</span><br><span class="line">&#123;</span><br><span class="line">    ResultText &#x3D; &quot;Multiple elements found&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="extract-distinct-values-assign-values-and-partition-collections"><a class="markdownIt-Anchor" href="#extract-distinct-values-assign-values-and-partition-collections"></a> Extract Distinct Values, Assign Values and Partition Collections</h2><h3 id="set-operations"><a class="markdownIt-Anchor" href="#set-operations"></a> Set Operations</h3><ul><li>Iterate over entire collection</li><li>Set a property value in collection (similar to a SQL UPDATE)</li></ul><p>In this example, the object has a NameLength property and we need to assign the value <code>prop.Name.Length</code> to this <code>prop.NameLength</code> property.</p><p>For the Query approach, we need to declare a tmp variable because it has to be a statement, not an assignment. But the Method approach doesn’t have this issue.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">public void ForEach()</span><br><span class="line">&#123;</span><br><span class="line">    if (UseQuerySyntax)</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; Query Syntax</span><br><span class="line">        Products &#x3D; (from prod in Products</span><br><span class="line">                    let tmp &#x3D; prod.NameLength &#x3D; prod.Name.Length</span><br><span class="line">                    select prod).ToList();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    else</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; Method Syntax</span><br><span class="line">        Products.ForEach(prod &#x3D;&gt; prod.NameLength &#x3D; prod.Name.Length);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ResultText &#x3D; $&quot;Total Products: &#123;Products.Count&#125;&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>In this example we have a Sales object, and we need to calculate how many item we have sold for a certain product.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">private decimal SalesForProduct(Product prod)</span><br><span class="line">&#123;</span><br><span class="line">    return Sales.Where(sale &#x3D;&gt; sale.ProductID &#x3D;&#x3D; prod.ProductID)</span><br><span class="line">                .Sum(sale &#x3D;&gt; sale.LineTotal);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>We could then use this to set the TotalSales property for each Product</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">if (UseQuerySyntax)</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Query Syntax</span><br><span class="line">    Products &#x3D; (from prod in Products</span><br><span class="line">                let tmp &#x3D; prod.TotalSales &#x3D; SalesForProduct(prod)</span><br><span class="line">                select prod).ToList();</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Method Syntax</span><br><span class="line">    Products.ForEach(prod &#x3D;&gt; prod.TotalSales &#x3D; SalesForProduct(prod));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="take-specific-amount-of-elements"><a class="markdownIt-Anchor" href="#take-specific-amount-of-elements"></a> Take Specific Amount of Elements</h3><p>Take the first 5 elements from the list</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">if (UseQuerySyntax)</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Query Syntax</span><br><span class="line">    Products &#x3D; (from prod in Products</span><br><span class="line">                orderby prod.Name</span><br><span class="line">                select prod).Take(5).ToList();</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Method Syntax</span><br><span class="line">    Products &#x3D; Products.OrderBy(prod &#x3D;&gt; prod.Name).Take(5).ToList();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>TakeWhile(): take elements while condition is true</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">if (UseQuerySyntax)</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Query Syntax</span><br><span class="line">    Products &#x3D; (from prod in Products</span><br><span class="line">                orderby prod.Name</span><br><span class="line">                select prod).TakeWhile(prod &#x3D;&gt; prod.Name.StartsWith(&quot;A&quot;)).ToList();</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Method Syntax</span><br><span class="line">    Products &#x3D; Products.OrderBy(prod &#x3D;&gt; prod.Name).TakeWhile(prod &#x3D;&gt; prod.Name.StartsWith(&quot;A&quot;)).ToList();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="skip-specific-amount-of-elements"><a class="markdownIt-Anchor" href="#skip-specific-amount-of-elements"></a> Skip specific amount of elements</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">if (UseQuerySyntax)</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Query Syntax</span><br><span class="line">    Products &#x3D; (from prod in Products</span><br><span class="line">                orderby prod.Name</span><br><span class="line">                select prod).Skip(20).ToList();</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Method Syntax</span><br><span class="line">    Products &#x3D; Products.OrderBy(prod &#x3D;&gt; prod.Name).Skip(20).ToList();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>Skip elements while condition is true</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">if (UseQuerySyntax)</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Query Syntax</span><br><span class="line">    Products &#x3D; (from prod in Products</span><br><span class="line">                orderby prod.Name</span><br><span class="line">                select prod).SkipWhile(prod &#x3D;&gt; prod.Name.StartsWith(&quot;A&quot;)).ToList();</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Method Syntax</span><br><span class="line">    Products &#x3D; Products.OrderBy(prod &#x3D;&gt; prod.Name).SkipWhile(prod &#x3D;&gt; prod.Name.StartsWith(&quot;A&quot;)).ToList();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="select-distinct-values"><a class="markdownIt-Anchor" href="#select-distinct-values"></a> Select Distinct Values</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">if (UseQuerySyntax)</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Query Syntax</span><br><span class="line">    colors &#x3D; (from prod in Products select prod.Color).Distinct().ToList();</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Method Syntax</span><br><span class="line">    colors &#x3D; Products.Select(prod &#x3D;&gt; prod.Color).Distinct().ToList();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="identify-what-kind-of-data-is-contained-in-collections"><a class="markdownIt-Anchor" href="#identify-what-kind-of-data-is-contained-in-collections"></a> Identify What Kind of Data is Contained in Collections</h2><h3 id="all-will-return-a-true-or-false-value-to-see-if-all-items-meet-the-requirement"><a class="markdownIt-Anchor" href="#all-will-return-a-true-or-false-value-to-see-if-all-items-meet-the-requirement"></a> All() will return a true or false value to see if all items meet the requirement.</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">if (UseQuerySyntax)</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Query Syntax</span><br><span class="line">    value &#x3D; (from prod in Products select prod).All(prod &#x3D;&gt; prod.Name.Contains(search));</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Method Syntax</span><br><span class="line">    value &#x3D; Products.All(prod &#x3D;&gt; prod.Name.Contains(search));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="any-will-return-true-if-any-of-the-item-meet-the-requirement-and-will-return-false-will-all-items-doesnt-meet-the-requirement"><a class="markdownIt-Anchor" href="#any-will-return-true-if-any-of-the-item-meet-the-requirement-and-will-return-false-will-all-items-doesnt-meet-the-requirement"></a> Any() will return true if any of the item meet the requirement. And will return false will all items doesn’t meet the requirement.</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">if (UseQuerySyntax)</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Query Syntax</span><br><span class="line">    value &#x3D; (from prod in Products select prod).Any(prod &#x3D;&gt; prod.Name.Contains(search));</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Method Syntax</span><br><span class="line">    value &#x3D; Products.Any(prod &#x3D;&gt; prod.Name.Contains(search));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="contains-can-be-used-in-primitive-types-and-objects"><a class="markdownIt-Anchor" href="#contains-can-be-used-in-primitive-types-and-objects"></a> Contains can be used in primitive types and objects</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">bool value &#x3D; true;</span><br><span class="line">List&lt;int&gt; numbers &#x3D; new List&lt;int&gt; &#123; 1, 2, 3, 4, 5 &#125;;</span><br><span class="line"></span><br><span class="line">if (UseQuerySyntax)</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Query Syntax</span><br><span class="line">    value &#x3D; (from num in numbers select num).Contains(3);</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Method Syntax</span><br><span class="line">    value &#x3D; numbers.Contains(3);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>When using Contains() on a collection of objects. We need to use EqualityComparer, because by default objects are compared by reference not value.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">public class ProductIdComparer : EqualityComparer&lt;Product&gt; &#123;</span><br><span class="line">    public override bool Equals(Product x, Product y) &#123;</span><br><span class="line">        return (x.ProductID &#x3D;&#x3D; y.ProductID);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public override int GetHashCode(Product obj) &#123;</span><br><span class="line">    return obj.ProductID.GetHashCode();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Now when calling Contains() method, we pass in the Comparer object, so it will loop through all products and compare each one with our prodToFind Product. The Comparer will use prodToFind as the first parameter and each Product as the second parameter.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">int search &#x3D; 744;</span><br><span class="line">bool value &#x3D; true;</span><br><span class="line">ProductIdComparer pc &#x3D; new ProductIdComparer();</span><br><span class="line">Product prodToFind &#x3D; new Product &#123; ProductID &#x3D; search &#125;;</span><br><span class="line"></span><br><span class="line">if (UseQuerySyntax)</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Query Syntax</span><br><span class="line">    value &#x3D; (from prod in Products select prod).Contains(prodToFind, pc);</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Method Syntax</span><br><span class="line">    value &#x3D; Products.Contains(prodToFind, pc);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="compare-and-union-two-collections"><a class="markdownIt-Anchor" href="#compare-and-union-two-collections"></a> Compare and Union Two Collections</h2><h3 id="sequenceequal"><a class="markdownIt-Anchor" href="#sequenceequal"></a> SequenceEqual()</h3><p>Compares two collections for equlity.</p><ul><li>For Simple data types (int, decimal, boolean…) it checks values</li><li>For object data types checks reference</li><li>If you want to compare values in objects, you need to create a comparer class to check the values inside each properties.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Use SequenceEqual on primitives</span><br><span class="line">bool value &#x3D; true;</span><br><span class="line">&#x2F;&#x2F; Create a list of numbers</span><br><span class="line">List&lt;int&gt; list1 &#x3D; new List&lt;int&gt; &#123; 1, 2, 3, 4, 5 &#125;;</span><br><span class="line">&#x2F;&#x2F; Create a list of numbers</span><br><span class="line">List&lt;int&gt; list2 &#x3D; new List&lt;int&gt; &#123; 1, 2, 3, 4, 5 &#125;;</span><br><span class="line"></span><br><span class="line">if (UseQuerySyntax)</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Query Syntax</span><br><span class="line">    value &#x3D; (from num in list1 select num).SequenceEqual(list2);</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Method Syntax</span><br><span class="line">    value &#x3D; list1.SequenceEqual(list2);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>If we want to compare each object in a collection by value, we need to create a new Comparer override the Compare method.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">bool value &#x3D; true;</span><br><span class="line">ProductComparer pc &#x3D; new ProductComparer();</span><br><span class="line">&#x2F;&#x2F; Load all Product Data</span><br><span class="line">List&lt;Product&gt; list1 &#x3D; ProductRepository.GetAll();</span><br><span class="line">&#x2F;&#x2F; Load all Product Data</span><br><span class="line">List&lt;Product&gt; list2 &#x3D; ProductRepository.GetAll();</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Remove an element from &#39;list1&#39; to make the collections different</span><br><span class="line">list1.RemoveAt(0);</span><br><span class="line"></span><br><span class="line">if (UseQuerySyntax)</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Query Syntax</span><br><span class="line">    value &#x3D; (from num in list1 select num).SequenceEqual(list2, pc);</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Method Syntax</span><br><span class="line">    value &#x3D; list1.SequenceEqual(list2, pc);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="except"><a class="markdownIt-Anchor" href="#except"></a> Except</h3><ul><li>It finds all values in one list, but not the other, returns a collection of items.</li><li>Similar to Contains and SequenceEqual, if we are comparing primitive types, we can just use it, but if we are comparing objects values, we need to create a Comparer class and override the Compare method.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">List&lt;int&gt; exceptions &#x3D; new List&lt;int&gt;();</span><br><span class="line">&#x2F;&#x2F; Create a list of numbers</span><br><span class="line">List&lt;int&gt; list1 &#x3D; new List&lt;int&gt; &#123; 1, 2, 3, 4 &#125;;</span><br><span class="line">&#x2F;&#x2F; Create a list of numbers</span><br><span class="line">List&lt;int&gt; list2 &#x3D; new List&lt;int&gt; &#123; 3, 4, 5 &#125;;</span><br><span class="line"></span><br><span class="line">if (UseQuerySyntax)</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Query Syntax</span><br><span class="line">    exceptions &#x3D; (from num in list1 select num).Except(list2).ToList();</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Method Syntax</span><br><span class="line">    exceptions &#x3D; list1.Except(list2).ToList();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Using Except on a collection of objects</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">ProductComparer pc &#x3D; new ProductComparer();</span><br><span class="line">&#x2F;&#x2F; Load all Product Data</span><br><span class="line">List&lt;Product&gt; list1 &#x3D; ProductRepository.GetAll();</span><br><span class="line">&#x2F;&#x2F; Load all Product Data</span><br><span class="line">List&lt;Product&gt; list2 &#x3D; ProductRepository.GetAll();</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Remove all products with color &#x3D; &quot;Black&quot; from &#39;list2&#39;</span><br><span class="line">&#x2F;&#x2F; to give us a difference in the two lists</span><br><span class="line">list2.RemoveAll(prod &#x3D;&gt; prod.Color &#x3D;&#x3D; &quot;Black&quot;);</span><br><span class="line"></span><br><span class="line">if (UseQuerySyntax)</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Query Syntax</span><br><span class="line">    Products &#x3D; (from prod in list1 select prod).Except(list2, pc).ToList();</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Method Syntax</span><br><span class="line">    Products &#x3D; list1.Except(list2, pc).ToList();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="intersect"><a class="markdownIt-Anchor" href="#intersect"></a> Intersect</h3><ul><li>It finds all values in common between both lists</li><li>Similar to Contains, SequenceEqual and Except, it compares values for primitive types and references for objects. We need to create comparer class to check values in properties.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">ProductComparer pc &#x3D; new ProductComparer();</span><br><span class="line">&#x2F;&#x2F; Load all Product Data</span><br><span class="line">List&lt;Product&gt; list1 &#x3D; ProductRepository.GetAll();</span><br><span class="line">&#x2F;&#x2F; Load all Product Data</span><br><span class="line">List&lt;Product&gt; list2 &#x3D; ProductRepository.GetAll();</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Remove &#39;black&#39; products from &#39;list1&#39;</span><br><span class="line">list1.RemoveAll(prod &#x3D;&gt; prod.Color &#x3D;&#x3D; &quot;Black&quot;);</span><br><span class="line">&#x2F;&#x2F; Remove &#39;red&#39; products from &#39;list2&#39;</span><br><span class="line">list2.RemoveAll(prod &#x3D;&gt; prod.Color &#x3D;&#x3D; &quot;Red&quot;);</span><br><span class="line"></span><br><span class="line">if (UseQuerySyntax)</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Query Syntax</span><br><span class="line">    Products &#x3D; (from num in list1 select num).Intersect(list2, pc).ToList();</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Method Syntax</span><br><span class="line">    Products &#x3D; list1.Intersect(list2, pc).ToList();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="unions"><a class="markdownIt-Anchor" href="#unions"></a> Unions</h3><ul><li>It adds the contents of two lists together.</li><li>Union() checks for duplicates</li><li>Concat() does not check for duplicates</li><li>Use comparer class with objects</li></ul><p>Union() need Comparer to eliminate duplicates</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">ProductComparer pc &#x3D; new ProductComparer();</span><br><span class="line">&#x2F;&#x2F; Load all Product Data</span><br><span class="line">List&lt;Product&gt; list1 &#x3D; ProductRepository.GetAll();</span><br><span class="line">&#x2F;&#x2F; Load all Product Data</span><br><span class="line">List&lt;Product&gt; list2 &#x3D; ProductRepository.GetAll();</span><br><span class="line"></span><br><span class="line">if (UseQuerySyntax)</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Query Syntax</span><br><span class="line">    Products &#x3D; (from num in list1 select num).Union(list2, pc).OrderBy(prod &#x3D;&gt; prod.Name).ToList();</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Method Syntax</span><br><span class="line">    Products &#x3D; list1.Union(list2, pc).OrderBy(prod &#x3D;&gt; prod.Name).ToList();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="concat"><a class="markdownIt-Anchor" href="#concat"></a> Concat()</h3><ul><li>Adds the contents of two collections with duplicates</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Load all Product Data</span><br><span class="line">List&lt;Product&gt; list1 &#x3D; ProductRepository.GetAll();</span><br><span class="line">&#x2F;&#x2F; Load all Product Data</span><br><span class="line">List&lt;Product&gt; list2 &#x3D; ProductRepository.GetAll();</span><br><span class="line"></span><br><span class="line">if (UseQuerySyntax)</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Query Syntax</span><br><span class="line">    Products &#x3D; (from num in list1 select num).Concat(list2).OrderBy(prod &#x3D;&gt; prod.Name).ToList();</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Method Syntax</span><br><span class="line">    Products &#x3D; list1.Concat(list2).OrderBy(prod &#x3D;&gt; prod.Name).ToList();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="joining-two-collections-together"><a class="markdownIt-Anchor" href="#joining-two-collections-together"></a> Joining Two Collections Together</h2><h3 id="inner-join"><a class="markdownIt-Anchor" href="#inner-join"></a> Inner Join</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">var query &#x3D; Products.Join(Sales, prod &#x3D;&gt; prod.ProductID, sale &#x3D;&gt; sale.ProductID, (prod, sale) &#x3D;&gt; new</span><br><span class="line">&#123;</span><br><span class="line">    prod.ProductID,</span><br><span class="line">    prod.Name,</span><br><span class="line">    prod.Color,</span><br><span class="line">    prod.StandardCost,</span><br><span class="line">    prod.ListPrice,</span><br><span class="line">    prod.Size,</span><br><span class="line">    sale.SalesOrderID,</span><br><span class="line">    sale.OrderQty,</span><br><span class="line">    sale.UnitPrice,</span><br><span class="line">    sale.LineTotal,</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h3 id="inner-join-with-two-fields"><a class="markdownIt-Anchor" href="#inner-join-with-two-fields"></a> Inner Join with two fields</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">short qty &#x3D; 6;</span><br><span class="line"></span><br><span class="line">var query &#x3D; Products.Join(</span><br><span class="line">    Sales,</span><br><span class="line">    prod &#x3D;&gt; new &#123; prod.ProductID, Qty &#x3D; qty &#125;,</span><br><span class="line">    sale &#x3D;&gt; new &#123; sale.ProductID, Qty &#x3D; sale.OrderQty &#125;,</span><br><span class="line">    (prod, sale) &#x3D;&gt; new</span><br><span class="line">    &#123;</span><br><span class="line">        prod.ProductID,</span><br><span class="line">        prod.Name,</span><br><span class="line">        prod.Color,</span><br><span class="line">        prod.StandardCost,</span><br><span class="line">        prod.ListPrice,</span><br><span class="line">        prod.Size,</span><br><span class="line">        sale.SalesOrderID,</span><br><span class="line">        sale.OrderQty,</span><br><span class="line">        sale.UnitPrice,</span><br><span class="line">        sale.LineTotal</span><br><span class="line">    &#125;);</span><br></pre></td></tr></table></figure><h2 id="aggregating-data-in-collections"><a class="markdownIt-Anchor" href="#aggregating-data-in-collections"></a> Aggregating Data in Collections</h2><h3 id="count"><a class="markdownIt-Anchor" href="#count"></a> Count()</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">value &#x3D; Products.Count(prod &#x3D;&gt; prod.Color &#x3D;&#x3D; &quot;Yellow&quot;);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Another way using Where</span><br><span class="line">value &#x3D; Products.Where(prod &#x3D;&gt; prod.Color &#x3D;&#x3D; &quot;Yellow&quot;).Count();</span><br></pre></td></tr></table></figure><h3 id="min-and-max"><a class="markdownIt-Anchor" href="#min-and-max"></a> Min() and Max()</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">value &#x3D; Products.Min(prod &#x3D;&gt; prod.ListPrice);</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">value &#x3D; Products.Max(prod &#x3D;&gt; prod.ListPrice);</span><br></pre></td></tr></table></figure><h3 id="average-and-sum"><a class="markdownIt-Anchor" href="#average-and-sum"></a> Average() and Sum()</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">value &#x3D; Products.Average(prod &#x3D;&gt; prod.ListPrice);</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">value &#x3D; Products.Sum(prod &#x3D;&gt; prod.ListPrice);</span><br></pre></td></tr></table></figure><h3 id="custom-calculation-using-aggregate"><a class="markdownIt-Anchor" href="#custom-calculation-using-aggregate"></a> Custom Calculation using Aggregate()</h3><p>The first parameter initialize an internal variable, which setup the start value.</p><p>The second parameter is an anonymous function which you pass the initial value and loop through each item in the collection</p><ul><li>Aggregate Sum</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">value &#x3D; Products.Aggregate(0m, (sum, prod) &#x3D;&gt; sum +&#x3D; prod.ListPrice);</span><br></pre></td></tr></table></figure><ul><li>Aggregate Multiply</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">value &#x3D; Products.Aggregate(0m, (sum, prod &#x3D;&gt; sum +&#x3D; prod.ListPrice * prod.Qty));</span><br></pre></td></tr></table></figure><ul><li>Aggregate with GroupBy and Having</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">var stats &#x3D; Products.GroupBy(sale &#x3D;&gt; sale.Size)</span><br><span class="line">    .Where(sizeGroup &#x3D;&gt; sizeGroup.Count() &gt; 0)</span><br><span class="line">    .Select(sizeGroup &#x3D;&gt; new &#123;</span><br><span class="line">        Size &#x3D; sizeGroup.Key,</span><br><span class="line">        TotalProducts &#x3D; sizeGroup.Count(),</span><br><span class="line">        Max &#x3D; sizeGroup.Max(s &#x3D;&gt; s.ListPrice),</span><br><span class="line">        Min &#x3D; sizeGroup.Min(s &#x3D;&gt; s.ListPrice),</span><br><span class="line">        Average &#x3D; sizeGroup.Average(s &#x3D;&gt; s.ListPrice)</span><br><span class="line">    &#125;)</span><br><span class="line">    .OrderBy(result &#x3D;&gt; result.Size)</span><br><span class="line">    .Select(result &#x3D;&gt; result);</span><br></pre></td></tr></table></figure><h2 id="deferred-execution"><a class="markdownIt-Anchor" href="#deferred-execution"></a> Deferred Execution</h2><ul><li>A LINQ query is a data structure ready to execute</li><li>Query is not executed until a value is needed</li><li>The execution happens with one of the folloing functions (<code>foreach()</code>, <code>Count()</code>, <code>ToList()</code>, <code>OrderBy()</code>…)</li></ul><h2 id="streaming-operators"><a class="markdownIt-Anchor" href="#streaming-operators"></a> Streaming Operators</h2><ul><li>Results can be returned prior to the entire collection is read</li><li>Examples: Distinct(), GroupBy(), Join(), Select(), Skip(), Take(), Union(), Where()</li></ul><h2 id="non-streaming-operators"><a class="markdownIt-Anchor" href="#non-streaming-operators"></a> Non-Streaming Operators</h2><ul><li>All data in collection must be read before a result can be returned</li><li>Examples: Except(), GroupBy(), GroupJoin(), Intersect(), Join(), OrderBy(), ThenBy()</li></ul><h2 id="the-yield-keyword"><a class="markdownIt-Anchor" href="#the-yield-keyword"></a> The yield keyword</h2><p>When write our own Filter function, we could use <code>yield</code> to make the function to be Streaming. So it returns data while looping through the collection.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public static IEnumrable&lt;T&gt; Filter&lt;T&gt; (this IEnumrable&lt;T&gt; source, Func&lt;T, bool&gt; predicate) &#123;</span><br><span class="line">    foreach(var item in source) &#123;</span><br><span class="line">        if (predicate(item)) &#123;</span><br><span class="line">            yield return item;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>In the below example, Where and Take are both Streaming Operators, so this query will loop through the collection until the requirement is met. That is when it found the first item that has Color red. It doesn’t need to go through the entire collection.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Products &#x3D; Products.Where(prod &#x3D;&gt; prod.Color &#x3D;&#x3D; &quot;red&quot;).Take(1).ToList();</span><br></pre></td></tr></table></figure><p>However, in this example, because <code>OrderBy()</code> is an non-streaming operator, so it will loop through the entire list first, order them by <a href="http://prod.Name">prod.Name</a>, then apply the Where condition. Non-streaming operator will go before the Streaming operator.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Products &#x3D; Products.Where(prod &#x3D;&gt; prod.Color &#x3D;&#x3D; &quot;red&quot;).OrderBy(prod &#x3D;&gt; prod.Name).ToList();</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> LINQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Entity Framework Core 5</title>
      <link href="2021/04/20/Entity-Framework-Core-5/"/>
      <url>2021/04/20/Entity-Framework-Core-5/</url>
      
        <content type="html"><![CDATA[<p>Microsoft’s cross-platform data access framework for .NET</p><h2 id="orm-object-relational-mapper"><a class="markdownIt-Anchor" href="#orm-object-relational-mapper"></a> ORM (Object Relational Mapper)</h2><p>EF Core is an ORM, it is designed to reduce the friction between how data is structure in a relational database and how you define your classes. Without ORM, we need to write lots of code to transform database results to instances of the types in our software.</p>]]></content>
      
      
      
        <tags>
            
            <tag> Entity Framework </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Building GraphQL APIs with ASP.NET Core</title>
      <link href="2021/04/20/Building-GraphQL-APIs-with-ASP-NET-Core/"/>
      <url>2021/04/20/Building-GraphQL-APIs-with-ASP-NET-Core/</url>
      
        <content type="html"><![CDATA[<p>The consumer of a GraphQL API defines the data structure it want to receive in a query</p><p>First, let us see how a REST API works.</p><p>On the far right, there is data, for example in the form of a database, and there are entity classes. Each instance of an entity class represents one row of data in the table. An object-relational mapper like Entity Framework may take care of instantiating and populating these objects, but you don’t want to expose these entities directly. So they are converted to models or data transfer objects, objects that have a data structure that is easy to consume for clients, and maybe have some validation built in using attributes. Once you have the model, it’s the controller’s job to make it available to the outside world. There’s typically a controller for each type of model. For example, it could be a product controller, an order controller, etc. What controller is activated when a request comes in is determined by routing, which maps the URL to a certain controller, and all of these controllers react to HTTP methods. Each HTTP method triggers a different operation in the controller. A GET gets data, a POST introduces new data, etc. So there are typically quite a few controllers that have quite a few operations.</p><p><img src="/../images/Building-GraphQL-APIs-with-ASP-NET-Core/1.png" alt="" /></p><p>With GraphQL, there are typically no models, there is something called Schema. This Schema declares what a consumer of the API can access. The Schema also knows how to get the data. The API support GET or POST request, and there is always a query in the request.</p><p><img src="/../images/Building-GraphQL-APIs-with-ASP-NET-Core/2.png" alt="" /></p><h2 id="queries"><a class="markdownIt-Anchor" href="#queries"></a> Queries</h2><ul><li>Determines what happens in the API</li><li>Not tied to HTTP. HTTP is just a transport used to get the quert to the API</li><li>Downside: HTTP Caching: when using HTTP, because now each request is not at a unique URL anymore, it is now difficult to do HTTP caching.</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> GraphQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Design Patterns - Repository</title>
      <link href="2021/04/19/Design-Patterns-Repository/"/>
      <url>2021/04/19/Design-Patterns-Repository/</url>
      
        <content type="html"><![CDATA[<p>A repository encapsulates the data access so the consumer on longer has to know about the underlying data structure</p><p><img src="/../Design-Patterns-Repository/1.png" alt="" /></p><h3 id="why-this-design-is-problematic"><a class="markdownIt-Anchor" href="#why-this-design-is-problematic"></a> Why this Design is Problematic</h3><ul><li>The controller is tightly coupled with the data access layer</li><li>it is difficult to write a test for the controller without side effects</li><li>Hard to extend entities with domain specific behavior</li></ul><p><img src="/../Design-Patterns-Repository/2.png" alt="" /></p><h3 id="benefits-of-the-repository-pattern"><a class="markdownIt-Anchor" href="#benefits-of-the-repository-pattern"></a> Benefits of the Repository Pattern</h3><ul><li>The consumer(controller) is now separated (decoupled) from the data access</li><li>Easy to write a test without side-effects<ul><li>In production, we use the Repository Pattern to communicate with the Data layer. In Test, we replace the Repository with a faked local Data store. This can be done using Strategy Pattern.</li></ul></li><li>Modify and extend entities before they are passed on to the consumer</li><li>A sharable abstraction resulting in less duplication of code</li><li>Improved maintainability</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Design Patterns </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Design Patterns - Proxy</title>
      <link href="2021/04/19/Design-Patterns-Proxy/"/>
      <url>2021/04/19/Design-Patterns-Proxy/</url>
      
        <content type="html"><![CDATA[<h2 id="problem"><a class="markdownIt-Anchor" href="#problem"></a> Problem</h2><p>Need to control access to a type for performance, security or other reasons.</p><p><img src="/../Design-Patterns-Proxy/1.png" alt="" /></p><p>Client should not know if they were calling the real service or a proxy.</p><p>Proxy also gives us time to do necessary things before sending request to real service and before sending response back to client.(like logging, caching, encrypt/decrypt…)</p><p><img src="/../Design-Patterns-Proxy/2.png" alt="" /></p><p>Proxy has similar structure as the Decorator Pattern, but the intent is different, Decorator pattern is for adding extra funcationalities to the original class whereas Proxy is focusing on control the access to the object.</p><p><img src="/../Design-Patterns-Proxy/3.png" alt="" /></p><p>This is another implementation of the Proxy Pattern, it doesn’t have the interface so we need to compose the RealService object in Proxy Class. One thing to notice is that the RealService properties and methods need to be marked as virtual for the Proxy Class to override them.</p><h2 id="proxy-variants"><a class="markdownIt-Anchor" href="#proxy-variants"></a> Proxy Variants</h2><ul><li>Virtual Proxy<ul><li>stand in for expensive to create objects</li></ul></li><li>Remote Proxy<ul><li>Hide the detail to work with remote data or services.</li></ul></li><li>Smart Proxy<ul><li>Performs additional actions when a resource is accessed</li></ul></li><li>Protective Proxy<ul><li>controls access to a sensitive resource by checking for whether or not the client is authorized to perform those operations.</li></ul></li></ul><h2 id="virtual-proxy"><a class="markdownIt-Anchor" href="#virtual-proxy"></a> Virtual Proxy</h2><p>Stands in for an expensive-to-create object. Typically responsible for getting real object. UI placeholders. Lazy-loaded Entity Properties.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">public class ExpensiveToFullyLoad : BaseClassWithHistory</span><br><span class="line">&#123;</span><br><span class="line">    public static ExpensiveToFullyLoad Create()</span><br><span class="line">    &#123;</span><br><span class="line">        return new VirtualExpensiveToFullyLoad();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public virtual IEnumerable&lt;ExpensiveEntity&gt; HomeEntities &#123; get; protected set; &#125;</span><br><span class="line">    public virtual IEnumerable&lt;ExpensiveEntity&gt; AwayEntities &#123; get; protected set; &#125;</span><br><span class="line">    </span><br><span class="line">    protected ExpensiveToFullyLoad()</span><br><span class="line">    &#123;</span><br><span class="line">        History.Add(&quot;Constructor called.&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>When you have some expensive properties. You don’t want to create them when you don’t need them. So we could create a Proxy Class(VirtualExpensiveToFullyLoad), which will only create the property when its getting called.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">public class VirtualExpensiveToFullyLoad : ExpensiveToFullyLoad</span><br><span class="line">&#123;</span><br><span class="line">    public override IEnumerable&lt;ExpensiveEntity&gt; AwayEntities </span><br><span class="line">    &#123;</span><br><span class="line">        get</span><br><span class="line">        &#123;</span><br><span class="line">            if(base.AwayEntities &#x3D;&#x3D; null)</span><br><span class="line">            &#123;</span><br><span class="line">                base.AwayEntities &#x3D; ExpensiveDataSource.GetEntities(this);</span><br><span class="line">            &#125;</span><br><span class="line">            return base.AwayEntities;</span><br><span class="line">        &#125;</span><br><span class="line">        protected set &#x3D;&gt; base.AwayEntities &#x3D; value; </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public override IEnumerable&lt;ExpensiveEntity&gt; HomeEntities </span><br><span class="line">    &#123;</span><br><span class="line">        get</span><br><span class="line">        &#123;</span><br><span class="line">            if (base.HomeEntities &#x3D;&#x3D; null)</span><br><span class="line">            &#123;</span><br><span class="line">                base.HomeEntities &#x3D; ExpensiveDataSource.GetEntities(this);</span><br><span class="line">            &#125;</span><br><span class="line">            return base.HomeEntities;</span><br><span class="line">        &#125;</span><br><span class="line">        protected set &#x3D;&gt; base.HomeEntities &#x3D; value;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>When we test the class, we can see object history will only increase after we get the Entities from the class.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[Fact]</span><br><span class="line">public void LogsCollectionLoadingToHistory()</span><br><span class="line">&#123;</span><br><span class="line">    var obj &#x3D; ExpensiveToFullyLoad.Create();</span><br><span class="line">    var list &#x3D; obj.HomeEntities;</span><br><span class="line"></span><br><span class="line">    Assert.Equal(2, obj.History.Count());</span><br><span class="line"></span><br><span class="line">    var anotherList &#x3D; obj.AwayEntities;</span><br><span class="line">    Assert.Equal(3, obj.History.Count());</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>We could also use the C# <code>Lazy&lt;T&gt;</code> type which will handle the lazy instantiation and thread-safe for use</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">public class LazyExpensiveToFullyLoad : BaseClassWithHistory</span><br><span class="line">&#123;</span><br><span class="line">    private Lazy&lt;IEnumerable&lt;ExpensiveEntity&gt;&gt; _homeEntities;</span><br><span class="line">    public IEnumerable&lt;ExpensiveEntity&gt; HomeEntities &#123; get &#123; return _homeEntities.Value; &#125; &#125;</span><br><span class="line"></span><br><span class="line">    private Lazy&lt;IEnumerable&lt;ExpensiveEntity&gt;&gt; _awayEntities;</span><br><span class="line">    public IEnumerable&lt;ExpensiveEntity&gt; AwayEntities &#123; get &#123; return _awayEntities.Value; &#125; &#125;</span><br><span class="line"></span><br><span class="line">    public LazyExpensiveToFullyLoad()</span><br><span class="line">    &#123;</span><br><span class="line">        History.Add(&quot;Constructor called.&quot;);</span><br><span class="line">        _homeEntities &#x3D; new Lazy&lt;IEnumerable&lt;ExpensiveEntity&gt;&gt;(() &#x3D;&gt; ExpensiveDataSource.GetEntities(this));</span><br><span class="line">        _awayEntities &#x3D; new Lazy&lt;IEnumerable&lt;ExpensiveEntity&gt;&gt;(() &#x3D;&gt; ExpensiveDataSource.GetEntities(this));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="remote-proxy"><a class="markdownIt-Anchor" href="#remote-proxy"></a> Remote Proxy</h2><p>Client works with proxy as if remote resource were local. Hides network details from client. Centralizes knowledge of network details.</p><h2 id="smart-proxy"><a class="markdownIt-Anchor" href="#smart-proxy"></a> Smart Proxy</h2><p>Performs additional logic around resource access. Example: Resource counting, Cache management, Locking shared resources</p><p>Here we are trying to open the same file two times, normally this will throw an exception.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">var fs &#x3D; new FileSmartProxy();</span><br><span class="line"></span><br><span class="line">byte[] outputBytes1 &#x3D; Encoding.ASCII.GetBytes(&quot;1. ardalis.com\n&quot;);</span><br><span class="line">byte[] outputBytes2 &#x3D; Encoding.ASCII.GetBytes(&quot;2. weeklydevtips.com\n&quot;);</span><br><span class="line">using var file &#x3D; fs.OpenWrite(_testFile);</span><br><span class="line">using var file2 &#x3D; fs.OpenWrite(_testFile);</span><br><span class="line"></span><br><span class="line">file.Write(outputBytes1);</span><br><span class="line">file2.Write(outputBytes2);</span><br><span class="line"></span><br><span class="line">file.Close();</span><br><span class="line">file2.Close();</span><br></pre></td></tr></table></figure><p>But we are using FileSmartProxy() Class, when we catch the exception, we will check if the file is already opened, and return the same reference to the file stream.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">public class FileSmartProxy : IFile</span><br><span class="line">&#123;</span><br><span class="line">    Dictionary&lt;string, FileStream&gt; _openStreams &#x3D; new Dictionary&lt;string, FileStream&gt;();</span><br><span class="line"></span><br><span class="line">    public FileStream OpenWrite(string path)</span><br><span class="line">    &#123;</span><br><span class="line">        try</span><br><span class="line">        &#123;</span><br><span class="line">            var stream &#x3D; File.OpenWrite(path);</span><br><span class="line">            _openStreams.Add(path, stream);</span><br><span class="line">            return stream;</span><br><span class="line">        &#125;</span><br><span class="line">        catch (IOException)</span><br><span class="line">        &#123;</span><br><span class="line">            if(_openStreams.ContainsKey(path))</span><br><span class="line">            &#123;</span><br><span class="line">                var stream &#x3D; _openStreams[path];</span><br><span class="line"></span><br><span class="line">                if(stream !&#x3D; null &amp;&amp; stream.CanWrite)</span><br><span class="line">                &#123;</span><br><span class="line">                    return stream;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            throw;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="protective-proxy"><a class="markdownIt-Anchor" href="#protective-proxy"></a> Protective Proxy</h2><p>Manages access to a resource based on authorization rules. Eliminates repetitive security checks from client code and othe resource itself. Acts as a gatekeeper around a resource</p><h2 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h2><p>If we are not using the Proxy Pattern, we often end up mixing the concerns of access control, or lazy loading or other funcationality in the resource class itself. Every client the consume this class must perform this work. The concerns of access control are mixed with the concerns of client or the resource. Proxy Pattern helps us to separate this.</p><p>Usually Proxy Pattern has built in class that support it.(Remote Proxy)</p><h2 id="related-patterns"><a class="markdownIt-Anchor" href="#related-patterns"></a> Related Patterns</h2><ul><li>Decorator: the structure is similar, but the intent of Decorator Pattern is to add funcationality. Whereas the intent of Proxy Pattern is to control access.</li><li>Prototype: Prototype and Virtual Proxy Pattern both deal with objects that are expensive to create. But Virtual Proxy Pattern only provides a placeholder of the object and fetch it when required. The Prototype Pattern keeps a copy of the object on hand and can clone it when required.</li><li>Adapter: similar structure, but the intent of the Adapter Pattern is to convert an incompatible interface into one that works for the client.</li><li>Flyweight: designed to manage many reference to a shared instance.</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Design Patterns </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Design Patterns - Adapter</title>
      <link href="2021/04/19/Design-Patterns-Adapter/"/>
      <url>2021/04/19/Design-Patterns-Adapter/</url>
      
        <content type="html"><![CDATA[<h2 id="problem"><a class="markdownIt-Anchor" href="#problem"></a> Problem</h2><p>Incompatible interfaces between a client and a service provider.</p><p>Adapters convert the interface of one class into an interface a client expects.</p><h2 id="two-kinds-of-adapters"><a class="markdownIt-Anchor" href="#two-kinds-of-adapters"></a> Two Kinds of Adapters</h2><h3 id="object-adapters"><a class="markdownIt-Anchor" href="#object-adapters"></a> Object Adapters</h3><ul><li>Hold an instance of the Adaptee</li><li>Implement or inherit the adapter type</li><li>Use composition and single inheritance</li></ul><p><img src="/../images/Design-Patterns-Adapter/1.png" alt="" /></p><p>C# doesn’t support multiple inheritance, and a design principle of C# is to prefer composition over inheritance. So C# is prefer object adapter.</p><p>The Client is calling method on an adapter abstraction(IAdapter). A specific adapter is created for each specific adaptee.</p><h3 id="class-adapters"><a class="markdownIt-Anchor" href="#class-adapters"></a> Class Adapters</h3><ul><li>Inherit from the adaptee</li><li>Implement the adapter interface</li></ul><p><img src="/../images/Design-Patterns-Adapter/2.png" alt="" /></p><p>The Client is calling a target class’s particular method, but it wants to use a different implementation(incompatibleMethod) now. The adapter class inherits from both classes and overrides the SomeMethod() call, so that instead of doing what it did in the target class, it now calls the IncompatibleMethod() and does any work necessary to make it compatible with the SomeMethod() interface.</p><p><img src="/../images/Design-Patterns-Adapter/3.png" alt="" /></p><p>What C# can do is to implement the interface the Client is calling and rather than holding onto an instance of the concrete adaptee type, we can inherit from it. SomeMethod() calls IncompetibleMethod() and does any necessary work to modify it to work with the SomeMethod() interface.</p><p>Example: We are going to read a list of People and there are two ways of doing it. First, we could read People from a file. Second, we could call a Web API.</p><p>IAdapter interface will only have a method, GetCharacters(), get it returns a list of Peoson</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public interface ICharacterSourceAdapter</span><br><span class="line">&#123;</span><br><span class="line">    Task&lt;IEnumerable&lt;Person&gt;&gt; GetCharacters();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Get list of Person from a web API is easy.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">public async Task&lt;List&lt;Person&gt;&gt; GetCharacters()</span><br><span class="line">&#123;</span><br><span class="line">    using (var client &#x3D; new HttpClient())</span><br><span class="line">    &#123;</span><br><span class="line">        string url &#x3D; &quot;https:&#x2F;&#x2F;swapi.co&#x2F;api&#x2F;people&quot;;</span><br><span class="line">        string result &#x3D; await client.GetStringAsync(url);</span><br><span class="line">        var people &#x3D; JsonConvert.DeserializeObject&lt;ApiResult&lt;Person&gt;&gt;(result).Results;</span><br><span class="line"></span><br><span class="line">        return people;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>But get list of Person from a file need a parameter (filename)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public async Task&lt;List&lt;Person&gt;&gt; GetCharactersFromFile(string filename)</span><br><span class="line">&#123;</span><br><span class="line">    var characters &#x3D; JsonConvert.DeserializeObject&lt;List&lt;Person&gt;&gt;(await File.ReadAllTextAsync(filename));</span><br><span class="line"></span><br><span class="line">    return characters;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>To make it work with the GetCharacters() method, we need to create an Adapter Class</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">public class CharacterFileSourceAdapter : ICharacterSourceAdapter</span><br><span class="line">&#123;</span><br><span class="line">    private string _fileName;</span><br><span class="line">    private readonly CharacterFileSource _characterFileSource;</span><br><span class="line"></span><br><span class="line">    public CharacterFileSourceAdapter(string fileName, CharacterFileSource characterFileSource)</span><br><span class="line">    &#123;</span><br><span class="line">        _fileName &#x3D; fileName;</span><br><span class="line">        _characterFileSource &#x3D; characterFileSource;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public async Task&lt;IEnumerable&lt;Person&gt;&gt; GetCharacters()</span><br><span class="line">    &#123;</span><br><span class="line">        return await _characterFileSource.GetCharactersFromFile(_fileName);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>It implements the IAdapter interface, and inside GetCharacters() method, it calls the GetCharactersFromFile(_filename) method to make it compatible with our interface method.</p><p>When we use it, it doesn’t need to know anything about the filename or which way we choose to get the list of Person.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">var people &#x3D; await _characterSourceAdapter.GetCharacters();</span><br></pre></td></tr></table></figure><h2 id="related-patterns"><a class="markdownIt-Anchor" href="#related-patterns"></a> Related Patterns</h2><ul><li><p>Decorator: has a similar structure, but the intent of a decorator is to add functionality.</p></li><li><p>Bridge: has a similar structure, but it allows interfaces and their implementations to vary independently from one another.</p></li><li><p>Proxy: similar structure, but its intent is to control access to a resource, not to convert an incompatible interface</p></li><li><p>Repository: sometimes it acts an adapter, providing a common interface for persistence that can map various incompatible interfaces to a single common data access strategy</p></li><li><p>Strategy: very frequently used with Adapter pattern as a way of injecting different implementations of behavior into a particular client class.</p></li><li><p>Facade: the intent of facade is similar to the adapters in that it alters an interface to make it easier for a client to use. The difference is Facade often sits in front of multiple different types and its goal is to simplify a complex set of operation</p></li></ul><h2 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h2><ul><li>An Adapter converts an incompatible interface into a compatible one</li><li>In C#, the Adapter pattern uses composition and is known as an object adapter. It means that your adapter implementation will contain instances of the incompatible type and will delegate calls to this instalce’s incompatible methods or properties.</li><li>Adapters can work with service providers but can also wrap result types.</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Design Patterns </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Design Patterns - Decorator</title>
      <link href="2021/04/18/Design-Patterns-Decorator/"/>
      <url>2021/04/18/Design-Patterns-Decorator/</url>
      
        <content type="html"><![CDATA[<h2 id="decorator-pattern"><a class="markdownIt-Anchor" href="#decorator-pattern"></a> Decorator Pattern</h2><p>A structural design pattern used for dynamically adding behavior to a class without making changes to that class.</p><p><img src="/../images/Design-Patterns-Decorator/1.png" alt="" /></p><p>The Decorator Class will take an object implementing the same interface. This allows us to pass the object being decorated into the decorator object and allows the decorator object to act as a wrapper<br />around this original object.</p><p><img src="/../images/Design-Patterns-Decorator/2.png" alt="" /></p><p>The Decorator object will keep a reference of the object being decorated(the component object). Because the decorator object implement the same interface as the original component object, it now has a chance to intercept any method calls on the interface and inject some additional behavior into those calls.</p><p><img src="/../images/Design-Patterns-Decorator/3.png" alt="" /></p><p>Decorator Class and be nested.</p><p><img src="/../images/Design-Patterns-Decorator/4.png" alt="" /></p><p>This is the Example we are going to use.</p><h2 id="using-decorator-objects"><a class="markdownIt-Anchor" href="#using-decorator-objects"></a> Using Decorator Objects</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Standard component instantiation</span><br><span class="line">IWeatherService weatherService &#x3D; new WeatherService();</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Instantiation with decorator objects</span><br><span class="line">IWeatherService weatherService &#x3D; </span><br><span class="line">    new CachingDecorator(</span><br><span class="line">        new LogginDecorator(</span><br><span class="line">            new WeatherService()));</span><br></pre></td></tr></table></figure><p>To achieve this, we need to make sure the original component class and all the decorator classes need to implement from the same interface. And all decortor classes need to take the object of type IWeatherService in their constructors.</p><h2 id="logging-decorator"><a class="markdownIt-Anchor" href="#logging-decorator"></a> Logging Decorator</h2><p>Log how often a method was called, how long it took, parameters and responses.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public interface IWeatherService</span><br><span class="line">&#123;</span><br><span class="line">    CurrentWeather GetCurrentWeather(String location);</span><br><span class="line"></span><br><span class="line">    LocationForecast GetForecast(String location);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>This is the interface for our original WeatherService Class and our new Decorator Class</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">public class WeatherServiceLoggingDecorator : IWeatherService</span><br><span class="line">&#123;</span><br><span class="line">    private IWeatherService _weatherService;</span><br><span class="line">    private ILogger&lt;WeatherServiceLoggingDecorator&gt; _logger;</span><br><span class="line"></span><br><span class="line">    public WeatherServiceLoggingDecorator(IWeatherService weatherService, ILogger&lt;WeatherServiceLoggingDecorator&gt; logger)</span><br><span class="line">    &#123;</span><br><span class="line">        _weatherService &#x3D; weatherService;</span><br><span class="line">        _logger &#x3D; logger;</span><br><span class="line">    &#125;</span><br><span class="line">    public CurrentWeather GetCurrentWeather(string location)</span><br><span class="line">    &#123;</span><br><span class="line">        Stopwatch sw &#x3D; Stopwatch.StartNew();</span><br><span class="line">        CurrentWeather currentWeather &#x3D; _weatherService.GetCurrentWeather(location);</span><br><span class="line">        sw.Stop();</span><br><span class="line">        long elapsedMillis &#x3D; sw.ElapsedMilliseconds;</span><br><span class="line"></span><br><span class="line">        _logger.LogWarning(&quot;Retrieved weather data for &#123;location&#125; - Elapsed ms: &#123;&#125; &#123;@currentWeather&#125;&quot;, location, elapsedMillis, currentWeather);</span><br><span class="line"></span><br><span class="line">        return currentWeather;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public LocationForecast GetForecast(string location)</span><br><span class="line">    &#123;</span><br><span class="line">        Stopwatch sw &#x3D; Stopwatch.StartNew();</span><br><span class="line">        LocationForecast locationForecast &#x3D; _weatherService.GetForecast(location);</span><br><span class="line">        sw.Stop();</span><br><span class="line">        long elapsedMillis &#x3D; sw.ElapsedMilliseconds;</span><br><span class="line"></span><br><span class="line">        _logger.LogWarning(&quot;Retrieved weather data for &#123;location&#125; - Elapsed ms: &#123;&#125; &#123;@locationForecast&#125;&quot;, location, elapsedMillis, locationForecast);</span><br><span class="line"></span><br><span class="line">        return locationForecast;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>This is our new Decorator Class, we implement from the IWeatherService Interface, it is taking the interface as a parameter in the constructor, and implemented two methods. In the GetCurrentWeather() method, it logs the time it takes to run the method, then calling the original _weatherService.GetCurrentWeather() method.</p><h2 id="caching-decorator"><a class="markdownIt-Anchor" href="#caching-decorator"></a> Caching Decorator</h2><p>Cache weather conditions, forecasts for a city to reduce the number of external API calls.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">public class WeatherServiceCachingDecorator : IWeatherService</span><br><span class="line">&#123;</span><br><span class="line">    private IWeatherService _weatherService;</span><br><span class="line">    private IMemoryCache _cache;</span><br><span class="line"></span><br><span class="line">    public WeatherServiceCachingDecorator(IWeatherService weatherService, IMemoryCache cache)</span><br><span class="line">    &#123;</span><br><span class="line">        _weatherService &#x3D; weatherService;</span><br><span class="line">        _cache &#x3D; cache;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public CurrentWeather GetCurrentWeather(string location)</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; if we can found value in the cache, return it</span><br><span class="line">        &#x2F;&#x2F; otherwise get the current weather then add it to the cache for 30 mins</span><br><span class="line">        string cacheKey &#x3D; $&quot;WeatherConditions::&#123;location&#125;&quot;;</span><br><span class="line">        if (_cache.TryGetValue&lt;CurrentWeather&gt;(cacheKey, out var currentWeather))</span><br><span class="line">        &#123;</span><br><span class="line">            return currentWeather;</span><br><span class="line">        &#125;</span><br><span class="line">        else</span><br><span class="line">        &#123;</span><br><span class="line">            var currentConditions &#x3D; _weatherService.GetCurrentWeather(location);</span><br><span class="line">            _cache.Set&lt;CurrentWeather&gt;(cacheKey, currentConditions, TimeSpan.FromMinutes(30));</span><br><span class="line">            return currentConditions;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public LocationForecast GetForecast(string location)</span><br><span class="line">    &#123;</span><br><span class="line">        string cacheKey &#x3D; $&quot;WeatherForecast::&#123;location&#125;&quot;;</span><br><span class="line">        if (_cache.TryGetValue&lt;LocationForecast&gt;(cacheKey, out var forecast))</span><br><span class="line">        &#123;</span><br><span class="line">            return forecast;</span><br><span class="line">        &#125;</span><br><span class="line">        else</span><br><span class="line">        &#123;</span><br><span class="line">            var locationForecast &#x3D; _weatherService.GetForecast(location);</span><br><span class="line">            _cache.Set&lt;LocationForecast&gt;(cacheKey, locationForecast, TimeSpan.FromMinutes(30));</span><br><span class="line">            return locationForecast;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>And meanwhile in the HomeController, we need to build this onion like structure from inside to outside.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">IWeatherService weatherService &#x3D; new WeatherService(apiKey);</span><br><span class="line">IWeatherService withLoggingDecorator &#x3D; new WeatherServiceLoggingDecorator(weatherService, _loggerFactory.CreateLogger&lt;WeatherServiceLoggingDecorator&gt;());</span><br><span class="line">IWeatherService withCachingDecorator &#x3D; new WeatherServiceCachingDecorator(withLoggingDecorator, memoryCache);</span><br><span class="line"></span><br><span class="line">_weatherService &#x3D; withCachingDecorator;</span><br></pre></td></tr></table></figure><p>The call stack will be: CachingDecorator =&gt; LoggingDecorator =&gt; WeatherService</p><h2 id="decorator-summary"><a class="markdownIt-Anchor" href="#decorator-summary"></a> Decorator Summary</h2><ul><li>Multiple decorators can be used in conjunction with one another</li><li>Each decorator can focus on a single task, promoting separation of concerns</li><li>Decorator classes allow functionality to be added dynamically</li></ul><h3 id="decorator-pattern-characteristics"><a class="markdownIt-Anchor" href="#decorator-pattern-characteristics"></a> Decorator Pattern Characteristics</h3><ol><li>Implement the same base interface as the original object</li><li>Take a instance of the original object as part of their constructor</li><li>Add new behaviors to the original object they are wrapping</li></ol><h2 id="using-decorators-with-dependency-injection-container"><a class="markdownIt-Anchor" href="#using-decorators-with-dependency-injection-container"></a> Using Decorators with Dependency Injection Container</h2><p>.NET Core has built in IoC container which will help us to create WeatherService object when we need it and manage the lifetime of object.</p><p>We could simplify the HomeController constructor to this</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">private readonly IWeatherService _weatherService;</span><br><span class="line"></span><br><span class="line">public HomeController(ILogger&lt;HomeController&gt; logger, IWeatherService weatherService)</span><br><span class="line">&#123;</span><br><span class="line">    _weatherService &#x3D; weatherService;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>And in the startUp.cs, we configure the IoC container to this</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">public void ConfigureServices(IServiceCollection services)</span><br><span class="line">&#123;</span><br><span class="line">    services.AddControllersWithViews();</span><br><span class="line"></span><br><span class="line">    services.AddMemoryCache();</span><br><span class="line"></span><br><span class="line">    String apiKey &#x3D; Configuration.GetValue&lt;String&gt;(&quot;OpenWeatherMapApiKey&quot;);</span><br><span class="line">    services.AddScoped&lt;IWeatherService&gt;(serviceProvider &#x3D;&gt;</span><br><span class="line">    &#123;</span><br><span class="line">        String apiKey &#x3D; Configuration.GetValue&lt;String&gt;(&quot;OpenWeatherMapApiKey&quot;);</span><br><span class="line"></span><br><span class="line">        var logger &#x3D; serviceProvider.GetService&lt;ILogger&lt;WeatherServiceLoggingDecorator&gt;&gt;();</span><br><span class="line"></span><br><span class="line">        var memoryCache &#x3D; serviceProvider.GetService&lt;IMemoryCache&gt;();</span><br><span class="line"></span><br><span class="line">        IWeatherService weatherService &#x3D; new WeatherService(apiKey);</span><br><span class="line">        IWeatherService withLoggingDecorator &#x3D; new WeatherServiceLoggingDecorator(weatherService, logger);</span><br><span class="line">        IWeatherService withCachingDecorator &#x3D; new WeatherServiceCachingDecorator(withLoggingDecorator, memoryCache);</span><br><span class="line"></span><br><span class="line">        return withCachingDecorator;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Now whenever we need a IWeatherService object, it will be created and provided to us with this structure. (CachingDecorator =&gt; LoggingDecorator =&gt; WeatherService)</p><h2 id="when-to-use-decorator-pattern"><a class="markdownIt-Anchor" href="#when-to-use-decorator-pattern"></a> When to use Decorator Pattern</h2><ul><li>Cross cutting concerns<ul><li>Logging, Performance Tracking(Timer, StopWatch…), Caching, Authorization</li></ul></li><li>Manipulate data going to/from component<ul><li>object we need to encrypt and decrypt before being passed to a component</li></ul></li></ul><h3 id="question-what-if-your-component-does-not-have-an-interfaceextend-from-a-base-class"><a class="markdownIt-Anchor" href="#question-what-if-your-component-does-not-have-an-interfaceextend-from-a-base-class"></a> Question: What if your component does not have an interface/extend from a base class?</h3><ul><li>Extract an interface from the class</li></ul><h3 id="what-if-you-cant-modify-the-class"><a class="markdownIt-Anchor" href="#what-if-you-cant-modify-the-class"></a> What if you can’t modify the class?</h3><ul><li>Adapter Pattern</li></ul><p>To put a class in front of your component and extract an interface from the Adapter Class</p><p><img src="/../images/Design-Patterns-Decorator/5.png" alt="" /></p><h2 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h2><ul><li>Design Patterns are about ideas</li><li>Interfaces allow us to create loosely coupled designs</li><li>the decorator pattern adds the ability to dynamically add behavior</li><li>This is accomplished by wrapping around the original object and intercepting methods</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Design Patterns </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Design Patterns - Factory and Abstract Factory</title>
      <link href="2021/04/17/Design-Patterns-Factory-and-Abstract-Factory/"/>
      <url>2021/04/17/Design-Patterns-Factory-and-Abstract-Factory/</url>
      
        <content type="html"><![CDATA[<h2 id="what-is-factory-pattern"><a class="markdownIt-Anchor" href="#what-is-factory-pattern"></a> What is Factory Pattern</h2><p>A factory is an object for creating objects</p><h2 id="factory-pattern-variations"><a class="markdownIt-Anchor" href="#factory-pattern-variations"></a> Factory Pattern Variations</h2><ul><li>Simple Factory</li><li>Factory Method</li><li>Abstract Factory</li></ul><h2 id="factory-pattern-characteristics"><a class="markdownIt-Anchor" href="#factory-pattern-characteristics"></a> Factory Pattern Characteristics</h2><ul><li>Client: Asks for a created product<ul><li>Shopping cart</li></ul></li><li>Creator: Facilitates a creation<ul><li>ShippingProviderFactory</li></ul></li><li>Product: The product of the creation<ul><li>ShippingProvider Instance</li></ul></li></ul><p>The Client no longer needs to know how to create an object or exactly what flavor of that class it will use</p><h2 id="simple-factory-example"><a class="markdownIt-Anchor" href="#simple-factory-example"></a> Simple Factory Example</h2><p>We have a ShoppingCart Class and inside this Class we create a shippingProvider object. It will create different shippingProvider based on order’s sender country</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">if (order.Sender.Country &#x3D;&#x3D; &quot;Australia&quot;)</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F;Australia Post Shipping Provider</span><br><span class="line">&#125;</span><br><span class="line">else if (order.Sender.Country &#x3D;&#x3D; &quot;Sweden&quot;)</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F;Swedish Postal Service Shipping Provider</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">&#123;</span><br><span class="line">    throw new NotSupportedException(&quot;No shipping provider found for origin country&quot;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>But the shippingProvider object should not be created inside the ShoppingCart Class, ShoppingCart Class should just ask a ShippingProviderFactory Class for a shippingProvider object, and it will be provided one.</p><p>So we should moved the code to a new ShippingProviderFactory Class and invoke this class’s Creation method.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">var shippingProvider &#x3D; ShippingProviderFactory.CreateShippingProvider(order.Sender.Country);</span><br></pre></td></tr></table></figure><p>One problem is not we are still hardcoding the Country inside our ShippingProviderFactory Class. We should add another layer of abstraction between the ShippingProviderFactory and the implementation of the ShippingProvider.</p><h2 id="factory-method"><a class="markdownIt-Anchor" href="#factory-method"></a> Factory Method</h2><p>The Factory Method Pattern is introduced to allow for a flexible and extensible application</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">public abstract class ShippingProviderFactory &#123;</span><br><span class="line">    public abstract ShippingProvider CreateShippingProvider(string country);</span><br><span class="line"></span><br><span class="line">    public ShippingProvider GetShippingProvider(string country) &#123;</span><br><span class="line">        var provider &#x3D; CreateShippingProvider(country)</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; we may want to do some common changes on the shippingProvider created </span><br><span class="line">        &#x2F;&#x2F; before we return it back to the caller (ShoppingCart)</span><br><span class="line">        if (country &#x3D;&#x3D; &quot;Sweden&quot; &amp;&amp; provider.InsuranceOptions.ProviderHasInsurance)</span><br><span class="line">        &#123;</span><br><span class="line">            provider.RequireSignature &#x3D; false;</span><br><span class="line">        &#125;</span><br><span class="line">        return provider;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>It contains two methods.</p><p>The CreateShippingProvider() method will be implemented by its subclasses with different implementations.</p><p>The GetShippingProvider() method will allow user to decide what’s passed into the creation. And it allows user to do additional common interactions with the result of the creation before it’s being passed back to the caller(ShoppingCart).</p><p><img src="/../images/Design-Patterns-Factory-and-Abstract-Factory/1.png" alt="" /></p><p>Now we can create different implementations of the creation of a shippingProvider based on the input parameter(country).</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">public class StandardShippingProviderFactory : ShippingProviderFactory</span><br><span class="line">&#123;</span><br><span class="line">    public override ShippingProvider CreateShippingProvider(string country)</span><br><span class="line">    &#123;</span><br><span class="line">        return new StandardShippingProviderFactory();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public class GlobalExpressShippingProviderFactory : ShippingProviderFactory</span><br><span class="line">&#123;</span><br><span class="line">    public override ShippingProvider CreateShippingProvider(string country)</span><br><span class="line">    &#123;</span><br><span class="line">        return new GlobalExpressShippingProvider();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>In the caller Class (ShoppingCart) we can inject ShippingProviderFactory</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; inject ShippingProviderFactory into the ShoppingCart Constructor</span><br><span class="line">public ShoppingCart(Order order, ShippingProviderFactory shippingProviderFactory)</span><br><span class="line">&#123;</span><br><span class="line">    this.order &#x3D; order;</span><br><span class="line">    this.shippingProviderFactory &#x3D; shippingProviderFactory;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Also compose the ShippingProviderFactory object on app start</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">var cart &#x3D; new ShoppingCart(order, new StandardShippingProviderFactory());</span><br></pre></td></tr></table></figure><h2 id="abstract-factory-pattern"><a class="markdownIt-Anchor" href="#abstract-factory-pattern"></a> Abstract Factory Pattern</h2><p>The abstract factory pattern provides a way to encapsulete a group of individual factories that have a common theme without specifying their concrete classes.</p><p><img src="/../images/Design-Patterns-Factory-and-Abstract-Factory/2.png" alt="" /></p><p>It adds another layer of abstraction which allow users to choose which factory to use on app start.</p><p>Different factories have the same methods but with different implementations</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">public interface IPurchaseProviderFactory</span><br><span class="line">&#123;</span><br><span class="line">    ShippingProvider CreateShippingProvider(Order order);</span><br><span class="line">    IInvoice CreateInvoice(Order order);</span><br><span class="line">    ISummary CreateSummary(Order order);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public class AustraliaPurchaseProviderFactory : IPurchaseProviderFactory</span><br><span class="line">&#123;</span><br><span class="line">    public IInvoice CreateInvoice(Order order)</span><br><span class="line">    &#123;</span><br><span class="line">        return new GSTInvoice();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public ShippingProvider CreateShippingProvider(Order order)</span><br><span class="line">    &#123;</span><br><span class="line">        var shippingProviderFactory &#x3D; new StandardShippingProviderFactory();</span><br><span class="line"></span><br><span class="line">        return shippingProviderFactory.GetShippingProvider(order.Sender.Country);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public ISummary CreateSummary(Order order)</span><br><span class="line">    &#123;</span><br><span class="line">        return new CSVSummary();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public class SwedenPurchaseProviderFactory : IPurchaseProviderFactory</span><br><span class="line">&#123;</span><br><span class="line">    public IInvoice CreateInvoice(Order order)</span><br><span class="line">    &#123;</span><br><span class="line">        if (order.Recipient.Country !&#x3D; order.Sender.Country)</span><br><span class="line">        &#123;</span><br><span class="line">            return new NoVATInvoice();</span><br><span class="line">        &#125;</span><br><span class="line">        return new VATInvoice();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public ShippingProvider CreateShippingProvider(Order order)</span><br><span class="line">    &#123;</span><br><span class="line">        ShippingProviderFactory shippingProviderFactory;</span><br><span class="line"></span><br><span class="line">        if (order.Sender.Country !&#x3D; order.Recipient.Country)</span><br><span class="line">        &#123;</span><br><span class="line">            shippingProviderFactory &#x3D; new GlobalExpressShippingProviderFactory();</span><br><span class="line">        &#125;</span><br><span class="line">        else</span><br><span class="line">        &#123;</span><br><span class="line">            shippingProviderFactory &#x3D; new StandardShippingProviderFactory();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        return shippingProviderFactory.GetShippingProvider(order.Sender.Country);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public ISummary CreateSummary(Order order)</span><br><span class="line">    &#123;</span><br><span class="line">        return new EmailSummary();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Client (ShoppingCart) Class doesn’t need to know which factory to use, it just needs to know when to create a product using the factory.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">public ShoppingCart(Order order, IPurchaseProviderFactory purchaseProviderFactory)  </span><br><span class="line">&#123;</span><br><span class="line">    this.order &#x3D; order;</span><br><span class="line">    this.purchaseProviderFactory &#x3D; purchaseProviderFactory;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public string Finalize()</span><br><span class="line">&#123;</span><br><span class="line">    var shippingProvider &#x3D; purchaseProviderFactory.CreateShippingProvider(order);</span><br><span class="line"></span><br><span class="line">    var invoice &#x3D; purchaseProviderFactory.CreateInvoice(order);</span><br><span class="line"></span><br><span class="line">    var summary &#x3D; purchaseProviderFactory.CreateSummary(order);</span><br><span class="line"></span><br><span class="line">    summary.Send();</span><br><span class="line"></span><br><span class="line">    order.ShippingStatus &#x3D; ShippingStatus.ReadyForShippment;</span><br><span class="line"></span><br><span class="line">    return shippingProvider.GenerateShippingLabelFor(order);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>The concrete factory object will be instantiated on app starts(or based on user input).</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">IPurchaseProviderFactory purchaseProviderFactory;</span><br><span class="line"></span><br><span class="line">if (order.Sender.Country &#x3D;&#x3D; &quot;Sweden&quot;)</span><br><span class="line">&#123;</span><br><span class="line">    purchaseProviderFactory &#x3D; new SwedenPurchaseProviderFactory();</span><br><span class="line">&#125;</span><br><span class="line">else if (order.Sender.Country &#x3D;&#x3D; &quot;Australia&quot;)</span><br><span class="line">&#123;</span><br><span class="line">    purchaseProviderFactory &#x3D; new AustraliaPurchaseProviderFactory();</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">&#123;</span><br><span class="line">    throw new Exception(&quot;Country not supported.&quot;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">var cart &#x3D; new ShoppingCart(order, purchaseProviderFactory);</span><br></pre></td></tr></table></figure><h2 id="factory-pattern-in-testing"><a class="markdownIt-Anchor" href="#factory-pattern-in-testing"></a> Factory Pattern in Testing</h2><p>Extract creation of mocked, facked or commonly oused intances in tests.</p><p>We could use the Factory Pattern in our Unit Tests. it will be easier to test the parts that use them as you can inhect faked or mocked implementations</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">public abstract class OrderFactory</span><br><span class="line">&#123;</span><br><span class="line">    protected abstract Order CreateOrder();</span><br><span class="line"></span><br><span class="line">    public Order GetOrder()</span><br><span class="line">    &#123;</span><br><span class="line">        var order &#x3D; CreateOrder();</span><br><span class="line"></span><br><span class="line">        order.LineItems.Add(</span><br><span class="line">            new Item(&quot;testA&quot;, &quot;testB&quot;, 100m), 1</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        order.LineItems.Add(</span><br><span class="line">            new Item(&quot;TestC&quot;, &quot;TestD&quot;, decimal.MaxValue), 1</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        return order;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public class StandardOrderFactory : OrderFactory</span><br><span class="line">&#123;</span><br><span class="line">    protected override Order CreateOrder()</span><br><span class="line">    &#123;</span><br><span class="line">        var order &#x3D; new Order</span><br><span class="line">        &#123;</span><br><span class="line">            Recipient &#x3D; new Address</span><br><span class="line">            &#123;</span><br><span class="line">                To &#x3D; &quot;Yuan&quot;,</span><br><span class="line">                Country &#x3D; &quot;Australia&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            Sender &#x3D; new Address</span><br><span class="line">            &#123;</span><br><span class="line">                To &#x3D; &quot;Someone else&quot;,</span><br><span class="line">                Country &#x3D; &quot;Australia&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        return order;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public class InternationalOrderFactory : OrderFactory</span><br><span class="line">&#123;</span><br><span class="line">    protected override Order CreateOrder()</span><br><span class="line">    &#123;</span><br><span class="line">        var order &#x3D; new Order</span><br><span class="line">        &#123;</span><br><span class="line">            Recipient &#x3D; new Address</span><br><span class="line">            &#123;</span><br><span class="line">                To &#x3D; &quot;Yuan&quot;,</span><br><span class="line">                Country &#x3D; &quot;Australia&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            Sender &#x3D; new Address</span><br><span class="line">            &#123;</span><br><span class="line">                To &#x3D; &quot;Someone else&quot;,</span><br><span class="line">                Country &#x3D; &quot;Sweden&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        return order;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h2><ul><li><p>Separates the client(ShoppingCart) from the creation</p></li><li><p>Introduce subclasses (StandardShippingProviderFactory, GlobalExpressShippingProviderFactory) and concrete implementations to add functionality.</p></li><li><p>Factory Pattern is very common when writing tests</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Design Patterns </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Design Patterns - Command</title>
      <link href="2021/04/16/Design-Patterns-Command/"/>
      <url>2021/04/16/Design-Patterns-Command/</url>
      
        <content type="html"><![CDATA[<h2 id="command-pattern-characteristics"><a class="markdownIt-Anchor" href="#command-pattern-characteristics"></a> Command Pattern Characteristics</h2><ul><li>Command<ul><li>Holds the instructions and references to things that it needs in order for it to be executed</li></ul></li><li>Receiver<ul><li>Command will execute Receiver</li></ul></li><li>Invoker<ul><li>Invoker will execute Command, and will also keep track of all executed commands</li></ul></li><li>Client<ul><li>Client decides which command to schedule for execution</li></ul></li></ul><p><img src="/../images/Design-Patterns-Command/1.png" alt="" /></p><p>A command contains all the data to process the request now or at a later time. This means we could execute the command right away once the client schedule that command, or we could schedule all the commands to be executed later on in the lifetime of our application.</p><p>Example: AddToCartCommand</p><ul><li>The product which should be added to the cart</li><li>The shopping cart</li><li>A way to check stock availability</li></ul><p><img src="/../images/Design-Patterns-Command/2.png" alt="" /></p><h2 id="icommand-interface"><a class="markdownIt-Anchor" href="#icommand-interface"></a> ICommand Interface</h2><p>Because we may need to implement different command, we should create a ICommand interface.</p><p>It contains three methods. Execute() will execute the command. CanExecute() will check if a command can be execute of not. Undo() will undo all commands we executed before (using a Stack to maintain all executed commands)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public interface ICommand</span><br><span class="line">&#123;</span><br><span class="line">    void Execute();</span><br><span class="line">    bool CanExecute();</span><br><span class="line">    void Undo();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Next we need to implement CommandManager, which is the Invoker component. It contains a Stack Data Structure to maintain the Commands list. When the Client (UI Button) adds a command to the CommandManager, it will be added to the list. (We can also add extra feature like introduce a delay of executing commands or redo all commands later).</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">public class CommandManager</span><br><span class="line">&#123;</span><br><span class="line">    private Stack&lt;ICommand&gt; commands &#x3D; new Stack&lt;ICommand&gt;();</span><br><span class="line"></span><br><span class="line">    public void Invoke(ICommand command)</span><br><span class="line">    &#123;</span><br><span class="line">        if (command.CanExecute())</span><br><span class="line">        &#123;</span><br><span class="line">            commands.Push(command);</span><br><span class="line">            command.Execute();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void Undo()</span><br><span class="line">    &#123;</span><br><span class="line">        while (commands.Count &gt; 0)</span><br><span class="line">        &#123;</span><br><span class="line">            var command &#x3D; commands.Pop();</span><br><span class="line">            command.Undo();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Next we start to implement a command AddToCartCommand</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public class AddToCartCommand : ICommand</span><br></pre></td></tr></table></figure><p>It takes a shoppingCartRepository object, a productRepository object and a product</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public AddToCartCommand(IShoppingCartRepository shoppingCartRepository,</span><br><span class="line">    IProductRepository productRepository,</span><br><span class="line">    Product product)</span><br><span class="line">&#123;</span><br><span class="line">    this.shoppingCartRepository &#x3D; shoppingCartRepository;</span><br><span class="line">    this.productRepository &#x3D; productRepository;</span><br><span class="line">    this.product &#x3D; product;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Just a reminder, the Repository is a pattern for abstracting data access. We could have access the data store from a SQL DB, a web service or a CSV file, but our application doesn’t need to know that.</p><p>In our case, the shoppingCartRepository and the productRepository are both just a local Dictionary data structure.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public bool CanExecute()</span><br><span class="line">&#123;</span><br><span class="line">    if (product &#x3D;&#x3D; null) return false;</span><br><span class="line"></span><br><span class="line">    return productRepository.GetStockFor(product.ArticleId) &gt; 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>CanExecute() will check if our productRepository actually has the required product.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public void Execute()</span><br><span class="line">&#123;</span><br><span class="line">    if (product &#x3D;&#x3D; null) return;</span><br><span class="line"></span><br><span class="line">    productRepository.DecreaseStockBy(product.ArticleId, 1);</span><br><span class="line"></span><br><span class="line">    shoppingCartRepository.Add(product);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Execute() will decrease the product quantity by one and add it to shoppingCartRepository</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">public void Undo()</span><br><span class="line">&#123;</span><br><span class="line">    if (product &#x3D;&#x3D; null) return;</span><br><span class="line"></span><br><span class="line">    var lineItem &#x3D; shoppingCartRepository.Get(product.ArticleId);</span><br><span class="line"></span><br><span class="line">    productRepository.IncreaseStockBy(product.ArticleId, lineItem.Quantity);</span><br><span class="line"></span><br><span class="line">    shoppingCartRepository.RemoveAll(product.ArticleId);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Undo() will put the product from shoppingCartRepository back to the productRepository</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">var shoppingCartRepository &#x3D; new ShoppingCartRepository();</span><br><span class="line">var productsRepository &#x3D; new ProductsRepository();</span><br><span class="line"></span><br><span class="line">var product &#x3D; productsRepository.FindBy(&quot;SM7B&quot;);</span><br><span class="line"></span><br><span class="line">var addToCartCommand &#x3D; new AddToCartCommand(shoppingCartRepository,</span><br><span class="line">    productsRepository,</span><br><span class="line">    product);</span><br><span class="line"></span><br><span class="line">var increaseQuantityCommand &#x3D; new ChangeQuantityCommand(</span><br><span class="line">    ChangeQuantityCommand.Operation.Increase,</span><br><span class="line">    shoppingCartRepository,</span><br><span class="line">    productsRepository,</span><br><span class="line">    product);</span><br><span class="line"></span><br><span class="line">var manager &#x3D; new CommandManager();</span><br><span class="line">manager.Invoke(addToCartCommand);</span><br><span class="line">manager.Invoke(increaseQuantityCommand);</span><br><span class="line">manager.Invoke(increaseQuantityCommand);</span><br><span class="line">manager.Invoke(increaseQuantityCommand);</span><br><span class="line">manager.Invoke(increaseQuantityCommand);</span><br></pre></td></tr></table></figure><p>Finally we just need to compose all the necessary objects on app starts. And add the commands to CommandManager.</p><h2 id="command-pattern-in-wpf"><a class="markdownIt-Anchor" href="#command-pattern-in-wpf"></a> Command Pattern in WPF</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">public interface ICommand</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F;</span><br><span class="line">    &#x2F;&#x2F; Summary:</span><br><span class="line">    &#x2F;&#x2F;     Occurs when changes occur that affect whether or not the command should execute.</span><br><span class="line">    event EventHandler CanExecuteChanged;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;</span><br><span class="line">    &#x2F;&#x2F; Summary:</span><br><span class="line">    &#x2F;&#x2F;     Defines the method that determines whether the command can execute in its current</span><br><span class="line">    &#x2F;&#x2F;     state.</span><br><span class="line">    &#x2F;&#x2F;</span><br><span class="line">    &#x2F;&#x2F; Parameters:</span><br><span class="line">    &#x2F;&#x2F;   parameter:</span><br><span class="line">    &#x2F;&#x2F;     Data used by the command. If the command does not require data to be passed,</span><br><span class="line">    &#x2F;&#x2F;     this object can be set to null.</span><br><span class="line">    &#x2F;&#x2F;</span><br><span class="line">    &#x2F;&#x2F; Returns:</span><br><span class="line">    &#x2F;&#x2F;     true if this command can be executed; otherwise, false.</span><br><span class="line">    bool CanExecute(object parameter);</span><br><span class="line">    &#x2F;&#x2F;</span><br><span class="line">    &#x2F;&#x2F; Summary:</span><br><span class="line">    &#x2F;&#x2F;     Defines the method to be called when the command is invoked.</span><br><span class="line">    &#x2F;&#x2F;</span><br><span class="line">    &#x2F;&#x2F; Parameters:</span><br><span class="line">    &#x2F;&#x2F;   parameter:</span><br><span class="line">    &#x2F;&#x2F;     Data used by the command. If the command does not require data to be passed,</span><br><span class="line">    &#x2F;&#x2F;     this object can be set to null.</span><br><span class="line">    void Execute(object parameter);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>WPF application has built in ICommand interface. If we want to use our Command implementation (RemoveAllFromCartCommand) with this ICommand interface. We could bind the method with a UI button, then create a RelayCommand Class, which will invoke RemoveAllFromCartCommand method.</p><ul><li>UI Button -&gt;(bind)-&gt; ICommand method -&gt;(invoke)-&gt; RelayCommand -&gt;(invoke)-&gt; RemoveAllFromCartCommand</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;Button Margin&#x3D;&quot;0 5 5 0&quot; Command&#x3D;&quot;&#123;Binding RemoveAllFromCartCommand&#125;&quot;&gt;Clear&lt;&#x2F;Button&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public System.Windows.Input.ICommand RemoveAllFromCartCommand &#123; get; private set; &#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">RemoveAllFromCartCommand &#x3D; new RelayCommand(</span><br><span class="line">    execute: () &#x3D;&gt;</span><br><span class="line">    &#123;</span><br><span class="line">        removeAllFromCartCommand.Execute();</span><br><span class="line"></span><br><span class="line">        Refresh();</span><br><span class="line">    &#125;, </span><br><span class="line">    canExecute:() &#x3D;&gt; removeAllFromCartCommand.CanExecute()</span><br><span class="line">);</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">public class RelayCommand : System.Windows.Input.ICommand</span><br><span class="line">&#123;</span><br><span class="line">    private readonly Action execute;</span><br><span class="line">    private readonly Func&lt;bool&gt; canExecute;</span><br><span class="line"></span><br><span class="line">    public RelayCommand(Action execute, Func&lt;bool&gt; canExecute)</span><br><span class="line">    &#123;</span><br><span class="line">        this.execute &#x3D; execute;</span><br><span class="line">        this.canExecute &#x3D; canExecute;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public bool CanExecute(object parameter)</span><br><span class="line">    &#123;</span><br><span class="line">        return canExecute?.Invoke() ?? false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void Execute(object parameter)</span><br><span class="line">    &#123;</span><br><span class="line">        execute?.Invoke();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public event EventHandler CanExecuteChanged</span><br><span class="line">    &#123;</span><br><span class="line">        add &#123; CommandManager.RequerySuggested +&#x3D; value; &#125;</span><br><span class="line">        remove &#123; CommandManager.RequerySuggested -&#x3D; value; &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void RaiseCanExecuteChanged()</span><br><span class="line">    &#123;</span><br><span class="line">        CommandManager.InvalidateRequerySuggested();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h2><p>Command Pattern converts the request from Client to an object(ICommand). And the children implementation of the ICommand (AddToCartCommand) will take the Receiver as one of its input parameters (ShoppingCartRepository, ProductRepository). And it will implement the Execute() method, decide what should the Receiver do in Execute() method. And the Receiver should have all the needed information about the request(Product)</p>]]></content>
      
      
      
        <tags>
            
            <tag> Design Patterns </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Design Patterns - Strategy</title>
      <link href="2021/04/16/Design-Patterns-Strategy/"/>
      <url>2021/04/16/Design-Patterns-Strategy/</url>
      
        <content type="html"><![CDATA[<p>Strategy pattern is also called Policy pattern</p><h2 id="strategy-pattern-characteristics"><a class="markdownIt-Anchor" href="#strategy-pattern-characteristics"></a> Strategy Pattern Characteristics</h2><ul><li>Context: has a reference to a strategy and invokes it<ul><li>Calls IStrategy.Method(object);</li></ul></li><li>IStrategy: Defines the interface for the given strategy<ul><li>Defines the contract Method(object)</li></ul></li><li>Strategy: A concrete implementation of the strategy<ul><li>Implementation of Method(object)</li></ul></li></ul><p>Select an implementation at runtime based on user input without having to extend the class.</p><p>Example: ISalesTaxStrategy is an interface. We have multiple different implementations of Strategies to calculate tax. They all implement the ISalesTaxStrategy interface.</p><p>The code below doesn’t need to know what Strategy is chosen at this step. It only needs to invoke the GetTaxFor() Method.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public ISalesTaxStrategy SalesTaxStrategy &#123; get; set; &#125;</span><br><span class="line"></span><br><span class="line">public decimal GetTax()</span><br><span class="line">&#123;</span><br><span class="line">    return SalesTaxStrategy &#x3D;&#x3D; null ? 0m : SalesTaxStrategy.GetTaxFor(this);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="what-did-we-achieve"><a class="markdownIt-Anchor" href="#what-did-we-achieve"></a> What did we achieve?</h3><ul><li>A more extensible, object oriented and dynamic implementation</li><li>Easily add new strategies without affecting existing ones</li><li>Cleaner approach with single responsiblity in mind</li></ul><p>Another thing we could do is to pass the interface to the GetTax() method.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public decimal GetTax(ISalesTaxStrategy salesTaxStrategy) &#123;</span><br><span class="line">    return salesTaxStrategy &#x3D;&#x3D; null ? 0m : salesTaxStrategy.GetTaxFor(this);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>And the concrete implementation of the strategy could be determined when we invoke the GetTax() Method</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">order.GetTax(new SwedenSalesTaxStrategy()</span><br></pre></td></tr></table></figure><p>This is still meaning we have a hard dependency between the Order and the SalesTaxStrategy</p><h2 id="strategy-pattern-with-dependency-injection"><a class="markdownIt-Anchor" href="#strategy-pattern-with-dependency-injection"></a> Strategy Pattern with Dependency Injection</h2><p>Pass the already created SalesTaxStrategy to the Order Contructor will help us remove the hard dependency between the Order and the Strategy.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">private ISalesTaxStrategy _salesTaxStrategy;</span><br><span class="line">private IInvoiceStrategy _invoiceStrategy;</span><br><span class="line">private IShippingStrategy _shippingStrategy;</span><br><span class="line"></span><br><span class="line">public Order(ISalesTaxStrategy salesTaxStrategy, IInvoiceStrategy invoiceStrategy, IShippingStrategy shippingStrategy)</span><br><span class="line">&#123;</span><br><span class="line">    _salesTaxStrategy &#x3D; salesTaxStrategy;</span><br><span class="line">    _invoiceStrategy &#x3D; invoiceStrategy;</span><br><span class="line">    _shippingStrategy &#x3D; shippingStrategy;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Then Order(Context in Strategy Pattern) just need to invoke Strategy implementations without having to know which imeplementation it is invoking.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">public decimal GetTax()</span><br><span class="line">&#123;</span><br><span class="line">    return _salesTaxStrategy &#x3D;&#x3D; null ? 0m : _salesTaxStrategy.GetTaxFor(this);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public void FinalizeOrder()</span><br><span class="line">&#123;</span><br><span class="line">    if (SelectedPayments.Any(x &#x3D;&gt; x.PaymentProvider &#x3D;&#x3D; PaymentProvider.Invoice) &amp;&amp; AmountDue &gt; 0 &amp;&amp; ShippingStatus &#x3D;&#x3D; ShippingStatus.WaitingForPayment)</span><br><span class="line">    &#123;</span><br><span class="line">        _invoiceStrategy.Generate(this);</span><br><span class="line">        ShippingStatus &#x3D; ShippingStatus.ReadyForShippment;</span><br><span class="line">    &#125;</span><br><span class="line">    else if (AmountDue &gt; 0)</span><br><span class="line">    &#123;</span><br><span class="line">        throw new Exception(&quot;Unable to finalize order&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    _shippingStrategy.Ship(this);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>On Application start we create different Strategies based on user input</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">switch (origin)</span><br><span class="line">&#123;</span><br><span class="line">    case EnumTaxStrategy.Sweden:</span><br><span class="line">        salesTaxStrategy &#x3D; new SwedenSalesTaxStrategy();</span><br><span class="line">        break;</span><br><span class="line">    case EnumTaxStrategy.USA:</span><br><span class="line">        salesTaxStrategy &#x3D; new USAStateSalesTaxStrategy();</span><br><span class="line">        break;</span><br><span class="line">    default:</span><br><span class="line">        salesTaxStrategy &#x3D; new SwedenSalesTaxStrategy();</span><br><span class="line">        break;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">switch (inputInvoiceStrategy)</span><br><span class="line">&#123;</span><br><span class="line">    case EnumInvoiceStrategy.Email:</span><br><span class="line">        invoiceStrategy &#x3D; new EmailInvoiceStrategy();</span><br><span class="line">        break;</span><br><span class="line">    case EnumInvoiceStrategy.File:</span><br><span class="line">        invoiceStrategy &#x3D; new FileInvoiceStrategy();</span><br><span class="line">        break;</span><br><span class="line">    case EnumInvoiceStrategy.PrintOnDemand:</span><br><span class="line">        invoiceStrategy &#x3D; new PrintOnDemandInvoiceStrategy();</span><br><span class="line">        break;</span><br><span class="line">    default:</span><br><span class="line">        invoiceStrategy &#x3D; new FileInvoiceStrategy();</span><br><span class="line">        break;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">switch (inputShippingStrategy)</span><br><span class="line">&#123;</span><br><span class="line">    case EnumShippingStrategy.DHL:</span><br><span class="line">        shippingStrategy &#x3D; new DHLShippingStrategy();</span><br><span class="line">        break;</span><br><span class="line">    case EnumShippingStrategy.Fedex:</span><br><span class="line">        shippingStrategy &#x3D; new FedexShippingStrategy();</span><br><span class="line">        break;</span><br><span class="line">    case EnumShippingStrategy.SwedishPostalService:</span><br><span class="line">        shippingStrategy &#x3D; new SwedishPostalServiceShippingStrategy();</span><br><span class="line">        break;</span><br><span class="line">    case EnumShippingStrategy.UPS:</span><br><span class="line">        shippingStrategy &#x3D; new UPSShippingStrategy();</span><br><span class="line">        break;</span><br><span class="line">    case EnumShippingStrategy.USPS:</span><br><span class="line">        shippingStrategy &#x3D; new UnitedStatesPostalServiceShippingStrategy();</span><br><span class="line">        break;</span><br><span class="line">    default:</span><br><span class="line">        shippingStrategy &#x3D; new DHLShippingStrategy();</span><br><span class="line">        break;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h2><ul><li>One of the most commonly used patterns</li><li>Decouple the context and the concrete implementation</li><li>Allows for a cleaner implementation in the context</li><li>Easily extend with additional startegies without affecting current implementations</li><li>Makes testing a lot easier as you can write mocked implementations to inject</li><li>Identify existing implementations and where you have used the pattern before</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Design Patterns </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Design Patterns - Singleton</title>
      <link href="2021/04/15/Design-Patterns-Singleton/"/>
      <url>2021/04/15/Design-Patterns-Singleton/</url>
      
        <content type="html"><![CDATA[<p>A singleton is a class designed to only ever have one instance.</p><h2 id="singleton-features"><a class="markdownIt-Anchor" href="#singleton-features"></a> Singleton Features</h2><ul><li>At any time, only 0 or 1 instance of the Singleton class exists in the application</li><li>Singleton classes are created without parameters</li><li>Assume lazy instantiation as the default</li><li>A single, private, parameterless constructor</li><li>Sealed class</li><li>A private, static field holds the only reference to the instance</li><li>A public static method provides access to the field</li></ul><h2 id="naive-implementation-of-singleton"><a class="markdownIt-Anchor" href="#naive-implementation-of-singleton"></a> Naive implementation of Singleton</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">namespace Singleton</span><br><span class="line">&#123;</span><br><span class="line">#nullable enable</span><br><span class="line">    public sealed class Singleton</span><br><span class="line">    &#123;</span><br><span class="line">        private static Singleton? _instance;</span><br><span class="line">        public static Singleton Instance</span><br><span class="line">        &#123;</span><br><span class="line">            get</span><br><span class="line">            &#123;</span><br><span class="line">                &#x2F;&#x2F; lazy instantiate</span><br><span class="line">                Logger.Log(&quot;Instance called&quot;);</span><br><span class="line">                return _instance ??&#x3D; new Singleton();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        private Singleton()</span><br><span class="line">        &#123;</span><br><span class="line">            &#x2F;&#x2F; cannot be created except within this class</span><br><span class="line">            Logger.Log(&quot;Constructor invoked&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>The problem of this native implementation is Thread safety. In multi-thread environment, the If block can be reached by multiple threads concurrently, resulting in multiple instantiations of Singleton.</p><h2 id="thread-safe-singleton"><a class="markdownIt-Anchor" href="#thread-safe-singleton"></a> Thread Safe Singleton</h2><p>One way to make sure the Singleton Instance will not be created in a multiple thread environment is to use a lock</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">private static readonly object padlock &#x3D; new object();</span><br></pre></td></tr></table></figure><p>This lock is a private static readonly object that will be shared by all references to the Singleton instance</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; this lock is used on every reference to Singleton</span><br><span class="line">lock (padlock)</span><br><span class="line">&#123;</span><br><span class="line">    Logger.Log(&quot;Instance called.&quot;);</span><br><span class="line">    &#x2F;&#x2F; lazy instantiation</span><br><span class="line">    return _instance ??&#x3D; new Singleton();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>A slight better way to add lock is to use the double check locking pattern, this gives us a better performance because we don’t need to check lock very often</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">if (_instance &#x3D;&#x3D; null)</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; this lock is used on every reference to Singleton</span><br><span class="line">    lock (padlock)</span><br><span class="line">    &#123;</span><br><span class="line">        Logger.Log(&quot;Instance called.&quot;);</span><br><span class="line">        &#x2F;&#x2F; lazy instantiation</span><br><span class="line">        _instance &#x3D; new Singleton();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">return _instance;</span><br></pre></td></tr></table></figure><ul><li>Locking adds thread safety</li><li>First version imposes lock on every access, not just first time</li><li>Second version is better, but has some issues with the ECMA CLI spec that may be a concern</li><li>Neither approach works as well as the next ones</li></ul><h2 id="static-constructors"><a class="markdownIt-Anchor" href="#static-constructors"></a> Static Constructors</h2><ul><li>C# static constructors only run once per app domain</li><li>static constructors are called when any static member of a type is referenced</li><li>Make sure you use an explicit static constructor to avoid issue with C# compiler and beforefieldinit (beforefieldinit is a hint the compiler uses to let it know static initializers can be called sooner, and this is the default if the type does not have an explicit static constructor. Adding an explicit static constructor avoids having beforefieldinit applied, which helps make our singleton behavior <strong>lazier</strong>)</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">public sealed class StaticConstructorSingleton : ISingleton</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; reading this will initialize the instance</span><br><span class="line">    public static readonly string GREETING &#x3D; &quot;Hi!&quot;;</span><br><span class="line"></span><br><span class="line">    public static StaticConstructorSingleton Instance</span><br><span class="line">    &#123;</span><br><span class="line">        get</span><br><span class="line">        &#123;</span><br><span class="line">            Logger.Log(&quot;Instance called&quot;);</span><br><span class="line">            return Nested._instance;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private class Nested</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F;Tell C# compiler not to mark type as beforefieldinit</span><br><span class="line">        static Nested()</span><br><span class="line">        &#123;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">        internal static readonly StaticConstructorSingleton _instance &#x3D; new StaticConstructorSingleton();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private StaticConstructorSingleton()</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; cannot be created except within this class</span><br><span class="line">        Logger.Log(&quot;Constructor invoked.&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>This approach is Thread-safe, no locks (good performance), but is complex and non-intuitive.</p><h2 id="lazyt"><a class="markdownIt-Anchor" href="#lazyt"></a> Lazy<T></h2><p>One difference between this approach and the naive approach is that the private static readonly field is type of <code>Lazy&lt;Singleton&gt;</code> rather than just Singleton, this field is initilized at construction to create a new <code>Lazy&lt;T&gt;</code> instance, and a lambda function is passed into the <code>Lazy&lt;T&gt;</code> constructor with the logic needed to create the singleton instance.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">public sealed class LazyTSingleton</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; reading this will initilize the instance</span><br><span class="line">    private static readonly Lazy&lt;LazyTSingleton&gt; _lazy &#x3D; new Lazy&lt;LazyTSingleton&gt;(() &#x3D;&gt; new LazyTSingleton());</span><br><span class="line"></span><br><span class="line">    public static LazyTSingleton Instance</span><br><span class="line">    &#123;</span><br><span class="line">        get</span><br><span class="line">        &#123;</span><br><span class="line">            Logger.Log(&quot;Instance called.&quot;);</span><br><span class="line">            return _lazy.Value;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private LazyTSingleton()</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; cannot be created except within this class</span><br><span class="line">        Logger.Log(&quot;Constructor invoked.&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>This approach is very easy to understand and has the performance and thread safe feature.</p><h2 id="singletons-vs-static-classes"><a class="markdownIt-Anchor" href="#singletons-vs-static-classes"></a> Singletons vs Static Classes</h2><table><thead><tr><th>Singletons</th><th style="text-align:center">Static Classes</th></tr></thead><tbody><tr><td>Can implement interfaces</td><td style="text-align:center">No interfaces</td></tr><tr><td>Can be passed as an argument</td><td style="text-align:center">Cannot be passed as arguments</td></tr><tr><td>Can be assigned to variables</td><td style="text-align:center">Cannot be assigned</td></tr><tr><td>Support polymorphism</td><td style="text-align:center">Purely procedural</td></tr><tr><td>Can have state</td><td style="text-align:center">Can only access global state</td></tr><tr><td>Can be serialized</td><td style="text-align:center">No support for serialization</td></tr></tbody></table><h2 id="singleton-behavior-using-containersioc"><a class="markdownIt-Anchor" href="#singleton-behavior-using-containersioc"></a> Singleton Behavior Using Containers(IoC)</h2><ul><li>.NET Core has built-in support for IoC Containers</li><li>Classes request dependencies via constructor</li><li>Classes should follow Explicit Dependencies Principle</li><li>Container manages abstraction-implementation mapping</li><li>Container manages instnace lifetime</li></ul><p>Manage Lifetime Using Container, not Class Design</p><p>Easily manage and modify individual class lifetimes using an IoC container</p><p>Can also be used by any service, console application, etc…</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public void ConfigureService(ServiceCollection services) </span><br><span class="line">&#123;</span><br><span class="line">    services.AddTransient&lt;IOrderService, OrderService&gt;();</span><br><span class="line">    services.AddScoped&lt;IOrderRepository, OrderRepository&gt;();</span><br><span class="line">    services.AddSingleton&lt;IConnectionManager, ConnectionManager&gt;();</span><br><span class="line">    services.AddSingleton&lt;SomeInstance&gt;(new SomeInstance);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Transient: A new instance of the type is provided any time a class requests that type as a dependency.</p><p>Scope: Define a scope and any instance requested within that scope will be shared if it’s requested again within that socpe. The first request will get a new instance and all subsequent requests in that scope will get that same instance.</p><p>Singleton: only one instance will be created and shared by all references. Just like the Singleton pattern.</p><p>IoC containers are probably the best approach in systems that already use them. Otherwise, <code>Laszy&lt;T&gt;</code> provides an elegant, easily understood approach.</p><h2 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h2><ul><li>A Singleton class is designed to only ever have one instance created.</li><li>The Singleton pattern makes the class itself responsible for enforcing Singleton behavior</li><li>It’s easy to get the pattern wrong when implementing by hand</li><li><code>Lazy&lt;T&gt;</code> is one of the better ways to apply the pattern</li><li>Singletons are different from Static Classes</li><li>IoC/DI containers are usually a better place to manage instance lifetime in .NET applications.</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Design Patterns </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Creating Automated Browser Tests with Selenium in C#</title>
      <link href="2021/04/14/Creating-Automated-Browser-Tests-with-Selenium-in-C/"/>
      <url>2021/04/14/Creating-Automated-Browser-Tests-with-Selenium-in-C/</url>
      
        <content type="html"><![CDATA[<h2 id="what-is-selenium"><a class="markdownIt-Anchor" href="#what-is-selenium"></a> What is Selenium?</h2><p>Selenium is a portable framework for testing web applications. The tests can then run against most modern web browsers. Selenium runs on Windows, Linux, and macOS.</p><h3 id="some-of-the-features-we-can-do-using-selenium-webdriver"><a class="markdownIt-Anchor" href="#some-of-the-features-we-can-do-using-selenium-webdriver"></a> Some of the features we can do using Selenium WebDriver</h3><ul><li>Navigate to a specific page/forware/back</li><li>Click the button with an ID</li><li>Type text into the <code>&lt;input&gt;</code></li><li>Get the text content of the SPAN that has a CSS class</li><li>Choose a radio button</li><li>Check a tick box</li><li>Get the title of the current page</li><li>Maximum the browser window</li><li>Take a screenshot</li></ul><h3 id="selenium-webdriver-testing-architecture"><a class="markdownIt-Anchor" href="#selenium-webdriver-testing-architecture"></a> Selenium WebDriver Testing Architecture</h3><p><img src="/../images/Creating-Automated-Browser-Tests-with-Selenium-in-C/1.png" alt="" /></p><h3 id="the-limitations-of-automated-browser-tests"><a class="markdownIt-Anchor" href="#the-limitations-of-automated-browser-tests"></a> The Limitations of Automated Browser Tests</h3><ul><li>Slower than other types of tests (unit tests)</li><li>Not a replacement of all manuall testing</li><li>Additional dependencies (Selenium, WebDriver…)</li></ul><h2 id="setting-up-the-test-project"><a class="markdownIt-Anchor" href="#setting-up-the-test-project"></a> Setting up the test project</h2><h3 id="install-nuget-packages"><a class="markdownIt-Anchor" href="#install-nuget-packages"></a> Install NuGet Packages</h3><ol><li>Selenium.WebDriver</li><li>Selenium.WebDriver.ChromeDriver</li></ol><h3 id="your-first-test-case"><a class="markdownIt-Anchor" href="#your-first-test-case"></a> Your first test case</h3><p>The Web App has to be running for Selenium to work</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">private string baseUrl &#x3D; &quot;http:&#x2F;&#x2F;localhost:29128&#x2F;&quot;;</span><br><span class="line"></span><br><span class="line">[Test]</span><br><span class="line">[Category(&quot;Login&quot;)]</span><br><span class="line">public void ShouldLogin()</span><br><span class="line">&#123;</span><br><span class="line">    using (IWebDriver driver &#x3D; new ChromeDriver())</span><br><span class="line">    &#123;</span><br><span class="line">        driver.Navigate().GoToUrl(baseUrl);</span><br><span class="line"></span><br><span class="line">        var userNameBox &#x3D; driver.FindElement(By.Id(&quot;username&quot;));</span><br><span class="line">        userNameBox.SendKeys(&quot;admin&quot;);</span><br><span class="line"></span><br><span class="line">        Thread.Sleep(1000);</span><br><span class="line"></span><br><span class="line">        var passwordBox &#x3D; driver.FindElement(By.Id(&quot;password&quot;));</span><br><span class="line">        passwordBox.SendKeys(&quot;admin&quot;);</span><br><span class="line"></span><br><span class="line">        Thread.Sleep(1000);</span><br><span class="line"></span><br><span class="line">        var submitButton &#x3D; driver.FindElement(By.Id(&quot;submit&quot;));</span><br><span class="line">        submitButton.Click();</span><br><span class="line"></span><br><span class="line">        Thread.Sleep(1000);</span><br><span class="line"></span><br><span class="line">        var currentPageTitle &#x3D; driver.Title;</span><br><span class="line">        Assert.That(currentPageTitle, Is.EqualTo(&quot;identityOne - Home Page&quot;));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="get-page-title"><a class="markdownIt-Anchor" href="#get-page-title"></a> Get Page Title</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[Test]</span><br><span class="line">[Category(&quot;Test&quot;)]</span><br><span class="line">public void GetPageTitle()</span><br><span class="line">&#123;</span><br><span class="line">    using (IWebDriver driver &#x3D; new ChromeDriver())</span><br><span class="line">    &#123;</span><br><span class="line">        driver.Navigate().GoToUrl(baseUrl);</span><br><span class="line"></span><br><span class="line">        Assert.That(&quot;identityOne - Home Page&quot;, driver.Title);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="read-current-url"><a class="markdownIt-Anchor" href="#read-current-url"></a> Read current URL</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[Test]</span><br><span class="line">[Category(&quot;Test&quot;)]</span><br><span class="line">public void ReadCurrentUrl()</span><br><span class="line">&#123;</span><br><span class="line">    using (IWebDriver driver &#x3D; new ChromeDriver())</span><br><span class="line">    &#123;</span><br><span class="line">        driver.Navigate().GoToUrl(baseUrl);</span><br><span class="line"></span><br><span class="line">        Assert.That(baseUrl, driver.Url);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="reload-current-page-go-backwardforward"><a class="markdownIt-Anchor" href="#reload-current-page-go-backwardforward"></a> Reload current page / go backward/forward</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[Test]</span><br><span class="line">[Category(&quot;Test&quot;)]</span><br><span class="line">public void ReloadCurrentPage()</span><br><span class="line">&#123;</span><br><span class="line">    using (IWebDriver driver &#x3D; new ChromeDriver())</span><br><span class="line">    &#123;</span><br><span class="line">        driver.Navigate().GoToUrl(baseUrl);</span><br><span class="line"></span><br><span class="line">        driver.Navigate().Refresh();</span><br><span class="line">        driver.Navigate().Back();</span><br><span class="line">        driver.Navigate().Forward();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="manipulating-html-elements"><a class="markdownIt-Anchor" href="#manipulating-html-elements"></a> Manipulating HTML Elements</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">[Test]</span><br><span class="line">[Category(&quot;Test&quot;)]</span><br><span class="line">public void ReloadCurrentPage()</span><br><span class="line">&#123;</span><br><span class="line">    using (IWebDriver driver &#x3D; new ChromeDriver())</span><br><span class="line">    &#123;</span><br><span class="line">        driver.Navigate().GoToUrl(baseUrl);</span><br><span class="line"></span><br><span class="line">        IWebElement textElement &#x3D; driver.FindElement(By.Id(&quot;username&quot;)); &#x2F;&#x2F; find element by ID</span><br><span class="line">        string usernameText &#x3D; textElement.Text; &#x2F;&#x2F; Get HTML element text</span><br><span class="line"></span><br><span class="line">        IWebElement buttonElement &#x3D; driver.FindElement(By.Name(&quot;button&quot;)); &#x2F;&#x2F; find element by Name</span><br><span class="line">        buttonElement.Click(); &#x2F;&#x2F; Click a button or link</span><br><span class="line"></span><br><span class="line">        IWebElement linkElement &#x3D; driver.FindElement(By.LinkText(&quot;link&quot;)); &#x2F;&#x2F; find element by LinkText</span><br><span class="line">        linkElement.Click(); &#x2F;&#x2F; Click a button or link</span><br><span class="line"></span><br><span class="line">        IWebElement buttonElement &#x3D; driver.FindElement(By.CssSelector(&quot;body&quot;)); &#x2F;&#x2F; find element by CssSelector</span><br><span class="line"></span><br><span class="line">        IWebElement buttonElement &#x3D; driver.FindElement(By.ClassName(&quot;TestClass&quot;)); &#x2F;&#x2F; find element by class name</span><br><span class="line"></span><br><span class="line">        IWebElement textElement &#x3D; driver.FindElement(By.TagName(&quot;td&quot;)); &#x2F;&#x2F; find element by tag name</span><br><span class="line"></span><br><span class="line">        IWebElement linkElement &#x3D; driver.FindElement(By.PartialLinkText(&quot;Partial Text&quot;)); &#x2F;&#x2F; find element by PartialLinkText</span><br><span class="line"></span><br><span class="line">        IWebElement linkElement &#x3D; driver.FindElement(By.XPath(&quot;&#x2F;html&#x2F;body&#x2F;div[4]&#x2F;p&#x2F;a&quot;)); &#x2F;&#x2F; find element by XPath</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; this relative XPath will find all &lt;a&gt; elements with its text contains &#39;some text&#39;</span><br><span class="line">        IWebElement linkElement &#x3D; driver.FindElement(By.XPath(&quot;&#x2F;&#x2F;a[text()[contains(.,&#39;some text&#39;)]]&quot;)); &#x2F;&#x2F; find element by Relative XPath</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; WebDriverWait is given a timeout value indicating how long to wait for the condition.</span><br><span class="line">        WebDriverWait wait &#x3D; new WebDriverWait(driver, TimeSpan.FromSeconds(1));</span><br><span class="line">        &#x2F;&#x2F; Selenium will try to find the linkElement until the timeout value is reached</span><br><span class="line">        IWebElement linkElement &#x3D; wait.Until(d &#x3D;&gt; d.FineElement(By.LinkText(&quot;some text&quot;)));</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; Selecting multiple elements</span><br><span class="line">        ReadOnlyCollection&lt;IWebElement&gt; tableCells &#x3D; driver.FindElements(By.TagName(&quot;td&quot;));</span><br><span class="line"></span><br><span class="line">        Assert.That(&quot;first cell&quot;, tableCells[0].Text);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Selenium </tag>
            
            <tag> Functional Tests </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dependency Injection in .NET</title>
      <link href="2021/04/12/Dependency-Injection-in-NET/"/>
      <url>2021/04/12/Dependency-Injection-in-NET/</url>
      
        <content type="html"><![CDATA[<h2 id="what-is-dependency-injection"><a class="markdownIt-Anchor" href="#what-is-dependency-injection"></a> What is dependency injection?</h2><p>Dependency injection is a programming technique that makes a class independent of its dependencies. It achieves that by decoupling the usage of an object from its creation. This helps you to follow SOLID’s dependency inversion and single responsiblity principles.</p><h3 id="benefits-of-loose-coupling"><a class="markdownIt-Anchor" href="#benefits-of-loose-coupling"></a> Benefits of Loose Coupling</h3><ul><li>Easy to extend</li><li>Easy to test</li><li>Easy to maintain</li><li>Facilitates parallel development (rare conflict)</li><li>Facilitates late binding (runtime data binding)</li></ul><h3 id="dependency-injection-patterns"><a class="markdownIt-Anchor" href="#dependency-injection-patterns"></a> Dependency Injection Patterns</h3><ul><li>Constructor Injection</li><li>Property Injection</li><li>Method Injection</li><li>Ambient Context</li><li>Service Locator</li></ul><h2 id="application-overview"><a class="markdownIt-Anchor" href="#application-overview"></a> Application Overview</h2><p>The application contains four layers</p><ol><li>View (UI elements) such as the buttons and the list box</li><li>Presentation (UI logic): functions that the buttons call and the property that the data bound to the list box in the UI.</li><li>Data Access: Code that knows how to interact with the data store. It knows how to make a web service call, and then translate the results into objects that the Presentation layer can use.</li><li>Data Store: where we get the actual data, in this case, the web service.</li></ol><h3 id="tight-coupled-code"><a class="markdownIt-Anchor" href="#tight-coupled-code"></a> Tight Coupled Code</h3><p>In the initial code, all four layers are tightly coupled.</p><p>In the view layer, it creates PeopleViewModel()</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public PeopleViewerWindow()</span><br><span class="line">&#123;</span><br><span class="line">    InitializeComponent();</span><br><span class="line">    viewModel &#x3D; new PeopleViewModel();</span><br><span class="line">    this.DataContext &#x3D; viewModel;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>In the Presentation layer, it creates serviceReader()</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public PeopleViewModel()</span><br><span class="line">&#123;</span><br><span class="line">    DataReader &#x3D; new ServiceReader();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>In the Data Access layer, it hardcoded the web service url</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public class ServiceReader</span><br><span class="line">&#123;</span><br><span class="line">    WebClient client &#x3D; new WebClient();</span><br><span class="line">    string baseUri &#x3D; &quot;http:&#x2F;&#x2F;localhost:9874&#x2F;api&#x2F;people&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="potential-problems"><a class="markdownIt-Anchor" href="#potential-problems"></a> Potential problems</h3><ol><li><p>Hard to create unit test.<br />If I want to test UI element (like a button), I have to run the web services because they are tightly coupled. (PeopleViewerWindow needs PeopleViewModel which needs ServiceReader which needs WebClient).</p></li><li><p>Hard to extend<br />If I want to add another Data Store like read data from a CSV file or SQL DB, and I also want to have the option to choose to use cached data store. Then in the PeopleViewModel I need to write something like this</p></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">public PeopleViewModel() &#123;</span><br><span class="line">    switch(dataReaderType) &#123;</span><br><span class="line">        case &#39;service&#39;: DataReader &#x3D; new ServiceReader();</span><br><span class="line">            break;</span><br><span class="line">        case &#39;service_cached&#39;: DataReader &#x3D; new CachedServiceReader();</span><br><span class="line">            break;</span><br><span class="line">        case &#39;text&#39;: DataReader &#x3D; new CSVReader();</span><br><span class="line">            break;</span><br><span class="line">        case &#39;text_cached&#39;: DataReader &#x3D; new CachedCSVReader();</span><br><span class="line">            break;</span><br><span class="line">        case &#39;sql&#39;: DataReader &#x3D; new SQLReader();</span><br><span class="line">            break;</span><br><span class="line">        case &#39;sql_cached&#39;: DataReader &#x3D; new CachedSQLReader();</span><br><span class="line">            break;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>This breaks the Single Responsibility Principle, which is one of the SOLID principles. Because it is now doing too many things</p><ol><li>Presentation logic</li><li>Picking the data source (hardcoded web service url)</li><li>Managing object lifetime</li><li>Deciding when to use a cache</li></ol><h2 id="repository-pattern"><a class="markdownIt-Anchor" href="#repository-pattern"></a> Repository Pattern</h2><p>Mediates between the domain and data mapping layers using a collection-like interface for accessing domain objects.</p><p>It separates our application from the data storage technology.</p><p>In other words, we can say that a Repository Design Patternacts as a middleman or middle layer between the rest of the application and the data access logic. That means a repository pattern isolates all the data access code from the rest of the application. The advantage of doing so is that, if you need to do any change then you need to do in one place. Another benefit is that testing your controllers becomes easy because the testing framework need not run against the actual database access code.</p><p>The idea is that the repository knows how to communicate with the data store whether it is using HTTP, reading a file from the file system, or making a database call. It then takes the data that comes back and turns it into normal C# objects that the rest of the application can understand. This is exactly what the service reader does now. It makes a HTTP request to the web service, then parses the JSON result into Person objects that the application can use.</p><h3 id="crud-repository"><a class="markdownIt-Anchor" href="#crud-repository"></a> CRUD Repository</h3><p>The Interface Segregation Principle says that interfaces should only contain what the client needs. Normally a Repository should contain all Create, Read, Update and Delete. But in this case we only need Read.</p><h2 id="using-dependency-injection-to-build-loosely-coupled-application"><a class="markdownIt-Anchor" href="#using-dependency-injection-to-build-loosely-coupled-application"></a> Using Dependency Injection to Build Loosely-coupled Application</h2><p>Create a new interface</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public interface IPersonReader</span><br><span class="line">&#123;</span><br><span class="line">    IEnumerable&lt;Person&gt; GetPeople();</span><br><span class="line">    Person GetPerson(int id);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>In the Presentation layer, inject IPersonReader</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public PeopleViewModel(IPersonReader dataReader)</span><br><span class="line">&#123;</span><br><span class="line">    DataReader &#x3D; dataReader;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Now we don’t create new ServiceReader in the Presentation layer, instead we make it someone else’s responsibility by adding IPersonReader to a contrcutor parameter.</p><p>IPersonReader could be ServiceReader or SQLReader or CSVReader but PeopleViewModel doesn’t care.</p><p>IPersonReader need to be created before creating PeopleViewModel.</p><p>In the UI layer, inject PeopleViewModel</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public PeopleViewerWindow(PeopleViewModel peopleViewModel)</span><br><span class="line">&#123;</span><br><span class="line">    InitializeComponent();</span><br><span class="line">    viewModel &#x3D; peopleViewModel;</span><br><span class="line">    this.DataContext &#x3D; viewModel;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Similar things happened in UI layer, now we don’t create new PeopleViewModel, instead we inject it to the constrctor.</p><p>PeopleViewModel need to be created before creating PeopleViewerWindow but it doesn’t care, as long as it is being passed to the constructor.</p><h3 id="dependency-inversion-principle"><a class="markdownIt-Anchor" href="#dependency-inversion-principle"></a> Dependency Inversion Principle</h3><p>This is Dependency Inversion Principle in action, now the View Model and the Viewer Window are no longer responsible for creating or managing the lifetime of the dependencies. Instead, the dependency, the data reader, is given to the View Model and the Viewer Window to use.</p><h3 id="object-composition"><a class="markdownIt-Anchor" href="#object-composition"></a> Object composition</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">private static void ComposeObjects()</span><br><span class="line">&#123;</span><br><span class="line">    var serviceReader &#x3D; new ServiceReader();</span><br><span class="line">    var peopleViewModel &#x3D; new PeopleViewModel(serviceReader);</span><br><span class="line">    Application.Current.MainWindow &#x3D; new PeopleViewerWindow(peopleViewModel);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>The ServiceReader and PeopleViewModel objects have been created when the app starts. This code will run OnAppStarts.</p><h3 id="get-data-from-csv-file"><a class="markdownIt-Anchor" href="#get-data-from-csv-file"></a> Get Data from CSV file</h3><p>Because now the presentation layer and the data access layer are loosely coupled, if we want to change the data source, we could just create a CSVReader() instead of ServiceReader()</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">private static void ComposeObjects()</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F;var serviceReader &#x3D; new ServiceReader();</span><br><span class="line">    var serviceReader &#x3D; new CSVReader();</span><br><span class="line">    var peopleViewModel &#x3D; new PeopleViewModel(serviceReader);</span><br><span class="line">    Application.Current.MainWindow &#x3D; new PeopleViewerWindow(peopleViewModel);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>We just need to implement CSVReader class and create a new CSV object. We don’t need to change any existing code.</p><h2 id="decorator-pattern"><a class="markdownIt-Anchor" href="#decorator-pattern"></a> Decorator pattern</h2><p>Wrap an existing interface to add functionality</p><p>The idea is we wrap an existing data reader, add the caching functionality and then expose the same data reader interface to the outside world.</p><p>Our service reader implements the IPersonReader interface. We take that service reader and wrap it in a caching reader. This adds the caching funcationality that we need. The caching reader is also an IPersonReader. So it looks just like any other data reader to the rest of the application. By using a Decorator, we can wrap any of our existing data readers.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">public class CachingReader : IPersonReader</span><br><span class="line">&#123;</span><br><span class="line">    private IPersonReader _wrappedReader;</span><br><span class="line">    private TimeSpan _cacheDuration &#x3D; new TimeSpan(0, 0, 30);</span><br><span class="line"></span><br><span class="line">    private IEnumerable&lt;Person&gt; _cachedItems;</span><br><span class="line">    private DateTime _dataDateTime;</span><br><span class="line"></span><br><span class="line">    public CachingReader(IPersonReader wrappedReader)</span><br><span class="line">    &#123;</span><br><span class="line">        _wrappedReader &#x3D; wrappedReader;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public IEnumerable&lt;Person&gt; GetPeople() &#123;...&#125;</span><br><span class="line"></span><br><span class="line">    public Person GetPerson(int id) &#123;...&#125;</span><br><span class="line"></span><br><span class="line">    private bool IsCacheValid &#123;...&#125;</span><br><span class="line"></span><br><span class="line">    private void ValidateCache() &#123;...&#125;</span><br><span class="line"></span><br><span class="line">    private void InvalidateCache() &#123;...&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>In this implementation, CachingReader implements IPersonReader, so it also has GetPeople and GetPerson functions. But it has some other functions (extra caching funcationality).</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">private static void ComposeObjects()</span><br><span class="line">&#123;</span><br><span class="line">    var wrappedReader &#x3D; new ServiceReader();</span><br><span class="line">    var reader &#x3D; new CachingReader(wrappedReader);</span><br><span class="line">    var peopleViewModel &#x3D; new PeopleViewModel(reader);</span><br><span class="line">    Application.Current.MainWindow &#x3D; new PeopleViewerWindow(peopleViewModel);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>When we want to use the CachingReader, we could first create a ServiceReader, so it has GetPeople and GetPerson function, and we inject this ServiceReader to the CachingReader’s contructor, which adds the extra caching funcationality.</p><p>This follows the <strong>Open/Closed Principle</strong>. Existing data readers can be extended without being modified.</p><p>This also follows the <strong>Liskov substitution principle</strong>. This principle says that descendent classes (CachingReader) should behave the same way the base class (ServiceReader) behave. Meaning we could substitude a child class (CachingReader) for a base class (ServiceReader) in our application, and the application does not know the difference.</p><p>We have extended the behavior in the child class, but the calling code does not know the difference.</p><h2 id="unit-testing-with-dependency-injection"><a class="markdownIt-Anchor" href="#unit-testing-with-dependency-injection"></a> Unit Testing with Dependency Injection</h2><p>Before when we need to test the ViewModel, the data service needs to run. Because of the old code looks like this.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public PeopleViewModel() &#123;</span><br><span class="line">    DataReader &#x3D; new ServiceReader();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public class ServiceReader() &#123;</span><br><span class="line">    WebClient client &#x3D; new WebClient();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Now we can just create a fake Reader and provide some fake Person data. The test of ViewModel is isolated from the Data Store.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[Test]</span><br><span class="line">public void Test() &#123;</span><br><span class="line">    &#x2F;&#x2F; Arrange</span><br><span class="line">    IPersonReader reader &#x3D; GetFakeReader();</span><br><span class="line">    var viewModel &#x3D; new PeopleViewModel(reader);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; Act</span><br><span class="line">    viewModel.RefreshPeople();</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; Assert</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Below is the real unit test code. By passing the FakeReader() to the PeopleViewModel(), we don’t need to create WebClient any more, which makes it easier to write unit test.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[TestMethod]</span><br><span class="line">public void People_OnRefreshPeople_IsPopulated()</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; Arrange</span><br><span class="line">    var reader &#x3D; new FakeReader();</span><br><span class="line">    var viewModel &#x3D; new PeopleViewModel(reader);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; Act</span><br><span class="line">    viewModel.RefreshPeople();</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; Assert</span><br><span class="line">    Assert.IsNotNull(viewModel.People);</span><br><span class="line">    Assert.AreEqual(2, viewModel.People.Count());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Next we want to test CSVReader(), but we need to put a real CSV data file in the project directory to make it work because it is expecting a filePath.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public CSVReader()</span><br><span class="line">&#123;</span><br><span class="line">    string filePath &#x3D; AppDomain.CurrentDomain.BaseDirectory + &quot;People.txt&quot;;</span><br><span class="line">    FileLoader &#x3D; new CSVFileLoader(filePath);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Luckly, the FileLoader is a public property which can be overrided.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public ICSVFileLoader FileLoader &#123; get; set; &#125;</span><br></pre></td></tr></table></figure><p>So we could create a FakeFileReader that provides the fake data. We override the property with our own behavior so it doesn’t depend on the file system. This is called <strong>Property Injection</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[TestMethod]</span><br><span class="line">public void GetPeople_WithGoodRecords_ReturnsAllRecords()</span><br><span class="line">&#123;</span><br><span class="line">    var reader &#x3D; new CSVReader();</span><br><span class="line">    reader.FileLoader &#x3D; new FakeFileLoader(&quot;Good&quot;);</span><br><span class="line"></span><br><span class="line">    var result &#x3D; reader.GetPeople();</span><br><span class="line"></span><br><span class="line">    Assert.AreEqual(2, result.Count());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="property-injection"><a class="markdownIt-Anchor" href="#property-injection"></a> Property Injection</h3><p>Class property is initialized for standard behavior. By default, the standard behavior is used. Property can be set to provide alternate behavior.</p><p>One question is, why not use Constructor Injection like what we did in the previous charpter? Instead of creating CSVFileLoader in the CSVReader constructor, we could inject FileLoader.</p><p>This is because we only use FakeFileLoader when doing unit test. In production, it will use CSVFileLoader 100% of the time.</p><p>So Constructor injection is only good for when we want to force a decision on a dependency. Property injection is good for when we have a default dependency (CSVFileLoader) that we want to use most of the time.</p><h2 id="dependency-injection-containers"><a class="markdownIt-Anchor" href="#dependency-injection-containers"></a> Dependency Injection Containers</h2><ul><li>Autofac</li><li>Ninject</li><li>Unity</li><li>Castle Windsor</li><li><a href="http://Spring.NET">Spring.NET</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Dependency Injection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SQL Fundamentals</title>
      <link href="2021/04/11/SQL-Fundamentals/"/>
      <url>2021/04/11/SQL-Fundamentals/</url>
      
        <content type="html"><![CDATA[<h2 id="where"><a class="markdownIt-Anchor" href="#where"></a> WHERE</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM Table WHERE ColumnName &lt;&gt; &#39;Some value&#39;.</span><br></pre></td></tr></table></figure><p>This Query will not return Null values.</p><p>To return Null values we need to check if <code>Column is NULL</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM Table WHERE ColumnName IS NULL</span><br></pre></td></tr></table></figure><h2 id="like"><a class="markdownIt-Anchor" href="#like"></a> LIKE</h2><p>If a column has type <code>varchar(50)</code>, and in one row its value doesn’t have length 50. Spaces will be added to the end.</p><p>So <code>WHERE ColumnName LIKE '%SomeValue'</code> will return nothing. You can write the query like this. <code>WHERE ColumnName LIKE '%SomeValue%'</code></p><h2 id="functions"><a class="markdownIt-Anchor" href="#functions"></a> Functions</h2><ul><li>LEFT(): return the left most char from string</li><li>RIGHT(): return the right most char from string</li><li>LTRIM(): remove the spaces on the left of string</li><li>RTRIM(): remove the spaces on the right of string</li></ul><h2 id="group-by-and-having"><a class="markdownIt-Anchor" href="#group-by-and-having"></a> GROUP BY and HAVING</h2><p>GROUP BY will group values into different groups. HAVING can filter out some values after GROUP BY.</p><h2 id="join"><a class="markdownIt-Anchor" href="#join"></a> JOIN</h2><h3 id="inner-join"><a class="markdownIt-Anchor" href="#inner-join"></a> INNER JOIN</h3><p>The default JOIN, rows will be returned if they appear in both tables</p><h3 id="cross-join"><a class="markdownIt-Anchor" href="#cross-join"></a> CROSS JOIN</h3><p>Will return the combination of rows from Table A and Table B. If Table A has 4 rows and Table B has 10 row, it will return 40 rows.</p><h3 id="outer-join"><a class="markdownIt-Anchor" href="#outer-join"></a> OUTER JOIN</h3><ul><li>LEFT OUTER JOIN (LEFT JOIN)</li></ul><p>The OUTER keyword is optional. LEFT OUTER JOIN is the same as LEFT JOIN. Values will be returned if it appear in the LEFT table. It doesn’t need to be in the RIGHT table.</p><ul><li>RIGHT OUTER JOIN (RIGHT JOIN)</li></ul><p>RIGHT OUTER JOIN is the same as RIGHT JOIN. Values will be returned if it appear in the RIGHT table. It doesn’t need to be in the LEFT table.</p><ul><li>FULL OUTER JOIN (FULL JOIN)</li></ul><p>Values will be returned if they appear in either LEFT table or RIGHT table.</p><h2 id="union"><a class="markdownIt-Anchor" href="#union"></a> UNION</h2><p>UNION can be placed between SELECT queries.</p><p>Rows will be appended for each SELECT.</p><p>Each SELECT must have same number of Columns and DataType needs to match.</p><h3 id="union-all"><a class="markdownIt-Anchor" href="#union-all"></a> UNION ALL</h3><p>If SELECT queries return same rows, they will all be returned.</p><h2 id="insert"><a class="markdownIt-Anchor" href="#insert"></a> INSERT</h2><h3 id="insert-select"><a class="markdownIt-Anchor" href="#insert-select"></a> INSERT SELECT</h3><p>The values returned from SELECT will be inserted immediately. Works will multiple rows.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO TableA(ColumnA, ColumnB)</span><br><span class="line">SELECT ColumnA, ColumnB</span><br><span class="line">FROM TableB</span><br></pre></td></tr></table></figure><h2 id="update-and-delete"><a class="markdownIt-Anchor" href="#update-and-delete"></a> UPDATE and DELETE</h2><p>If we want to delete some value in a row, we could SET it to NULL</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UPDATE Table SET ColumnName &#x3D; NULL WHERE RowId &#x3D; 1</span><br></pre></td></tr></table></figure><h2 id="create-table"><a class="markdownIt-Anchor" href="#create-table"></a> CREATE TABLE</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE TableName </span><br><span class="line">(</span><br><span class="line">ProductId int NOT NULL,</span><br><span class="line">Quantity int NOT NULL DEFAULT 1,</span><br><span class="line">ProductName varchar(10) NULL</span><br><span class="line">);</span><br></pre></td></tr></table></figure><h2 id="create-view"><a class="markdownIt-Anchor" href="#create-view"></a> CREATE VIEW</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CREATE VIEW ViewName AS </span><br><span class="line">SELECT *</span><br><span class="line">FROM Table</span><br><span class="line">WHERE ...</span><br></pre></td></tr></table></figure><p>VIEW is a temp Table, it can save complex SELECT queries and can be reused later.</p><h2 id="transaction"><a class="markdownIt-Anchor" href="#transaction"></a> TRANSACTION</h2><p>If there is error in the middle of a TRANSACTION, it will not COMMIT</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">BEGIN TRANSACTION</span><br><span class="line">-- Multiple UPDATE&#x2F;INSERT&#x2F;DELETE queries</span><br><span class="line">COMMIT TRANSACTION</span><br></pre></td></tr></table></figure><h3 id="savepoint-and-rollback"><a class="markdownIt-Anchor" href="#savepoint-and-rollback"></a> SAVEPOINT and ROLLBACK</h3><p>If error happens in the middle of a TRANSACTION and we don’t want to ROLLBACK to the start. We can create SAVEPOINT and let it ROLLBACK to that point.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">BEGIN TRANSACTION</span><br><span class="line"></span><br><span class="line">INSERT INTO Table(ColumnA, ColumnB) VALUES (1, 2);</span><br><span class="line"></span><br><span class="line">SAVE TRANSACTION PointOne;</span><br><span class="line"></span><br><span class="line">INSERT INTO Table(ColumnA, ColumnB) VALUE (1, 2);</span><br><span class="line"></span><br><span class="line">If @@ERROR &lt;&gt; 0 ROLLBACK TRANSACTION PointOne;</span><br><span class="line"></span><br><span class="line">COMMIT TRANSACTION</span><br></pre></td></tr></table></figure><p>In the above code, if the second INSERT failed, @@ERROR will return a non-zero value, it will ROLLBACK to SAVEPOINT PointOne.</p><h2 id="constraint"><a class="markdownIt-Anchor" href="#constraint"></a> Constraint</h2><ul><li>Primary key</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE Table </span><br><span class="line">(</span><br><span class="line">    RowId int NOT NULL PRIMARY KEY</span><br><span class="line">);</span><br></pre></td></tr></table></figure><ul><li>Foreign key</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE Table </span><br><span class="line">(</span><br><span class="line">    RowId int NOT NULL PRIMARY KEY,</span><br><span class="line">    ForeignId int NOT NULL REFERENCES TableB(Id)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>Foreign Key values must come from Primary key in the other table.</p><p>Primary key records cannot be deleted unless all Foreign key records were deleted first.</p><p>Some DBMS support CASCADE DELETE, which will delete the Primary key record and related Foreign key record in other tables.</p><ul><li>UNIQUE</li></ul><p>One table could have multiple UNIQUE Constraint.</p><ul><li>CHECK</li></ul><p>Further restrict values in this Column</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE Table </span><br><span class="line">(</span><br><span class="line">    quantity int NOT NULL CHECK (quantity &gt; 0),</span><br><span class="line">    gender varchar(1) NOT NULL CHECK (gender LIKE &#39;[MF]&#39;)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><h2 id="index"><a class="markdownIt-Anchor" href="#index"></a> INDEX</h2><p>If you create an index on a Column, DB will sort this Column and store it. Next time you SELECT by this Column, DB will search faster (binary search) because it is sorted.</p><p>But add index to a Column will decrease the efficiency of doing UPDATE/INSERT/DELETE on those Columns. Because DB needs to update INDEX on those Columns.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CREATE INDEX Table_Column_Index</span><br><span class="line">ON Table (Column);</span><br></pre></td></tr></table></figure><h2 id="trigger"><a class="markdownIt-Anchor" href="#trigger"></a> TRIGGER</h2><p>TRIGGER will be execute when certain changes happen to a table</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">CREATE TRIGGER Table_trigger</span><br><span class="line">ON Table</span><br><span class="line">FOR INSERT, UPDATE</span><br><span class="line">AS </span><br><span class="line">UPDATE Table</span><br><span class="line">SET ColumnName &#x3D; Upper(ColumnName)</span><br><span class="line">WHERE Table.Id &#x3D; inserted.Id</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>.NET with NUnit Test</title>
      <link href="2021/04/08/NET-with-NUnit-Test/"/>
      <url>2021/04/08/NET-with-NUnit-Test/</url>
      
        <content type="html"><![CDATA[<h2 id="what-is-nunit"><a class="markdownIt-Anchor" href="#what-is-nunit"></a> What is NUnit?</h2><p>NUnit is a unit-testing framework for all .Net languages. Initially ported from JUnit, the current production release, version 3, has been completely rewritten with many new features and support for a wide range of .NET platforms.</p><h3 id="nuget-packages"><a class="markdownIt-Anchor" href="#nuget-packages"></a> NuGet Packages</h3><ol><li>NUnit</li><li>NUnit3TestAdapter</li><li>Microsoft.NET.Test.Sdk</li></ol><h3 id="your-first-nunit-test-case"><a class="markdownIt-Anchor" href="#your-first-nunit-test-case"></a> Your First NUnit Test Case</h3><p>Add <code>[TestFixture]</code> and <code>[Test]</code> to mark code as tests</p><p>Test can be run in Test Explorer and in Command Line</p><h2 id="why-write-automated-tests"><a class="markdownIt-Anchor" href="#why-write-automated-tests"></a> Why Write Automated Tests?</h2><p>Help to find defects and regressions. When we make a change to the project, we may find that unintentionally break one of the existing tests. Something that once working is no longer working.</p><p>Automated Tests give us greater confidence that the software is working as it should.</p><h2 id="understanding-the-nunit-test-framework"><a class="markdownIt-Anchor" href="#understanding-the-nunit-test-framework"></a> Understanding the NUnit Test Framework</h2><ul><li><p>NUnit Library</p><ul><li>Attributes e.g. <code>[Test]</code></li><li>Assertions</li></ul></li><li><p>Test Runner</p><ul><li>Recognizes attributes</li><li>Execute test methods</li><li>Report test results</li><li>Test explorer</li><li>donet test</li></ul></li></ul><h3 id="nunit-attributes-overview"><a class="markdownIt-Anchor" href="#nunit-attributes-overview"></a> NUnit attributes Overview</h3><ol><li><code>[TestFixture]</code>: Mark a class that contains tests</li><li><code>[Test]</code>: Mark a method as a test</li><li><code>[Category]</code>: Organize tests into categories</li><li><code>[TestCase]</code>: Data driven test cases</li><li><code>[Values]</code>: Data driven test parameters</li><li><code>[Sequential]</code>: How to combine test data</li><li><code>[SetUp]</code>: Run code before each test</li><li><code>[OneTimeSetUp]</code>: Run code before first test in class</li></ol><h3 id="nunite-assertions-overview"><a class="markdownIt-Anchor" href="#nunite-assertions-overview"></a> NUnite Assertions Overview</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Constraint Model of assertions (newer)</span><br><span class="line">Assert.That(sut.Years, Is.EqualTo(1));</span><br><span class="line">Assert.That(test result, constraint instance);</span><br></pre></td></tr></table></figure><p>This Classic Model is still supported but since no new features have been added to it for some time. the constraint-based model must be used in order to have full access to NUnit’s capabilities.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Classic Model of assertions (older)</span><br><span class="line">Assert.AreEqual(1, sut.Years);</span><br><span class="line">Assert.NotNull(sut.Years);</span><br><span class="line">Assert.xyz(...);</span><br></pre></td></tr></table></figure><h3 id="the-logical-arrange-act-assert-test-phases"><a class="markdownIt-Anchor" href="#the-logical-arrange-act-assert-test-phases"></a> The Logical Arrange, Act, Assert Test Phases</h3><ol><li>Arrange: Set up test objects, initialize test data</li><li>Act: call methods, set property, to cause some effect in the project</li><li>Assert: compare returned value/end state with expected</li></ol><h3 id="qualities-of-good-tests"><a class="markdownIt-Anchor" href="#qualities-of-good-tests"></a> Qualities of Good Tests</h3><ul><li>Fast</li><li>Repeatable</li><li>Isolated: One Test should not depend on others to run</li><li>Trustworthy</li><li>Valuable</li></ul><h2 id="asserting-on-different-types-of-results"><a class="markdownIt-Anchor" href="#asserting-on-different-types-of-results"></a> Asserting on Different Types of Results</h2><p><strong>Asserts</strong>: Evaluate and verify the outcome of a test based on a returned result, final object state, or the occurence of events observed during execution. An assert should either pass or fail.</p><h3 id="how-many-asserts-per-test"><a class="markdownIt-Anchor" href="#how-many-asserts-per-test"></a> How many asserts per test?</h3><p>A single test usually focuses on testing a single ‘behaviour’. Multiple asserts are usually ok if all the asserts are related to testing this single behaviour.</p><h3 id="asserting-on-equality"><a class="markdownIt-Anchor" href="#asserting-on-equality"></a> Asserting on Equality</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; compare value</span><br><span class="line">Assert.That(a, Is.EqualTo(...));</span><br><span class="line">Assert.That(a, Is.Not.EqualTo(...));</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; compare reference</span><br><span class="line">Assert.That(a, Is.SameAs(...));</span><br><span class="line">Assert.That(a, Is.Not.SameAs(...));</span><br></pre></td></tr></table></figure><h3 id="adding-custom-failure-message"><a class="markdownIt-Anchor" href="#adding-custom-failure-message"></a> Adding custom failure message</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Assert.That(a, Is.EqualTo(...), &quot;Custom Error Message&quot;);</span><br></pre></td></tr></table></figure><h3 id="asserting-on-floating-numbers"><a class="markdownIt-Anchor" href="#asserting-on-floating-numbers"></a> Asserting on Floating Numbers</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Assert.That(a, Is.EqualTo(0.33).Within(0.001));</span><br><span class="line">Assert.That(a, Is.EqualTo(0.33).Within(10).Percent);</span><br></pre></td></tr></table></figure><h3 id="asserting-on-null-values"><a class="markdownIt-Anchor" href="#asserting-on-null-values"></a> Asserting on Null Values</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">string name &#x3D; &quot;yuan&quot;;</span><br><span class="line"></span><br><span class="line">Assert.That(name, Is.Null); &#x2F;&#x2F; fail</span><br><span class="line">Assert.That(name, Is.Not.Null); &#x2F;&#x2F; pass</span><br></pre></td></tr></table></figure><h3 id="asserting-on-string-values"><a class="markdownIt-Anchor" href="#asserting-on-string-values"></a> Asserting on String Values</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">string name &#x3D; &quot;yuan&quot;;</span><br><span class="line"></span><br><span class="line">Assert.That(name, Is.Empty); &#x2F;&#x2F; fail</span><br><span class="line">Assert.That(name, Is.Not.Empty); &#x2F;&#x2F; pass</span><br><span class="line"></span><br><span class="line">Assert.That(name, Is.EqualTo(&quot;yuan&quot;)); &#x2F;&#x2F; pass</span><br><span class="line">Assert.That(name, Is.EqualsTo(&quot;YUAN&quot;)); &#x2F;&#x2F; fail, case-sensitive</span><br><span class="line">Assert.That(name, Is.EqualTo(&quot;YUAN&quot;).IgnoreCase); &#x2F;&#x2F; pass</span><br><span class="line"></span><br><span class="line">Assert.That(name, Does.StartWith(&quot;yu&quot;)); &#x2F;&#x2F; pass</span><br><span class="line">Assert.That(name, Does.EndWith(&quot;an&quot;)); &#x2F;&#x2F; pass</span><br><span class="line">Assert.That(name, Does.Contain(&quot;ua)); &#x2F;&#x2F; pass</span><br><span class="line">Assert.That(name, Does.Not.Contain(&quot;kk&quot;)); &#x2F;&#x2F; pass</span><br><span class="line">Assert.That(name, Does.StartWith(&quot;yu&quot;)</span><br><span class="line">                    .And</span><br><span class="line">                    .EndWith(&quot;an&quot;)); &#x2F;&#x2F; pass</span><br><span class="line">Assert.That(name, Does.StartWith(&quot;kk&quot;)</span><br><span class="line">                    .Or</span><br><span class="line">                    .EndWith(&quot;an&quot;)); &#x2F;&#x2F; pass</span><br></pre></td></tr></table></figure><h3 id="asserting-on-boolean-values"><a class="markdownIt-Anchor" href="#asserting-on-boolean-values"></a> Asserting on Boolean Values</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">bool isTrue &#x3D;  true;</span><br><span class="line"></span><br><span class="line">Assert.That(isTrue); &#x2F;&#x2F; pass</span><br><span class="line">Assert.That(isTrue, Is.True); &#x2F;&#x2F; pass</span><br><span class="line"></span><br><span class="line">bool isFalse &#x3D; false;</span><br><span class="line"></span><br><span class="line">Assert.That(isFalse &#x3D;&#x3D; false); &#x2F;&#x2F; pass</span><br><span class="line">Assert.That(isFalse, Is.False); &#x2F;&#x2F; pass</span><br><span class="line">Assert.That(isFalse, Is.Not.True); &#x2F;&#x2F; pass</span><br></pre></td></tr></table></figure><h3 id="asserting-within-ranges"><a class="markdownIt-Anchor" href="#asserting-within-ranges"></a> Asserting within Ranges</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">int i &#x3D; 42;</span><br><span class="line"></span><br><span class="line">Assert.That(i, Is.GreaterThan(42)); &#x2F;&#x2F; fail</span><br><span class="line">Assert.That(i, Is.GreaterThanOrEqualTo(42)); &#x2F;&#x2F; pass</span><br><span class="line">Assert.That(i, Is.LessThan(42)); &#x2F;&#x2F; fail</span><br><span class="line">Assert.That(i, Is.GreaterThanOrEqualTo(42)); &#x2F;&#x2F; pass</span><br><span class="line">Assert.That(i, Is.InRange(40, 50)); &#x2F;&#x2F; pass</span><br><span class="line"></span><br><span class="line">DateTiem d1 &#x3D; new DateTime(2021, 2, 20);</span><br><span class="line">DateTiem d2 &#x3D; new DateTime(2021, 2, 25);</span><br><span class="line"></span><br><span class="line">Assert.That(d1, Is.EqualTo(d2)); &#x2F;&#x2F; fail</span><br><span class="line">Assert.That(d1, Is.EqualTo(d2).Within(4).Days); &#x2F;&#x2F; fail</span><br><span class="line">Assert.That(d1, Is.EqualTo(d2).Within(5).Days); &#x2F;&#x2F; pass</span><br></pre></td></tr></table></figure><h3 id="asserting-on-objects"><a class="markdownIt-Anchor" href="#asserting-on-objects"></a> Asserting on Objects</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">class Product &#123;</span><br><span class="line">    int ProductId &#123;get; set;&#125;</span><br><span class="line">    string ProductName &#123;get; set;&#125;</span><br><span class="line"></span><br><span class="line">    Product(int ProductId, string ProductName) &#123;</span><br><span class="line">        this.ProductId &#x3D; ProductId;</span><br><span class="line">        this.ProductName &#x3D; ProductName;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">var products &#x3D; new List&lt;Product&gt; &#123;</span><br><span class="line">    new Product(1, &quot;a&quot;),</span><br><span class="line">    new Product(2, &quot;b&quot;),</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">Assert.That(products, Has.Exactly(2).Items); &#x2F;&#x2F; pass</span><br><span class="line">Assert.That(products, Is,Unique); &#x2F;&#x2F; pass</span><br><span class="line">Assert.That(products, Has.Exactly(1)</span><br><span class="line">                        .Property(&quot;ProductName&quot;).EqualTo(&quot;a&quot;)</span><br><span class="line">                        .And</span><br><span class="line">                        .Property(&quot;ProductId).EqualTo(1));</span><br><span class="line"></span><br><span class="line">Assert.That(products, Has.Exactly(1)</span><br><span class="line">                        .Matches&lt;Product&gt;(</span><br><span class="line">                        item &#x3D;&gt; item.ProductName &#x3D;&#x3D; &quot;a&quot; &amp;&amp;</span><br><span class="line">                                item.ProductId &#x3D;&#x3D; 1</span><br><span class="line">                        ));</span><br></pre></td></tr></table></figure><h2 id="controlling-test-execution"><a class="markdownIt-Anchor" href="#controlling-test-execution"></a> Controlling Test Execution</h2><p>Use <code>[Ignore]</code> to skip tests. <code>[Ignore]</code> could also be put before class to skip the entire test class</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[Test]</span><br><span class="line">[Ignore(&quot;Custom reason why we need to skip this test&quot;)]</span><br><span class="line">public void TestWillNotRun() &#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Use <code>[Category]</code> to add test cases to categories, we can only run tests for certain category.</p><p>In Test Explorer, we can group tests by <strong>Traits</strong>, which is just another name for Category</p><p>One Test Case can belongs to multiple <code>[Category]</code>.</p><p><code>[Category]</code> can be applied to <strong>Class</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[Test]</span><br><span class="line">[Category(&quot;Category 1&quot;)]</span><br><span class="line">public void TestInCategoryOne() &#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>[SetUp]</code> code will be executed before each test. So it is a good place to define variables and objects.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">public class TestClass &#123;</span><br><span class="line">    private List&lt;Product&gt; products;</span><br><span class="line">    private string test;</span><br><span class="line"></span><br><span class="line">    [SetUp]</span><br><span class="line">    public void Setup() &#123;</span><br><span class="line">        products &#x3D; new List&lt;Products&gt; &#123;</span><br><span class="line">            new Product(1, &quot;a&quot;),</span><br><span class="line">            new Product(2, &quot;b&quot;),</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        test &#x3D; &quot;test&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>[TearDown]</code> code will be executed after each test, it is the place to dispose all unnecessary objects</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public class TestClass &#123;</span><br><span class="line">    [TearDown]</span><br><span class="line">    public void Setup() &#123;</span><br><span class="line">        if (products !&#x3D; null) &#123;</span><br><span class="line">            ((IDisposable)products).Dispose();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>[OneTimeSetUp]</code> code will be executed once before the first test case. Define objects that will not be modified by test cases here.</p><p><code>[OneTimeTearDown]</code> code will be executed once after the last test case. Dispose any objects here.</p><h2 id="data-driven-tests-and-reducing-code-duplication"><a class="markdownIt-Anchor" href="#data-driven-tests-and-reducing-code-duplication"></a> Data Driven Tests and Reducing Code Duplication</h2><p><code>[TestCase]</code>: If we want to run the same test but with different data, we could pass different variables into the test function.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[Test]</span><br><span class="line">[TestCase(200_000, 6.5, 30, 1264.14)]</span><br><span class="line">[TestCase(200_000, 10, 30, 1755.14)]</span><br><span class="line">[TestCase(500_000, 10, 30, 4387.86)]</span><br><span class="line">public void CalculateCorrectMonthlyRepayment(decimal principal, decimal interestRate, int termInYears, decimal expectedMonthlyPayment)</span><br><span class="line">&#123;</span><br><span class="line">    var sut &#x3D; new LoanRepaymentCalculator();</span><br><span class="line"></span><br><span class="line">    var monthlyPayment &#x3D; sut.CalculateMonthlyRepayment(</span><br><span class="line">                            new LoanAmount(&quot;USD&quot;, principal), interestRate, new LoanTerm(termInYears));</span><br><span class="line"></span><br><span class="line">    Assert.That(monthlyPayment, Is.EqualTo(expectedMonthlyPayment));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[Test]</span><br><span class="line">[TestCase(200_000, 6.5, 30, ExpectedResult &#x3D; 1264.14)]</span><br><span class="line">[TestCase(200_000, 10, 30, ExpectedResult &#x3D; 1755.14)]</span><br><span class="line">[TestCase(500_000, 10, 30, ExpectedResult &#x3D; 4387.86)]</span><br><span class="line">public decimal CalculateCorrectMonthlyRepayment_SimplifiedTestCase(decimal principal, decimal interestRate, int termInYears)</span><br><span class="line">&#123;</span><br><span class="line">    var sut &#x3D; new LoanRepaymentCalculator();</span><br><span class="line"></span><br><span class="line">    return sut.CalculateMonthlyRepayment(new LoanAmount(&quot;USD&quot;, principal), interestRate, new LoanTerm(termInYears));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="create-test-case-from-centralized-data-class"><a class="markdownIt-Anchor" href="#create-test-case-from-centralized-data-class"></a> Create Test Case from Centralized Data Class</h3><p><code>[TestCaseSource(typeof(Class_Name), &quot;Function_Name&quot;)]</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[Test]</span><br><span class="line">[TestCaseSource(typeof(MonthlyRepaymentTestData), &quot;TestCases&quot;)]</span><br><span class="line">public void CalculateCorrectMonthlyRepayment_Centralized(decimal principal, decimal interestRate, int termInYears, decimal expectedMonthlyPayment)</span><br><span class="line">&#123;</span><br><span class="line">    var sut &#x3D; new LoanRepaymentCalculator();</span><br><span class="line"></span><br><span class="line">    var monthlyPayment &#x3D; sut.CalculateMonthlyRepayment(</span><br><span class="line">                            new LoanAmount(&quot;USD&quot;, principal), interestRate, new LoanTerm(termInYears));</span><br><span class="line"></span><br><span class="line">    Assert.That(monthlyPayment, Is.EqualTo(expectedMonthlyPayment));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="create-test-case-with-data-from-file"><a class="markdownIt-Anchor" href="#create-test-case-with-data-from-file"></a> Create Test Case with Data from File</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[Test]</span><br><span class="line">[TestCaseSource(typeof(MonthlyRepaymentCsvData), &quot;GetTestCases&quot;, new object[] &#123; &quot;Data.csv&quot; &#125;)]</span><br><span class="line">public void CalculateCorrectMonthlyRepayment_Csv(decimal principal, decimal interestRate, int termInYears, decimal expectedMonthlyPayment)</span><br><span class="line">&#123;</span><br><span class="line">    var sut &#x3D; new LoanRepaymentCalculator();</span><br><span class="line"></span><br><span class="line">    var monthlyPayment &#x3D; sut.CalculateMonthlyRepayment(</span><br><span class="line">                            new LoanAmount(&quot;USD&quot;, principal), interestRate, new LoanTerm(termInYears));</span><br><span class="line"></span><br><span class="line">    Assert.That(monthlyPayment, Is.EqualTo(expectedMonthlyPayment));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="create-test-cases-with-values-sequential-and-range"><a class="markdownIt-Anchor" href="#create-test-cases-with-values-sequential-and-range"></a> Create Test Cases with Values, Sequential and Range</h3><p>Without <code>[Sequential]</code>, it will create 3 * 3 * 3 = 27 test cases<br />With <code>[Sequential]</code>, it will only create 3 test cases</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[Test]</span><br><span class="line">[Sequential]</span><br><span class="line">public void CalculateCorrectMonthlyRepayment_Combinatorial(</span><br><span class="line">    [Values(100_000, 200_000, 500_000)] decimal principal,</span><br><span class="line">    [Values(6.5, 10, 20)] decimal interestRate,</span><br><span class="line">    [Values(10, 20, 30)] int termInYears)</span><br><span class="line">&#123;</span><br><span class="line">    var sut &#x3D; new LoanRepaymentCalculator();</span><br><span class="line"></span><br><span class="line">    var monthlyPayment &#x3D; sut.CalculateMonthlyRepayment(new LoanAmount(&quot;USD&quot;, principal), interestRate, new LoanTerm(termInYears));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="create-custom-category-attribute"><a class="markdownIt-Anchor" href="#create-custom-category-attribute"></a> Create Custom Category Attribute</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[AttributeUsage(AttributeTargets.Method | AttributeTargets.Class, AllowMultiple &#x3D; false)]</span><br><span class="line">class ProductComparisonAttribute : CategoryAttribute</span><br><span class="line">&#123;&#125;</span><br></pre></td></tr></table></figure><p>Then we can use Custom Attribute like this</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[Test]</span><br><span class="line">[ProductComparison]</span><br><span class="line">public void CustomAttributeTest() &#123;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Unit Tests </tag>
            
            <tag> .NET </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaScript Fundamentals</title>
      <link href="2021/04/03/JavaScript-Fundamentals/"/>
      <url>2021/04/03/JavaScript-Fundamentals/</url>
      
        <content type="html"><![CDATA[<h2 id="data-types"><a class="markdownIt-Anchor" href="#data-types"></a> Data Types</h2><ol><li>undefined</li><li>Boolean</li><li>Number</li><li>String</li><li>Symbol</li><li>null</li><li>object</li></ol><h3 id="undefined-and-null-in-javascript"><a class="markdownIt-Anchor" href="#undefined-and-null-in-javascript"></a> undefined and null in JavaScript</h3><ul><li>undefined mean a variable has been declared but not yet been assigned a value. The data type of undefined variable is also undefined. (undefined is a data type).</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">var x;</span><br><span class="line">alert(x); &#x2F;&#x2F; undefined</span><br><span class="line">alert(typeof x); &#x2F;&#x2F; undefined</span><br></pre></td></tr></table></figure><ul><li>null is an assignment value, it can be assigned to a variable as a representation of no value. The data type of null variable is an object.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">var x &#x3D; null;</span><br><span class="line">alert(x); &#x2F;&#x2F; null</span><br><span class="line">alert(typeof x); &#x2F;&#x2F; object</span><br></pre></td></tr></table></figure><ul><li>undefined and null are equal in value but different in type.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">typeof undefined; &#x2F;&#x2F; undefined</span><br><span class="line">typeof null; &#x2F;&#x2F; object</span><br><span class="line"></span><br><span class="line">null &#x3D;&#x3D;&#x3D; undefined; &#x2F;&#x2F; false</span><br><span class="line">null &#x3D;&#x3D; undefined; &#x2F;&#x2F; true</span><br></pre></td></tr></table></figure><h2 id="declare-variable"><a class="markdownIt-Anchor" href="#declare-variable"></a> Declare variable</h2><ul><li>var: normal way to declare a variable.</li><li>let: the variable you declared will only be used within the scope of where you declare it.</li><li>const: the variable value will never change</li></ul><h2 id="scope"><a class="markdownIt-Anchor" href="#scope"></a> Scope</h2><ul><li>Local scope</li><li>Global scope</li></ul><p>JavaScript has function scope, each function creates a new scope. Scope determines the accessibility of these variables. Variables defined inside a function are not accessible from outside the function</p><h2 id="array"><a class="markdownIt-Anchor" href="#array"></a> Array</h2><ul><li>push: Add anitem to the end of the array</li><li>pop: Remove an item from the end of the array</li><li>shift: Remove an item from the beginning of an array</li><li>unshift: Add an item to the beginning of an array</li><li>indexOf: find the index of an item in the array</li><li>splice: Remove items from an index position.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">let vegetables &#x3D; [&#39;Cabbage&#39;, &#39;Turnip&#39;, &#39;Radish&#39;, &#39;Carrot&#39;]</span><br><span class="line">console.log(vegetables)</span><br><span class="line">&#x2F;&#x2F; [&quot;Cabbage&quot;, &quot;Turnip&quot;, &quot;Radish&quot;, &quot;Carrot&quot;]</span><br><span class="line"></span><br><span class="line">let pos &#x3D; 1</span><br><span class="line">let n &#x3D; 2</span><br><span class="line"></span><br><span class="line">let removedItems &#x3D; vegetables.splice(pos, n)</span><br><span class="line">&#x2F;&#x2F; this is how to remove items, n defines the number of items to be removed,</span><br><span class="line">&#x2F;&#x2F; starting at the index position specified by pos and progressing toward the end of array.</span><br><span class="line"></span><br><span class="line">console.log(vegetables)</span><br><span class="line">&#x2F;&#x2F; [&quot;Cabbage&quot;, &quot;Carrot&quot;] (the original array is changed)</span><br><span class="line"></span><br><span class="line">console.log(removedItems)</span><br><span class="line">&#x2F;&#x2F; [&quot;Turnip&quot;, &quot;Radish&quot;]</span><br></pre></td></tr></table></figure><ul><li>slice: copy an array</li></ul><h3 id="objectfreeze"><a class="markdownIt-Anchor" href="#objectfreeze"></a> Object.freeze</h3><ul><li>const: creates an immutable binding, you cannot re-assign a new value to the binding. But if you delcare a const array or object. You can set new value to the element in the array or object</li><li>object.freeze: makes an object immutable, so you cannot change its properties.</li></ul><h2 id="object-dynamic-properties"><a class="markdownIt-Anchor" href="#object-dynamic-properties"></a> Object Dynamic Properties</h2><p>The property ‘test’ is a dynamic property, it’s value will be evaluated during runtime. So obj will have a property name ‘test’ with value 52.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">const test &#x3D; &#39;answer&#39;;</span><br><span class="line"></span><br><span class="line">const obj &#x3D; &#123;</span><br><span class="line">    p1:10,</span><br><span class="line">    p2:20,</span><br><span class="line">    [test]: 52</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">console.log(obj.test);</span><br><span class="line">console.log(obj.answer);</span><br></pre></td></tr></table></figure><h2 id="anonymous-function"><a class="markdownIt-Anchor" href="#anonymous-function"></a> Anonymous function</h2><ul><li>functions without name. You can also pass that function to a variable</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">var magic &#x3D; function() &#123;</span><br><span class="line">    return new Date();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="arrow-function"><a class="markdownIt-Anchor" href="#arrow-function"></a> Arrow function</h2><ul><li>You can convert anonymous function to arrow function</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">var magic &#x3D; () &#x3D;&gt; &#123;</span><br><span class="line">    return new Date();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">var magic &#x3D; () &#x3D;&gt; new Date();</span><br></pre></td></tr></table></figure><ul><li>Arrow function with parameters</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">var myConcat &#x3D; (var1, var2) &#x3D;&gt; arr1.concat(arr2);</span><br></pre></td></tr></table></figure><p>Example: Filter the array with only positive numbers and return the square of all remain elements in a new array</p><ul><li>Array.filter: The filter() method creates a new array with all elements that pass the test implemented by the provided function.</li><li>Array.map: The map() method creates a new array populated with the results of calling a provided function on every element in the calling array.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">const array &#x3D; [1,2,-3,4,-5,6,7];</span><br><span class="line"></span><br><span class="line">const squareList &#x3D; arr &#x3D;&gt; &#123;</span><br><span class="line">    const squaredList &#x3D; arr.filter(function callback(num) &#123;</span><br><span class="line">        return Number.isInteger(num) &amp;&amp; num &gt; 0;</span><br><span class="line">    &#125;).map(function square(num) &#123;</span><br><span class="line">        return num * num;</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    return squaredList;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">const squaredIntegers &#x3D; squareList(array);</span><br><span class="line"></span><br><span class="line">console.log(squaredIntegers);</span><br></pre></td></tr></table></figure><ul><li>Using Arrow functions</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">const array &#x3D; [1,2,-3,4,-5,6,7];</span><br><span class="line"></span><br><span class="line">const squareList &#x3D; arr &#x3D;&gt; &#123;</span><br><span class="line">    const squaredList &#x3D; arr.filter(num &#x3D;&gt; Number.isInteger(num) &amp;&amp; num &gt; 0).map(num &#x3D;&gt; num * num);</span><br><span class="line">    return squaredList;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">const squaredIntegers &#x3D; squareList(array);</span><br><span class="line">console.log(squaredIntegers);</span><br></pre></td></tr></table></figure><p>Example: Write a function that takes multiple parameters and add them up</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">function sum(x, y, z) &#123;</span><br><span class="line">    args &#x3D; [x, y, z];</span><br><span class="line">    return args.reduce((accumulator, currentValue) &#x3D;&gt; accumulator + currentValue, 0);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">console.log(sum(1,2,3));</span><br></pre></td></tr></table></figure><ul><li><p>Regular functions give access to their calling environment while arrow functions give access to their defining environment</p></li><li><p>The value of the ‘this’ keyword inside a regular function depends on HOW the function was CALLED (the OBJECT that made the call)</p></li><li><p>In arrow functions, this keyword doesn’t mean the caller of the arrow function. The value of the ‘this’ keyword inside an arrow function depends on WHERE the function was DEFINED (the scope that defined the function). This makes it great for delayed execution cases like events and listeners.</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">const test &#x3D; (function test () &#123;</span><br><span class="line">    const testerObj &#x3D; &#123;</span><br><span class="line">        func1: function() &#123;</span><br><span class="line">            console.log(&#39;func1&#39;, this);</span><br><span class="line">        &#125;,</span><br><span class="line"></span><br><span class="line">        func2: () &#x3D;&gt; &#123;</span><br><span class="line">            console.log(&#39;func2&#39;, this);</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    testerObj.func1();</span><br><span class="line">    testerObj.func2();    </span><br><span class="line">&#125;)()</span><br></pre></td></tr></table></figure><h2 id="using-rest-operator-to-represent-multiple-parameters"><a class="markdownIt-Anchor" href="#using-rest-operator-to-represent-multiple-parameters"></a> Using Rest operator to represent multiple parameters</h2><ul><li><p>Rest Operator: The rest parameter syntax allows a function to accept an indefinite number of arguments as an array,</p></li><li><p>Reduce: The reduce() method executes a reducer function (that you provide) on each element of the array, resulting in single output value.</p></li><li><p>The reducer function takes four arguments:</p></li></ul><ol><li>Accumulator</li><li>Current Value</li><li>Current Index</li><li>Source Array</li></ol><ul><li>Your reducer function’s returned value is assigned to the accumulator, whose value is remembered across each iteration throughout the array, and ultimately becomes the final, single resulting value.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">function sum(...args) &#123;</span><br><span class="line">    return args.reduce((accumulator, currentValue) &#x3D;&gt; accumulator + currentValue, 0);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">console.log(sum(1,2,3,4));</span><br></pre></td></tr></table></figure><h2 id="spread-syntax"><a class="markdownIt-Anchor" href="#spread-syntax"></a> Spread syntax</h2><p>Spread syntax (…) allows an iterable such as an array expression or string to be expanded in places where zero or more arguments (for function calls) or elements (for array literals) are expected, or an object expression to be expanded in places where zero or more key-value pairs (for object literals) are expected.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">const arr1 &#x3D; [&#39;JAN&#39;, &#39;FEB&#39;, &#39;MAR&#39;, &#39;APR&#39;, &#39;MAY&#39;];</span><br><span class="line"></span><br><span class="line">let arr2;</span><br><span class="line"></span><br><span class="line">(function () &#123;</span><br><span class="line">    &#x2F;&#x2F; spread arr1 into individual elements and create a new array by surrond it with []</span><br><span class="line">    arr2 &#x3D; [...arr1];</span><br><span class="line">    arr1[0] &#x3D; &#39;potato&#39;;</span><br><span class="line">&#125;)();</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; arr2[0] will still be &#39;JAN&#39;</span><br><span class="line">console.log(arr2);</span><br></pre></td></tr></table></figure><h2 id="destructuring-assignment"><a class="markdownIt-Anchor" href="#destructuring-assignment"></a> Destructuring assignment</h2><p>The destructuring assignment syntax is a JavaScript expression that makes it possible to unpack values from arrays, or properties from objects, into distinct variables.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">var obj &#x3D; &#123;x:3.6, y:7.4, z:6.5&#125;;</span><br><span class="line"></span><br><span class="line">const &#123;x : a, y: b, z: c&#125; &#x3D; obj;</span><br><span class="line"></span><br><span class="line">console.log(&#96;$&#123;a&#125; $&#123;b&#125; $&#123;c&#125;&#96;);</span><br></pre></td></tr></table></figure><ul><li>Destructuring Assignment: Nested Objects</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">const LOCAL_FORECAST &#x3D; &#123;</span><br><span class="line">    today: &#123;min : 72, max: 83&#125;,</span><br><span class="line">    tomorrow : &#123;min : 73.3, max: 84.6&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">function getMaxOfTmw(forecast) &#123;</span><br><span class="line">    const &#123;tomorrow : &#123;max : maxOfTomorrow &#125;&#125; &#x3D; forecast;</span><br><span class="line"></span><br><span class="line">    return maxOfTomorrow;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">console.log(getMaxOfTmw(LOCAL_FORECAST));</span><br></pre></td></tr></table></figure><ul><li>Destructuring Assignment: Arrays</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">const[x, y, , z] &#x3D; [1,2,3,4,5,6];</span><br><span class="line">console.log(x, y, z);</span><br></pre></td></tr></table></figure><ul><li>Destructuring Assignment: Pass an object</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">const stats&#x3D; &#123;</span><br><span class="line">    max: 56.7,</span><br><span class="line">    standard_deviation: 4.34,</span><br><span class="line">    median: 34.54,</span><br><span class="line">    mode: 23.5,</span><br><span class="line">    min: -0.4,</span><br><span class="line">    average: 45.6</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">function half(&#123;max, min&#125;) &#123;</span><br><span class="line">    return (max + min) &#x2F; 2.0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">console.log(half(stats));</span><br></pre></td></tr></table></figure><h2 id="object-literal-declarations-using-simple-fields"><a class="markdownIt-Anchor" href="#object-literal-declarations-using-simple-fields"></a> Object Literal Declarations Using Simple Fields</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">const createPerson &#x3D; (name, age, gender) &#x3D;&gt; ( &#123;name, age, gender&#125; )</span><br><span class="line"></span><br><span class="line">console.log(createPerson(&#39;Yuan Cheng&#39;, 27, &#39;male&#39;));</span><br></pre></td></tr></table></figure><h2 id="functions-in-objects"><a class="markdownIt-Anchor" href="#functions-in-objects"></a> Functions in Objects</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">const bicycle &#x3D; &#123;</span><br><span class="line">    gear : 2,</span><br><span class="line">    setGear: function(newGear) &#123;</span><br><span class="line">        this.gear &#x3D; newGear;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">bicycle.setGear(3);</span><br><span class="line">console.log(bicycle.gear);</span><br></pre></td></tr></table></figure><ul><li>we could remove the ‘function’ keyword</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">const bicycle &#x3D; &#123;</span><br><span class="line">    gear : 2,</span><br><span class="line">    setGear(newGear) &#123;</span><br><span class="line">        this.gear &#x3D; newGear;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">bicycle.setGear(3);</span><br><span class="line">console.log(bicycle.gear);</span><br></pre></td></tr></table></figure><h2 id="class-syntax"><a class="markdownIt-Anchor" href="#class-syntax"></a> class syntax</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">var SpaceShuttle &#x3D; function(targetPlanet) &#123;</span><br><span class="line">    this.targetPlanet &#x3D; targetPlanet;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">var zeus &#x3D; new SpaceShuttle(&#39;Jupiter&#39;);</span><br><span class="line">console.log(zeus.targetPlanet);</span><br></pre></td></tr></table></figure><ul><li>Using Class and Constructor</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">class SpaceShuttle &#123;</span><br><span class="line">    constructor(targetPlanet) &#123;</span><br><span class="line">        this.targetPlanet &#x3D; targetPlanet;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">var zeus &#x3D; new SpaceShuttle(&#39;Jupiter&#39;);</span><br><span class="line">console.log(zeus.targetPlanet);</span><br></pre></td></tr></table></figure><h2 id="getters-and-setters"><a class="markdownIt-Anchor" href="#getters-and-setters"></a> getters and setters</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">class Book &#123;</span><br><span class="line">    constructor(author) &#123;</span><br><span class="line">        this._author &#x3D; author;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; getter</span><br><span class="line">    get writer() &#123;</span><br><span class="line">        return this._author;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; setter</span><br><span class="line">    set writer(updatedAuthor) &#123;</span><br><span class="line">        this._author &#x3D; updatedAuthor;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="import-vs-require"><a class="markdownIt-Anchor" href="#import-vs-require"></a> import vs require</h2><p>import functions from other js files</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import &#123;capitalzeString&#125; from &quot;string_function&quot;</span><br></pre></td></tr></table></figure><h2 id="export"><a class="markdownIt-Anchor" href="#export"></a> export</h2><p>The export statement is used when creating JavaScript modules to export live bindings to functions, objects, or primitive values from the module so they can be used by other programs with the import statement. Bindings that are exported can still be modified locally; when imported, although they can only be read by the importing module the value updates whenever it is updated by the exporting module.</p><ul><li>below code is saved in a js file: string_function</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export const capitalizeString &#x3D; str &#x3D;&gt; str.toUpperCase();</span><br></pre></td></tr></table></figure><h2 id="to-import"><a class="markdownIt-Anchor" href="#to-import"></a> * to import</h2><p>import * will import every functions you export in the other file to a object</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import * as capitalizeStrings from &quot;capitalize_strings&quot;;</span><br></pre></td></tr></table></figure><h2 id="named-export-vs-export-default"><a class="markdownIt-Anchor" href="#named-export-vs-export-default"></a> Named export vs export default</h2><p>Named export: With named exports, one can have multiple named exports per file. Then import the specific exports they want surrounded in braces. The name of imported module has to be the same as the name of the exported module.</p><p>Export default: One can have only one default export per file.<br />The naming of import is completely independent in default export and we can use any name we like. No curly braces needed when import</p><h2 id="promises"><a class="markdownIt-Anchor" href="#promises"></a> Promises</h2><p>A promise is an object that might deliver data at a later point in the program.</p><p>Fetch API will return a promise, to consume that promise, we do a .then call on the result of fetch and supply a callback function. The Fetch API will have a raw response ‘resp’, you need to call the .json method on that response object. The json method is also a asynchronous function. It also returns a promise. So we do another .then call on the result of the json function</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">const fetchData &#x3D; () &#x3D;&gt; &#123;</span><br><span class="line">    fetch(&#39;https:&#x2F;&#x2F;api.github.com&#39;).then(resp &#x3D;&gt; &#123;</span><br><span class="line">        resp.json().then(data &#x3D;&gt; &#123;</span><br><span class="line">            console.log(data);</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">fetchData();</span><br></pre></td></tr></table></figure><p>The above code works, but it is difficult to read. We could use async/await.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">const fetchData &#x3D; async () &#x3D;&gt; &#123;</span><br><span class="line">    const resp &#x3D; await fetch(&#39;https:&#x2F;&#x2F;api.github.com&#39;);</span><br><span class="line"></span><br><span class="line">    const data &#x3D; await resp.json();</span><br><span class="line"></span><br><span class="line">    console.log(data);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">fetchData();</span><br></pre></td></tr></table></figure><p>the async function is another way for us to consume promises without having us to use .then calls</p>]]></content>
      
      
      
        <tags>
            
            <tag> JavaScript </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS SAA Architecting For Performance Efficiency</title>
      <link href="2021/03/16/AWS-SAA-Architecting-for-Performance-Efficiency/"/>
      <url>2021/03/16/AWS-SAA-Architecting-for-Performance-Efficiency/</url>
      
        <content type="html"><![CDATA[<ol><li><a href="#Part1">Part One: Understanding the Design Principles</a></li><li><a href="#Part2">Part Two: Considering Compute Performance Options</a></li><li><a href="#Part3">Part Three: Reviewing Storage Performance Options</a></li><li><a href="#Part4">Part Four: Examing Database Performance Options</a></li><li><a href="#Part5">Part Five: Evaluating Network Performance Options</a></li><li><a href="#Part6">Part Six: Preparing to Improve Your Architecture</a></li><li><a href="#Part7">Part Seven: Monitoring Your Architecture</a></li><li><a href="#Part8">Part Eight: Understanding the Trade-offs</a></li></ol><h2 id="part-one-understanding-the-design-principles"><a class="markdownIt-Anchor" href="#part-one-understanding-the-design-principles"></a> <a href="#title" title="Part 1">Part One: Understanding the Design Principles</a></h2><p>There are three main differences compare traditional on premises application and cloud application. 1. Cost. 2. Security and 3. Performance. We are going to focus on number three. Performance.</p><p>Cloud services are changing fast.</p><p>Go global: AWS have many regions, deploy application to the region that close to the user to reduce the latancy.</p><p>Go global: local region will comply to the laws and regulations</p><ol><li>Go global</li><li>Think serverless</li><li>Use new technologies</li><li>Experiment often</li><li>Right tool for the task</li></ol><h2 id="part-two-considering-compute-performance-options"><a class="markdownIt-Anchor" href="#part-two-considering-compute-performance-options"></a> <a href="#title" title="Part 2">Part Two: Considering Compute Performance Options</a></h2><p>What does compute performance includes?</p><p>Processing -&gt; CPU</p><p>Capacity -&gt; Storage</p><p>Scaling</p><p>Responsive</p><p>Economical</p><p>Understand your workload</p><p>Undetstand AWS compute</p><p>Need to gather and analyze data, and testing</p><h3 id="aws-compute-options"><a class="markdownIt-Anchor" href="#aws-compute-options"></a> AWS compute options</h3><h4 id="ec2-elastic-cloud-compute"><a class="markdownIt-Anchor" href="#ec2-elastic-cloud-compute"></a> EC2 Elastic Cloud Compute</h4><p>The default option, virtualized servers. IssA (infrustructure as a service)</p><p>Choose resources. You own the OS.(You are responsible for patching the OS and config all aspects of it.)</p><p>EC2 General resources</p><ol><li>vCPUs</li><li>Memory</li><li>Storage</li><li>Network</li></ol><p>EC2 extra features</p><ol><li>Burstable: if your EC2 is not using its full compute power, you gain credits which you can use in the future when you need it to burst the compute power of your instance for a short period of time.</li><li>GPU</li><li>FPGA (Filled Programmable Gate Arrays): Allows you to create customized hardware accelerators</li></ol><p>Instance Types</p><ol><li>General Purpose: Standard, balanced</li><li>Compute optimized: high compute power</li><li>Memory optimized: for memory intensive workloads</li><li>Accelerated computing: GPU or FPGA</li><li>Storage optimized: high storage</li><li>Bare metal</li></ol><p>EC2 Auto Scaling</p><ol><li>Metrics based: scale up or down based on the metric you choose</li><li>Schedule based: scale up or down for a booked time</li><li>Health based: replace unhealthy instances</li></ol><h4 id="ecs-elastic-container-service"><a class="markdownIt-Anchor" href="#ecs-elastic-container-service"></a> ECS Elastic Container Service</h4><p>Similar workloads as EC2</p><p>Migrate apps to the cloud, long running apps, batch processing, Microservices</p><p>Better utilize resources. Can run multiple containers on a single instance. ELB, balance traffic to each container, Autoscaling.</p><p>AWS Fargate: manages the instances on which your containers run. you don’t need to manage the server instances.</p><h4 id="aws-lambda"><a class="markdownIt-Anchor" href="#aws-lambda"></a> AWS Lambda</h4><p>FaaS (Function as a service). Serverless computing.</p><p>Backend processing, Event processing, Stream processing, Data processing</p><p>AWS resource triggers: other resources can trigger Lambda functions</p><p>You can choose memory needed for a lambda function</p><p>Advantages: Simply execute code. We don’t need to worry about the servers that run our Lambda codes.</p><p>Automatic scaling for Lambda function.</p><p>Fault tolerant: if a function fails, AWS will trigger the function again</p><p>Pay for usage</p><h4 id="applying-our-knowledge"><a class="markdownIt-Anchor" href="#applying-our-knowledge"></a> Applying our knowledge</h4><p>1. A company called Globomantics wants to move their application to cloud. They have customers globally.</p><p>The first application they want to move to cloud is an app that collections data from clinical trails. Doctors enter information each time they do checkings.</p><p>Considerations for Choice</p><ol><li>First app of many</li><li>Time should be fast</li><li>Predicatable usage</li></ol><p>They want to use ECS. Lift and shift: Easy to containerize the app. Able to scale. Able to choose instance sizes.</p><p>Allows them to leverage for future applications. Different containers in a single instance. Save costs</p><p>2. They also want to build a new web application for the cloud. Allow people to register medical devices. Share medical devices globally.</p><p>Considerations for Choice</p><ol><li>Manage costs</li><li>Global reach</li><li>Minimal maintenance</li></ol><p>They want to go with Lambda. Services behind a static site to save costs. Only pay for runtime.</p><p>Lambda scales besed on demand. Can be deployed to multiple regions. No servers to maintain.</p><h2 id="part-three-reviewing-storage-performance-options"><a class="markdownIt-Anchor" href="#part-three-reviewing-storage-performance-options"></a> <a href="#title" title="Part 3">Part Three: Reviewing Storage Performance Options</a></h2><h3 id="s3"><a class="markdownIt-Anchor" href="#s3"></a> S3</h3><p>data is encrypted. Access Managemenet(IAM), Lifecycle management. Query in place.(Don’t need to move the data to query it using SQL like command)</p><ol><li><p>Shared Access</p></li><li><p>Low latency</p></li><li><p>High thoughput: move data in or out S3 quickly</p></li><li><p>High Availability: available for multiple availability zones</p></li><li><p>High durability: data is duplicated across multiple availability zones</p></li><li><p>Standard</p></li><li><p>Intelligent Tier</p></li><li><p>Standard Infrequent Access(IA)(high latency)</p></li><li><p>One-Zone Infrequent Access(low availability, low durability)</p></li></ol><h3 id="glacier"><a class="markdownIt-Anchor" href="#glacier"></a> Glacier</h3><p>Immutable, data do not change once they are in Glacier.</p><p>Durable</p><p>Query stored data without retrieval.</p><ol><li>Archival storage</li><li>Encrypted</li><li>Access Control</li><li>Audit logging</li></ol><p>Latency options.</p><ol><li>Expedited. latency in minutes.</li><li>Standard. Default, number of hours to get data back.</li><li>Bulk. cheaper and takes longer.</li></ol><p>Economical, put data in Glacier is cheap and high durable.</p><p>Deep Archive. The cheapest and longest. normally 6-12 hours. Do not access data frequently, 2-3 times a year.</p><h3 id="ebs-elastic-block-storage"><a class="markdownIt-Anchor" href="#ebs-elastic-block-storage"></a> EBS (Elastic Block Storage)</h3><p>Attached to EC2 instances.</p><p>Multi-Attach, storage volumn can be attached to up to 16 instances. Instances must be in same availability zone.</p><p>Data is Replicated to multiple availbility zones. high availability and durability</p><p>Access control.</p><ol><li>Provisioned IOPS SSD</li><li>Standard Purpose IOPS SSD</li><li>Cold HDD</li><li>Thoughput optimized HDD</li></ol><p>Snapshots: a snapshots of a storage in that time and can be shared to other zones.</p><p>Elastic volumes. pay for what actually stored.</p><h3 id="efs"><a class="markdownIt-Anchor" href="#efs"></a> EFS</h3><ol><li>General Purpose</li><li>MAX I/O</li></ol><p>Same example as before. Migrating to AWS storage. It is one of the web applications. It requires global access. Data will be collected from clinical trials. And some data will be entered on daliy basis.</p><p>They need shared access of data.</p><p>Data must be durable.</p><p>Data will be stored in a long term basis.</p><p>S3 and Glacier: high durable. Access from ECS containers. Multiple access. Long term storage.</p><p>New application. Provide medical devices to people who need it. Global user base.</p><p>Lower cost. Local access. Non-critical images(could be lost, no big problem).</p><p>S3: single region. Reduced Redundancy Storage(RRD).</p><h2 id="part-four-examing-database-performance-options"><a class="markdownIt-Anchor" href="#part-four-examing-database-performance-options"></a> <a href="#title" title="Part 4">Part Four: Examing Database Performance Options</a></h2><h3 id="install-on-ec2"><a class="markdownIt-Anchor" href="#install-on-ec2"></a> Install on EC2</h3><p>we could choose to install a Database on a EC2 instance. But that means we need to do all the backup, restore ourselves. We are not using the serverless managed services provided by AWS. But in some cases, we have to choose this way. Situations like: 1. Control Environment. we want to control everything. 2. Certified. Maybe the services in AWS are not certified by the customer. 3. Specific tools. Our application needs some tools that have to work with standalone database.</p><ol><li>RDS</li><li>DynamoDB</li><li>Redshift</li></ol><h3 id="rds"><a class="markdownIt-Anchor" href="#rds"></a> RDS</h3><p>Default choice. Complex queries. Consistent transactions.</p><ol><li><p>Multi-AZ</p></li><li><p>Read replicas</p></li><li><p>Encryption</p></li><li><p>Backups and snapshots</p></li><li><p>Instance type</p></li><li><p>Storage type</p></li><li><p>Network setup</p></li><li><p>Backup</p></li></ol><h3 id="dynamodb"><a class="markdownIt-Anchor" href="#dynamodb"></a> DynamoDB</h3><p>Flexible structure</p><ol><li>Flexible structure</li><li>Less complex queries: You are able to query on particular keys, the partition key and any secondary keys that you define. Can’t join tables.</li><li>Low latency</li><li>Transactions</li><li>Global tables: store data in multiple regions</li><li>Encryption</li><li>Evolving schema: supports changes and growth in your application(add/remove columns…)</li><li>Integration with Lambda</li></ol><p>Partition key: store data on different nodes of the database</p><p>Secondary indexes</p><p>Provisioned capacity: number of reads and writes. Dynamodb will auto scale</p><p>on-demand capacity: pay for what you use. No auto scaling.</p><h3 id="redshift"><a class="markdownIt-Anchor" href="#redshift"></a> Redshift</h3><p>Large scale analytics</p><p>Setup in minutes</p><p>Warehouse and data lake</p><ol><li>Encryption</li><li>Scale to petabytes</li><li>Query S3</li><li>Economical</li></ol><p>Node type</p><ol><li>Dense compute: fast CPUs, large RAM and SSD for fast performance</li><li>Dense storage</li></ol><p>Same example as before.</p><p>They want to have minimum effort to do the migration</p><p>They want to leverage managed services</p><p>Improve availability</p><p>They have decided to use RDS. Using SQL server. Structured data. No servers to manage. High availability</p><p>New application.</p><p>DynamoDB. Flexible data structure(NoSQL). Trigger action(Lambda integration). Flexible cost structure(On-demand pricing). Global tables.</p><h2 id="part-five-evaluating-network-performance-options"><a class="markdownIt-Anchor" href="#part-five-evaluating-network-performance-options"></a> <a href="#title" title="Part 5">Part Five: Evaluating Network Performance Options</a></h2><h3 id="region-and-az"><a class="markdownIt-Anchor" href="#region-and-az"></a> Region and AZ</h3><p>Regions are geographical area. One region may have multiple AZs that are also isolated to each other.</p><p>While the AZs are isolated geographically, they are connected by AWS that allows data to be transferred between each zones.</p><h4 id="local-zones"><a class="markdownIt-Anchor" href="#local-zones"></a> Local Zones</h4><p>Some users still think the regions provided by AWS have high latency. They can choose to use local zones. They are built in large cities and connected to near by regions with low latency, high throughput connectivity. Local zones don’t have all the services provided by AWS as normal AZs.</p><p>Why do we choose one region over another?</p><ol><li>Laws and Regulations: e.g. Some governments required that any data of their citizens remain in their countries</li><li>User location: put application closer to your end users.</li><li>Data location</li><li>Cost</li></ol><h3 id="cloudfront"><a class="markdownIt-Anchor" href="#cloudfront"></a> CloudFront</h3><p>Global network: CloudFront is outside of AWS regions, that deliver our applications to end users</p><p>Content delivery: Similar to CDN</p><ol><li>Static content: static content is cached to the place closer to end users to reduce latency</li><li>Dynamic content: AWS also supported Dynamic content (intelligent caching)</li><li>Intelligent: you can setup geo-restrictions to not allow edge content to deliver content to certain geo-locations</li><li>Programmable: Lambda at edge: create serverless functions at edge locations. Put compute power closer to your end users.</li></ol><h3 id="route53"><a class="markdownIt-Anchor" href="#route53"></a> Route53</h3><p>DNS solution for AWS: translate a user-friendly URL to the IP address</p><p>Private DNS: Route53 supports private DNS, you can setup friendly names for your internal services</p><h4 id="traffic-flow"><a class="markdownIt-Anchor" href="#traffic-flow"></a> Traffic flow</h4><p>If you deploy your solution to multiple regions, you can config so that your users only send requests to their regions.</p><ol><li>Latency routing: Traffic flow will determine the region that will be serving the content with the least latency</li><li>Geographic routing: route users to the cloest region.</li><li>Health based routing: not route users to a region that with unhealthy status.</li><li>Round robin routing: route user to the next region available. Route traffic evenly to all regions.</li></ol><h3 id="direct-connect"><a class="markdownIt-Anchor" href="#direct-connect"></a> Direct Connect</h3><p>Instead of going through public internet, AWS will create a dedicated line for users to connect from AWS to your data center. It is encrypted and you can config the speed.</p><h3 id="vpc-endpoints"><a class="markdownIt-Anchor" href="#vpc-endpoints"></a> VPC endpoints</h3><p>Normally, if your VPC wants to connect to other AWS services, it can only go through public internet, but with VPC endpoints, it can connect to other AWS services directly through the private internet AWS network</p><h3 id="ec2-instance-types"><a class="markdownIt-Anchor" href="#ec2-instance-types"></a> EC2 instance types</h3><p>some EC2 instance types have better internet performance than others. Pay attention to it before you launch the EC2 instance. Choose the type that suitable for your applications.</p><h3 id="apply-our-knowledge"><a class="markdownIt-Anchor" href="#apply-our-knowledge"></a> Apply our knowledge</h3><p>They want their application to be deployed in a single region but to multiple AZs. They use AWS ECS(elastic container service) to manage their application. And use AWS Fargate to manage their containers. They also choose to use Multi-AZ RDS for their DB. They also want their Data to be stored in S3. So they want a VPC endpoint for S3 to reduce latency. So when they want to access data in S3. they don’t need to go through public internet.</p><p>They also have a new application that they want to have a friendly domain name. Reduced latency and managed cost. So they have decided to use Route53. because the application is hosted on S3 buckets. They need to register domain names for each S3 bucket. And configure Route 53 to route traffic to right S3 bucket using their domain names. They also want to have a global portal that has links to each deployed regions.</p><h2 id="part-six-preparing-to-improve-your-architecture"><a class="markdownIt-Anchor" href="#part-six-preparing-to-improve-your-architecture"></a> <a href="#title" title="Part 6">Part Six: Preparing to Improve Your Architecture</a></h2><h3 id="cicd-pipeline-continuous-integration-continuous-deployment"><a class="markdownIt-Anchor" href="#cicd-pipeline-continuous-integration-continuous-deployment"></a> CI/CD pipeline (Continuous Integration/ Continuous Deployment)</h3><p>We need to have repeatable builds, repeatable infrastructrue and Controlled tests</p><p><img src="/../images/AWS-SAA-Architecting-For-Performance-Efficiency/1.png" alt="" /></p><h3 id="cloudformation"><a class="markdownIt-Anchor" href="#cloudformation"></a> CloudFormation</h3><ol><li>Infrastructure template(JSON or YAML)</li><li>Automate creation</li><li>Ensure consistency</li></ol><h3 id="cloudformation-templates"><a class="markdownIt-Anchor" href="#cloudformation-templates"></a> CloudFormation templates</h3><p><img src="/../images/AWS-SAA-Architecting-For-Performance-Efficiency/2.png" alt="" /><br /><img src="/../images/AWS-SAA-Architecting-For-Performance-Efficiency/3.png" alt="" /><br /><img src="/../images/AWS-SAA-Architecting-For-Performance-Efficiency/4.png" alt="" /></p><ol><li>Format version</li><li>Description</li><li>Parameters</li><li>Resources</li><li>Output</li></ol><h2 id="part-seven-monitoring-your-architecture"><a class="markdownIt-Anchor" href="#part-seven-monitoring-your-architecture"></a> <a href="#title" title="Part 7">Part Seven: Monitoring Your Architecture</a></h2><h3 id="monitor"><a class="markdownIt-Anchor" href="#monitor"></a> Monitor</h3><ol><li>Resources</li><li>Application</li><li>Operations</li></ol><h3 id="respond"><a class="markdownIt-Anchor" href="#respond"></a> Respond</h3><ol><li>Ignore</li><li>Manually</li><li>Automate</li><li>Modify</li></ol><h3 id="cloudwatch"><a class="markdownIt-Anchor" href="#cloudwatch"></a> CloudWatch</h3><p>Metrics</p><ol><li>Application</li><li>Infrastructure</li><li>AWS or on-premises</li></ol><p>Actions: Autoscaling.</p><p>Actions: Messages</p><p>Actions: Lambda functions can be triggered from CloudWatch</p><p>Analytics: CloudWatch can store months of histoical data for you to analyse</p><h3 id="create-a-log-to-delete-s3-object"><a class="markdownIt-Anchor" href="#create-a-log-to-delete-s3-object"></a> Create a log to delete S3 object</h3><ol><li>Create CloudTrail Trail</li><li>Create Lambda function</li><li>Create CloudWatch Rule</li></ol><p>Create a CloudTrail Trail</p><p><img src="/../images/AWS-SAA-Architecting-For-Performance-Efficiency/5.png" alt="" /></p><p>Create a Lambda function</p><p><img src="/../images/AWS-SAA-Architecting-For-Performance-Efficiency/6.png" alt="" /></p><p>Create CloudWatch Rule</p><p><img src="/../images/AWS-SAA-Architecting-For-Performance-Efficiency/7.png" alt="" /></p><h2 id="part-eight-understanding-the-trade-offs"><a class="markdownIt-Anchor" href="#part-eight-understanding-the-trade-offs"></a> <a href="#title" title="Part 8">Part Eight: Understanding the Trade-offs</a></h2><ol><li>Time</li><li>Cost</li><li>Memory</li><li>Efficiency</li><li>Complexity</li></ol><h3 id="possible-trade-offs"><a class="markdownIt-Anchor" href="#possible-trade-offs"></a> Possible Trade-offs</h3><ol><li>Queuing</li><li>Partitioning</li><li>Caching</li><li>Compression</li></ol><h3 id="queuing"><a class="markdownIt-Anchor" href="#queuing"></a> Queuing</h3><p>AWS SQS (simple queuing service)</p><ol><li>Decouple (producer, consumer)</li><li>Scale independently (add producer or delete consumer)</li><li>Acceptable delay</li><li>Time vs Efficiency</li></ol><h3 id="data-paritioning"><a class="markdownIt-Anchor" href="#data-paritioning"></a> Data Paritioning</h3><p>For example: RDBMS doesn’t have partition. so we need to consider what data goes into which instance of database, that increase complexity. Whereas many NoSQL DB already has partition. In DynamoDB, we have partition key for each table. The data that has the same partition key will go into the same node. So when choose a partition key, choose a key that roughly evenly distributed across the data.</p><ol><li>Complexity / consistency vs Time</li><li>RDBMS vs NoSQL</li><li>Distribution</li><li>Maintenance</li></ol><h3 id="caching"><a class="markdownIt-Anchor" href="#caching"></a> Caching</h3><p>Cache: heavliy used data will be stored in memory.</p><p>Read Replics: if you have a read replica of your DB, users can go into read replica if they only read. Reduce the traffic of your primary server.</p><p>CDN: take data and store data closer to users place.</p><p>Memory/ consistency vs Time</p><h3 id="compression"><a class="markdownIt-Anchor" href="#compression"></a> Compression</h3><ol><li>Code assets: reduce the size of source code to reduce the time to load the application</li><li>Files: same. redurce the size of file will reduce the transfer time</li><li>Time vs memory</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> AWS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>React Overview</title>
      <link href="2021/03/16/React-Overview/"/>
      <url>2021/03/16/React-Overview/</url>
      
        <content type="html"><![CDATA[<h2 id="setting-up-a-development-environment"><a class="markdownIt-Anchor" href="#setting-up-a-development-environment"></a> Setting up a Development Environment</h2><ol><li>Create folder and package.json file</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir diy-react</span><br><span class="line">cd diy-react</span><br><span class="line">npm init --y</span><br></pre></td></tr></table></figure><h3 id="install-main-dependencies"><a class="markdownIt-Anchor" href="#install-main-dependencies"></a> Install Main Dependencies</h3><ol start="2"><li>Install Express</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm i express</span><br></pre></td></tr></table></figure><ol start="3"><li>Install React and React-dom</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm i react react-dom</span><br></pre></td></tr></table></figure><ol start="4"><li>Install webpack</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm i webpack webpack-cli</span><br></pre></td></tr></table></figure><p>Webpack is a module bunlder. A react application usually contains multiple modules and depends on many external modules too. When we ship the application to the browser we need to bundle all necessary files into a single bundle and ship it to the browser.</p><ol start="5"><li>Install Babel</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm i babel-loader @babel&#x2F;core @babel&#x2F;node @babel&#x2F;preset-env @babel&#x2F;preset-react</span><br></pre></td></tr></table></figure><p>Babel is the package that compiles JSX into regular React API calls.</p><h3 id="install-development-dependencies"><a class="markdownIt-Anchor" href="#install-development-dependencies"></a> Install Development Dependencies</h3><ol start="6"><li>Install nodemon</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm i -D nodemon</span><br></pre></td></tr></table></figure><p>nodemon is a package that lets us automatically restart node when we change things in node.</p><ol start="7"><li>Install ESLint</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm i -D eslint babel-eslint eslint-plugin-react eslint-plugin-react-hooks</span><br></pre></td></tr></table></figure><p>ESLint will immediately analyze your code and tell you the problems, you can have consistent styling to your code by using ESLint.</p><ol start="8"><li>Configure ESLint</li></ol><p>Go to your project directory, create a new file called ‘.eslintrc.js’ and paste the below code.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">module.exports &#x3D; &#123;</span><br><span class="line">    parser: &#39;babel-eslint&#39;,</span><br><span class="line">    env: &#123;</span><br><span class="line">      browser: true,</span><br><span class="line">      commonjs: true,</span><br><span class="line">      es6: true,</span><br><span class="line">      node: true,</span><br><span class="line">      jest: true,</span><br><span class="line">    &#125;,</span><br><span class="line">    parserOptions: &#123;</span><br><span class="line">      ecmaVersion: 2020,</span><br><span class="line">      ecmaFeatures: &#123;</span><br><span class="line">        impliedStrict: true,</span><br><span class="line">        jsx: true,</span><br><span class="line">      &#125;,</span><br><span class="line">      sourceType: &#39;module&#39;,</span><br><span class="line">    &#125;,</span><br><span class="line">    plugins: [&#39;react&#39;, &#39;react-hooks&#39;],</span><br><span class="line">    extends: [</span><br><span class="line">      &#39;eslint:recommended&#39;,</span><br><span class="line">      &#39;plugin:react&#x2F;recommended&#39;,</span><br><span class="line">      &#39;plugin:react-hooks&#x2F;recommended&#39;,</span><br><span class="line">    ],</span><br><span class="line">    settings: &#123;</span><br><span class="line">      react: &#123;</span><br><span class="line">        version: &#39;detect&#39;,</span><br><span class="line">      &#125;,</span><br><span class="line">    &#125;,</span><br><span class="line">    rules: &#123;</span><br><span class="line">      &#x2F;&#x2F; You can do your customizations here...</span><br><span class="line">      &#x2F;&#x2F; For example, if you don&#39;t want to use the prop-types package,</span><br><span class="line">      &#x2F;&#x2F; you can turn off that recommended rule with: &#39;react&#x2F;prop-types&#39;: [&#39;off&#39;]</span><br><span class="line">    &#125;,</span><br><span class="line">  &#125;;</span><br></pre></td></tr></table></figure><ol start="9"><li>Configure Jest</li></ol><p>jest is the package to test React applications</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm i -D jest babel-jest react-test-renderer</span><br></pre></td></tr></table></figure><ol start="10"><li>Basic React application structure</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">diy-react&#x2F;</span><br><span class="line">  dist&#x2F;</span><br><span class="line">    main.js</span><br><span class="line">  src&#x2F;</span><br><span class="line">    index.js</span><br><span class="line">    components&#x2F;</span><br><span class="line">      App.js</span><br><span class="line">    server&#x2F;</span><br><span class="line">      server.js</span><br></pre></td></tr></table></figure><p>dist: for distribution, webpack will put production-ready files to here<br />src: for React code files<br />components: for React components<br />server: for server files</p><ol start="11"><li>Configure Webpack and Babel</li></ol><p>Under project root directory, create a new file called ‘babel.config.js’ and paste the below code</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">module.exports &#x3D; &#123;</span><br><span class="line">  presets: [&#39;@babel&#x2F;preset-env&#39;, &#39;@babel&#x2F;preset-react&#39;],</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>Under project root directory, create a new file called ‘webpack.config.js’ and paste the below code<br />This will tell webpack to invoke babel for all files that end with .js. This is to convert JSX code to regular React API calls.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">module.exports &#x3D; &#123;</span><br><span class="line">  module: &#123;</span><br><span class="line">    rules: [</span><br><span class="line">      &#123;</span><br><span class="line">        test: &#x2F;\.js$&#x2F;,</span><br><span class="line">        exclude: &#x2F;node_modules&#x2F;,</span><br><span class="line">        use: &#123;</span><br><span class="line">          loader: &#39;babel-loader&#39;,</span><br><span class="line">        &#125;,</span><br><span class="line">      &#125;,</span><br><span class="line">    ],</span><br><span class="line">  &#125;,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><ol start="12"><li>Create npm scripts for development</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;dev:server&quot;: &quot;nodemon --exec .&#x2F;node_modules&#x2F;.bin&#x2F;babel-node src&#x2F;server&#x2F;server.js --ignore dist&#x2F;&quot;,</span><br></pre></td></tr></table></figure><p>This script will run nodemon command, which is run babel-node on a server.js file</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;dev:bundler&quot;: &quot;webpack -w --mode&#x3D;development&quot;</span><br></pre></td></tr></table></figure><p>This script will run the webpack command, in Watch mode(readable code, not minified) and in development node</p><h3 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h3><ol><li><a href="https://jscomplete.com/learn/1rd-reactful">Setting up React Development Environment</a></li></ol><hr /><ul><li><p>For Angular, Vue and Ember they put fake JS in HTML. Whereas React put fake HTML in JS (JSX), React is Javascript-centric, makes JS more powerful to handle HTML</p></li><li><p>React is lightweighted, you can slowly migrate your app from other technologies to React</p></li><li><p>React is lean and you only import the package you want to use.</p></li><li><p>React is one way data binding, it required more code, you need to expilictly declare a change handler. But this gives you more control and east to debug</p></li></ul><h2 id="the-basics"><a class="markdownIt-Anchor" href="#the-basics"></a> The Basics</h2><h3 id="reacts-basic-concepts"><a class="markdownIt-Anchor" href="#reacts-basic-concepts"></a> React’s Basic Concepts</h3><h4 id="components"><a class="markdownIt-Anchor" href="#components"></a> Components</h4><ul><li>Like functions</li><li>Input: props, state | Output: UI</li><li>Reusable and composable</li><li>Can be used as normal HTML tags <code>&lt;Component /&gt;</code></li><li>Can manage a private state</li></ul><h4 id="reactive-updates"><a class="markdownIt-Anchor" href="#reactive-updates"></a> Reactive updates</h4><ul><li>When the state of a React component, the input, changes, the user interface it represents, the output, changes as well</li></ul><h4 id="virtual-views-in-memory"><a class="markdownIt-Anchor" href="#virtual-views-in-memory"></a> Virtual views in memory</h4><ul><li>We don’t write HTML when building applications using React. We generate HTML using Javascript</li><li>Build smaller components such as buttons, forms, then build more complex components using the smaller components. Each component consist of HTML and JS.</li></ul><h2 id="tradeoffs"><a class="markdownIt-Anchor" href="#tradeoffs"></a> Tradeoffs</h2><h3 id="framework-vs-library"><a class="markdownIt-Anchor" href="#framework-vs-library"></a> Framework vs Library</h3><ul><li>Frameworks offer more opinion and standardization, but React’s library approach allows you to select only the tools that you need and pick the best tools for your use case.</li></ul><h3 id="data-binding"><a class="markdownIt-Anchor" href="#data-binding"></a> Data Binding</h3><ul><li>Other frameworks strive to be concise, using techniques like two‑way binding and abstractions over JavaScript operations. But React is explicit, so code is more readable and scalable at the admitted expense of doing a little more typing on the keyboard.</li></ul><h3 id="js-centric"><a class="markdownIt-Anchor" href="#js-centric"></a> JS Centric</h3><ul><li>React chooses to be JavaScript‑centric instead of template‑centric. React’s JavaScript‑centric approach is easier to understand and debug and requires learning less unique syntax, but at the cost of requiring modern JavaScript knowledge.</li></ul><h3 id="separate-vs-single-file"><a class="markdownIt-Anchor" href="#separate-vs-single-file"></a> Separate vs Single File</h3><ul><li>Many frameworks utilize a separate template file. In contrast, each React component is a single autonomous file that you can work with and test in isolation.</li></ul><h3 id="standard-vs-non-standard"><a class="markdownIt-Anchor" href="#standard-vs-non-standard"></a> Standard vs Non-standard</h3><ul><li>The web component standard has been around for years, yet it continues to lack broad adoption. Non‑standard approaches, like React and Angular, remain more popular because they offer the same power, more rapid innovation, and a superior developer experience.</li></ul><h3 id="community-vs-corporate"><a class="markdownIt-Anchor" href="#community-vs-corporate"></a> Community vs Corporate</h3><ul><li>And React is corporate‑backed, which means its design is influenced by Facebook’s needs. But Facebook continues to accept input from the community and has evolved React into a highly flexible and well‑supported system.</li></ul><h2 id="decisions-to-make"><a class="markdownIt-Anchor" href="#decisions-to-make"></a> Decisions to make</h2><ol><li>Develop environment - create-react-app</li><li>Classes or Functions - Functions</li><li>Types - PropTypes, TypeScript, Flow</li></ol><ul><li>TypeScript is a superset of JavaScript that adds strong typing support and compiles down to plain JavaScript</li><li>Flow: adding static type checking to JavaScrWipt</li></ul><ol start="4"><li>States - Plain React, Flux, Redux, MobX</li></ol><ul><li>Component State: Plain React</li><li>Centralized State: Flux, Redux</li><li>Observable State: MobX</li></ul><ol start="5"><li>Styling - Plain CSS/Sass/Less, CSS in JS<br />W</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> React </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ASP.NET Core with SignalR</title>
      <link href="2021/03/11/ASP-NET-Core-with-SignalR/"/>
      <url>2021/03/11/ASP-NET-Core-with-SignalR/</url>
      
        <content type="html"><![CDATA[<h2 id="understanding-the-real-time-web"><a class="markdownIt-Anchor" href="#understanding-the-real-time-web"></a> Understanding the Real-time Web</h2><h3 id="polling"><a class="markdownIt-Anchor" href="#polling"></a> Polling</h3><ul><li>Clients periodically ask the server if there’s an update. For each poll, a HTTP request is made, and the server either responds with a new status or 204 No Content</li></ul><h3 id="long-polling"><a class="markdownIt-Anchor" href="#long-polling"></a> Long Polling</h3><ul><li><p>Clients send HTTP request to the server. But the server will not complete the request but leave it until there’s an update. When there’s no update within a certain timeframe, the request will time out. When that happens, the client will just start the process again by issuing a new request.</p></li><li><p>Long Polling is more efficient than polling, but it is still using HTTP requests to ask for updates.</p></li></ul><h3 id="server-sent-events-sse"><a class="markdownIt-Anchor" href="#server-sent-events-sse"></a> Server Sent Events (SSE)</h3><ul><li><p>a HTML5 feature, the server creats an HTTP connection to the client(browser) with Server Sent Events. The browser will listen for messages that will come in as a stream. The connection will remain open until it is actively closed.</p></li><li><p>The browser will use an object called EventSource that has an event onmessage to process incoming messages.</p></li></ul><ol><li>Using simple HTTP</li><li>Auto reconnects</li><li>No support for older browsers</li><li>Easily polyfilled</li><li>Maximum HTTP connections issue (6 connections at most)</li><li>Only support text messages</li><li>One-way connection</li></ol><h3 id="web-sockets"><a class="markdownIt-Anchor" href="#web-sockets"></a> Web Sockets</h3><ul><li><p>A standardized way to use one TCP socket through which messages can be sent from server to client and vice versa and without the latency of HTTP.</p></li><li><p>A TCP socket typically remains open for as long as the stream of the messages are not done.</p></li><li><p>SignalR will use WebSockets most of the time because its the most efficient transport.</p></li></ul><ol><li>Full duplex messaging (client to server and vice versa)</li><li>No 6 connections limit</li><li>For most browsers, the connection limit for web sockets is about 50 connections</li><li>Multi data type support (text, binary)</li><li>TCP socket upgrade (Regular HTTP request uses a TCP socket as well)</li></ol><ul><li><p>The WebSockets standards uses a handshake mechanism to upgrade an existing socket used for HTTP traffic to a WebSocket. After that, messages can travel through the socket until the socket is actively closed. When closing, a reason for closing is communicated.</p></li><li><p>Every WebScoket starts its life as a simple HTTP socket, A GET HTTP call is made to the server, requesting an upgrade of the socket. If the server agrees, the socket becomes a WebSocket from that point onwards.</p></li></ul><h2 id="signalr"><a class="markdownIt-Anchor" href="#signalr"></a> SignalR</h2><ul><li>SignalR is an open source framework that wraps the complexity of real-time web transports. You don’t need to worry about the lower level transports like long polling, Server Sent Event or WebSockets.</li></ul><h3 id="transports"><a class="markdownIt-Anchor" href="#transports"></a> Transports</h3><ul><li>WebSockets, Server Sent Events, Long Polling</li><li>Requires client and server that supports transport</li><li>Fallback mechanism (if browser doesn’t support WebSocket, then use SSE instead, etc…)</li></ul><h3 id="remote-procedure-call-rpc"><a class="markdownIt-Anchor" href="#remote-procedure-call-rpc"></a> Remote Procedure Call (RPC)</h3><ul><li>Server can call a function in the Client and vice versa</li></ul><h3 id="hub"><a class="markdownIt-Anchor" href="#hub"></a> Hub</h3><ul><li>A hub is a server-side class that sends messages to and receives messages from clients by utilizing RPC.</li></ul><p><img src="/../images/ASP-NET-Core-with-SignalR/1.png" alt="" /></p><ul><li>A hub protocol is a format used to serialize parameters to and deserialize parameters from</li></ul><h3 id="differences-with-classic-signalr"><a class="markdownIt-Anchor" href="#differences-with-classic-signalr"></a> Differences with Classic SignalR</h3><ul><li>Simplified connection model</li><li>Single hub per connection</li><li>Async</li><li>Binary and custom protocols</li><li>No jQuery dependency for JavaScript client</li><li>Sticky session required</li></ul><h3 id="scaling-out"><a class="markdownIt-Anchor" href="#scaling-out"></a> Scaling Out</h3><ul><li>Running on muiltiple servers</li><li>Load Balancer picks server</li><li>Problem with non-WebSockets transport, it could send the first request to the first server, then send the second request to the second server, who doesn’t know anything about the context of the message.</li></ul><p><img src="/../images/ASP-NET-Core-with-SignalR/2.png" alt="" /></p><ul><li>We could solve this problem by using sticky sessions.</li><li>As part of the response of the first request, the load balancer sets a cookie in the browser, indicating the server that was used. On subsequent request, the load balancer then reads the cookie and assigns the request to the same server. (IIS using Application Request Routing Affinity (ARR Affinity))</li></ul><p><img src="/../images/ASP-NET-Core-with-SignalR/3.png" alt="" /></p><ul><li><p>Another problem, let’s say a user is working on a web document using Office 365, and she invites others to join her, the other might end up at another server. When user 1 on the server changes the document, a message has to be sent to the others, but server 1 doesn’t know about users that are connected to hubs in other servers.</p></li><li><p>To solve this, the servers need a way to share data. This can be done using a Database, but a faster alternative would be to use a Redis cache.</p></li></ul><p><img src="/../images/ASP-NET-Core-with-SignalR/4.png" alt="" /></p>]]></content>
      
      
      
        <tags>
            
            <tag> ASP.NET Core </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ASP.NET Core Fundamentals</title>
      <link href="2021/03/07/ASP-NET-Core-Fundamentals/"/>
      <url>2021/03/07/ASP-NET-Core-Fundamentals/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
        <tags>
            
            <tag> ASP.NET Core </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C# Fundamentals</title>
      <link href="2021/03/04/C-Fundamentals/"/>
      <url>2021/03/04/C-Fundamentals/</url>
      
        <content type="html"><![CDATA[<h2 id="dotnet-cli"><a class="markdownIt-Anchor" href="#dotnet-cli"></a> dotnet CLI</h2><ul><li>Create new dotnet project</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dotnet new console</span><br><span class="line">dotnet new xunit</span><br></pre></td></tr></table></figure><ul><li>Add unget package</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dotnet add package xunit --version 2.4.1</span><br></pre></td></tr></table></figure><ul><li>Add reference to another project in .csproj file</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dotnet add reference projectName.csproj</span><br></pre></td></tr></table></figure><ul><li>Run unit test project</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dotnet test</span><br></pre></td></tr></table></figure><ul><li>Run main project</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dotnet run</span><br></pre></td></tr></table></figure><ul><li>Create solution file to include all projects</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dotnet new sln</span><br></pre></td></tr></table></figure><ul><li>Add project into the solution file</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dotnet sln add PathToProjectFile.csproj</span><br></pre></td></tr></table></figure><ul><li>Build all project in solution</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dotnet build</span><br></pre></td></tr></table></figure><ul><li><p>C# passes variables by value unless you use keyword e.g. ref, out</p></li><li><p>C# has garbage collector</p></li></ul><h3 id="auto-property"><a class="markdownIt-Anchor" href="#auto-property"></a> Auto property</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public string Name &#123;</span><br><span class="line">    get &#123;</span><br><span class="line">        return name;</span><br><span class="line">    &#125;</span><br><span class="line">    set &#123;</span><br><span class="line">        name &#x3D; value</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>This code can be simplified to</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public string Name &#123; get; set; &#125;</span><br></pre></td></tr></table></figure><ul><li>difference between auto property and field</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public string Name &#123;get; set;&#125;</span><br><span class="line"></span><br><span class="line">public string Name;</span><br></pre></td></tr></table></figure><ul><li>You can specify custom code in getter and setter functions.</li><li>When serialize objects, fields may not be counted.</li></ul><h3 id="readonly"><a class="markdownIt-Anchor" href="#readonly"></a> readonly</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">readonly public string category;</span><br></pre></td></tr></table></figure><ul><li>readonly can only be assigned in constructor.</li></ul><h3 id="const"><a class="markdownIt-Anchor" href="#const"></a> const</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">const public string CATEGORY</span><br></pre></td></tr></table></figure><ul><li>const is more strict than readonly, you can’t assign it in constructor, it is not a variable. Once you initialized it, you can’t change its value. And when you access it. You can access it from the class name, not the object name. Because every object instance will have the same value for this const. So its better to access it from the class. Its more clear.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Book is a class</span><br><span class="line">&#x2F;&#x2F; CATEGORY is a const in Book</span><br><span class="line">&#x2F;&#x2F; Category is a readonly field in Book</span><br><span class="line">Console.WriteLine(Book.CATEGORY); &#x2F;&#x2F; const</span><br><span class="line"></span><br><span class="line">var book1 &#x3D; new Book();</span><br><span class="line">Console.WriteLine(book1.Category); &#x2F;&#x2F; readonly field</span><br></pre></td></tr></table></figure><h3 id="delegate"><a class="markdownIt-Anchor" href="#delegate"></a> Delegate</h3><ul><li>A delegate is a type that represents references to methods with a particular parameter list and return type. When you instantiate a delegate, you can associate its instance with any method with a compatible signature and return type. You can invoke (or call) the method through the delegate instance.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">public delegate string WriteLogDelegate (string logMessage);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; reference the main project to the test project in .csproj</span><br><span class="line">public class TypeTests</span><br><span class="line">&#123;</span><br><span class="line">    [Fact]</span><br><span class="line">    public void WriteLogDelegateCanPointToMethod() &#123;</span><br><span class="line">        WriteLogDelegate log &#x3D; new WriteLogDelegate(ReturnMessage);</span><br><span class="line"></span><br><span class="line">        var result &#x3D; log(&quot;Hello!&quot;);</span><br><span class="line">        Assert.Equal(&quot;Hello!&quot;, result);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private string ReturnMessage(string message) &#123;</span><br><span class="line">        return message;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="multi-cast-delegate"><a class="markdownIt-Anchor" href="#multi-cast-delegate"></a> Multi-Cast Delegate</h3><ul><li>One delegate variable can points to multiple methods, and by invoking that delegate variable, all subscribed methods will be invoked too</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">public delegate string WriteLogDelegate (string logMessage);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; reference the main project to the test project in .csproj</span><br><span class="line">public class TypeTests</span><br><span class="line">&#123;</span><br><span class="line">    int count &#x3D; 0;</span><br><span class="line"></span><br><span class="line">    [Fact]</span><br><span class="line">    public void WriteLogDelegateCanPointToMethod() &#123;</span><br><span class="line">        WriteLogDelegate log &#x3D; new WriteLogDelegate(ReturnMessage);</span><br><span class="line">        log +&#x3D; IncrementCounter;</span><br><span class="line"></span><br><span class="line">        var result &#x3D; log(&quot;Hello!&quot;);</span><br><span class="line">        Assert.Equal(2, count);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private string ReturnMessage(string message) &#123;</span><br><span class="line">        count++;</span><br><span class="line">        return message;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private string IncrementCounter(string message) &#123;</span><br><span class="line">        count++;</span><br><span class="line">        return message.Tolower();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="event"><a class="markdownIt-Anchor" href="#event"></a> Event</h3><ul><li>Sometimes after we have done someting, we want to broadcast it to all people that are interested. The broadcast delegate usually takes two parameters, the object sender and EventArgs. object is the base type in C#, all types and classes can be fitted into object.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">public delegate void GradeAddedDelegate(object sender, EventArgs eventArgs);</span><br><span class="line"></span><br><span class="line">public class Book &#123;</span><br><span class="line">    public event GradeAddedDelegate GradeAdded;</span><br><span class="line"></span><br><span class="line">    public void AddGrade(double grade) &#123;</span><br><span class="line">        if (grade &lt;&#x3D; 100 &amp;&amp; grade &gt;&#x3D; 0) &#123;</span><br><span class="line">            grades.Add(grade);</span><br><span class="line"></span><br><span class="line">            &#x2F;&#x2F; broadcast</span><br><span class="line">            &#x2F;&#x2F; if GradeAdded is null, then no one is listening to this event</span><br><span class="line">            &#x2F;&#x2F; so there is no need to invoke the delegate.</span><br><span class="line">            if (GradeAdded !&#x3D; null) &#123;</span><br><span class="line">                GradeAdded(this, new EventArgs())</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            throw new ArgumentException($&quot;Invalid &#123;nameof(grade)&#125;&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>In program.cs where we are trying to use this Book object</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">class Program</span><br><span class="line">&#123;</span><br><span class="line">    static void Main(string[] args)</span><br><span class="line">    &#123;</span><br><span class="line">        var book &#x3D; new Book(&quot;Yuan&#39;s Grade Book&quot;);</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; add OnGradeAdded to this delegate</span><br><span class="line">        book.GradeAdded +&#x3D; OnGradeAdded;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    static void OnGradeAdded(object sender, EventArgs e) &#123;</span><br><span class="line">        Console.WriteLine($&quot;A grade was added.&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="oop"><a class="markdownIt-Anchor" href="#oop"></a> OOP</h2><h3 id="inheritance"><a class="markdownIt-Anchor" href="#inheritance"></a> Inheritance</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">public class NamedObject &#123;</span><br><span class="line">    &#x2F;&#x2F; Name field</span><br><span class="line">    public string Name &#123;get; set;&#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; constructor</span><br><span class="line">    public NamedObject(string name) &#123;</span><br><span class="line">        Name &#x3D; name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; inherit from NamedObject base class</span><br><span class="line">public class BookBase : NamedObject &#123;</span><br><span class="line">    public BookBase(string name) : base(name) &#123;</span><br><span class="line">        Name &#x3D; name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public Program clas &#123;</span><br><span class="line">    static void Main(string[] args)</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; when you create a new instance of Book</span><br><span class="line">        &#x2F;&#x2F; you assign the new name Book 1 to Book class</span><br><span class="line">        &#x2F;&#x2F; Book class will pass the same name to its base class</span><br><span class="line">        Book book1 &#x3D; new Book(&quot;Book 1&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>When you want to use some attributes or functions from a base class, instead of rewrite the code, you can inherit the base class. The constructor of the child class will also need to pass in the variable to its base class</li></ul><h3 id="polymophism"><a class="markdownIt-Anchor" href="#polymophism"></a> Polymophism</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public abstract class BookBase : NamedObject &#123;</span><br><span class="line">    public BookBase (string name) : base(name) &#123;&#125;</span><br><span class="line"></span><br><span class="line">    public abstract void AddGrade(double grade);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p>The abstract modifier indicates that the thing being modified has a missing or incomplete implementation. And it will be implemented by its child class. Child class who inherit the base class will need to add an override keyword to implement the abstract function</p></li><li><p>Base class can have different implementations of it. A Car base class may have Truck and Sport Car as its children class and they have some same base field and functions but also many different.</p></li></ul><h3 id="interface"><a class="markdownIt-Anchor" href="#interface"></a> Interface</h3><ul><li>Where abstract may content actual implementation of some field and functions (some is missing). The Interface class doesn’t have any implementations.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">namespace GradeBook</span><br><span class="line">&#123;</span><br><span class="line">    public interface IBook</span><br><span class="line">    &#123;</span><br><span class="line">        void AddGrade(double grade);</span><br><span class="line">        string Name &#123;get;&#125;</span><br><span class="line">        event GradeAddedDelegate GradeAdded;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="virtual"><a class="markdownIt-Anchor" href="#virtual"></a> Virtual</h3><ul><li>For base class, there may be some functions that already have an implementation. But Virtual keyword meaning its children class may choose to override it.</li></ul><h3 id="difference-between-virtual-and-abstract"><a class="markdownIt-Anchor" href="#difference-between-virtual-and-abstract"></a> Difference between Virtual and Abstract</h3><ul><li><p>Virtual methods have an implementation and provide the derived classes with the option of overriding it. Abstract methods do not provide an implementation and force the derived classes to override the method.</p></li><li><p>So, abstract methods have no actual code in them, and subclasses HAVE TO override the method. Virtual methods can have code, which is usually a default implementation of something, and any subclasses CAN override the method using the override modifier and provide a custom implementation.</p></li></ul><h3 id="using"><a class="markdownIt-Anchor" href="#using"></a> using</h3><ul><li>When we are writing text to file, we need to open the file and close it after finish. But if the program crashes when we editing the file, we will leave the file open. One thing we can do is to use the try catch block to catch the exception and close the file finally. C# has a short keyword for this purpose, the using keyword. It will call Dispose() function in IDisposable -&gt; TextWriter -&gt; StreamWriter to free up the memory and close the file.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">using (var writer &#x3D; File.AppendText($&quot;&#123;Name&#125;.txt&quot;))</span><br><span class="line">&#123;</span><br><span class="line">    writer.WriteLine(grade);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> C# </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS SAA - Design Cost-Optimized Architectures</title>
      <link href="2021/02/28/AWS-SAA-Design-Cost-Optimized-Architectures/"/>
      <url>2021/02/28/AWS-SAA-Design-Cost-Optimized-Architectures/</url>
      
        <content type="html"><![CDATA[<ol><li><a href="#part-one-understanding-cost-effective-storage-in-aws">Part One: Understanding Cost Effective Storage in AWS</a></li><li><a href="#part-two-understanding-cost-effective-compute-in-aws">Part Two: Understanding Cost Effective Compute in AWS</a></li><li><a href="#part-three-understanding-database-pricing-and-cost-optimization">Part Three: Understanding Database Pricing and Cost Optimization</a></li><li><a href="#part-Four-understanding-cost-optimized-network-architectures">Part Four: Understanding Cost Optimized Network Architectures</a></li><li><a href="#part-five-making-cost-optimized-decisions">Part Five: Making Cost-optimized Decisions</a></li></ol><h2 id="part-one-understanding-cost-effective-storage-in-aws"><a class="markdownIt-Anchor" href="#part-one-understanding-cost-effective-storage-in-aws"></a> Part One: Understanding Cost Effective Storage in AWS</h2><h3 id="globomantics"><a class="markdownIt-Anchor" href="#globomantics"></a> Globomantics</h3><ul><li>Global health care organization</li><li>Been using AWS for some time</li><li>Most core service such as EC2, RDS, S3 etc.</li><li>We have been asked to<ul><li>identify solutions that will help reduce costs</li><li>maintain the same level of service and availability</li></ul></li></ul><h3 id="module-overview"><a class="markdownIt-Anchor" href="#module-overview"></a> Module Overview</h3><ol><li>S3<ul><li>Using S3 storage classes to reduce costs</li></ul></li><li>S3 glacier<ul><li>When to use S3 glacier and S3 glacier heep archieve</li></ul></li><li>EBS storage<ul><li>EBS pricing points and storage options</li></ul></li></ol><h3 id="s3-storage-classes"><a class="markdownIt-Anchor" href="#s3-storage-classes"></a> S3 Storage Classes</h3><ol><li>Influences availability, durability and cost for objects stored in S3</li><li>Applied at an object level, each S3 bucket can host objects with different classes</li><li>An objects storage class can be changed throughout its lifetime</li><li>Using the wrong storage class will lead to unnecessary spending</li></ol><ul><li>Standard: Charged based on object size</li><li>Standard - IA: Charged based on object size and retrieval</li><li>One Zone - IA: Stores objects in a single AZ</li><li>S3 Glacier: Used as an additional S3 storage class</li><li>Intelligent - Tiering: Transitions objects between classes based on their access frequencies</li></ul><h4 id="lifecycle-rules"><a class="markdownIt-Anchor" href="#lifecycle-rules"></a> Lifecycle rules</h4><ul><li>Use lifecycle rules to transition objects between classes and expire objects</li></ul><h4 id="caching"><a class="markdownIt-Anchor" href="#caching"></a> Caching</h4><ul><li>Downloading objects cost money, use caching to avoid unnecessary downloads and reduce S3 costs</li></ul><h4 id="globomantics-requirements"><a class="markdownIt-Anchor" href="#globomantics-requirements"></a> Globomantics Requirements</h4><ul><li>Use an appropriate storage class for each object</li><li>Avoid one zone -IA as it reduces availability (store data we can reproduce in OZ - IA)</li><li>Use lifecycle rules<ul><li>Transition to standard - IA</li><li>Transition to S3 Glacier</li><li>Expire objects(delete)</li></ul></li></ul><h3 id="s3-glacier-and-deep-archive"><a class="markdownIt-Anchor" href="#s3-glacier-and-deep-archive"></a> S3 Glacier and Deep Archive</h3><h4 id="globomantics-requirements-2"><a class="markdownIt-Anchor" href="#globomantics-requirements-2"></a> Globomantics Requirements</h4><ul><li>Need to store some data long term for compliance</li><li>Data must be stored for at least 10 years</li><li>Meet the following requirements<ul><li>Stored as cheaply as possible</li><li>Still be highly durable and available</li><li>Must be secure</li><li>Data won’t be needed again except for compliance requests</li></ul></li></ul><h4 id="s3-glacier"><a class="markdownIt-Anchor" href="#s3-glacier"></a> S3 Glacier</h4><ul><li>Long term archival storage</li><li>Two classes S3 Glacier and Deep Archive</li><li>Using S3 glacier we can retrieve archives in minutes</li><li>Using S3 glacier deep archive we can retrieve data within 12 hours</li></ul><ul><li>Data in S3 glacier are not available to you. You need to request a retrival.</li></ul><h4 id="comparing-storage-costs"><a class="markdownIt-Anchor" href="#comparing-storage-costs"></a> Comparing Storage Costs</h4><ul><li>S3 Standard - 10TB - eu-west-1 $245.64</li><li>S3 Glacier - 10TB - eu-west-1 $46.08</li><li>S3 Glacier Deep Archive - 10TB - eu-west-1 $18.44</li></ul><h3 id="ebs-storage"><a class="markdownIt-Anchor" href="#ebs-storage"></a> EBS Storage</h3><ul><li>Block storage for EC2 virtual machines</li><li>Persistent storage of up to 16TB per disk</li><li>SSD backed and HDD backed volumes</li><li>Provisioned storage priced at a GB per month rate</li></ul><ul><li>You are charged for the entire volume as soon as you created it. You can create a smaller EBS than increase it when you need it in the future</li></ul><h4 id="options"><a class="markdownIt-Anchor" href="#options"></a> Options</h4><ol><li>Cold HDD volumes, $0.025 per GB per month</li><li>Throughput optimized HDD volumes, $0.045 per GB per month</li><li>General purpose SSD volumes, $0.10 per GB per month</li><li>Provisioned IOPS SSD volumes, $0.125 per GB per month and $0.065 per provisioned IOPS per month</li></ol><h4 id="ebs-snapshots"><a class="markdownIt-Anchor" href="#ebs-snapshots"></a> EBS Snapshots</h4><ul><li>Snapshots consist of the used space in an EBS volume not the provisioned space</li><li>Charged on a per GB per month basis</li><li>Additional cost for EBS fast snapshot restore</li></ul><ul><li>If you have a 1000 GB provisioned EBS and only used 100 GB space, when you create a snapshot of this EBS, you will only be charged of 100 GB.</li></ul><h3 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h3><ol><li>Use S3 storage classes to reduce costs</li><li>Use S3 Glacier and its role in reducing costs</li><li>EBS storage pricing</li></ol><h2 id="part-two-understanding-cost-effective-compute-in-aws"><a class="markdownIt-Anchor" href="#part-two-understanding-cost-effective-compute-in-aws"></a> Part Two: Understanding Cost Effective Compute in AWS</h2><h3 id="module-overview-2"><a class="markdownIt-Anchor" href="#module-overview-2"></a> Module Overview</h3><ol><li>Discuss EC2 payment types</li><li>Discuss right sizing EC2 to optimize costs</li><li>Introduce cost benefits of serverless compute</li></ol><h3 id="pricing-points"><a class="markdownIt-Anchor" href="#pricing-points"></a> Pricing points</h3><ol><li>EC2 instance uptime</li><li>EBS storage</li><li>Data transfer out</li></ol><h3 id="instance-types"><a class="markdownIt-Anchor" href="#instance-types"></a> Instance types</h3><h4 id="on-demand-instances"><a class="markdownIt-Anchor" href="#on-demand-instances"></a> On Demand instances</h4><ul><li>Charged by the hour or second (minimum 60 seconds)</li><li>No upfront commitment, billed when instances are in a running state</li><li>Great when you want uninterrupted compute</li></ul><h4 id="reserved-instances"><a class="markdownIt-Anchor" href="#reserved-instances"></a> Reserved Instances</h4><ul><li>1-year or 3-year commitment</li><li>pay all, parital or no upront (the more you pay upfront, the bigger discount you will get)</li><li>Convertible RIs available</li><li>Capacity reservation with Zonal RIs</li><li>Instance size flexibility</li><li>Up to 72% saving</li></ul><h4 id="spot-instances"><a class="markdownIt-Anchor" href="#spot-instances"></a> Spot Instances</h4><ul><li>You are biding on unused capacity in an AZ</li><li>If your bid is higher than the spot price you pay the lower amount</li><li>Spot, Spot fleets (multiple machines, only launch when all of them can be launched at the same time), and spot blocks (multiple machines, only launch them when they can be running for a certain peroid of time) are available</li><li>When you loose the spot bid<ul><li>2-minute warning (to transfer your data)</li><li>instance terminate/hibernate/stop depend on your choice</li></ul></li></ul><h4 id="in-addition"><a class="markdownIt-Anchor" href="#in-addition"></a> In addition</h4><ul><li>Scheduled reserved instance: Useful if you are only running your instance periodically</li><li>Savings plans: Alternative to reserved instances, useful if you have mixed EC2 instance, AWS fargate and AWS lambda</li></ul><h3 id="globomantics-requirements-3"><a class="markdownIt-Anchor" href="#globomantics-requirements-3"></a> Globomantics Requirements</h3><ul><li>Use a minture of EC2 instances sizes and types</li><li>Currently only on-demand instance type used</li><li>EC2 instance characteristic<ul><li>Some instances run 24/7 and are expected to do so for at least 1 year (reserved instances with 1-year commitment)</li><li>Some instances are brought online for 48 hours every week to run weeekly batch jobs (scheduled reserved instances)</li><li>Other instances are brought online as needed to run short processes that must be completed within 2 hours (on-demand or spot block)</li></ul></li></ul><ul><li>Note using spot block you might need to wait for some time (when your bid is higher) before your instances can be launched</li></ul><h3 id="right-sizing-ec2-to-optimize-costs"><a class="markdownIt-Anchor" href="#right-sizing-ec2-to-optimize-costs"></a> Right Sizing EC2 to Optimize Costs</h3><ul><li>Eight instance familes: Groups of instances such as general purpose, compute optimized and memory optimized</li><li>Instance sizes: Each family has a range of instance sizes that offer different combinations of resources</li></ul><h4 id="burstable-and-fixed-performance-instances"><a class="markdownIt-Anchor" href="#burstable-and-fixed-performance-instances"></a> Burstable and Fixed performance instances</h4><ul><li>Fixed performance (e.g. M5) offers fixed compute</li><li>Burstable performance (e.g. T3) provide a baseline level of CPU (e.g. 20%) with the ability to burst above the baseline.</li><li>Standard and unlimited: For burstable instances, if you are not using your CPU, you will get tokens(credit) which you can use later when you need extra CPU power. For Standard, your compute power will reduce to original when you use up your tokens. For unlimited, you will be charged the on-demand price for the compute power but can still use the extra CPU power for as long as you need.</li></ul><h4 id="tools-for-right-ec2-sizing"><a class="markdownIt-Anchor" href="#tools-for-right-ec2-sizing"></a> Tools for Right EC2 Sizing</h4><ul><li>Amazon CloudWatch: Monitor CPU, network throughput, disk I/O</li><li>AWS Cost Explorer: Monitor your spending and view resource optimization recommendations</li><li>AWS Trusted Advisor: Best practice advice including advice on reduing costs</li></ul><h4 id="aws-serverless-platform"><a class="markdownIt-Anchor" href="#aws-serverless-platform"></a> AWS Serverless Platform</h4><ul><li>Compute: AWS lambda, AWS fargate</li><li>Storage: S3</li><li>Data Stores: DynamoDB, Aurora</li><li>API Proxy: Amazon API Gateway</li><li>Integration: Amazon SNS, Amazon SQS</li></ul><p><strong>Benefits of Serverless Compute</strong></p><ul><li>No server management: No need to provision administer or maintain EC2 instance</li><li>Flexible scaling: Scale automatically without downtime by adjusting capacity</li><li>High availability: Built for automated high availability and fault tolerance</li></ul><h4 id="globomantics-requirements-4"><a class="markdownIt-Anchor" href="#globomantics-requirements-4"></a> Globomantics Requirements</h4><ul><li>Deployed a 2-tier customer facing web application to AWS</li><li>Deployed using EC2 and RDS MySQL</li><li>Interested to know how this application would be deployed using serverless services?</li><li>Would there be cost benefits?</li></ul><p><img src="/../images/AWS-SAA-Design-Cost-Optimized-Architectures/1.png" alt="" /></p><h3 id="summary-2"><a class="markdownIt-Anchor" href="#summary-2"></a> Summary</h3><ol><li>Discussed different ways to pay for EC2</li><li>Demonstrated EC2 savings plans</li><li>Discussed right sizing of EC2</li><li>Discussed how serverless compute can help reduce costs</li></ol><h2 id="part-three-understanding-database-pricing-and-cost-optimization"><a class="markdownIt-Anchor" href="#part-three-understanding-database-pricing-and-cost-optimization"></a> Part Three: Understanding Database Pricing and Cost-optimization</h2><h3 id="module-overview-3"><a class="markdownIt-Anchor" href="#module-overview-3"></a> Module Overview</h3><ul><li>Discuss RDS Pricing</li><li>Discuss DynamoDB Pricing</li></ul><h3 id="rds-pricing-points"><a class="markdownIt-Anchor" href="#rds-pricing-points"></a> RDS Pricing Points</h3><ol><li>Instance type and size</li><li>Database storage</li><li>Data transfer out between AZs and between regions</li><li>Backup storage</li></ol><h4 id="amazon-rds-instance-types"><a class="markdownIt-Anchor" href="#amazon-rds-instance-types"></a> Amazon RDS Instance Types</h4><ol><li>General purpose: Including M4 and M5, good balance between computer memory and network resources</li><li>Memory optimized: Including R4 and R5, designed for memory-intensive database workloads</li><li>Burstable performance: Offering a baseline level of CPU with the ability to burst above the baseline</li></ol><h4 id="rds-payment-options"><a class="markdownIt-Anchor" href="#rds-payment-options"></a> RDS Payment Options</h4><ol><li>On-Demand: Pay as you go, no upfront payments</li><li>Reserved instances: 1-year or 3-year commitment for up to 69% saving</li></ol><h4 id="rds-storage"><a class="markdownIt-Anchor" href="#rds-storage"></a> RDS Storage</h4><ol><li>General purpose SSD: From 20GB to 64GB prices at a $ per GB per month</li><li>Provisioned IOPS SSD: Priced on a $ per GB per month plus $ per IOPS per month</li><li>Magnetic storage: Cheapest storage, not recommended for new deployments</li></ol><h3 id="amazon-aurora"><a class="markdownIt-Anchor" href="#amazon-aurora"></a> Amazon Aurora</h3><ol><li>Faster than MySQL and PostgreSQL</li><li>Offers additional features like Aurora serverless</li><li>Cheaper than both MySQL and PostgreSQL</li></ol><h3 id="dynamodb-pricing-points"><a class="markdownIt-Anchor" href="#dynamodb-pricing-points"></a> DynamoDB Pricing Points</h3><ol><li>On-demend: Charged foe the data reads and writes your application performs</li><li>Provisioned capacity: You buy the read and write capacity units that you need for your application</li></ol><h4 id="dynamodb-capacity-units"><a class="markdownIt-Anchor" href="#dynamodb-capacity-units"></a> DynamoDB Capacity Units</h4><ol><li>WCU(Write Capacity Units)<ul><li>Each WCU is equivalent to one 1KB write per second.</li><li>e.g. If each of your record is 10KB, and you need to write 5 records per second, then you need 50 WCU</li></ul></li><li>RCU(Read Capacity Units)<ul><li>Eventual &lt; Strongly &lt; transactional consistency</li><li>Each RCU is equivalent to one 4KB strongly consistent read per second.</li><li>Each RCU is equivalent to two 4KB eventual consistent read per second</li><li>Each RCU is equivalent to 0.5 transactional consistent read per second</li></ul></li></ol><ul><li>DynamoDB auto scaling: Dynamically adjusts provisioned throughput in response to traffic patterns</li><li>Reserved capacity: Purchase RCUs and WCUs with a 1-year or 3-year commitment at a reduced rate</li></ul><h4 id="additional-dynamodb-costs"><a class="markdownIt-Anchor" href="#additional-dynamodb-costs"></a> Additional DynamoDB Costs</h4><ul><li>Global secondary indexes need their own capacity units</li><li>Global DynamoDB tables will need additional capacity units</li><li>DynamoDB backups will increase costs</li></ul><h3 id="summary-3"><a class="markdownIt-Anchor" href="#summary-3"></a> Summary</h3><ul><li>Discussed RDS pricing options</li><li>Discussed DynamoDB pricing options</li></ul><h2 id="part-four-understanding-cost-optimized-network-architectures"><a class="markdownIt-Anchor" href="#part-four-understanding-cost-optimized-network-architectures"></a> Part Four: Understanding Cost-optimized Network Architectures</h2><h3 id="module-overview-4"><a class="markdownIt-Anchor" href="#module-overview-4"></a> Module Overview</h3><ul><li>Discuss using ELB and Auto Scale to reduce costs</li><li>Discuss VPC routing and hybrid connectivity cost decisions</li><li>Discuss using offloading to reduce costs</li></ul><h3 id="elb-and-auto-scaling"><a class="markdownIt-Anchor" href="#elb-and-auto-scaling"></a> ELB and Auto Scaling</h3><h4 id="globomantics-requirements-5"><a class="markdownIt-Anchor" href="#globomantics-requirements-5"></a> Globomantics Requirements</h4><ol><li>Deployed a 3-tier customer facing web application to AWS</li><li>Deployed using EC2 and RDS MySQL</li><li>Peak time for the application is Friday and Saturday where up to two times the amount of compute is needed</li></ol><p><img src="/../images/AWS-SAA-Design-Cost-Optimized-Architectures/2.png" alt="" /></p><ol><li>Right size the EC2 instances and RDS instances</li><li>Introduce EC2 auto scale for the web and app tier</li><li>Introduce load balancing for the app tier</li></ol><p><img src="/../images/AWS-SAA-Design-Cost-Optimized-Architectures/3.png" alt="" /></p><h4 id="auto-scaling-saves-money"><a class="markdownIt-Anchor" href="#auto-scaling-saves-money"></a> Auto Scaling Saves Money</h4><ol><li>With auto scaling we design for the normal</li><li>Auto scaling leads to better cost management</li><li>Integrate with load balancing to make use of launched instance</li><li>Using min and max values allow us to better predict costs</li></ol><h3 id="vpc-routing-and-hybrid-connectivity-decisions"><a class="markdownIt-Anchor" href="#vpc-routing-and-hybrid-connectivity-decisions"></a> VPC Routing and Hybrid Connectivity Decisions</h3><h4 id="globalmantics-requirements"><a class="markdownIt-Anchor" href="#globalmantics-requirements"></a> Globalmantics Requirements</h4><ol><li>Connect Globalmantics HQ and smaller regional offices to their AWS deployed VPC</li><li>Connect resources in their AWS deployed VPC to S3</li><li>Connect Globalmantics application VPC to a VPC that contains monitoring servers</li><li>Cost is a major factor, all designs should balance performance, funcationality and cost</li></ol><p><img src="/../images/AWS-SAA-Design-Cost-Optimized-Architectures/4.png" alt="" /></p><ol><li>For connecting HQ to AWS VPC, we can use Direct connect or site-to-site VPN, Direct connect will give us better performance but more expensive.</li><li>For connecting Branch offices to AWS VPC, site-to-site VPN should be good enough considering offices are small.</li><li>For connecting Application VPC to Monitoring VPC, we could use VPC peering, it will only charge us for data transfer. The others options are: Transit Gateway and site-to-site VPNs (more expensive).</li><li>For connecting Application VPC to S3, we could use VPC endpoints. Other option is to use public gateway but that is less secure(need to go through public internet).</li></ol><h4 id="aws-connectivity"><a class="markdownIt-Anchor" href="#aws-connectivity"></a> AWS Connectivity</h4><ul><li>Keep as much traffic as possible on the AWS backbone</li><li>Consider using Direct Connect hosted connections</li><li>Use AWS services to reduce development and management costs</li><li>Balance performance, functionality and cost</li></ul><h3 id="offloading-with-cloudfront"><a class="markdownIt-Anchor" href="#offloading-with-cloudfront"></a> Offloading with CloudFront</h3><h4 id="how-can-deploying-a-additional-technology-like-cloudfront-reduce-costs"><a class="markdownIt-Anchor" href="#how-can-deploying-a-additional-technology-like-cloudfront-reduce-costs"></a> How can deploying a additional technology like CloudFront reduce costs?</h4><ul><li>S3 charges a retrieval fee per GB and fees based on the type of request</li><li>CloudFront charges a retrieval fee and a fee for HTTP or HTTPS requests</li><li>CloudFront fees are cheaper than S3 fees</li><li>Serving content from CloudFront can be cheaper then serving content from S3</li></ul><p><img src="/../images/AWS-SAA-Design-Cost-Optimized-Architectures/5.png" alt="" /></p><h3 id="summary-4"><a class="markdownIt-Anchor" href="#summary-4"></a> Summary</h3><ul><li>Learned how ELB and auto scale can help reduce costs</li><li>Discussed VPC routing and hybrid connectivity options</li><li>Learned how offloading can help reduce costs</li></ul><h2 id="part-five-making-cost-optimized-decisions"><a class="markdownIt-Anchor" href="#part-five-making-cost-optimized-decisions"></a> Part Five: Making Cost-optimized Decisions</h2><h3 id="overview"><a class="markdownIt-Anchor" href="#overview"></a> Overview</h3><ul><li>Discuss factors that can affect costs</li><li>Work with AWS tools to monitor and estimate costs</li></ul><h4 id="some-factors-that-can-affect-cost"><a class="markdownIt-Anchor" href="#some-factors-that-can-affect-cost"></a> Some factors that can affect cost</h4><ul><li>AWS region and zone: Resource are priced per-region and per-availability zone</li><li>EC2 size and type: Instance type and size will have a big impact on the cost of your compute</li><li>S3 storage class: Choose the correct class for the objects you are storing</li></ul><h4 id="tips-to-help-save-money-in-aws"><a class="markdownIt-Anchor" href="#tips-to-help-save-money-in-aws"></a> Tips to Help Save Money in AWS</h4><ul><li>EC2 Payment: Use the correct payment model</li><li>Databases: Use reservation for RDS and DynamoDB</li><li>Tag Everything: Introduce and effective tagging policy</li><li>Intriduce SCPs(Service Control Policy): Use SCPs to restrict available features</li><li>Monitor everything: Use all the monitoring tools available to you</li><li>AutoScale: Implement AutoScale to avoid planning for peak</li><li>Offloading: Use offloading in your architectures (CloudFront, ElasticCache, RDS Read Replicas)</li><li>Turn things off: Shutdown and delete resources that you are not using</li></ul><h2 id="course-summary"><a class="markdownIt-Anchor" href="#course-summary"></a> Course Summary</h2><h3 id="storage-and-compute"><a class="markdownIt-Anchor" href="#storage-and-compute"></a> Storage and Compute</h3><ol><li>S3 Storage classes</li><li>S3 lifecycle rules</li><li>EBS storage options</li><li>EC2 pricing</li><li>EC2 right sizing</li><li>Serverless compute</li></ol><h3 id="databases-and-networks"><a class="markdownIt-Anchor" href="#databases-and-networks"></a> Databases and networks</h3><ol><li>RDS pricing and optimization</li><li>DynamoDB pricing and optimization</li><li>Cost optimized networks<ul><li>ELB and autoscale</li><li>Hybrid connectivity</li><li>VPC connectivity</li><li>Offloading with CloudFront</li></ul></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> AWS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java Learning Path</title>
      <link href="2021/02/21/Java-Learning-Path/"/>
      <url>2021/02/21/Java-Learning-Path/</url>
      
        <content type="html"><![CDATA[<h1 id="入坑java开发的学习之路"><a class="markdownIt-Anchor" href="#入坑java开发的学习之路"></a> 入坑Java开发的学习之路</h1><h2 id="基础知识"><a class="markdownIt-Anchor" href="#基础知识"></a> 基础知识</h2><ul><li>编程语言： Java Python C</li><li>基本算法</li><li>基本网络知识： TCP/IP HTTP HTTPS</li><li>基本设计模式</li></ul><hr /><h2 id="工具方面"><a class="markdownIt-Anchor" href="#工具方面"></a> 工具方面</h2><ul><li>操作系统： Linux (CentOS/Ubuntu…)</li><li>代码管理： SVN / Git</li><li>持续集成(CI/CD): Jenkins</li><li>Java项目管理工具： Maven / Gradle</li></ul><hr /><h2 id="框架方面"><a class="markdownIt-Anchor" href="#框架方面"></a> 框架方面</h2><h4 id="应用层框架"><a class="markdownIt-Anchor" href="#应用层框架"></a> 应用层框架</h4><ul><li><s>ssh: spring + structs + hibernate</s></li><li>ssm: spring + spring mvc + mybatis</li><li>spring boot</li></ul><h4 id="中间件"><a class="markdownIt-Anchor" href="#中间件"></a> 中间件</h4><ul><li>MQ 消息队列</li><li>RPC 通信框架 gRPC thrift dubbo spring cloud</li><li>Elasticsearch 数据库 搜索引擎</li></ul><h4 id="数据库"><a class="markdownIt-Anchor" href="#数据库"></a> 数据库</h4><ul><li>SQL: MySQL / Postgre SQL</li><li>NoSQL: Redis Memcached mongoDB elasticsearch</li></ul><hr /><h2 id="架构方面"><a class="markdownIt-Anchor" href="#架构方面"></a> 架构方面</h2><h4 id="分布式微服务架构"><a class="markdownIt-Anchor" href="#分布式微服务架构"></a> 分布式/微服务架构</h4><ul><li>spring cloud</li><li>dubbo</li><li>RPC通信</li></ul><h4 id="虚拟化容器化"><a class="markdownIt-Anchor" href="#虚拟化容器化"></a> 虚拟化/容器化</h4><ul><li>Docker</li><li>k8s kubernetes</li></ul><hr /><h2 id="关注源码性能"><a class="markdownIt-Anchor" href="#关注源码性能"></a> 关注源码/性能</h2><ul><li>JDK源码以及部分设计思想</li><li>Spring源码</li><li>JVM 细节与排错</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS SAA - Design Secure Applications and Architectures</title>
      <link href="2021/02/15/AWS-SAA-Design-Secure-Applications-and-Architectures/"/>
      <url>2021/02/15/AWS-SAA-Design-Secure-Applications-and-Architectures/</url>
      
        <content type="html"><![CDATA[<ol><li><a href="#part-one-protecting-aws-credentials">Part One: Protecting AWS Credentials</a></li><li><a href="#part-two-capturing-and-analyzing-logs">Part Two: Capturing and Analyzing Logs</a></li><li><a href="#part-three-protecting-network-and-host-level-boundaries">Part Three: Protecting Network and Host-level Boundaries</a></li><li><a href="#part-four-protecting-data-at-rest">Part Four: Protecting Data at Rest</a></li><li><a href="#part-five-protecting-data-in-transit">Part Five: Protecting Data in Transit</a></li><li><a href="#part-six-configuring-data-backup-replication-and-recovery">Part Six: Configuring Data Backup, Replication, and Recovery</a></li></ol><h2 id="part-one-protecting-aws-credentials"><a class="markdownIt-Anchor" href="#part-one-protecting-aws-credentials"></a> Part One: Protecting AWS Credentials</h2><ul><li>Security is about protecting data.</li></ul><h3 id="the-cia-triad"><a class="markdownIt-Anchor" href="#the-cia-triad"></a> The CIA Triad</h3><ul><li>Confidentiality</li><li>Integrity</li><li>Availability</li></ul><ul><li><p>Confidentiality: Only authorized parties can access data. (ACLs and encryption)</p></li><li><p>Integrity: Data has not been improperly modified. Includes knowing if data has been modified.</p></li><li><p>Availability: Authorized parties have access to data when they need it. Includes protecting systems that store, process, and deliver data.</p></li><li><p>Defense in depth: Protecting the confidentiality, integrity, and availability of data by securing everything that touches the data, including storage, compute and networking</p></li><li><p>Levels of Architecture: AWS services, Operating systems, Applications</p></li></ul><h3 id="aws-credentials"><a class="markdownIt-Anchor" href="#aws-credentials"></a> AWS Credentials</h3><ul><li><p>Root User: Full access to all AWS resources. Only one root user per account.</p></li><li><p>IAM principal: Any entity(could be a user or an application) that can perform actions on AWS services and resources. Policies determine what permissions a principal has</p></li><li><p>Locking down the Root user: Enable MFA. Don’t use the root user for administrative tasks. Use a non-root IAM user with administrative permissions</p></li><li><p>IAM Principal: The foundation of IAM. An entity that can take an action on an AWS service. Often used as a synonym for identity. Principles include users and roles</p></li><li><p>A non-root principal has no permissions by default. Policies determine what permission a principal has</p></li><li><p>You must grant permissions to a principal by associating it with a policy.</p></li><li><p>Policy and Permission: A policy consists of multiple permission statements. A permission statement consists of 4 elements.</p></li></ul><ol><li>Effect (allow or deny)</li><li>Service (etc: EC2)</li><li>Action/Operation (RunInstances)</li><li>Resource (image/ami-fjdfjfsdk)</li><li>Request condition(MFA, IP range, time…) (198.51.100.0/24)</li></ol><ul><li>This permission will allow a principal to run an EC2 instance with certain AMI, when it is in certain IP range.</li><li>AWS managed policies: AWS has many managed policies created for us to use. (they are updated regularly to include new services)</li><li>The deny effect always takes precedence over the allow effect (deny &gt; allow)</li></ul><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/1.png" alt="" /></p><ul><li>We can create inline policy for a user to deny he’s access to terminate any EC2 instances.</li></ul><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/2.png" alt="" /></p><ul><li>This is the JSON representation of the policy</li></ul><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/3.png" alt="" /></p><ul><li>We could use policy simulator to check the effectiveness of the policy.</li><li>We could also create inline policy for a group.</li></ul><h3 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h3><ol><li>Implement MFA for the root user</li><li>User an administrative user instead of root user</li><li>AWS managed policies are updated as new services and actions are added</li><li>A policy permission consists of an effect, service, action/operation and resource</li><li>A user policy is an inline policy embedded in a user</li><li>A group policy is embedded in a group</li><li>Customer Managed policies work like AWS managed policies, but are created and managed by you</li></ol><h2 id="part-two-capturing-and-analyzing-logs"><a class="markdownIt-Anchor" href="#part-two-capturing-and-analyzing-logs"></a> Part Two: Capturing and Analyzing Logs</h2><h3 id="module-overview"><a class="markdownIt-Anchor" href="#module-overview"></a> Module Overview</h3><ol><li>Capturing events with CloudTrail</li><li>Viewing Logs with CloudWatch Logs</li><li>Creating alerts with CloudWatch Alarms</li><li>Searching logs with Athena</li><li>Tracking changes with AWS config</li></ol><ul><li>CloudTrail logs are stored in S3. Limit what you log to control costs</li></ul><h3 id="cloudtrail-event-types"><a class="markdownIt-Anchor" href="#cloudtrail-event-types"></a> CloudTrail event types</h3><ul><li><p>Management: Configuration changes to AWS services. Reading resources. Logging into the management console. Assuming a role.</p></li><li><p>Data: Access to S3 objects. Lambda function execution</p></li><li><p>CloudTrail: Logs AWS actions. Stores logs in S3</p></li><li><p>CloudWatch Logs: Aggregates logs from CloudTrail and non-AWS sources. Provides interface to view and search logs</p></li></ul><h3 id="create-iam-service-role"><a class="markdownIt-Anchor" href="#create-iam-service-role"></a> Create IAM service role</h3><ul><li>Contains inline service policy that grants CloudTrail permissions to send logs to CloudWatch Logs</li><li>Contains trust policy that allows CloudTrail to assume the role</li><li>Role is an IAM principal for CloudTrail to use to authenticate to CloudWatch Logs</li></ul><h3 id="demo"><a class="markdownIt-Anchor" href="#demo"></a> Demo</h3><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/4.png" alt="" /></p><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/5.png" alt="" /></p><h4 id="create-a-log-group-in-cloudwatch-logs"><a class="markdownIt-Anchor" href="#create-a-log-group-in-cloudwatch-logs"></a> Create a log group in CloudWatch Logs</h4><ul><li>Create an IAM role for CloudTrail to assume. The Role will have two permission statements. It can create log streams and it can put the log into CloudWatch Log groups.</li></ul><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/6.png" alt="" /></p><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/7.png" alt="" /></p><ul><li>The CloudTrail and the Role have a trusted relationship. If we have a look at the JSON policy. It will allow CloudTrail to assume the Role. The Role will give its permissions to CloudTrail.</li></ul><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/8.png" alt="" /></p><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/9.png" alt="" /></p><ul><li>Create CloudWatch Alarm we need to select a metric, in this case, IncomingLogEvents. We define the alarm so that it triggers the alarm if CloudTrail send more than 1 log to CloudWatch Logs within 1 minute period of time.</li></ul><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/10.png" alt="" /></p><ul><li>We also created new topic with an email address so I will get notified if this happens.</li></ul><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/11.png" alt="" /></p><ul><li>After the alarm has been created, the status is OK because we didn’t receive any logs in the last 1 minutes. And we treat missing logs as Good.</li></ul><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/12.png" alt="" /></p><ul><li>When there is logs coming in, the status will be changed to In alarm for that 1 minute period and will be changed back to OK the next minute.</li><li>Notice the alarm logs are not in real time. There maybe a couple of minutes delay.</li></ul><h3 id="why-athena"><a class="markdownIt-Anchor" href="#why-athena"></a> Why Athena?</h3><ul><li><p>Maybe you don’t want to use CloudWatch Logs. You can use SQL like queries to search thought logs and all S3 objects. If the files are in correct format (e.g. csv, JSON, CloudTrail logs stored in S3 are in JSON format)</p></li><li><p>Athena usrs SQL, so to search files in s3, we need to provide the schema. AWS provides the schema for CloudTrail Logs</p></li></ul><h3 id="demo-2"><a class="markdownIt-Anchor" href="#demo-2"></a> Demo</h3><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/13.png" alt="" /></p><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/14.png" alt="" /></p><ul><li>Note you need to create a save location for the Athena search result in S3 before run the query.</li></ul><h3 id="tracking-configuration-changes-in-aws-config"><a class="markdownIt-Anchor" href="#tracking-configuration-changes-in-aws-config"></a> Tracking Configuration Changes in AWS Config</h3><ul><li>Tracks configuration changes over time.</li><li>AWS config can tell you the stats of all AWS services of any point of time in the past.</li><li>Records changes in S3.</li><li>Notifies of changes</li></ul><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/15.png" alt="" /></p><h3 id="summary-2"><a class="markdownIt-Anchor" href="#summary-2"></a> Summary</h3><ul><li>CouldTrail tracks events</li><li>ClousdWatch Logs aggregates logs from different sources</li><li>CloudWatch Alarms trigger based on specific log activity</li><li>Athena performs SQL queries against objects in S3</li><li>AWS Config tracks configuration states over time</li></ul><h2 id="part-three-protecting-network-and-host-level-boundaries"><a class="markdownIt-Anchor" href="#part-three-protecting-network-and-host-level-boundaries"></a> Part Three: Protecting Network and Host-level Boundaries</h2><h3 id="tic-tac-toe-web-application"><a class="markdownIt-Anchor" href="#tic-tac-toe-web-application"></a> Tic-tac-toe web application</h3><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/16.png" alt="" /></p><ul><li>Host-level boundary is the default security group between the public subnet and the EC2 instance(auto created).</li><li>NACL(netwoek access control list): controls traffic in and out the subnet</li><li>having both the security group and NACL gives you layers of security around your instance.</li><li>The game data stored in DynamoDB, to communicate with it, we have two options</li></ul><ol><li>We can go over the public internet via igw(internet gateway)</li><li>We can also use a VPC endpoint, which is a non-internet private connection</li></ol><h3 id="module-overview-2"><a class="markdownIt-Anchor" href="#module-overview-2"></a> Module Overview</h3><ol><li>Creating a public subnet</li><li>Creating and using an IAM instance profile</li><li>Using SSH key pairs</li><li>Using VPC endpoints</li><li>Network access control lists</li></ol><h3 id="demo-3"><a class="markdownIt-Anchor" href="#demo-3"></a> Demo</h3><ol><li>Create VPC</li><li>Create subnet</li><li>Create igw</li><li>Attach igw to VPC</li><li>Add routes in VPC’s main route table</li><li>Add VPC’s inbound rules</li><li>Create IAM role to allow access to DynamoDB</li><li>Role will contain a trust policy to allow EC2 instances to assume the role</li><li>Launch instance and attach instance profile</li></ol><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/17.png" alt="" /></p><ul><li>Create VPC</li></ul><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/18.png" alt="" /></p><ul><li>Create public subnet, we use the CIDR block the same as our VPC because we are only going to create one subnet for this VPC</li></ul><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/19.png" alt="" /></p><ul><li>Create internet gateway</li></ul><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/20.png" alt="" /></p><ul><li>Attach internet gateway to VPC</li></ul><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/21.png" alt="" /></p><ul><li>Edit the main route table, add another record. Route all traffic to igw. By doing this we make our subnet a public subnet</li></ul><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/22.png" alt="" /></p><ul><li>Add two inbound rules in our VPC’s default security group. Use my home IP as source. So only at my home can I access the VPC services by HTTP or SSH.</li></ul><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/23.png" alt="" /></p><ul><li>Create IAM role to access DynamoDB</li></ul><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/24.png" alt="" /></p><ul><li>Create a role and attach the policy to it. Because we choose EC2 as the service that will be using this role, the trusted entity is EC2. It also creates an instance profile for us.</li></ul><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/25.png" alt="" /></p><ul><li>Create an EC2 instance</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh ec2-user@13.55.117.52 -i .\hellcyAWSkey.pem</span><br></pre></td></tr></table></figure><ul><li>Access EC2 instance via SSH</li><li>You need to go to your private key location (pem) and change the access level to 400(linux) or change the Owner to yourself and remove all other groups and users. <a href="https://superuser.com/questions/1296024/windows-ssh-permissions-for-private-key-are-too-open">Check here</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum -y install git python2-pip.noarch</span><br></pre></td></tr></table></figure><ul><li>install the app</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;benpiper&#x2F;dynamodb-tictactoe-example-app</span><br></pre></td></tr></table></figure><ul><li>clone the repo from github</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pip install flask boto</span><br></pre></td></tr></table></figure><ul><li>install dependecies</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo python application.py</span><br></pre></td></tr></table></figure><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/26.png" alt="" /></p><ul><li>cd to the application folder and run the app.</li><li>You can play the game with other people who logs in</li></ul><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/27.png" alt="" /></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl 169.254.169.254&#x2F;latest&#x2F;meta-data&#x2F;iam&#x2F;security-credentials&#x2F;tic-tac-toe-app</span><br></pre></td></tr></table></figure><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/28.png" alt="" /></p><ul><li>this is the secret token generated by AWS STS(Security Token Service) using instance profile(from the role) to allow our instance to access DynamoDB.</li></ul><h3 id="using-vpc-endpoints"><a class="markdownIt-Anchor" href="#using-vpc-endpoints"></a> Using VPC Endpoints</h3><ul><li>Now we are going to change our traffic to go through a private link via VPC endpoint.</li></ul><h3 id="demo-4"><a class="markdownIt-Anchor" href="#demo-4"></a> Demo</h3><ol><li>Block outbound internet access from the instance</li><li>Configure VPC endpoint</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nslookup dynamodb.ap-southeast-2.amazonaws.com</span><br></pre></td></tr></table></figure><ul><li>look up the ip address of DynamoDB at our current AWS region</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo netstat -tp | grep python</span><br></pre></td></tr></table></figure><ul><li>check outbound connection from our EC2 instance to DynamoDB. Note our application needs to be running for this to work.</li></ul><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/29.png" alt="" /></p><h4 id="create-vpc-endpoint"><a class="markdownIt-Anchor" href="#create-vpc-endpoint"></a> Create VPC Endpoint</h4><ul><li>New route rules will be added to the route table. This is to change the traffic sent to the DynamoDB from the private VPC endpint instead of the public igw</li><li>Note it is required to create a policy for this VPC endpoint. The policy controls what the requests can do to the DynamoDB. Remember we already created a policy for a role and attached that role to our EC2 instance. They are two different policies. One for EC2, One for VPC endpoint.</li></ul><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/30.png" alt="" /></p><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/31.png" alt="" /></p><ul><li><p>in the VPC’s security group. We need to remove the outbound rule for accessing public internet. Add a new rule to access DynamoDB endpoint.</p></li><li><p>Note that we can access to the EC2 instance because we still have the inbound rules.</p></li><li><p>Security Groups are stateful. They track the state of the connections to and from your instance. If you allow the traffic into your instance, then the security group will automatically allow the instance to reply to that traffic.</p></li><li><p>Note there is a file <strong>bootstrap-responsive.css</strong> missing in the course app. I used FlieZilla uploaded this file to EC2. Below is the FlieZilla connection settings. Note port is 22.</p></li></ul><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/32.png" alt="" /></p><h3 id="network-access-control-lists"><a class="markdownIt-Anchor" href="#network-access-control-lists"></a> Network Access Control Lists</h3><ul><li>Security Group controls in/out traffic for a EC2 instance. While NACL controls all traffic in the subnet. They are two layers of security.</li></ul><h4 id="differences-between-security-group-and-nacl"><a class="markdownIt-Anchor" href="#differences-between-security-group-and-nacl"></a> Differences between Security Group and NACL</h4><ol><li>Security Group<ul><li>Instance Level</li><li>Stateful</li><li>Unnumbered rules (rules don’t have order)</li></ul></li><li>NACL<ul><li>Subnet level</li><li>Stateless</li><li>Numbered rules (rules have order)</li></ul></li></ol><ul><li><p>Stateful means security groups will automatically allow reply traffic.</p></li><li><p>Stateless means if you only have inbound rule to access the instance. But do not have the outbound rule. Then the traffic can not leave the subnet. You have to setup both in/out rules to access an instance in the subnet.</p></li><li><p>Numbered rules means each rule will have a number. Smaller number rules will be applied first(high priority).</p></li></ul><h3 id="summary-3"><a class="markdownIt-Anchor" href="#summary-3"></a> Summary</h3><ol><li>A public subnet has a default route to an internet gateway</li><li>Use an IAM instance profile to grant an instance access to an AWS service</li><li>Decide whether to connect to AWS endpoints via the internet or a VPC endpoint</li><li>Security groups and network access control lists act as firewalls but differ in significant ways</li></ol><h2 id="part-four-protecting-data-at-rest"><a class="markdownIt-Anchor" href="#part-four-protecting-data-at-rest"></a> Part Four: Protecting Data at Rest</h2><ul><li>Data at Rest is the data stored in a place(hard drive)</li><li>Data in Transit is the data being sent in public internet</li></ul><ol><li>Access Permissions<ul><li>Bucket policies</li><li>User policies</li><li>Access Control lists</li></ul></li><li>Encryption<ul><li>Requires access to a key to encrypt and decrypt data</li><li>if the key is gone. so is the data!</li></ul></li></ol><h3 id="module-overview-3"><a class="markdownIt-Anchor" href="#module-overview-3"></a> Module Overview</h3><ol><li>Create a customer master key(CMK)</li><li>Encrypt an EBS volumn</li><li>S3 access control lists, bucket policies, and user policies</li><li>Securely grant anonymous access to S3 object</li><li>Encrypt S3 object</li></ol><h3 id="demo-create-a-customer-master-key-using-kms"><a class="markdownIt-Anchor" href="#demo-create-a-customer-master-key-using-kms"></a> Demo Create a customer master key using KMS</h3><ol><li>Assign a key alias(friendly name)</li><li>Define key administrators (people who manages the key)</li><li>Define key users (people who will be using the key)</li></ol><h3 id="demo-encrypt-the-data-on-an-unencrypted-ebs-volume"><a class="markdownIt-Anchor" href="#demo-encrypt-the-data-on-an-unencrypted-ebs-volume"></a> Demo Encrypt the data on an unencrypted EBS volume</h3><ol><li>Stop the web1 instance (tic-tac-toe)</li><li>Take a snapshot of the root volume</li><li>Make an encrypted copy of the snapshot</li><li>Create an AMI(instance image) using the encrypted snapshot</li><li>Launch another instance using the new AMI</li></ol><h3 id="demo-s3-access-permissions"><a class="markdownIt-Anchor" href="#demo-s3-access-permissions"></a> Demo S3 Access Permissions</h3><ol><li>Create an S3 bucket</li><li>Configure bucket access control lists</li><li>Create a bucket policy</li></ol><ul><li>There are two types of policies</li></ul><ol><li>identity based policy<ul><li>we set this up in IAM, we can grant policy to a IAM user</li></ul></li><li>resource based policy<ul><li>we set this up in resource page. We can add IAM users to the policy to let the resource know that these people can access it.</li></ul></li></ol><ul><li>Create a folder in the new S3 bucket and try to access this folder using another IAM user who only has read access to S3 buckets. Then try to use the new user to create another folder in S3 (will fail).</li><li>Note folder in S3 is just another object(just look like a folder). So it requires the same permission as objects.</li></ul><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/33.png" alt="" /></p><ul><li>using Bucket inline policy generator, we can add another IAM user to the access list in S3 policy. Need to specify the IAM user ARN and S3 bucket ARN. After doing this we can create another folder using another IAM user.</li></ul><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/34.png" alt="" /></p><h3 id="demo-cloudfront-origin-access-identity"><a class="markdownIt-Anchor" href="#demo-cloudfront-origin-access-identity"></a> Demo CloudFront Origin Access Identity</h3><ol><li>Create an S3 bucket</li><li>Create an origin access identity(OAI)</li><li>Grant OAI access to the bucket</li><li>Create a CloudFront distribution</li></ol><ul><li>Note to grant OAI access to the S3 bucket, we need to create an inline policy for the S3 bucket. Tell the bucket to let our OAI user have the read access.</li><li>Now only through the CloudFront can we access the bucket files.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># Load named profile</span><br><span class="line">export AWS_PROFILE&#x3D;ben</span><br><span class="line"></span><br><span class="line"># Create S3 bucket</span><br><span class="line">aws s3api create-bucket --bucket yuan.com-cloudfront</span><br><span class="line"></span><br><span class="line"># Create and uplaod index.html document</span><br><span class="line">echo &quot;Hello, world!&quot; &gt; index.html</span><br><span class="line">aws s3 cp index.html s3:&#x2F;&#x2F;yuan.com-cloudfront&#x2F;</span><br><span class="line"></span><br><span class="line"># Create the origin access identity (OAI)</span><br><span class="line">aws cloudfront create-cloud-front-origin-access-identity --cloud-front-origin-access-identity-config CallerReference&#x3D;&quot;demo&quot;,Comment&#x3D;&quot;OAI for yuan.com-cloudfront&quot;</span><br><span class="line"></span><br><span class="line"># Apply a bucket policy granting read access to the OAI</span><br><span class="line">aws s3api put-bucket-policy --bucket yuan.com-cloudfront --policy file:&#x2F;&#x2F;bucketpolicy.json</span><br><span class="line"></span><br><span class="line"># Verify bucket policy</span><br><span class="line">aws s3api get-bucket-policy --bucket yuan.com-cloudfront</span><br><span class="line"></span><br><span class="line"># Create a CloudFront distribution</span><br><span class="line">aws cloudfront create-distribution --distribution-config file:&#x2F;&#x2F;dist-config.json</span><br></pre></td></tr></table></figure><h3 id="demo-granting-anonymous-access-with-object-acls-and-bucket-policies"><a class="markdownIt-Anchor" href="#demo-granting-anonymous-access-with-object-acls-and-bucket-policies"></a> Demo Granting Anonymous Access with Object ACLs and Bucket Policies</h3><ol><li>Grant anonymous access to an individual S3 object</li><li>Grant read permissions to everyone using the object’s ACL (Resources based policy)</li><li>Use a bucket policy to grant everyone permission to perform the GetObject action against the object (identity based policy)</li></ol><ul><li><p>Note even if we logged as the IAM who has full access to S3 object (owner). When we try to access a certain file in S3 bucket. We will still get Access Denied response. Why is that? Because when we click the link to access S3 object, our browser will make an anonymous request to the object, which doesn’t not include any authentication information with it.</p></li><li><p>Note if you are trying to modify bucket policy to give public access to a file. You have to make the bucket public first.</p></li></ul><h3 id="encrypting-s3-objects-with-kms-managed-keys"><a class="markdownIt-Anchor" href="#encrypting-s3-objects-with-kms-managed-keys"></a> Encrypting S3 Objects with KMS-managed Keys</h3><ol><li>Generate a new CMK</li><li>Enable encryption on our S3 bucket (existing files in bucket will not be encrypted)</li><li>Verify that unauthorized users can’t decrypt data</li></ol><h3 id="summary-4"><a class="markdownIt-Anchor" href="#summary-4"></a> Summary</h3><ol><li>Use KMS to create customer master keys</li><li>Use the key policy to grant principals permission to use the key</li><li>To encrypt data on an existing EBS volume, snapshot the volume, and make an encrypted copy of a snapshot</li><li>Enabling KMS encryption on an S3 bucket doesn’t encrypt existing objects.</li><li>Don’t delete a key that’s being used to encrypt or decrypt data! (you can’t decrypt data after key’s deleted)</li><li>To control access to S3, you can use access control lists, bucket policies, or user policies(identity based policies)</li><li>Use object ACLs to grant anonymous access to individual objects</li><li>Bucket policies contain the principal element while user policies don’t</li></ol><h2 id="part-five-protecting-data-in-transit"><a class="markdownIt-Anchor" href="#part-five-protecting-data-in-transit"></a> Part Five: Protecting Data in Transit</h2><ul><li>Encrypting data between users in public internet and AWS cloud</li></ul><h3 id="transport-layer-security-tls"><a class="markdownIt-Anchor" href="#transport-layer-security-tls"></a> Transport Layer Security (TLS)</h3><ul><li>People sometimes incorrectly call this SSL(secure sockets layer, which is the old technology that nobody uses anymore)</li><li>HTTPS uses TLS (S stands for security which the underlying protocol is TLS)</li></ul><ol><li><p>Configure application to use TLS</p><ul><li>Application-dependent configuration</li><li>independent of AWS</li></ul></li><li><p>Application Load Balancer (We use this in this course)</p><ul><li>Configure AWS application load balancer to use TLS</li><li>Force all clients through the load balancer</li></ul></li></ol><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/35.png" alt="" /></p><ul><li>We are going to create a load balancer and a TLS certificate using AWS ACM, then install the certificate on the load balancer. All users need to access the load balancer to access our instances (which hosted the tic-tac-toe application). And all traffic between users and load balancer are encrypted.</li></ul><h3 id="module-overview-4"><a class="markdownIt-Anchor" href="#module-overview-4"></a> Module Overview</h3><ol><li>Prepare the infrastructure to support an applicatioin load balancer</li><li>Create a secure Application load balancer</li></ol><h3 id="demo-preparing-for-the-load-balancer"><a class="markdownIt-Anchor" href="#demo-preparing-for-the-load-balancer"></a> Demo Preparing for the Load Balancer</h3><ol><li>Create a new subnet in a different zone (load balancer requires instances to be at different AZs)</li><li>Bring up an instance named web2</li><li>Launch the application</li><li>Reconfigure security group (permit access to/from load balancer)</li></ol><h3 id="demo-creating-a-secure-application-load-balancer"><a class="markdownIt-Anchor" href="#demo-creating-a-secure-application-load-balancer"></a> Demo Creating a Secure Application Load Balancer</h3><ol><li>Use the AWS Certificate Manager to create a TLS certificate</li><li>Create an Application Load Balancer</li><li>Create a DNS record for the application</li><li>Browse to the application using HTTPS</li></ol><ul><li><p>If you use Route53 to control the DNS records of your domain. You can let AWS create the CNAME record for you.</p></li><li><p>To create a load balancer, you need to specify the following</p><ol><li>Load Balancer type: HTTPS, internet facing</li><li>VPC AZs (tic-tac-toe)</li><li>Security groups (tic-tac-toe)</li><li>Routing (new target group HTTP:80 to both instances)</li><li>Register both instance as load balancer targets</li><li>DNS name is the load balancer name we can browse to</li><li>Create an A record in Route53 convert load balancer DNS name to a friendly domain name.</li></ol></li><li><p>Now you can browse to the URL using HTTPS</p></li></ul><h3 id="summary-5"><a class="markdownIt-Anchor" href="#summary-5"></a> Summary</h3><ol><li>Choose where to terminate the TLS connection<ul><li>Individual instances (you need to configure TLS connection of your application and install TLS certificate on each instance)</li><li>Application Load Balancer (only need to install one TLS certificate on the load balancer)</li></ul></li><li>ALB requires two availability zones</li><li>ACM requires you to verify control of the domain name in the certificate</li></ol><h2 id="part-six-configuring-data-backup-replication-and-recovery"><a class="markdownIt-Anchor" href="#part-six-configuring-data-backup-replication-and-recovery"></a> Part Six: Configuring Data Backup, Replication, and Recovery</h2><h3 id="module-overview-5"><a class="markdownIt-Anchor" href="#module-overview-5"></a> Module Overview</h3><ol><li>Versioning</li><li>Lifecycle rules</li><li>Cross-region replication</li></ol><h3 id="demo-versioning"><a class="markdownIt-Anchor" href="#demo-versioning"></a> Demo Versioning</h3><ol><li>Versioning prevents accidental deletion and overwriting of data</li><li>Enable versioning</li><li>Upload object</li><li>Restoring versions</li></ol><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/36.png" alt="" /></p><ul><li>After you enabling the versioning of a S3 bucket, when you deleted a file. AWS will not delete the file but instead hide it and give the file a deletion marker. In the version list, you can see all versions of the same file. And if you delete the version with deletion marker, you can bring the deleted files back.</li></ul><h3 id="lifecycle-management"><a class="markdownIt-Anchor" href="#lifecycle-management"></a> Lifecycle Management</h3><ol><li>Different storage classes provide different levels of redundency</li><li>Standard is the default storage class</li><li>Automatically migrate older objects to a cheaper class</li><li>Automatically delete old objects</li></ol><h3 id="demo-liftcycle-management"><a class="markdownIt-Anchor" href="#demo-liftcycle-management"></a> Demo Liftcycle Management</h3><ol><li>Examine object storage classes</li><li>Create a lifecycle rule</li></ol><p><img src="/../images/AWS-SAA-Design-Secure-Applications-and-Architectures/37.png" alt="" /></p><ul><li>This image explains the current lifecycle I set up for the bucket.</li></ul><ol><li>On day 30, objects will be moved to One-Zone IA</li><li>On day 31, objects will be added a delete marker and become previous versions</li><li>On day 32, objects will be moved to Glacier</li><li>On day 39, objects will be deleted permenately</li></ol><ul><li>Note, small objects in Glacier will have higher costs (objects &lt; 128KB)</li></ul><h3 id="demo-cross-region-replication"><a class="markdownIt-Anchor" href="#demo-cross-region-replication"></a> Demo Cross-Region Replication</h3><ol><li>Congifure cross-region replication</li><li>Replication doesn’t include existing objects</li></ol><ul><li>When enable replication rules</li></ul><ol><li>choose destination bucket</li><li>choose keys to decrypt data in source bucket</li><li>choose keys to encrypt data in destination bucket</li></ol><h3 id="summary-6"><a class="markdownIt-Anchor" href="#summary-6"></a> Summary</h3><ol><li>Versioning<ul><li>Every change results in a new object version</li><li>deleting an object creates a marker</li><li>delete the marker to restore the object</li></ul></li><li>Lifecycle Management<ul><li>Move objects to different classes</li><li>delete objects</li></ul></li><li>Cross-region replication<ul><li>Synchronously copy new objects to a different bucket</li><li>Replicating to a different region offers protection against local catastrophes</li></ul></li></ol><h2 id="couse-summary"><a class="markdownIt-Anchor" href="#couse-summary"></a> Couse Summary</h2><ul><li><p>Remember that the goal of security is protect the confidentiality, integrity, and availability of data. It’s that CIA triad.</p></li><li><p><strong>Protecting AWS Credentials</strong>: At the start of this course, you learned how to configure identity and access management. This is like the building security system. It controls who can enter the building, what rooms they can go into, and so on.</p></li><li><p><strong>Capturing and Analyzing Logs</strong>: After that, you learned how to capture and analyze logs using CloudTrail and CloudWatch. In a physical building, this would be the building’s cameras, security guards, and log books. You’re not just concerned with what should happen, but what did happen. You want to know everything that’s going on inside that building.</p></li><li><p><strong>Protecting Network and Host-level Boundaries</strong>: However, perhaps the nature of your particular building is such that it’s not practical to identify everyone that exits and enters. If you’ve got a business that has clients coming in and out all the time, making them sign in and sign out can be a burden. In that case, you need a different way of controlling access to the building. This is analogous to protecting network and host-level boundaries in your AWS environment. Think of security groups and network access control lists. You’ll let strangers in your building, but you’re going to be strict about where they can go and what they can do.</p></li><li><p><strong>Protecting Data at Rest</strong>: Next, you learned how to protect at rest using encryption and access controls. Think of a combination safe that contains a secret message. The safe is locked in a room that you have to use a badge to gain access to. First, you swipe your badge to get into the room, and then once in the room, you must possess the correct combination to open the safe.</p></li><li><p><strong>Protecting Data in Transit</strong>: Next, you’ll learn how to protect data in transit by way of, yes, encryption. Again, if you want to take a top secret document out of the building and deliver it to someone, you might stick it in a locked briefcase or perhaps hire an armored courier to transport it for you. As long as the document is outside of the building, it remains under lock and key until it gets to its destination.</p></li><li><p><strong>Configuring Data Backup, Replication and Recovery</strong>: Lastly, we looked at how to perform data backup, replication, and recovery. Basically, if all else fails and your data does get destroyed, at least it’s not gone forever. You can get it back.</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> AWS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS SAA - Architecting for Reliability on AWS</title>
      <link href="2020/10/15/AWS-SAA-Architecting-for-Reliability-on-AWS/"/>
      <url>2020/10/15/AWS-SAA-Architecting-for-Reliability-on-AWS/</url>
      
        <content type="html"><![CDATA[<p>AWS SAA C02 exam will include 4 topic</p><ol><li>Resilience</li><li>Performance</li><li>Security</li><li>Cost-Optimization</li></ol><h3 id="chapter-one-resilience"><a class="markdownIt-Anchor" href="#chapter-one-resilience"></a> Chapter One: Resilience</h3><h4 id="section-one-availability"><a class="markdownIt-Anchor" href="#section-one-availability"></a> Section One: Availability</h4><p>Resiliency: The ability of an application to avoid and recover from failure.</p><p>Availability: The percentage of time that an application is performing as expected.</p><p>Poor performance implies low availablility. Uptime isn’t the same as availability.</p><p>The service level agreement(SLA) for each service includes its annual availability.</p><p>The availability of a single EC2 instance is 90%</p><p>The availability of an ELB(Elastic Load Balancer) and EFS(Elastic File System) is 99.99%</p><p>The availability of a RDS(Relational DataBase System) multi-AZ(multi-Availability Zone) is 99.95%</p><p>The availability of a Lambda is 99.95%</p><p>The availability of a S3 is 99.9%</p><p>The availability of a DynamoDB with Global Tables (replicates our database across multiple regions) is 99.999%</p><p>Traditional web application: can be convert to AWS web application without having to change the code. For example, a traditional video processing application can use Elastic File System(EFS) to store video data. But it cannot use S3 to store video data. Because that requires changes of code.</p><p>EFS provides a network file system (NFS) volume, NFS is an established standard that most Linux distributions support.</p><p>For DB: we can use (Relational Database Service)RDS. It offers managed database engines (MySQL, MariaDB, PostgreSQL, Microsoft SQL server, Oracle…). AWS manages database infrastructure and backups.</p><h4 id="loose-coupling"><a class="markdownIt-Anchor" href="#loose-coupling"></a> Loose Coupling</h4><p>One component doesn’t depend on a specific component (e.g. URL points to ELB, not a specific EC2), one-to-many relationship</p><p>is EFS a single point of failure?</p><p>No, Elastic services are always composed of redundant components, they just hide it. Elastic services are always loosely coupled with other services like EC2.</p><p>Loose Coupling helps Performance: If our application’s performance is low and we want to upgrade our EC2 instances, because they are loose coupled, we can upgrade EC2 instances one by one and our application will still be available, ELB will just route traffic to other instances.</p><p>Performance and Availability are linked.</p><h4 id="simple-queue-service"><a class="markdownIt-Anchor" href="#simple-queue-service"></a> Simple Queue Service</h4><p>The concept of Loose Coupling can be applied to the application level too. For example, we have a video processing application, we can create two components for this application, the web interface part and the video processing part. Users go to the webpage and submit a request of a video with differnt options, and video processing part gets the request and start processing.</p><p>But because processing videos take much more time than sending requests. We need a Message Queue Service to save all the requests in order. Simple Queue Service(SQS) is one option with high availability.</p><h4 id="elastic-container-service"><a class="markdownIt-Anchor" href="#elastic-container-service"></a> Elastic Container Service</h4><p>Container helps you to deploy web serices easier. Build an image of your container, deploy the image to an instance, and launch the containser in the image. E.g. Docker</p><p>You can have multiple containers in one instance, so it is like you are running multiple web services for the price of one instance. Also, if one container is down, the other containers on that instance will still be running. (Processes running inside the container are isolated from the host.)</p><h4 id="cloud-native-applications"><a class="markdownIt-Anchor" href="#cloud-native-applications"></a> Cloud Native Applications</h4><p>Depend on a cloud service that can’t be deployed on-premises</p><p>Examples: SQS, S3, DynamoDB</p><p>Lambda, S3 and DynamoDB are three main serverless components.</p><p>Rather than running the video processing function on a service on a EC2 instance, we could write a Lambda function to do that. Lambda is a serverless service (they are running on a server of course, but the server is managed by AWS and we don’t need to worry about it, so we call it serverless.)</p><p>Advantages of using Cloud Native Architecture: Scalability, Performance, Convenience</p><p>Disadvantages: Could vendor lock-in (have to use AWS services), Slightly lower availability (Cloud services are hard dependencies).</p><p>However, because of the scalability of Cloud Applications, if we deploy the application to two different regions, we could improve the availability. (introduce more redundence)</p><h4 id="trusted-advisor"><a class="markdownIt-Anchor" href="#trusted-advisor"></a> Trusted Advisor</h4><p>Where you can found the number of limits for all services on AWS.</p><h4 id="section-one-summary"><a class="markdownIt-Anchor" href="#section-one-summary"></a> Section One Summary</h4><p>Availability is not cheap, we need to found the balance between availability and cost. We can achieve high availability use Redundancy and Loose Coupling</p><p>The Simple Queue Service can act as a go-between for loosely coupled services. 1. Sending service places message in a queue. 2. Receiving service polls the queue for new messages. E.g. Online voting service</p><p>The Elastic Container Service deploys microservices using Docker containers, can improve availability by running multiple containers on a single instance.</p><h4 id="section-two-setting-up-aws-environment"><a class="markdownIt-Anchor" href="#section-two-setting-up-aws-environment"></a> Section Two: Setting up AWS Environment</h4><h4 id="aws-budget"><a class="markdownIt-Anchor" href="#aws-budget"></a> AWS Budget</h4><p>In the Billing section, you can create an AWS Budget and setup an email alert, AWS will send you an email when the budget amount has been reached. There are more options.</p><h4 id="aws-iam"><a class="markdownIt-Anchor" href="#aws-iam"></a> AWS IAM</h4><p>AWS has two account types, Root User account and IAM account. We can setup a password policy for AWS accounts.</p><p>AWS provides MFA for Root User account in case someone else knows your AWS account credentials.</p><p>Delete root user access keys: if someone knows your root user access key, he can use CLI to do anything. MFA will not be required to use CLI if he knows root user access key. So it is recommanded to create an IAM user and create access key for IAM users.</p><p>You can create IAM accounts and Groups and assign Policies to Users or Groups, IAM users will use Root account ID or Alias and their account details to login.</p><p>CloudTrail: where AWS logs all events such as: user login, user create new resources, user attach policy to its account etc…</p><p>Configure AWS account using AWS CLI. This command can also be used to change default AWS credentials in .aws folder.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws configure</span><br></pre></td></tr></table></figure><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/1.png" alt="" /></p><h4 id="tls-certificate"><a class="markdownIt-Anchor" href="#tls-certificate"></a> TLS Certificate</h4><p>TLS(Transport Layer Security): Make sure messages being transferred between Load Balancer and Clients are secure.</p><p>ACM(Amazon Certificate Manager): we ask ACM to issue us a TLS certificate</p><p>Route 53: when you purchase a domain, you need to config the DNS records, you can do this in the service where you purchased the domain (e.g. GoDaddy) or in Route 53.</p><p>Note: Once your TLS certificate has been issued, you still can’t visit your website via https, you have to link your TLS certificate to other AWS services like CloudFront or ELB</p><h4 id="section-two-summary"><a class="markdownIt-Anchor" href="#section-two-summary"></a> Section Two Summary</h4><ol><li>Set up budget alert</li><li>Create IAM policy</li><li>Set up MFA for the root user</li><li>Create IAM user</li><li>View CloudTrail event history</li><li>Configure AWS CLI</li><li>Create a TLS certificate using ACM</li></ol><h4 id="section-three-vpc-networks"><a class="markdownIt-Anchor" href="#section-three-vpc-networks"></a> Section Three: VPC networks</h4><p>AWS managers underlying VPC infrastructrue and is responsible for reliability of VPC network components. You don’t need to worry about VPC failures. There are many redundencies built in.</p><p>VPC contains one or more subnets. A subnet exists in an availability zone. An instance exists in a subnet.</p><p>Because one instance only exists in one subnet which exists in one availability zone, it lacks of redundency and availability is not high. If the zone fails, the instance will fail.</p><p>Availability zones: they are basically the data centers in different locations. if you have your instances running in different availability zones, it is highly unlikely that all zones fail.</p><p>Client(me) can access a VPC via three ways: 1. Internet Gateway, 2. VPN network, 3. Direct Connect link provided by AWS.</p><p>Transit Gateway: high availability service that can connect two networks together (two VPCs)</p><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/2.png" alt="" /></p><h4 id="elastic-ip-address"><a class="markdownIt-Anchor" href="#elastic-ip-address"></a> Elastic IP Address</h4><p>EIP allows an instance to retain the same public IP address. EIP is bound to an ENI(Elastic Network Interface), which is attached to an instance. You can move an EIP to differnt ENI</p><p>To check EC2 instances EIPs.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws ec2 describe-addresses</span><br></pre></td></tr></table></figure><p>To allocate new EIP</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws ec2 allocate-address</span><br></pre></td></tr></table></figure><p>To release the EIP</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws ec2 release-address --allocation-id (your_allocation_id)</span><br></pre></td></tr></table></figure><h4 id="global-accelerator"><a class="markdownIt-Anchor" href="#global-accelerator"></a> Global Accelerator</h4><p>Provides two anycast IPv4 addresses. While ELP is bound to a AWS region, Global Accelerator IPs doesn’t, Users connects to a global accelerator static IP will be routed to a nearest POP(points-of-presence), which then will provide you with resources in any region.</p><h4 id="vpc-architecture"><a class="markdownIt-Anchor" href="#vpc-architecture"></a> VPC Architecture</h4><p>Public Subnet: has full access to the internet, can also be reached from the internet.</p><p>Private Subnet: is isolated from the internet, cannot reach internet nor be reached from the internet.</p><p>NAT Gateway: Provides outbound internet access for instance in Private Subnet</p><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/3.png" alt="" /></p><p>Create VPC with Public Subnet and Private Subnet.</p><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/4.png" alt="" /></p><p>Public Subnet has a default Route Rule which route all requests(0.0.0.0/0) to a IGW(Internet Gateway), this allows instance in Public Subnet access public internet(inbound and outbound).</p><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/5.png" alt="" /></p><p>Private Subnet has a default Route Rule which route all requests(0.0.0.0/0) to a NAT(NAT Gateway), this allows instance in Private Subnet outbound only access to internet.</p><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/6.png" alt="" /></p><p>NAT Gateway: Instance in private subnet send outbound traffic to NAT Gateway, NAT Gateway then sends traffic to Internet Gateway.</p><p>Create multiple Public and Private subnets for redundency.</p><p>To find a subnet by its CIDR block, we will be using the subnet ID to launch the instance.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws ec2 describe-subnets --filters Name&#x3D;cidr-block,Values&#x3D;&quot;10.0.11.0&#x2F;24&quot;</span><br></pre></td></tr></table></figure><p>Launch an EC2 instance into a public subnet:</p><p>Note: subnetId is the ID of your public subnet, which you can get by using the describe-subnets command above. ImageID is the ID of the EC2 instance, it specify some options about the instance you want to launch. key-name is the name of the SSH key pair you created, which you can use later to login to the instance.</p><p>You can create or manage your SSH key pair under your EC2 panel, NETWORK &amp; SECURITY tab.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws ec2 run-instances --subnet-id subnet-0aa8c9baa867b88f0 --image-id ami-0e6449745600ac1da --instance-type t3.micro --key-name hellcyAWSkey</span><br></pre></td></tr></table></figure><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/7.png" alt="" /></p><p>Note: You could optionally associate a public IP address to the instance you are about to launch. By using the command</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--associate-public-ip-address</span><br></pre></td></tr></table></figure><p>It will make EC2 to associate a temporary public IP address to this instance, and will close the ip address when the instance is stopped. I will not do that because I want to keep the IP and so I will associate an EIP to this instance.</p><p>To allocate a new EIP</p><p>Note before we have associated the EIP to the NAT gateway. Now we are going to associate the new EIP to the EC2 instacne</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws ec2 allocate-address</span><br></pre></td></tr></table></figure><p>To associate the new EIP to the new EC2 instance</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws ec2 associate-address --instance-id Your_Instance_Id --allocation-id Your_EIP_Allocation_Id</span><br></pre></td></tr></table></figure><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/8.png" alt="" /></p><p>To terminate the EC2 instance</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws ec2 terminate-instances --instance-ids Your_Instance_Id</span><br></pre></td></tr></table></figure><p>To release the EIP so AWS will not charge us</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws ec2 release-address --allocation-id Your_EIP_Allocation_Id</span><br></pre></td></tr></table></figure><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/9.png" alt="" /></p><p>Launch an EC2 instance into private subnet</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws ec2 run-instances --subnet-id [private_subnet_id] --image-id ami-0e6449745600ac1da --instance-type t3.micro --key-name hellcyAWSkey</span><br></pre></td></tr></table></figure><p>To delete NAT gateway</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws ec2 delete-nat-gateway --nat-gateway-id Your_NAT_Gateway_Id</span><br></pre></td></tr></table></figure><p>Don’t forget to release the EIP associated with the NAT gateway.(They will charge for un-associated EIP)</p><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/10.png" alt="" /></p><h4 id="aws-shield-standard"><a class="markdownIt-Anchor" href="#aws-shield-standard"></a> AWS Shield Standard</h4><p>Free service that detects against DDoS attacks, always ON</p><h4 id="direct-connect"><a class="markdownIt-Anchor" href="#direct-connect"></a> Direct Connect</h4><p>Low-latency connection to an AWS region. Bypasses the internet, Two types: Dedicated, Hosted</p><p>Dedicated: Physical connection that terminates at a Direct Connection location, fast, 1 or 10 Gbps</p><p>Hosted: Last-mile connection provided by a Direct Connect partner(Local ISP). 50 Mbps to 10 Gbps</p><h4 id="vpn-connection"><a class="markdownIt-Anchor" href="#vpn-connection"></a> VPN Connection</h4><p>Encrypted IPsec connection over the internet, Unpredicatable latency, Can be implemented in two ways: Virtual private gateway, Transit gateway.</p><p>Virtual private gateway: Enables you to establish a VPN tunnel with only one VPC. Doesn’t scale well when you have multiple VPCs, then you need to create multiple Virtual private gateway for each VPC you want to connect.</p><p>Transit Gateway: Connects VPCs and on-premises networks, 1. Terminates multiple VPN connections, 2. Supports Direct Connect. Connects multiple VPCs together.</p><p>Transit Gateway Route Tables: Control how traffic is routed between subnets. Can block traffic.</p><p>To create a Transit Gateway</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws ec2 create-transit-gateway</span><br></pre></td></tr></table></figure><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/11.png" alt="" /></p><p>To create a VPC</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws ec2 create-vpc --cidr-block 127.27.0.0&#x2F;16</span><br></pre></td></tr></table></figure><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/12.png" alt="" /></p><p>To create a Subnet in the VPC</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws ec2 create-subnet --vpc-id Your_VPC_Id --cidr-block 172.27.1.0&#x2F;24 --availability-zone ap-southeast-2a</span><br></pre></td></tr></table></figure><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/13.png" alt="" /></p><p>To attach Transit Gateway to the subnet of the VPC</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws ec2 create-transit-gateway-vpc-attachment --transit-gateway-id Your_TGW_Id --vpc-id Your_VPC_Id --subnet-ids Your_Subnet_Ids</span><br></pre></td></tr></table></figure><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/14.png" alt="" /></p><h4 id="section-three-summary"><a class="markdownIt-Anchor" href="#section-three-summary"></a> Section Three Summary</h4><ol><li>Allocating and assigning EIP addresses</li><li>Creating VPCs</li><li>Creating public and private subnets</li><li>Launching instances into subnets</li><li>Transit gateways</li></ol><h4 id="section-four-automated-deployments-with-cloudformation"><a class="markdownIt-Anchor" href="#section-four-automated-deployments-with-cloudformation"></a> Section Four: Automated Deployments with CloudFormation</h4><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/15.png" alt="" /></p><p>Overview of the architecture: The architecture has two tiers, the web tier and the application tier. The client connects to the internet facing application load balancer, it proxies the connection to one of the instances in the web tier, and all of the instances in the web tier are running a web server. The web tier instance then opens a back-end connection to the internal load balancer, which then proxies the connection to one of the instances in the application tier. The idea is that the web tier instance grabs some information from an instance in the app tier, and it displays that information to a webpage, which presents to the client.</p><p>The instances in the web tier and the app tier are going to be part of two different Auto Scaling groups. Auto Scaling is going to launch these isntances and make sure we always have a minimum number of healthy instances. If an instance fail, Auto Scaling will terminate it and launch a new one.</p><h4 id="cloudformation"><a class="markdownIt-Anchor" href="#cloudformation"></a> CloudFormation</h4><p>JSON or YAML document that describes AWS resources. Infrastructrue as code. Used to create a stack.</p><p>Stack: Created by a template, is a COLLECTION OF RESOURCES that you create, update, and delete as a single unit. You can manually manage individual resources in a stack.</p><p>Multiple templates: Different teams manage different resources. Resources have different lifecycles. Distributing resources across different stacks makes them easier to manage.</p><p>Template for this course can be downloaded from <a href="https://github.com/benpiper/architecting-reliability-aws/">here</a>. Name: app-stack.json and network-stack.json.</p><p>app-stack.json depends on network-stack.json, so it calls network-stack.json to create the nested stack first, then it will create the parent stack by using some of the outputs from network-stack.json.</p><p>Stack output: key-value pairs that CloudFormation makes available to other stacks and via the aws cloudformation describe-stacks CLI command.</p><h4 id="application-load-balancers"><a class="markdownIt-Anchor" href="#application-load-balancers"></a> Application Load Balancers</h4><ol><li>Supports HTTP and HTTPS traffic</li><li>You can use any TCP port, default is 80 and 443</li><li>ALB listener receives connection from a client and proxies it to an instance in the target group</li><li>Uses round-robin load balancing by default</li><li>Can monitor health of instances</li></ol><p>ALB Schemes</p><p>internet-facing: reachable from the internet, public IP address, Public DNS name</p><p>internel: Not reachable from the internet, private IP address, Private DNS name</p><p>Health Checks</p><p>Each instance must pass its health check before receiving traffic. ALB will send HTTP GET request and looks for a success code every 10 seconds.</p><h4 id="auto-scaling-groups"><a class="markdownIt-Anchor" href="#auto-scaling-groups"></a> Auto Scaling Groups</h4><ol><li>Launch a certain number of instances into the Auto Scaling group</li><li>Add the instacnes to the ALB target group</li><li>Terminate and recreate unhealthy instances</li><li>Scale in or out based on average group CPU utilization</li></ol><p>Follow the steps to deploy stack to AWS Cloudformation</p><p>First validate the templates, you will see the output parameters if template format is correct.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws cloudformation validate-template --template-body file:&#x2F;&#x2F;app-stack.json</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws cloudformation validate-template --template-body file:&#x2F;&#x2F;network-stack.json</span><br></pre></td></tr></table></figure><p>deploy the stack to AWS cloudformation</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws cloudformation deploy --template-file &quot;app-stack.json&quot; --stack-name &quot;app-stack&quot;</span><br></pre></td></tr></table></figure><ol><li>Change the TLS certificate ARN</li><li>Change the S3 URL to yours</li><li>Change the SSH key pairs for logging into EC2 instance</li><li>Change the EC2 instance image ID</li></ol><p>Note: the template will only work for us-east-1 region, tried using ap-southeast-2 but failed when waiting for the cfn-signal. Probably because the application doesn’t exist in ap-southeast-2 docker market.</p><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/17.png" alt="" /></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws cloudformation describe-stacks --stack-name &quot;app-stack&quot;</span><br></pre></td></tr></table></figure><p>Using the command above we can find the URL of the Internet-facing application load balancer. We securely(HTTPS) connect to this load balancer. And it redirect us to one of the instance in web tier.</p><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/16.png" alt="" /></p><p>Note we do added a TLS certificate in the template. But the TLS certficate is for my website <a href="http://theyuancheng.com">theyuancheng.com</a>, and the domain of the EC2 instance does not match. So we are connecting using HTTP protocol.</p><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/19.png" alt="" /><br /><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/18.png" alt="" /></p><p>Also pay attention to the EC2 hostname, Web tier server information, ip-10-0-1-42 belongs to Public Subnet A, and one of the instance is running inside this subnet. App server information, ip-10-0-102-180 belongs to Private Subnet B, one of the instance is running inside this subnet too.</p><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/20.png" alt="" /><br /><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/21.png" alt="" /></p><p>If you refresh the URL a couple of times, you can see that the hostname ip we are connecting to changes, which means the load balancer redirect us to a different instance.</p><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/22.png" alt="" /></p><p>Now, let us try to terminate both of the web tier instances and see if Auto Scaling will recreate the instances for us.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws autoscaling describe-auto-scaling-instances</span><br></pre></td></tr></table></figure><p>This command will list all the instances, we can find the instance ids in the list.</p><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/23.png" alt="" /></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws ec2 termin ate-instances --instance-ids</span><br></pre></td></tr></table></figure><p>We can see Auto Scaling automatically recreate another two instances, the intance ids are different.</p><p>Use this command to delete the stack.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws cloudformation delete-stack --stack-name &quot;app-stack&quot;</span><br></pre></td></tr></table></figure><p>After deleting the stack, use this command to check if the stack has been deleted.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws cloudformation describe-stacks</span><br></pre></td></tr></table></figure><h4 id="section-four-summary"><a class="markdownIt-Anchor" href="#section-four-summary"></a> Section Four Summary</h4><ol><li>Use Stack template to deploy Auto Scaling multi-tier web application with load balancer.</li><li>Stack will automatically rollback everything if deploy failed.</li><li>Elastic load balancing and Auto Scaling work together. ELB provides health checks, Auto Scaling adds instances to the ELB target group.</li></ol><h4 id="section-five-multi-region-applications-with-route-53"><a class="markdownIt-Anchor" href="#section-five-multi-region-applications-with-route-53"></a> Section Five: Multi-region Applications with Route 53</h4><ol><li>Deploying a multi-region application</li><li>Active-active redundancy using weighted resource records</li><li>Active-passive redundancy using failover resource records</li><li>Route 53 health checks</li></ol><p>We are going to deploy two cloudFormation stacks into the same region to simulate the multi-region application deployment.</p><p>But because we have two URLs for the two Internet facing ALB, we need Route 53 to send traffic to these two ALBs. This is called an active-active scanario, because they are both active. We are going to create two weighted resource record sets with equal weight, so Route 53 will distribute traffic evenly.</p><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/26.png" alt="" /><br /><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/27.png" alt="" /></p><p>See the image above to create a new record.</p><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/28.png" alt="" /></p><p>Create another record and route traffic to the two load balancers evenly.</p><p>Checklist for creating records</p><ol><li>Routing Policy: Weighted</li><li>Record name: www</li><li>Turn on Alias</li><li>Record Type: A</li><li>Route traffic to: Classic load balancer, region (us-east-1), webtier-app-stack-1</li><li>Weight: 50</li><li>Record ID: app-stack-1</li></ol><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/29.png" alt="" /></p><p>The connection to the instance is now secure. (Notice the lock icon at top left corner, in front of the URL)</p><p>How to check if Route53 distribute the traffic evenly to two load balancers? Go to <a href="dnschecker.org">DNS checker</a> and type in <a href="http://www.theyuancheng.com">www.theyuancheng.com</a>. And you will see that half of the traffic ending in one IP.</p><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/30.png" alt="" /></p><h4 id="active-passive-redundancy-using-failover-resource-records"><a class="markdownIt-Anchor" href="#active-passive-redundancy-using-failover-resource-records"></a> Active-passive Redundancy using Failover Resource Records</h4><ul><li>Primary region services all requests</li><li>Secondary region does not service any requests unless the primary fails</li><li>Also called active-standby architecture</li></ul><p>Two ways to run this architecture</p><p>Pilot Light: Secondary region runs minimal amount of resources to keep costs down. (in our case, maybe only one instance in the web tier and one instance in the app tier (normally should be 2 and 2)). When we need the secondary region, Auto Scaling can increase the instance number when needed.</p><p>Warm Standby: Secondary region has roughly the same capacity as the primary region. Quicker to start, doesn’t need Auto Scanling.</p><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/31.png" alt="" /></p><p>Similar to what we did before, this time we create two records, one pointing to app-stack-1 and the other is pointing to app-stack-2. As long as app-stack-1 is healthy, Route 53 will not send any traffic to app-stack-2.</p><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/32.png" alt="" /></p><p>For the Routing policy we choose Failover and Failover Record Type is Primary for the first record.(Secondary for the second record).</p><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/33.png" alt="" /></p><p>Now both records are created. We can go the <a href="dnschecker.org">DNS checker</a> and check the differences.</p><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/34.png" alt="" /></p><p>Now they all resolve to the same set of IP addresses.</p><p>Now let us try to shut down app-stack-1.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws cloudformation delete-stack --stack-name &quot;app-stack-1&quot;</span><br></pre></td></tr></table></figure><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/35.png" alt="" /><br /><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/36.png" alt="" /></p><p>Now the DNS checker returns a different set of ip addresses over time. (from 236, 12 to 252, 207)</p><h4 id="route-53-health-checks"><a class="markdownIt-Anchor" href="#route-53-health-checks"></a> Route 53 Health Checks</h4><p>We are going to use the two instances in app-stack-2, use below command to get the IPs</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws ec2 describe-instances --query &quot;Reservations[*].Instances[*].PublicIpAddress&quot; --output&#x3D;text</span><br></pre></td></tr></table></figure><p>Create Route 53 health checks. Type in the IPs of the instances.</p><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/37.png" alt="" /></p><p>Once both health checks have been created, we can try to shut down one of them.</p><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/38.png" alt="" /></p><p>Create another record with instance IP and health check.</p><p><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/39.png" alt="" /><br /><img src="/../images/AWS-SAA-Architecting-for-Reliability-on-AWS/40.png" alt="" /></p><p>Route 53 will distribute traffic evenly to both instances, if one of the instances fail, the Route 53 health check will detect that and Route 53 will stop sending traffic to it. If you don’t need <strong>ELB</strong>, DNS based load balancing is a cost-effective option.</p><h4 id="course-summary"><a class="markdownIt-Anchor" href="#course-summary"></a> Course Summary</h4><ol><li>Architecture for availability</li><li>Setting up AWS environment</li><li>VPC(Subnets, NAT Gateways, Direct Connect, VPN, Transit Gateways)</li><li>CloudFormation, Elastic Load Balancing, Auto Scaling</li><li>Multi-region Applications(Route 53, Active-active weighted records, Active-passive failover records)</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> AWS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS SAM and CloudFront</title>
      <link href="2020/10/07/AWS-SAM-and-CloudFront/"/>
      <url>2020/10/07/AWS-SAM-and-CloudFront/</url>
      
        <content type="html"><![CDATA[<ol><li><a href="#part-one-aws-sam">Part One: AWS SAM</a></li><li><a href="#part-two-aws-sso">Part Two: AWS SSO</a></li><li><a href="#part-three-aws-cloudfront">Part Three: AWS CloudFront</a></li></ol><h2 id="part-one-aws-sam"><a class="markdownIt-Anchor" href="#part-one-aws-sam"></a> Part One: AWS SAM</h2><ul><li>Note: This is a brief introduction about how to setup a Serverless Application Model using VS Code and Nodejs. I will probably be adding more details later.</li></ul><h3 id="visual-studio-code"><a class="markdownIt-Anchor" href="#visual-studio-code"></a> Visual Studio Code</h3><ul><li>VS Code is an perfect IDE for writing/testing/deploying SAM. Some key points need attention are listed.</li></ul><ol><li>AWS credentials in Users/UserName/.aws folder.</li><li>Create yaml file with resources: lambda function, policies, runtime language, environment variable etc…</li><li>Writing lambda function in Nodejs, CROS policy…</li><li>CRUD operation: marshall/unmarshall object etc…</li><li>AWS CLI: package and deploy SAM to AWS</li></ol><ul><li>AWS CLI command to package and deploy SAM to AWS.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sam deploy --template-file output-yamlFileName.yaml --stack-name Your_Stack_Name --capabilities CAPABILITY_IAM</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sam package --template-file yamlFileName.yaml --s3-bucket S3_Bucket_Name --output-template-file output-yamlFileName.yaml</span><br></pre></td></tr></table></figure><ul><li>A very useful course I took about AWS SAM: <a href="https://app.pluralsight.com/library/courses/aws-deploying-serverless-applications-application-model/table-of-contents">Deploying Serverless Applications in AWS Using the Serverless Application Model</a></li></ul><h2 id="part-two-aws-sso"><a class="markdownIt-Anchor" href="#part-two-aws-sso"></a> Part Two: AWS SSO</h2><h3 id="create-custom-saml-application"><a class="markdownIt-Anchor" href="#create-custom-saml-application"></a> Create Custom SAML Application</h3><p>We can use AWS SSO as an IDP for our web application.</p><p>Create new Custom SAML 2.0 application.</p><p><img src="/../images/AWS-SAM-and-CloudFront/8.png" alt="" /></p><p>This is IDP metadata, we will download it after finishing configuring return attributes.</p><p><img src="/../images/AWS-SAM-and-CloudFront/9.png" alt="" /></p><p>This is SP metadata, which we will prepare and upload.</p><p><img src="/../images/AWS-SAM-and-CloudFront/10.png" alt="" /></p><p>This is where we config the return attribute in SAML response. Supported attribute list can be found [here](https://docs.aws.amazon.com/singlesignon/latest/userguide/attributemappingsconcept.html?icmpid=docs_sso_console)</p><p><img src="/../images/AWS-SAM-and-CloudFront/11.png" alt="" /></p><h3 id="create-users"><a class="markdownIt-Anchor" href="#create-users"></a> Create Users</h3><ul><li>Users can be created by simply fill this form. You can also setup MFA device after creating the user.</li></ul><p><img src="/../images/AWS-SAM-and-CloudFront/12.png" alt="" /></p><h2 id="part-three-aws-cloudfront"><a class="markdownIt-Anchor" href="#part-three-aws-cloudfront"></a> Part Three: AWS CloudFront</h2><h3 id="restricting-access-to-files-in-amazon-s3-buckets"><a class="markdownIt-Anchor" href="#restricting-access-to-files-in-amazon-s3-buckets"></a> Restricting Access to Files in Amazon S3 Buckets</h3><ul><li>You can optionally secure the content in your Amazon S3 bucket so that users can access it through CloudFront but cannot access it directly by using Amazon S3 URLs. This prevents someone from bypassing CloudFront and using the Amazon S3 URL to get content that you want to restrict access to. (Using Origin Access Identity)</li></ul><h3 id="block-all-public-access-to-s3-bucket"><a class="markdownIt-Anchor" href="#block-all-public-access-to-s3-bucket"></a> Block all public access to S3 bucket</h3><p><img src="/../images/AWS-SAM-and-CloudFront/1.png" alt="" /></p><p><img src="/../images/AWS-SAM-and-CloudFront/2.png" alt="" /></p><ul><li>When creating new distribution in CloudFront, do the following steps</li></ul><ol><li>Select Web distribution</li><li>Select the S3 bucket you want to connect to</li><li>Select Redirect HTTP to HTTPS if you don’t want people to access your content by HTTP requests</li><li>Select Yes for ‘Restrict Viewer Access’</li><li>Select Self as trusted signer</li></ol><h3 id="create-trusted-signer"><a class="markdownIt-Anchor" href="#create-trusted-signer"></a> Create Trusted Signer</h3><p>Note When 'Restrict Viewer Access' is selected, you can specify which account is the 'Trusted Signer'. Which means they have the permission to create signed URL or signed cookie for people to access your private content.</p><p>Self is the default 'Truested Signer', which is the account your are currently using. You can also add another accounts by entering their account ID.</p><h3 id="create-another-behavior"><a class="markdownIt-Anchor" href="#create-another-behavior"></a> Create another behavior</h3><ul><li>Login page should be accessiable by public, so as the js, css and image files. So we should create another behavior to let CloudFront know which file access is retricted and which are not.</li></ul><p><img src="/../images/AWS-SAM-and-CloudFront/3.png" alt="" /></p><p>Path Pattern decides which files can be set to public(also select No for 'Retrict Viewer Access' this time)</p><p>Rules about Path Pattern can be found [here](https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-web-values-specify.html#DownloadDistValuesPathPattern)</p><h3 id="create-cloudfront-key-pairs"><a class="markdownIt-Anchor" href="#create-cloudfront-key-pairs"></a> Create CloudFront Key Pairs</h3><p>We need CloudFront key pairs to create signed URLs and signed Cookies, they are a pair of public and private keys AWS uses to encrypt requests people send to CloudFront, so it knows whether they are authenticated users.</p><p>This step can only be done using AWS root account, IAM account cannot create CloudFront key pairs.</p><p><img src="/../images/AWS-SAM-and-CloudFront/4.png" alt="" /></p><ul><li>Save the private key pem file and Access key ID to a save place. We will use it later.</li></ul><h3 id="create-signed-url"><a class="markdownIt-Anchor" href="#create-signed-url"></a> Create Signed URL</h3><p>This is the most important part.</p><p>I used two ways to create signed URL, nodejs and C#. I use nodejs to create a lambda function as an API, which will return the signed URL generated. I also add this feature to the SAML project, so when IDP returned SAML response, I can add signed details to the URL and redirect user to the home page.</p><p><img src="/../images/AWS-SAM-and-CloudFront/5.png" alt="" /></p><p>Note that yaml file supports multiple line string (a vertical line followed by a hyphen), so we can add private key string in the yaml file as a environment variable, so as the public key.</p><p><img src="/../images/AWS-SAM-and-CloudFront/13.png" alt="" /></p><p>Also note expiry time input are in [Unix Epoch Time format](https://www.epochconverter.com/) in miliseconds(13 digits). However, the expires argument in the signed URL are in seconds format (10 digits).</p><p>Also note that C# doesn't recognize private key string in PEM format. We have to convert it to XML format before create signed URL.</p><p><img src="/../images/AWS-SAM-and-CloudFront/6.png" alt="" /></p><ul><li>The signed URL created will append three arguments at the end of the original URL: Expires, Signature and Key-Pair-Id</li></ul><p><img src="/../images/AWS-SAM-and-CloudFront/7.png" alt="" /></p><ul><li>Note the signature contains information about the original URL so you cannot reuse it with different URLs. We have to generate new signed URLs when direct user to other pages.(this will also refresh the session time, which is we want.)</li></ul><h3 id="create-signed-cookies"><a class="markdownIt-Anchor" href="#create-signed-cookies"></a> Create Signed Cookies</h3><p>NodeJs: Signed Cookies can be created using below code. I used <a href="https://github.com/h-arora/aws-cloudfront-cookie-signer/blob/master/cookieSign.js">this</a> post as a reference.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">&quot;use strict&quot;</span><br><span class="line">const AWS &#x3D; require(&quot;aws-sdk&quot;)</span><br><span class="line"></span><br><span class="line">exports.handler &#x3D; async (event, context, callback) &#x3D;&gt; &#123;</span><br><span class="line">    var cfsign &#x3D; require(&#39;aws-cloudfront-sign&#39;);</span><br><span class="line">    </span><br><span class="line">    &#x2F;&#x2F; 5 seconds</span><br><span class="line">    var expireTime &#x3D; Math.floor((+new Date() + 1000 * 300) &#x2F; 1000);</span><br><span class="line">    </span><br><span class="line">    var signingParams &#x3D; &#123;</span><br><span class="line">    keypairId: process.env.PUBLIC_KEY,</span><br><span class="line">    privateKeyString: process.env.PRIVATE_KEY,</span><br><span class="line">    &#x2F;&#x2F; Optional - this can be used as an alternative to privateKeyString</span><br><span class="line">    &#x2F;&#x2F;privateKeyPath: &#39;&#x2F;path&#x2F;to&#x2F;private&#x2F;key&#39;,</span><br><span class="line">    expireTime: expireTime</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    const body &#x3D; JSON.parse(event.body);</span><br><span class="line">    </span><br><span class="line">    &#x2F;&#x2F; Method 2: Generating singed Cookies</span><br><span class="line">    let policy &#x3D; &#123;</span><br><span class="line">        &#39;Statement&#39;: [&#123;</span><br><span class="line">        &#39;Resource&#39;: body.url + &#39;*&#39;,</span><br><span class="line">        &#39;Condition&#39;: &#123;</span><br><span class="line">            &#39;DateLessThan&#39;: &#123;&#39;AWS:EpochTime&#39;: expireTime&#125;</span><br><span class="line">        &#125;</span><br><span class="line">        &#125;]</span><br><span class="line">    &#125;;</span><br><span class="line">    let policyString &#x3D; JSON.stringify(policy);</span><br><span class="line">    const signer &#x3D; new AWS.CloudFront.Signer(signingParams.keypairId, signingParams.privateKeyString);</span><br><span class="line"></span><br><span class="line">    const options &#x3D; &#123;</span><br><span class="line">    url: body.url,</span><br><span class="line">    policy: policyString</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    const signedCookie &#x3D; signer.getSignedCookie(options);</span><br><span class="line"></span><br><span class="line">    var response &#x3D; &#123;</span><br><span class="line">        statusCode: 200,</span><br><span class="line">        headers: &#123;</span><br><span class="line">            &quot;Access-Control-Allow-Origin&quot; : &quot;*&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        body: JSON.stringify(signedCookie)</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    callback(null, response);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><ul><li>By default, CloudFront caches a response from Amazon S3 for 24 hours, so if you just updated contents in S3 bucket, CloudFront may still serve you the outdated content. Use the below code in cmd to force CloudFront to update its files from S3.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws cloudfront create-invalidation --distribution-id &#39;YOUR DISTRIBUTION ID&#39; --paths &quot;&#x2F;*&quot;</span><br></pre></td></tr></table></figure><h3 id="references"><a class="markdownIt-Anchor" href="#references"></a> References</h3><ol><li><a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-task-list.html">Task List for Serving Private Content using S3 and CloudFront</a></a></li><li><a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-restricting-access-to-s3.html">Restricting Access to Amazon S3 Content by Using an Origin Access Identity</a></a></li><li><a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-trusted-signers.html">Specifying the AWS Accounts That Can Create Signed URLs and Signed Cookies (Trusted Signers)</a></a></li><li><a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-trusted-signers.html#private-content-reformatting-private-key">Reformatting the CloudFront Private Key (.NET and Java Only)</a></a></li><li><a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-signed-urls.html">Using Signed URLs</a></a></li><li><a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-creating-signed-url-canned-policy.html">Creating a Signed URL Using a Canned Policy</a></a></li><li><a href="https://aws.amazon.com/blogs/developer/creating-amazon-cloudfront-signed-urls-in-node-js/">Code Example: Creating Amazon CloudFront Signed URLs in Node.js</a></a></li><li><a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/CreateSignatureInCSharp.html">Code Example: Create a URL Signature Using C# and the .NET Framework</a></a></li><li><a href="https://github.com/h-arora/aws-cloudfront-cookie-signer/blob/master/cookieSign.js">Code Example: Create Signed Cookies using NodeJs</a></a></li><li><a href="https://medium.com/@himanshuarora/protect-private-content-using-cloudfront-signed-cookies-fd9674faec3">Test Signed Cookies using Postman</a></a></li><li><a href="https://www.epochconverter.com/">Epoch &amp; Unix Timestamp Conversion Tools</a></a></li><li><a href="https://aws.amazon.com/premiumsupport/knowledge-center/cloudfront-serving-outdated-content-s3/">Why is CloudFront serving outdated content from Amazon S3?</a></a></li><li><a href="https://stackoverflow.com/questions/8637419/rsa-public-private-keys-in-yaml">RSA public/private keys in YAML</a></a></li><li><a href="https://stackoverflow.com/questions/9091900/how-can-i-convert-pem-public-key-to-rsa-public-key-with-bouncycastle-in-c">Convert PEM to XML in C#</a></a></li><li><a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-web-values-specify.html#DownloadDistValuesPathPattern">CloudFront Path Pattern Rules</a></a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> AWS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Wishlist 2021</title>
      <link href="2020/10/06/Wishlist-2021/"/>
      <url>2020/10/06/Wishlist-2021/</url>
      
        <content type="html"><![CDATA[<ol><li>Get AWS SAA C02 certificate - finished</li><li>Finish 1500+ Leetcode Problems (at least 2 problems per day)</li><li>Get 2000+ points in Leetcode contests</li><li>Setup a simple LAMP website - finished</li><li>Get a new job by the end of year 2021 - finished</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Wishlist </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dynamic Programming</title>
      <link href="2020/08/27/Dynamic-Programming/"/>
      <url>2020/08/27/Dynamic-Programming/</url>
      
        <content type="html"><![CDATA[<h2 id="lecture-1-introduction"><a class="markdownIt-Anchor" href="#lecture-1-introduction"></a> Lecture 1 Introduction</h2><h3 id="什么是动态规划"><a class="markdownIt-Anchor" href="#什么是动态规划"></a> 什么是动态规划？</h3><ul><li>1.计数型</li><li>有多少种方式走到右下角</li><li>有多少种方法选出k个数使得和是Sum</li><li>2.求最大最小值</li><li>从左上角到右下角的路径的最大数字和</li><li>最长上升子序列长度</li><li>3.求存在性</li><li>取石子游戏，先手是否必胜</li><li>能不能选出k个数使得和是sum</li><li>Coin Change(最大最小型)</li><li>一般想法：先用面值大的硬币，最后想办法用小硬币</li><li>动态规划四个步骤</li><li><ol><li>确定状态</li></ol></li><li>一般来说，解决动态规划需要开一个数组，可能是一维的或者二维的，要确定数组的每一个元素代表什么</li><li>转移方程有几个变量就需要创建几维数组</li><li>确定状态需要两个意识：最后一步是什么，子问题是什么</li><li><ol start="2"><li>转移方程</li></ol></li><li>每个子问题到下一个子问题的过程</li><li><ol start="3"><li>初始条件和边界情况</li></ol></li><li>什么时候停下来？初始条件是什么?</li><li><ol start="4"><li>计算顺序</li></ol></li><li>一般是从小到大</li><li>Coin Change</li><li>从第一步算到m步，每一步算n次，其中m为最后的硬币sum，n为总共有多少种不用的硬币，时间复杂度为O（m*n）</li><li>最后一步是由前面几步的最小值确定的，所以先确定前面的值，从小到大，就能判断出最后一步的值</li><li>Unique Path:计数型</li><li>Jump Game：存在型</li></ul><h3 id="lecture-2-coordinates-and-bit-operation"><a class="markdownIt-Anchor" href="#lecture-2-coordinates-and-bit-operation"></a> Lecture 2 Coordinates and Bit Operation</h3><ul><li>序列型：前i个，最小，方式数，可行性。。</li><li>Paint House</li><li>分别记录每栋房子之前的房子的每种颜色的最小花费</li><li>划分型</li><li>Decode ways</li><li>解密数字串即划分成若干段数字，每段数字对应一个字母</li><li>知道前N-1和N-2个数字分别有多少种方式，再相加</li><li>坐标型</li><li>需要找到序列中某些子序列或者网格中的某条路径：计数，最大，最小，存在性</li><li>Minimum Path Sum</li><li>空间优化：计算第i行时，只需要i行和i-1行的f值（滚动数组）</li><li>Bomb Enemy</li><li>给定输入为序列或者网格矩阵</li><li>问题一般为：以第i个元素结尾的某种性质，到格子（i， j）的路径的性质</li><li>Minimum path sum打印路径：新建一个二维数组，记录每次的方向，然后从最后（右下角）往前推，最后记住要反转数组才是从开始到结束的顺序</li><li>位操作型动态规划</li><li>Counting bits: removing the last bits</li></ul><h3 id="lecture-3-sequence"><a class="markdownIt-Anchor" href="#lecture-3-sequence"></a> Lecture 3 Sequence</h3><ul><li>给定一个序列，转移方程f（i）下标i表示前i个元素的某种性质， f(0)就是空序列的性质</li><li>Paint House II: Similar to Paint House I, Optimization: pick the smallest and the second smallest cost of all colors, reduce the min calculation to O(1) and totoal time complexity from O(N * K * K) to O(N * K * 2), where N is the number of houses and K is the number of colors</li><li>House Robber</li><li>House Robber II:想办法把圈断开，分两种情况处理，变成两种序列情况</li><li>Buy and Sell Stock III:分成五个状态，分别记录下每天每个状态的情况（类似于Paint house）</li><li>Russian Doll Envelope</li></ul><h3 id="lecture-4-划分型博弈型背包型"><a class="markdownIt-Anchor" href="#lecture-4-划分型博弈型背包型"></a> Lecture 4 划分型，博弈型，背包型</h3><ul><li>划分型</li><li>Perfect Squares</li><li>Palindrome Partitioning II:1. find all possible palindrome from the string s ans store them in a 2d array expand palindrome start and end index to both sides. 2. partition dp: dp[i] = min(dp[i], dp[j] &amp;&amp; isPalin(s[j][i - 1]))</li><li>Copy Books(LintCode)</li><li>划分型dp关键字：连续！Substring, continuous subarray</li><li>博弈型(两方游戏)</li><li>从第一部开始分析!!!问题规模会越来越小。</li><li>Coins in a line: Alince and Bob takes one or two coins each turn</li><li>Alice先手还剩N个Coin，与Bob先手还剩N-1个Coin是一样的，所以每个局面都可以看成是先手但是剩下不同数量的Coin</li><li>背包型</li><li>你有一个背包，背包有最大承重</li><li>商店里有若干物品，都是免费拿</li><li>目标： 1. 装下最多重量的物品， 2. 装下最大总价值的物品。 3. 有多少种方式正好带走满满一书包物品</li><li>给定背包最大承重M， 物品的重量都是整数</li><li>每个方案的总重量都是从0到M</li><li>对于每个重量方案，我们要知道能不能做到</li><li>Note：背包问题中，dp数组大小和总承重有关</li><li>现在需要知道前N个物品能否拼出重量W</li><li>如果前N-1个物品能拼出W，当然前N个物品也可以拼出W</li><li>如果前N-1个物品能拼出W-A(N-1),A(N-1)为第N个物品的重量，那么前N个物品也能拼出W</li><li>BackPack I - V</li><li>Coin Change 1, 2</li><li>当每个物品只能用一次时，需要多开一维的dp数组去计算前N个物品的方式</li></ul><h3 id="lecture-5-背包型-区间型"><a class="markdownIt-Anchor" href="#lecture-5-背包型-区间型"></a> Lecture 5 背包型, 区间型</h3><ul><li>背包型</li><li>Backpack II：现在每个物品有价值，求能带走最大多少价值的物品</li><li>f[i][j]: 用前i个物品拼出重量j时的最大总价值，j = -1表示不能拼出</li><li>dp[i][j] = Math.max(dp[i - 1][j], dp[i - 1][j - nums[i - 1]] + Value[i - 1])</li><li>区间型：当子问题还是连续的index时</li><li>Scramble String</li><li>Burst Ballons</li><li>消去型的题目要从后往前想，最后一步只剩一个，然后往前想</li><li>先从小的len开始计算</li></ul><h3 id="lecture-6-双序列型"><a class="markdownIt-Anchor" href="#lecture-6-双序列型"></a> Lecture 6 双序列型</h3><ul><li>有两个序列</li><li>每个序列本身是一维的</li><li>可以转化为二维的动态规划</li><li>查看最后一个字符是否匹配，缩减问题规模</li><li>易错点： 记得初始化，空串处理，结果是否 + 1</li><li>Longest common subsequence</li><li>Interleaving String</li><li>Edit Distance</li><li>Distinct Distance</li><li>Regular Expression Matching</li><li>Wildcard Matching</li><li>Ones and Zeros</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Dynamic Programming </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Harvard CS75 Web Development</title>
      <link href="2020/06/30/Harvard-CS75-Web-Development/"/>
      <url>2020/06/30/Harvard-CS75-Web-Development/</url>
      
        <content type="html"><![CDATA[<ol><li><a href="#chapter-0-http">Chapter 0: HTTP</a></li><li><a href="#chapter-1-php">Chapter 1: PHP</a></li><li><a href="#chapter-2-php-continued">Chapter 2: PHP Continued</a></li><li><a href="#chapter-3-mvc-xml">Chapter 3: MVC XML</a></li><li><a href="#chapter-4-sql">Chapter 4: SQL</a></li><li><a href="#chapter-5-sql-continued">Chapter 5: SQL Continued</a></li><li><a href="#chapter-6-javascript">Chapter 6: JavaScript</a></li><li><a href="#chapter-7-ajax">Chapter 7: AJAX</a></li><li><a href="#chapter-8-security">Chapter 8: Security</a></li><li><a href="#chapter-9-scalability">Chapter 9: Scalability</a></li></ol><h2 id="chapter-0-http"><a class="markdownIt-Anchor" href="#chapter-0-http"></a> Chapter 0: HTTP</h2><h3 id="what-happens-after-you-pressing-enter"><a class="markdownIt-Anchor" href="#what-happens-after-you-pressing-enter"></a> What happens after you pressing Enter?</h3><ul><li>The URL address will be translate to an IP address. 我们现在所用的IP address是ipv4,它由四组0-255的数字组成，总共32bits，可以有40亿总可能，我们现在每个人都有很多设备，ipv4的组合已经快不够用了。</li><li>所以新的ipv6要替代原来的ip address，它由8组4位的16进制组成，总共有128bits</li><li>怎么样将hostname网址转换成IP address呢？我们需要用到DNS（Domain name server）,他储存有ip address到hostname的一个mapping table，如果你访问的网址不在这个DNS里，他就会不断的访问上级服务器，直到访问到root server，root server知道谁有可能知道这个ip address，在不断的访问到下级服务器/DNS，直到找到并把hostname转换成ip address</li><li>互联网就像一个邮件系统，我们现在知道邮件该送给谁，我们知道自己的ip address(return address). 我们就可以把信息送给我们想送的网站，<a href="http://xn--google-hh4kj42j.com">比如google.com</a>，他收到信后，会拆开看我们相访问哪个网址，比如index.html,然后把我们想要的内容装进信封，颠倒送件人和收件人，然后送回来，我们拆开信封看到html信息，浏览器就会显示这些信息</li><li>Private Ip address</li><li>对于一个家庭来说，所有的设备共享一个公共ip，但是每个设备都会有自己的private ip，192.168.x.y. 或者172.16.x.y. 当你需要很多设备时，比如在大型公司，你可以使用10.x.y.z</li><li>TCP/IP</li><li>IP用来确认谁要向谁传送信息，TCP就是传送协议</li><li>Port Number</li><li>信息的传送有很多种，不光是HTTP，还有邮件，短信等等，我们使用不同的port number来让服务器知道进来的request是哪种请求，比如HTTP: TCP 80，我们让服务器听取port 80的网页请求，还可以SMTP: TCP 25让服务器听取port 25 的邮件请求， HTTPS： TCP 443, 加密的网页请求。</li><li>现在的浏览器会自动在网址后面加上port number</li><li>Getting your own domain name</li><li>我们的设备虽然可以联网，但是他只有一个公共ip，如果我们想host我们自己的网站，我们就需要有一个域名 GoDaddy, NameCheap</li><li>Hosting your own website</li><li>当我们有了域名之后，我们还需要一个web server用来存放我们的网站相关文件，HTML， CSS， JAVASCRIPT等等，这需要我们再找一个提供DNS服务的公司（<a href="http://dreamhost.com">dreamhost.com</a>），向他们租用一些online storeage，他们也会提供两个ip addresses（还有一个是备用的）。并且与我们的域名关联</li><li>DNS</li><li>例子：如果你的网站是一个邮件服务网站，比如Google email。我们的email虽然可以是yuan@unicard.com，但是其实我们使用的是Google的邮件服务，DNS识别出以unicard结尾的邮件地址是属于Google的一个服务，并把他发送到Google的服务器。</li><li>NS Name Server</li><li>一个NS record的作用是告诉大家哪个name server知道关于我们域名的一些信息</li><li>NS stands for ‘name server’ and this record indicates which DNS server is authoritative for that domain (which server contains the actual DNS records). A domain will often have multiple NS records which can indicate primary and backup name servers for that domain</li><li>A</li><li>A record的作用是把ip address和域名相连(Domain name to ip address)</li><li>CNAME Canonical name</li><li>与A record不同的是CNAME是把域名和域名相连(Domain name to domain name)，因为比如我们相用Google的邮件服务，所以我们想把yuan@unicard.com，关联到yuan@google.com,然后Google用他们呢的DNS server去把他转换成ip address，我们就不用担心Google改变他的ip address了。 再比如说，如果Dell公司的客户服务是外包出去的，那么我们访问Dell的网站，在通过Dell官网进入到他们的客户服务网站，我们就会发现我们从<code>Dell.com</code> 到了<code>customerService.com</code>，这样可能不太好，Dell想让他的网站看起来是一个整体，所以就可以用CNAME让<code>customerService.com</code>的名字隐藏起来，只显示成<code>support.dell.com</code></li></ul><p><img src="/../images/Harvard-CS75-Web-Development/1.png" alt="" /></p><ul><li>MX Mail Exchange</li><li>MX record把负责处理请求的server和他们的ip address相连，这样就可以知道进来的email请求该由哪个server负责</li></ul><h3 id="what-happens-when-you-reach-the-target-website"><a class="markdownIt-Anchor" href="#what-happens-when-you-reach-the-target-website"></a> What happens when you reach the target website?</h3><ul><li>Web host</li><li>Web host companies host multiple websites with one ip address, they share one ip address. Server response with different content based on the headers in the request</li><li>If the hosting server is using Php v4.3, you have to use the same. If the hosting server is down, all websites related to this server is also down.</li><li>VPS(Virtual Private Server)</li><li>VMware, Parallels, Virtual Box</li><li>Install multiple instances of Windows or Linux or MacOS on the server, and you can control the software and tools on that VPS</li><li>SSH/SFTP</li><li>SSH: Connecting to a remote server and execute commands on it. SFTP: Transfer files to a remote server.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">telnet www.google.com 80</span><br><span class="line"></span><br><span class="line">GET &#x2F; HTTP&#x2F;1.1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(press enter twice)</span><br></pre></td></tr></table></figure><ul><li>If your webiste is hosted by a server that are shared with other website, you have to send a get request with a host header specify your domain name. Otherwise the server don’t know what content to return.</li><li>nslookup <a href="http://google.com">google.com</a></li><li>will list ip address for that host</li><li>sudo vi /etc/hosts</li><li>this is a local ip address &lt;-&gt; domain name mapping table, browser will check this file first before sending any request</li></ul><h2 id="chapter-1-php"><a class="markdownIt-Anchor" href="#chapter-1-php"></a> Chapter 1: PHP</h2><h3 id="apache"><a class="markdownIt-Anchor" href="#apache"></a> Apache</h3><ul><li>Configuration file for Apache web server: httpd.conf, apache.conf, apache2.conf</li></ul><p><img src="/../images/Harvard-CS75-Web-Development/2.png" alt="" /></p><ol><li>listen to port 80 of any ip addresses of incoming requests</li><li>ServerName and ServerAlias: the destination of the incoming requests, both will need an A record in DNS to work (or CNAME)</li><li>CustomLog, ErrorLog: Specify where to save the log files</li><li>DocumentRoot: Root path of your website</li><li>port 443 uses SSL(Secure socket layer), needs a certificate to be installed on the server.<br />SSL: there are two keys, public key and private key, when a user visits our website, the website sends the public key to the user’s machine, user uses it to encrypt the message. Then when our website receives the message from the user, we use the private to decrypt it to get the original message. But this is not enough, we need to ask some Certificate Authorization(CA) for a certificate. This is because user doesn’t trust our website. but because our website is trusted by a CA, so the user can trust our website. Certificate needs to be digitally signed.</li><li>SSLCertificateKeyFile: the private key on the server</li><li>SSLCertificateFile: the certificate</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mod_rewrite</span><br><span class="line"></span><br><span class="line">RewriteEngine On</span><br><span class="line">RewriteCond %&#123;HTTP_HOST&#125; !^www\.cs75\.net [NC]</span><br><span class="line">RewriteRule (.*) https:&#x2F;&#x2F;www.cs75.net&#x2F;$1 [R&#x3D;301, L]</span><br></pre></td></tr></table></figure><ul><li><ol><li>HTTP_HOST is an environment variable, it is the host name. In English, the first line is a condition, it is saying if the host name is not starting with <a href="http://www.cs75.net">www.cs75.net</a>(Regex), do the following line, [NC], no case, case insensetive</li></ol></li><li><ol start="2"><li>(.*) one or more any characters, it remembers what user was typing, redirect user to the correct URL, 301 move permanently, the browser saves the result and next time will redirect you automatically. whereas 302 is move temporarily.</li></ol></li><li>The reason to do this is to make sure the URL in user’s browser is the website URL. Because there are multiple ways to visit the website and not typing the website URl. We could use ip address, we could use ‘udo vi /etc/hosts’(see end of lecture 0). So this will make sure that the URL will always be <a href="http://www.cs75.net">www.cs75.net</a> no matter what user originally typed.</li><li>XAMPP</li><li>Linux, Apache, MySQL, PHP, Perl</li><li>We can set up our dynamic website without using remote virtual server, people from outside world cannot visit it. But it is good for development purposes</li><li>GET/POST</li><li>GET: will change the state of the url, add parameters behind the quesiont mark ‘?’, parameters are separated by &amp;, everything will be shown in URL, not good to send sensitive or huge information</li><li>POST: can upload files(images), it is not in URL, can send sensitive information. Post request cannot be copied. One of the downsides of POST is that when user click reload or backbutton, browser will try to submit the form again, you may end up buying things twice. One of the solutions would be, whenever user submitted a form, immediately redirect user to another website page with only GET request, so they cannot revisit the POST request page anymore.</li><li>PHP</li><li>Very well documented. Interpreted(alternative to compiled) language, you don’t need to compile it first then to run it, you can just give your code to a interpreter and it will run. Downside is performance. Once a C++ language be compiled, the complied code can be run by CPU superfast. whereas PHP needs to be interpreted everytime.</li><li>suPHP</li><li>Web servers usually have root user(administrator) and other users. If you are user A, and you want the web server to be able to use your PHP code. You have to set them to be readable. Then another user B would be able to see your PHP code. Use suPHP could solve this issue. It makes sure that web server can only execute A’s code when A’s logged in. And B cannot see it when B’s logged in. And A can only delete A’s file, so no one else could modify or break A’s code. If A’s website’s users upload files or images, they are stored in the server where only A can see.</li><li>Variables</li><li>Data Types(loose in PHP), PHP functions will return different data types based on situations</li><li>Superglobals</li></ul><ol><li>$_COOKIE, key values from browser</li><li>$_ENV, lower details of user’s machine</li><li>$_FILES</li><li>$_GET, hash table</li><li>$_POST, array</li><li>$_REQUEST, details from requests</li><li>$_SERVER, user agent, browser and OS</li><li>$_SESSION, states, save values</li></ol><ul><li>Command line</li><li>mkdir, make directory</li><li>cd, change directory</li><li>cat/more, show content of a file</li><li>ls, list content of a directory</li><li>. current folder</li><li>… parent folder</li><li>ls -al, list permission settings for all files in current directory</li><li>chmod, change mode of a file or directory: e.g. chmod a+r filename: give read access to a file called filename</li><li>permission settings looks like this: -rw-rw-r–, the first - means it is a file or it can be ‘d’ for directory, it can then be split into three groups, they are the owner, the group and the world.</li><li>Use $_GET[‘username’] to get the variable values user send by GET request.</li><li>Use htmlspecialchars to escape all html tags to sanity check user inputs</li></ul><h2 id="chapter-2-php-continued"><a class="markdownIt-Anchor" href="#chapter-2-php-continued"></a> Chapter 2: PHP Continued</h2><ul><li>PHP is an interpreted language, it can be run at anywhere no matter what the PC is like. Compiled language depends on the PC, it may run at one PC and may not run at another.</li><li>POST request</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;pre&gt;</span><br><span class="line">    &lt;?php print_r($_POST) ?&gt;</span><br><span class="line">&lt;&#x2F;pre&gt;</span><br></pre></td></tr></table></figure><ul><li>use print_r to recursivly display all data inside the POST request</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;?</span><br><span class="line">    if (empty($_POST[&#39;fname&#39;]) || empty($_POST[&#39;lname&#39;])) &#123;</span><br><span class="line">        header(&quot;Location: http:&#x2F;&#x2F;localhost&#x2F;yuan&quot;);</span><br><span class="line">        exit;</span><br><span class="line">    &#125;</span><br><span class="line">?&gt;</span><br></pre></td></tr></table></figure><ul><li>check if necessary form information is filled(not empty). If not, redirect user back to the previous form page. header(“Location: URL”) is to redirect user</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;? if (empty($_POST[&#39;fname&#39;]) || empty($_POST[&#39;lname&#39;])): ?&gt;</span><br><span class="line">    You must provide your full name and gender to continue. Go &lt;a href&#x3D;&quot;index.html&quot;&gt;back&lt;&#x2F;a&gt;</span><br><span class="line">&lt;? else: ?&gt;</span><br><span class="line">    You are registered!</span><br><span class="line">    &lt;pre&gt;&lt;? print_r($_POST) ?&gt;&lt;&#x2F;pre&gt;</span><br><span class="line">&lt;? endif ?&gt; </span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;? if (empty($_POST[&#39;fname&#39;]) || empty($_POST[&#39;lname&#39;])) &#123; ?&gt;</span><br><span class="line">    You must provide your full name and gender to continue. Go &lt;a href&#x3D;&quot;index.html&quot;&gt;back&lt;&#x2F;a&gt;</span><br><span class="line">&lt;? &#125; else &#123; ?&gt;</span><br><span class="line">    You are registered!</span><br><span class="line">    &lt;pre&gt;&lt;? print_r($_POST) ?&gt;&lt;&#x2F;pre&gt;</span><br><span class="line">&lt;? &#125; ?&gt; </span><br></pre></td></tr></table></figure><ul><li>if else conditions in PHP supports both colon and curly brackets</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">if (!empty($_POST[&#39;fname&#39;]) &amp;&amp; !empty($_POST[&#39;lname&#39;])) &#123;</span><br><span class="line">    $to &#x3D; &#39;chengyuan82281681@hotmail.com&#39;;</span><br><span class="line">    $subject &#x3D; &#39;Registration&#39;;</span><br><span class="line">    $body &#x3D; &quot;This person just registered!\n\n&quot; .</span><br><span class="line">    $_POST[&#39;fname&#39;] . &quot;\n&quot; .</span><br><span class="line">    $_POST[&#39;lname&#39;];</span><br><span class="line">    $headers &#x3D; &quot;From: chengyuan82281681@hotmail.com\r\n&quot;;</span><br><span class="line">    mail($to, $subject, $body, $headers);</span><br><span class="line">&#125;</span><br><span class="line">else &#123;</span><br><span class="line">    header(&quot;Location: http:&#x2F;&#x2F;localhost&#x2F;yuan&#x2F;index.html&quot;);</span><br><span class="line">    exit;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>Dot symbol is a concatenation symbol, connect two strings into one</li><li>This mail function comes with PHP doesn’t uaually work on local network, because ISP blocks outbound port 25 for SMTP. Same reason as they block port 80.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;?</span><br><span class="line">    if (isset($_POST[&#39;action&#39;])) &#123;</span><br><span class="line">        if (empty($_POST[&#39;fname&#39;]) || empty($_POST[&#39;lname&#39;])) &#123;</span><br><span class="line">            $error &#x3D; true;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">?&gt;</span><br><span class="line"></span><br><span class="line">&lt;? if ($error): ?&gt;</span><br><span class="line">    &lt;div style&#x3D;&quot;color: red&quot;&gt;You must fill out the form!&lt;&#x2F;div&gt;</span><br><span class="line">&lt;? endif ?&gt;</span><br></pre></td></tr></table></figure><ul><li>To be able to check form errors using PHP code, index.html has to be changed to index.php</li><li>in index.php, setup a variable named ‘action’(other names work too) and send it to the backend, the server code will know if user submit a form by checking by variable.</li><li>if form has errors, send user back to itself with errors.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$DORMS &#x3D; array(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;);</span><br><span class="line">&lt;? foreach ($DORMS as $dorm): ?&gt;</span><br><span class="line">    &lt;option value&#x3D;&quot;&lt;?&#x3D; $dorm ?&gt;&quot;&gt;&lt;?&#x3D; $dorm ?&gt;&lt;&#x2F;option&gt; </span><br><span class="line">&lt;? endforeach ?&gt;</span><br></pre></td></tr></table></figure><ul><li>Define array in PHP</li><li>Foreach loop in PHP</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;?</span><br><span class="line">    foreach ($DORMS as $dorm) &#123;</span><br><span class="line">        if (isset($_POST[&quot;dorm&quot;]) &amp;&amp; $_POST[&quot;dorm&quot;] &#x3D;&#x3D; $dorm)</span><br><span class="line">            echo &quot;&lt;option selected&#x3D;&#39;selected&#39; value&#x3D;&#39;$dorm&#39;&gt;$dorm&lt;&#x2F;option&gt;&quot;;</span><br><span class="line">        else</span><br><span class="line">            echo &quot;&lt;option value&#x3D;&#39;$dorm&#39;&gt;$dorm&lt;&#x2F;option&gt;&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">?&gt;</span><br></pre></td></tr></table></figure><ul><li>When redirect user back because there are some errors in the form, the selected value will stay</li><li>Xdebug: extension of PHP to debug.</li></ul><h3 id="let-website-remember-your-login-with-sessions"><a class="markdownIt-Anchor" href="#let-website-remember-your-login-with-sessions"></a> Let website remember your login with sessions</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">&lt;?</span><br><span class="line">    &#x2F;&#x2F; 1</span><br><span class="line">    session_start();</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 2</span><br><span class="line">    define(&quot;USER&quot;, &quot;yuan&quot;);</span><br><span class="line">    define(&quot;PASS&quot;, &quot;123&quot;);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 3</span><br><span class="line">    if (isset($_POST[&quot;user&quot;]) &amp;&amp; isset($_POST[&quot;pass&quot;])) &#123;</span><br><span class="line">        if ($_POST[&quot;user&quot;] &#x3D;&#x3D; USER &amp;&amp; $_POST[&quot;pass&quot;] &#x3D;&#x3D; PASS) &#123;</span><br><span class="line">            $_SESSION[&quot;authenticated&quot;] &#x3D; true;</span><br><span class="line"></span><br><span class="line">            &#x2F;&#x2F; 4 save user in cookie for a week</span><br><span class="line">            setcookie(&quot;user&quot;, $_POST[&quot;user&quot;], time() + 7 * 24 * 60 * 60);</span><br><span class="line">            </span><br><span class="line">            &#x2F;&#x2F; redirect user to home page, using absolute path.</span><br><span class="line">            redirect(&quot;home.php&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 5</span><br><span class="line">    function redirect($file) &#123;</span><br><span class="line">        $host &#x3D; $_SERVER[&quot;HTTP_HOST&quot;];</span><br><span class="line">        $path &#x3D; rtrim(dirname($_SERVER[&quot;PHP_SELF&quot;]), &quot;&#x2F;\\&quot;); &#x2F;&#x2F; current php directory, trim out unwanted leading slashes</span><br><span class="line">        header(&quot;Location: http:&#x2F;&#x2F;$host$path&#x2F;$file&quot;);</span><br><span class="line">        exit;</span><br><span class="line">    &#125;</span><br><span class="line">?&gt;</span><br></pre></td></tr></table></figure><ul><li><ol><li>this will enable session, must be at the top of your code. Make sure no whitespaces or any code in front of this.</li></ol></li><li><ol start="2"><li>Define constants</li></ol></li><li><ol start="3"><li>check user form data are exist and valid</li></ol></li><li><ol start="4"><li>Session will be saved on the web server on the disk with a unique session id. Cookie will saved on the client machine. Everytime user visit the website, it will show us the cookies, web server will quickly open up the file saved with the same session id, and grab all the values(key-value pairs) to our webpage. Webpage also can access to the user Cookies.</li></ol></li><li><ol start="5"><li>define functions in PHP</li></ol></li><li>Note: make sure to give web server user the write permission to the session folder. Otherwise it cannot write session variables to the file. Also, make sure to use session_start(); in home.php as well. So it can have access to the session variables after redirecting. Any sensitive information should not be stored in the Cookies.</li><li>Note: make sure to give web server user the write permission to the session folder. Otherwise it cannot write session variables to the file. Also, make sure to use session_start(); in home.php as well. So it can have access to the session variables after redirecting.</li></ul><h2 id="chapter-3-mvc-xml"><a class="markdownIt-Anchor" href="#chapter-3-mvc-xml"></a> Chapter 3: MVC XML</h2><h3 id="mvc"><a class="markdownIt-Anchor" href="#mvc"></a> MVC</h3><ul><li>Change permission to write and read directory or files:</li><li>Read: r = 4</li><li>Write: w = 2</li><li>Execute: x = 1</li><li>adds them up to get the mode code.</li><li>e.g. sudo chmod 644 filename means: give the file the permission level: -rw-r–r--</li><li>sudo chmod 700 filename: give the file the permission level -rwx------</li><li>commonly used mode of files:</li><li>644: can be read and write by the file owner, also can be read by other group of users and the whole world.</li><li>600: can be read and write by the file owner only.</li><li>html 644</li><li>gif 644</li><li>jpg 644</li><li>css 644</li><li>js 644</li><li>png 644</li><li>php 600</li><li>For directory: Read means user can list all content inside a directory(same as the ls command in terminal). Execute means user can go into this directory(same as the cd command).</li><li>Common permission level for directory:</li><li>dir 711: user can go into this directory, can read/write all its files. Other groups or outside world can only go into this directory. If they know the exact filename in this directory and has read permission to that particular file. They can read it. But they can’t list all filenames of that directory.</li><li>dir 755: user can go into this directory, can read/write all its files, Other groups or outside world can go inside and list all files.</li><li>Use different hostname with only one web server. Change the hosts table file to give your domain a different name locally instead of localhost. sudo vi /etc/hosts</li><li>Use RewriteModule to manipulate the URL, route user to correct places with cleaner URLs</li></ul><h3 id="xml"><a class="markdownIt-Anchor" href="#xml"></a> XML</h3><p><img src="/../images/Harvard-CS75-Web-Development/3.png" alt="" /></p><ul><li>XML is an extensible markup language where you can extend structure without breaking existing data and applications.</li><li>Adding more children to an element is 100% fine.</li><li>Config files can be XML, you can add more KEYs and variables to the config files later.</li><li>Escape entities(pre-defined keywords) in XML: <code>&amp;amp;amp; &amp;amp;lt; &amp;amp;gt; &amp;amp;apos; &amp;amp;quot;</code></li><li>Declare your own entity: <code>&amp;lt;!ENTITY nbsp &quot;&amp;amp;#160;&quot;&amp;gt;</code></li><li>SimpleXML API: See XML in a Tree Structure</li><li>DOM(Document Object Model)</li><li>RSS</li></ul><p><img src="/../images/Harvard-CS75-Web-Development/4.png" alt="" /></p><ul><li>In PHP, we can use SimpleXML API to read an XML file and load its contents.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt;?</span><br><span class="line">    $dom &#x3D; simplexml_load_file(&quot;lectures.xml&quot;);</span><br><span class="line">    foreach ($dom-&gt;xpath(&quot;&#x2F;lectures&#x2F;lecture&quot;) as $lecture) &#123;</span><br><span class="line">    print &quot;&quot;;</span><br><span class="line">    print &quot;Lecture &quot; . $lecture[&quot;number&quot;] . &quot;: &quot;;</span><br><span class="line">    print $lecture-&gt;title;</span><br><span class="line">    print &quot;&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">?&lt;</span><br></pre></td></tr></table></figure><ul><li>Recall dot symbol . in PHP means concatenation.</li><li>Select XML node from PHP using xpath: If you only want to display certain lecture, for example, lecture 3, you could add additional condition in xpath<br /><code>$dom-&gt;xpath(&quot;/lectures/lecture[@number='3']&quot;)</code></li><li>@ is short for attributes, we can expend it as ‘attributes::’</li><li>We can also start at any given node and go to its parent, chlid or siblings by define the axis in the path(below is just an example and will not work):<br /><code>$dom-&gt;xpath(&quot;/parent::lectures/child::lecture[attributes::number='3']&quot;)</code></li></ul><h2 id="chapter-4-sql"><a class="markdownIt-Anchor" href="#chapter-4-sql"></a> Chapter 4: SQL</h2><ul><li>CSV(comma separated values)</li><li>PSV(Pipe separated values) pipe is the vertical line in the keyboard |</li><li>TSV(Tab separated values)</li><li>CSV</li><li>fgetcsv: load csv file content into an array of arrays</li><li>fputcsv: write content to a csv file</li><li>XML: SimpleXML</li><li>MySQL: database</li><li>SQLite: Allow you to use SQL without an actual Database, it is just a file stored in your disk.</li><li>SQL</li><li>CREATE</li><li>ALTER</li><li>DROP</li><li>SELECT</li><li>INSERT</li><li>UPDATE</li><li>DELETE</li><li>Connection MySQL to PHP: MyPHPAdmin</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">&gt;?</span><br><span class="line">    &#x2F;&#x2F; enable sessions</span><br><span class="line">    session_start();</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; connect to databsae</span><br><span class="line">    if (($connection &#x3D; mysqli_connect(&quot;localhost&quot;, &quot;yuan&quot;, &quot;123&quot;, &quot;yuan_lecture&quot;)) &#x3D;&#x3D;&#x3D; false)</span><br><span class="line">    die(&quot;Could not connect to database&quot;);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; if username and password were submitted, check them</span><br><span class="line">    if (isset($_POST[&quot;user&quot;]) &amp;&amp; isset($_POST[&quot;pass&quot;]))</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; prepare SQL</span><br><span class="line">        $sql &#x3D; sprintf(&quot;SELECT * FROM users WHERE username&#x3D;&#39;%s&#39;&quot;, mysqli_real_escape_string($connection, $_POST[&quot;user&quot;]));</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; execute query</span><br><span class="line">        $result &#x3D; mysqli_query($connection, $sql);</span><br><span class="line">        if ($result &#x3D;&#x3D;&#x3D; false)</span><br><span class="line">            die(&quot;Could not query database&quot;);</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; check whether we found a row</span><br><span class="line">        if (mysqli_num_rows($connection, $result) &#x3D;&#x3D; 1) &#123;</span><br><span class="line">            &#x2F;&#x2F; fetch row</span><br><span class="line">            $row &#x3D; mysqli_fetch_assoc($connection, $result);</span><br><span class="line"></span><br><span class="line">            &#x2F;&#x2F; check password</span><br><span class="line">            if ($row[&quot;password&quot;] &#x3D;&#x3D; $_POST[&quot;pass&quot;]) &#123;</span><br><span class="line">            &#x2F;&#x2F; remember that user&#39;s logged in</span><br><span class="line">            $_SESSION[&quot;authenticated&quot;] &#x3D; true;</span><br><span class="line"></span><br><span class="line">            &#x2F;&#x2F; redirect user to home page, using absolute path.</span><br><span class="line">            redirect(&quot;home.php&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    function redirect($file) &#123;</span><br><span class="line">    $host &#x3D; $_SERVER[&quot;HTTP_HOST&quot;];</span><br><span class="line">    $path &#x3D; rtrim(dirname($_SERVER[&quot;PHP_SELF&quot;]), &quot;&#x2F;\\&quot;); &#x2F;&#x2F; current php directory, trim out unwanted leading slashes</span><br><span class="line">    header(&quot;Location: http:&#x2F;&#x2F;$host$path&#x2F;$file&quot;);</span><br><span class="line">    exit;</span><br><span class="line">    &#125;</span><br><span class="line">?&lt;</span><br></pre></td></tr></table></figure><ul><li><ol><li>in mysql_connect(), the first variable is the DB server, second is username of the DB, thrid is the password of the DB</li></ol></li><li><ol start="2"><li>mysql_real_escape_string is preventing SQL injection attack.</li></ol></li><li><ol start="3"><li>$result is a temporary table get from DB</li></ol></li><li><ol start="4"><li>mysql_num_rows return number of rows in the temp table</li></ol></li><li><ol start="5"><li>mysql_fetch_assoc return an associated array with keys and values from the temp table</li></ol></li><li>One way hash password</li><li>It is not good to store password in the DB in plain text. So we should use a hash function to hash the password into some random characters, whenever user logs in, we use the same algorithm to hash the password and check if it equals to the same random characters in the DB.</li><li>SQL indexes, Constraints</li><li>PRIMARY KEY</li><li>INDEX: doing a binary search or some other tree structure to a column, so it will be much faster to run a query. Cost more disk space. The below image shows that this table has two indexes, and it is using BTREE structure to store all values.</li></ul><p><img src="/../images/Harvard-CS75-Web-Development/8.png" alt="" /></p><ul><li>UNIQUE</li><li>FULLTEXT</li><li>BLOB (Binary Large Object) -&gt; etc. Images</li><li>Although you can store images into DB, it cost space, it would be better to store it in a folder(file system), and store the link to this file into the DB.</li><li>Foriegn Key: is a primary key in another table</li></ul><h2 id="chapter-5-sql-continued"><a class="markdownIt-Anchor" href="#chapter-5-sql-continued"></a> Chapter 5: SQL Continued</h2><ul><li>CRUD (Create Read Update Delete) model</li><li>VARCHAR will save more space than using CHAR, because it uses different length of chars for each value.</li><li>CHAR will use same length of chars for all values, but it will run query faster, because it knows the length of values, it can move to next value by adding the length to the current position. (For VARCHAR it has to keep searching until reach to the end of the value.)</li><li>AI (Auto Increment) Good for IDs, plus one each time. When you delete the ID, the ID number will NOT be reused.</li><li>Float numbers: 32-bit or 64-bit numbers are finite. If we are using it to represents real numbers(infinite), SQL will round the number to its closest number that it can find. e.g. if you enter 1.9, it might give you 1.89999999 instead. So it is not good to use Float to represent Money etc… important values</li><li>MySQL Functions</li><li>PDO(Portable Data Object)</li></ul><p><img src="/../images/Harvard-CS75-Web-Development/5.png" alt="" /></p><ul><li>Assign variables to values, so when you change database next time, you don’t have to change the code. You just need to change the variables of PDO arguments.</li><li>JOIN</li></ul><p><img src="/../images/Harvard-CS75-Web-Development/6.png" alt="" /><br /><img src="/../images/Harvard-CS75-Web-Development/7.png" alt="" /></p><ul><li>Join tables together. Get data from multiple tables at once.</li><li>In the above example, we could further create another table that has Product_Id and Product_Name, and use only Product_Id in the orders table.</li></ul><p><img src="/../images/Harvard-CS75-Web-Development/9.png" alt="" /></p><ul><li>Only the person that have sold products are displayed.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT Employees.Name, Orders.Product</span><br><span class="line">FROM Employees</span><br><span class="line">JOIN Orders ON Employees.Employee_ID &#x3D; Orders.Employee_ID</span><br></pre></td></tr></table></figure><ul><li>This is another syntax to use to join tables. This is the same as the other SQL syntax shown above.</li><li>Left Join, Right Join</li><li>Their are differnt type of joins, they decides which table should carry more weight in this query. For example, in the Employees table, if someone has left the company and is no longer exist in the Employees table. But his sell history is still in the orders table. We want to keep the sell history. Then we could use a Right Join, it will display all sell history related. But will show NULL in the Employee_ID(because there is no corresponding Employee_ID in the Employees table).</li><li>Race Conditions(Atomicity)</li><li>In computer programming, an operation done by a computer is considered atomic if it is guaranteed to be isolated from other operations that may be happening at the same time. Put another way, atomic operations are indivisible.</li><li>INSERT INTO table (a,b,c) VALUES (1,2,3) ON DUPLICATE KEY UPDATE c=c+1;</li><li>This will help you to merge SELECT and UPDATE into one query. Potentially solve the race conditions issue(NOT enough though).</li><li>Transactions</li><li>Transactions means do the following queries atomically, do not allow any other queries perform in the meantime.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">START TRANSACTION;</span><br><span class="line">UPDATE ACCOUNT SET BALANCE &#x3D; BALANCE - 1000 WHERE NUMBER &#x3D; 2;</span><br><span class="line">UPDATE ACCOUNT SET BALANCE &#x3D; BALANCE + 1000 WHERE NUMBER &#x3D; 1;</span><br><span class="line">COMMIT;</span><br></pre></td></tr></table></figure><ul><li>In the example above, we transfer 1000 balance from account 1 to account 2 at the same time.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">START TRANSACTION;</span><br><span class="line">UPDATE ACCOUNT SET BALANCE &#x3D; BALANCE - 1000 WHERE NUMBER &#x3D; 2;</span><br><span class="line">UPDATE ACCOUNT SET BALANCE &#x3D; BALANCE + 1000 WHERE NUMBER &#x3D; 1;</span><br><span class="line">SELECT BALANCE FROM ACCOUNT WHERE NUMBER &#x3D; 2;</span><br><span class="line"># suppose account number 2 has a negative balance here!</span><br><span class="line">ROLLBACK;</span><br></pre></td></tr></table></figure><ul><li>In the example above, if we find something wrong happened after we perform the transaction, ROLLBACK will undo all the changes in the transaction.</li><li>Locks (MyISAM)</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">LOCK TABLES account WRITE;</span><br><span class="line">SELECT balance FROM account WHERE number &#x3D; 2;</span><br><span class="line">UPDATE account SET balance &#x3D; 1500 WHERE number &#x3D; 2;</span><br><span class="line">UNLOCK TABLES;</span><br></pre></td></tr></table></figure><ul><li>‘LOCK TABLES account WRITE;’’ will lock the table ‘account’, prevening people from WRITING to the table.</li><li>One downside is that LOCK will lock the entire table, so no one can write to the table even if they are updating other accounts.</li></ul><p><img src="/../images/Harvard-CS75-Web-Development/10.png" alt="" /></p><ul><li>Add Foreign key constraints so that the DB knows the primary key in one table is related to another foreign key in another table.</li><li>ON DELETE RESTRICT and ON UPDATE RESTRICT means if we want to delete something that is actually a primary key in a table, DB will reject it because it is related to another tables. If we changed it to CASCADE, then if we delete a record that is a primary key, DB will delete all records that are related to this primary key in other tables too.</li></ul><h2 id="chapter-6-javascript"><a class="markdownIt-Anchor" href="#chapter-6-javascript"></a> Chapter 6: JavaScript</h2><ul><li>Javacript, like PHP, is also an interpreted language. Node.js is a server side js language.</li></ul><h3 id="global-objects"><a class="markdownIt-Anchor" href="#global-objects"></a> Global objects</h3><ol><li>Array</li><li>Boolean</li><li>Date</li><li>Function</li><li>Math</li><li>Number</li><li>Object</li><li>RegExp</li><li>String</li></ol><h3 id="array"><a class="markdownIt-Anchor" href="#array"></a> Array</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">var array &#x3D; [];</span><br><span class="line">array[0] &#x3D; &#39;abc&#39;;</span><br><span class="line">array.push(&#39;abc&#39;);</span><br></pre></td></tr></table></figure><ul><li>Array doesn’t have a fixed length, you can use index or ‘push’ method to add elements.</li><li>Put cursor in form field that is empty.</li></ul><p><img src="/../images/Harvard-CS75-Web-Development/11.png" alt="" /></p><ul><li>Document is a super global object. It is a DOM(document object model)</li></ul><p><img src="/../images/Harvard-CS75-Web-Development/12.png" alt="" /></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;script&gt;</span><br><span class="line">    function validate(f)</span><br><span class="line">    &#123;</span><br><span class="line">        if (f.email.value &#x3D;&#x3D; &quot;&quot;)</span><br><span class="line">        &#123;</span><br><span class="line">            alert(&quot;You must provide an email adddress.&quot;);</span><br><span class="line">            return false;</span><br><span class="line">        &#125;</span><br><span class="line">        else if (f.password1.value &#x3D;&#x3D; &quot;&quot;)</span><br><span class="line">        &#123;</span><br><span class="line">            alert(&quot;You must provide a password.&quot;);</span><br><span class="line">            return false;</span><br><span class="line">        &#125;</span><br><span class="line">        else if (f.password1.value !&#x3D; f.password2.value)</span><br><span class="line">        &#123;</span><br><span class="line">            alert(&quot;You must provide the same password twice.&quot;);</span><br><span class="line">            return false;</span><br><span class="line">        &#125;</span><br><span class="line">        else if (!f.agreement.checked)</span><br><span class="line">        &#123;</span><br><span class="line">            alert(&quot;You must agree to our terms and conditions.&quot;);</span><br><span class="line">            return false;</span><br><span class="line">        &#125;</span><br><span class="line">        return true;</span><br><span class="line">    &#125;</span><br><span class="line">&lt;&#x2F;script&gt;</span><br><span class="line">&lt;title&gt;&lt;&#x2F;title&gt;</span><br><span class="line">&lt;&#x2F;head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;form action&#x3D;&quot;process.php&quot; method&#x3D;&quot;get&quot; name&#x3D;&quot;registration&quot; onsubmit&#x3D;&quot;return validate(this);&quot;&gt;</span><br><span class="line">    Email: &lt;input name&#x3D;&quot;email&quot; type&#x3D;&quot;text&quot;&gt;</span><br><span class="line">    &lt;br&gt;</span><br><span class="line">    Password: &lt;input name&#x3D;&quot;password1&quot; type&#x3D;&quot;password&quot;&gt;</span><br><span class="line">    &lt;br&gt;</span><br><span class="line">    Password (again): &lt;input name&#x3D;&quot;password2&quot; type&#x3D;&quot;password&quot;&gt;</span><br><span class="line">    &lt;br&gt;</span><br><span class="line">    I agree to the terms and conditions: &lt;input name&#x3D;&quot;agreement&quot; type&#x3D;&quot;checkbox&quot;&gt;</span><br><span class="line">    &lt;br&gt;&lt;br&gt;</span><br><span class="line">    &lt;input type&#x3D;&quot;submit&quot; value&#x3D;&quot;Submit&quot;&gt;</span><br><span class="line">&lt;&#x2F;form&gt;</span><br><span class="line">&lt;&#x2F;body&gt;</span><br><span class="line">&lt;&#x2F;html&gt;</span><br></pre></td></tr></table></figure><ul><li>check the form fields values at client side using Javascript. validate(this), is passing ‘document.forms.registration’ to the function.</li><li>Both client side and server side form validation and necessary. User’s can change js using tools like inspector console and bypass the client side validation.</li><li>Regular Expressions</li><li>Object</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">var obj &#x3D; &#123;&#125;;</span><br><span class="line">obj.key &#x3D; value;</span><br><span class="line">obj[&#39;key&#39;] &#x3D; value;</span><br><span class="line">var obj &#x3D; &#123;key: value&#125;;</span><br></pre></td></tr></table></figure><h3 id="event-handlers"><a class="markdownIt-Anchor" href="#event-handlers"></a> Event handlers</h3><ol><li>onblur</li><li>onchange</li><li>onclick</li><li>onfocus</li><li>onkeydown</li><li>onkeyup</li><li>onload</li><li>onmousedown</li><li>onmouseup</li><li>onmouseout</li><li>onmouseover</li><li>onresize</li><li>onselect</li><li>onsubmit</li></ol><ul><li>Call a function as a reference</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&lt;html&gt;</span><br><span class="line">    &lt;head&gt;</span><br><span class="line">    &lt;script&gt;</span><br><span class="line">        function blinker()</span><br><span class="line">        &#123;</span><br><span class="line">            var blinks &#x3D; document.getElementsByTagName(&quot;blink&quot;);</span><br><span class="line">            for (var i &#x3D; 0; i &lt; blinks.length; i++)</span><br><span class="line">            &#123;</span><br><span class="line">                if (blinks[i].style.visibility &#x3D;&#x3D; &quot;hidden&quot;)</span><br><span class="line">                    blinks[i].style.visibility &#x3D; &quot;visible&quot;;</span><br><span class="line">                else</span><br><span class="line">                    blinks[i].style.visibility &#x3D; &quot;hidden&quot;;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        window.setInterval(blinker, 500);</span><br><span class="line">    &lt;&#x2F;script&gt;</span><br><span class="line">    &lt;title&gt;&lt;&#x2F;title&gt;</span><br><span class="line">    &lt;&#x2F;head&gt;</span><br><span class="line">    &lt;body&gt;</span><br><span class="line">    &lt;center&gt;</span><br><span class="line">        &lt;blink&gt;&lt;h1&gt;hello, world&lt;&#x2F;h1&gt;&lt;&#x2F;blink&gt;</span><br><span class="line">    &lt;&#x2F;center&gt;</span><br><span class="line">    &lt;&#x2F;body&gt;</span><br><span class="line">&lt;&#x2F;html&gt;</span><br></pre></td></tr></table></figure><ul><li>Notice in the code above, when we call the blinker function in window.setInterval(blinker, 500), we are not adding () at the end of the function name. This is because we are passing a reference of that function(blinker) to it. If we use window.setInterval(blinker(), 500), we are passing the return result of blinker function to it, which will not work because blinker function doesn’t return anything.</li><li>Anonymous function(lambda function)</li><li>window.setInterval(function() { alert(“HI”); }, 5000);</li><li>Javascript code can be minimized to save traffic. Variable names and spaces will be shrinked.</li></ul><h2 id="chapter-7-ajax"><a class="markdownIt-Anchor" href="#chapter-7-ajax"></a> Chapter 7: AJAX</h2><p><img src="/../images/Harvard-CS75-Web-Development/13.png" alt="" /></p><ul><li>XML and json and data transfer machanism, json tends to be much more popular thesedays</li><li>XMLHttpRequest</li></ul><ol><li>abort()</li><li>getAllResponseHeaders()</li><li>getResponseHeader()</li><li>open(method, url)</li><li>open(method, url, async)</li><li>open(method, url, async, user)</li><li>open(method, url, async, user, password)</li><li>send()</li><li>send(data)</li><li>setRequestHeader(header, value)</li></ol><h3 id="xmlhttprequest-properties"><a class="markdownIt-Anchor" href="#xmlhttprequest-properties"></a> XMLHttpRequest properties</h3><ol><li>onreadystatechange</li><li>readyState(0 unitialized, 1 open, 2 sent, 3 receiving, 4 loaded)</li><li>responseBody</li><li>responseText</li><li>responseXML</li><li>status(200 OK, 404 Not Found, 500 Internal Server Error)</li><li>statusText</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">function handler()</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; only handle requests in &quot;loaded&quot; state</span><br><span class="line">        if (xhr.readyState &#x3D;&#x3D; 4)</span><br><span class="line">        &#123;</span><br><span class="line">            if (xhr.status &#x3D;&#x3D; 200)</span><br><span class="line">            &#123;</span><br><span class="line">                &#x2F;&#x2F; get XML</span><br><span class="line">                var xml &#x3D; xhr.responseXML;</span><br><span class="line"></span><br><span class="line">                &#x2F;&#x2F; update price</span><br><span class="line">                var prices &#x3D; xml.getElementsByTagName(&quot;price&quot;);</span><br><span class="line">                if (prices.length &#x3D;&#x3D; 1)</span><br><span class="line">                &#123;</span><br><span class="line">                    var price &#x3D; prices[0].firstChild.nodeValue;</span><br><span class="line">                    document.getElementById(&quot;price&quot;).innerHTML &#x3D; price;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                &#x2F;&#x2F; update low</span><br><span class="line">                var lows &#x3D; xml.getElementsByTagName(&quot;low&quot;);</span><br><span class="line">                if (lows.length &#x3D;&#x3D; 1)</span><br><span class="line">                &#123;</span><br><span class="line">                    var low &#x3D; lows[0].firstChild.nodeValue;</span><br><span class="line">                    document.getElementById(&quot;low&quot;).innerHTML &#x3D; low;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                &#x2F;&#x2F; update high</span><br><span class="line">                var highs &#x3D; xml.getElementsByTagName(&quot;high&quot;);</span><br><span class="line">                if (highs.length &#x3D;&#x3D; 1)</span><br><span class="line">                &#123;</span><br><span class="line">                    var high &#x3D; highs[0].firstChild.nodeValue;</span><br><span class="line">                    document.getElementById(&quot;high&quot;).innerHTML &#x3D; high;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            else</span><br><span class="line">                alert(&quot;Error with Ajax call!&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><ul><li>if PHP return data as XML type, ajax has a function called responseXML, but it is not very easy to get the data you want. Because XML data structure is quite complex.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">&lt;html&gt;</span><br><span class="line">    &lt;head&gt;</span><br><span class="line">    &lt;script&gt;</span><br><span class="line">        &#x2F;&#x2F; an XMLHttpRequest</span><br><span class="line">        var xhr &#x3D; null;</span><br><span class="line">        &#x2F;*</span><br><span class="line">            * void</span><br><span class="line">            * quote()</span><br><span class="line">            *</span><br><span class="line">            * Gets a quote.</span><br><span class="line">            *&#x2F;</span><br><span class="line">        function quote()</span><br><span class="line">        &#123;</span><br><span class="line">            &#x2F;&#x2F; instantiate XMLHttpRequest object</span><br><span class="line">            try</span><br><span class="line">            &#123;</span><br><span class="line">                xhr &#x3D; new XMLHttpRequest();</span><br><span class="line">            &#125;</span><br><span class="line">            catch (e)</span><br><span class="line">            &#123;</span><br><span class="line">                xhr &#x3D; new ActiveXObject(&quot;Microsoft.XMLHTTP&quot;);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            &#x2F;&#x2F; handle old browsers</span><br><span class="line">            if (xhr &#x3D;&#x3D; null)</span><br><span class="line">            &#123;</span><br><span class="line">                alert(&quot;Ajax not supported by your browser!&quot;);</span><br><span class="line">                return;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            &#x2F;&#x2F; get symbol</span><br><span class="line">            var symbol &#x3D; document.getElementById(&quot;symbol&quot;).value;</span><br><span class="line"></span><br><span class="line">            &#x2F;&#x2F; construct URL</span><br><span class="line">            var url &#x3D; &quot;quote7.php?symbol&#x3D;&quot; + symbol;</span><br><span class="line"></span><br><span class="line">            &#x2F;&#x2F; get quote</span><br><span class="line">            xhr.onreadystatechange &#x3D;</span><br><span class="line">            function()</span><br><span class="line">            &#123;</span><br><span class="line">                &#x2F;&#x2F; only handle loaded requests</span><br><span class="line">                if (xhr.readyState &#x3D;&#x3D; 4)</span><br><span class="line">                &#123;</span><br><span class="line">                    if (xhr.status &#x3D;&#x3D; 200)</span><br><span class="line">                    &#123;</span><br><span class="line">                        &#x2F;&#x2F; evaluate JSON</span><br><span class="line">                        var quote &#x3D; eval(&quot;(&quot; + xhr.responseText + &quot;)&quot;);</span><br><span class="line"></span><br><span class="line">                        &#x2F;&#x2F; show JSON in textarea</span><br><span class="line">                        document.getElementById(&quot;code&quot;).value &#x3D; xhr.responseText;</span><br><span class="line"></span><br><span class="line">                        &#x2F;&#x2F; insert quote into DOM</span><br><span class="line">                        var div &#x3D; document.createElement(&quot;div&quot;);</span><br><span class="line">                        var text &#x3D; document.createTextNode(symbol + &quot;: &quot; + quote.price);</span><br><span class="line">                        div.appendChild(text);</span><br><span class="line">                        document.getElementById(&quot;quotes&quot;).appendChild(div);</span><br><span class="line">                    &#125;</span><br><span class="line">                    else</span><br><span class="line">                        alert(&quot;Error with Ajax call!&quot;);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            xhr.open(&quot;GET&quot;, url, true);</span><br><span class="line">            xhr.send(null);</span><br><span class="line">        &#125;</span><br><span class="line">    &lt;&#x2F;script&gt;</span><br><span class="line">    &lt;title&gt;&lt;&#x2F;title&gt;</span><br><span class="line">    &lt;&#x2F;head&gt;</span><br><span class="line">    &lt;body&gt;</span><br><span class="line">    &lt;form onsubmit&#x3D;&quot;quote(); return false;&quot;&gt;</span><br><span class="line">        Symbol: &lt;input id&#x3D;&quot;symbol&quot; type&#x3D;&quot;text&quot;&gt;</span><br><span class="line">        &lt;br&gt;&lt;br&gt;</span><br><span class="line">        &lt;input type&#x3D;&quot;submit&quot; value&#x3D;&quot;Get Quote&quot;&gt;</span><br><span class="line">    &lt;&#x2F;form&gt;</span><br><span class="line">    &lt;br&gt;&lt;br&gt;</span><br><span class="line">    &lt;div id&#x3D;&quot;quotes&quot;&gt;&lt;&#x2F;div&gt;</span><br><span class="line">    &lt;br&gt;&lt;br&gt;</span><br><span class="line">    &lt;textarea cols&#x3D;&quot;80&quot; id&#x3D;&quot;code&quot; rows&#x3D;&quot;16&quot;&gt;&lt;&#x2F;textarea&gt;</span><br><span class="line">    &lt;&#x2F;body&gt;</span><br><span class="line">&lt;&#x2F;html&gt;</span><br></pre></td></tr></table></figure><ul><li>Encode ajax response to json and return to js as an object. json_encode is a PHP function that convert data into json string. ‘eval’ is a js function that convert json data into js object.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$(document).ready(function() &#123;</span><br><span class="line">    $(&quot;#form&quot;).submit(function() &#123;</span><br><span class="line">        $.ajax(&#123;</span><br><span class="line">        url: &quot;quote7.php&quot;,</span><br><span class="line">        data: &#123; </span><br><span class="line">        symbol: $(&quot;#symbol&quot;).val()</span><br><span class="line">        &#125;,</span><br><span class="line">        success: function(data) &#123;</span><br><span class="line">            $(&quot;#price&quot;).html(data.price);</span><br><span class="line">            $(&quot;#high&quot;).html(data.high);</span><br><span class="line">            $(&quot;#low&quot;).html(data.low);</span><br><span class="line">        &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        return false;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><ul><li>Another even cleaner example is to using jQuery. Dollar sign $ is short for ‘jQuery’. $(&quot;#form&quot;) is equals to jQuery(&quot;#form&quot;)</li><li>jQuery is a library that provides more functionality to your code. $(document) is passing document to the jQuery library so you can use the extra features that jQuery provides.</li><li>.ready is to make sure the whole html page is being loaded correctly. Because some of the code in ready function may require html elements.</li><li>.ajax function takes one argument, which is in the parentheses, the argument is an object. JS only has two data structures, array and object, which represented by [] and {} respectively.</li><li>the object in .ajax function has three keys, url, data and success.</li><li>url takes a string, which is the url we will go to.</li><li>data takes an object, which is the data we send.</li><li>success takes an anonymous function, it is only being called when ajax request is success.(state is ready and response code is 200)</li><li>the anonymous function after the .submit event handler return false because we don’t want to submit the form again, we already got the data from the ajax call.</li><li>Content Types</li><li>Specify the data type of the current file.</li><li>HTML (text/html) (default)</li><li>XML (text/XML)</li><li>JSON (application/json)</li><li>PHP + JSON</li><li>json_encode($value): convert data to json on server side to be ready to send</li><li>eval(string): convert data from json to object so we can access it on the client side</li><li>Same Origin Policy</li><li>We are not allowed to display data we get from another domain. We can make ajax call at JS and get response, but we cannot display it. You cannot embed it into your DOM. CORS can override this.</li></ul><h2 id="chapter-8-security"><a class="markdownIt-Anchor" href="#chapter-8-security"></a> Chapter 8: Security</h2><ul><li>Obvious Threats</li><li>Telnet, FTP, HTTP, MySQL</li><li>suPHP, all users can only access to their own files. No one can delete or modify your files.</li><li>Session Hijacking(scenarios)</li><li>Physical Access</li><li>Packet Sniffing: For website not using HTTPS</li><li>Session Fixation: Guess the session ID</li><li>XSS: Cross site scripting attack</li><li>SSL Certificate</li><li>Public key Cryptography</li><li>There is a public key and a private key. Imagine we want to buy something from a website. Before we sending credit card information to the website. The website will send me the public key(can be see by everyone). And we are going to use the public key to encrypt the information. Only the private key can be used to decrypt the information. And only the website has the private key. Likewise, if the website wants to send me some information. I need to send it the public key too. And use my private key to decrypt it when I receive the information.</li><li>SQL injection attacks</li><li>mysql_real_escape_string(): put backslash to quote etc…</li><li>Same-Origin Policy: You can only get data from the same origin as your HTML DOM. (ajax calls)</li><li>CORS can override same origin policy, jsonp</li><li>Attacks</li><li>CSRF (Cross-site scripting forgery): If you login to some stock trade website recently and saved your login session. And you visited the bad website in the meantime and being tricked to click the link in their website. The link is actually a request and will send a request to the stock trade website to buy some stock. Note: User click a link could send both GET/POST request. Forms can be hidden and submitted by JS code. So just change the buying request to POST request doesn’t solve this issue.</li><li>1.The way to prevent this is whenever you want to send a request, the website will send a random session token back to you. And you have to add this token in the request to be able to make the request work. The CSRF link will never know what the token is.</li><li>2.CAPTCHA: enter some words that easy for human to see but not for machine.</li><li>3.Whenever you want to checkout, the website will make you log out immediately when you click the checkout button.</li><li>XSS</li><li>You can access to the Cookie from JS</li><li>And there is a flawed website which writing values to its body, and you can be tricked to click the link and send your Cookie to other people.</li><li>An attacker can use XSS to send a malicious script to an unsuspecting user. The end user’s browser has no way to know that the script should not be trusted, and will execute the script. Because it thinks the script came from a trusted source, the malicious script can access any cookies, session tokens, or other sensitive information retained by the browser and used with that site.</li><li>Escape HTML special chars</li></ul><h2 id="chapter-9-scalability"><a class="markdownIt-Anchor" href="#chapter-9-scalability"></a> Chapter 9: Scalability</h2><h3 id="vertical-scaling"><a class="markdownIt-Anchor" href="#vertical-scaling"></a> Vertical Scaling</h3><ul><li>增加服务器的CPU，内存，硬盘等，但总会不够用</li></ul><ol><li>CPU: cores, L2 cache…</li><li>Disk: PATA, SATA, SAS, RAID</li><li>RAID(Redundent array of independent disks)<ol><li>RAID 0 :如果你有n块磁盘，原来只能同时写一块磁盘，写满了再下一块，做了RAID 0之后，n块可以同时写，速度提升很快，但由于没有备份，可靠性很差。n最少为2。</li><li>RAID 1: 正因为RAID 0太不可靠，所以衍生出了RAID1。如果你有n块磁盘，把其中n/2块磁盘作为镜像磁盘，在往其中一块磁盘写入数据时，也同时往另一块写数据。坏了其中一块时，镜像磁盘自动顶上，可靠性最佳，但空间利用率太低。n最少为2。</li><li>RAID 10: 是RAID 0 和RAID 1 的结合，同时写入n/2的硬盘并将剩下n/2作为备份，可靠性和速度都有，但是需要两倍的钱。</li><li>RAID 3：为了说明白RAID 5，先说RAID 3.RAID 3是若你有n块盘，其中1块盘作为校验盘，剩余n-1块盘相当于作RAID 0同时读写，当其中一块盘坏掉时，可以通过校验码还原出坏掉盘的原始数据。这个校验方式比较特别，奇偶检验，1 XOR 0 XOR 1=0，0 XOR 1 XOR 0=1，最后的数据时校验数据，当中间缺了一个数据时，可以通过其他盘的数据和校验数据推算出来。但是这有个问题，由于n-1块盘做了RAID 0，每一次读写都要牵动所有盘来为它服务，而且万一校验盘坏掉就完蛋了。最多允许坏一块盘。n最少为3.</li><li>RAID 5：在RAID 3的基础上有所区别，同样是相当于是1块盘的大小作为校验盘，n-1块盘的大小作为数据盘，但校验码分布在各个磁盘中，不是单独的一块磁盘，也就是分布式校验盘，这样做好处多多。最多坏一块盘。n最少为3.</li><li>RAID 6：在RAID 5的基础上，又增加了一种校验码，和解方程似的，一种校验码一个方程，最多有两个未知数，也就是最多坏两块盘。</li></ol></li><li>RAM</li></ol><h3 id="horizontal-scaling"><a class="markdownIt-Anchor" href="#horizontal-scaling"></a> Horizontal Scaling</h3><ul><li>增加更多的服务器，而不是提升每个服务器的配置。当我们拥有多于一个服务器时，当用户向服务器发送请求时，我们要一个load balancer去将进来的request平均分配给所有的服务器。load balancer拥有一个public IP。而每一个服务器有一个private IP，他们不需要public IP</li></ul><h3 id="load-balancing"><a class="markdownIt-Anchor" href="#load-balancing"></a> Load Balancing</h3><ul><li>如何给服务器平均分配request？我们可以将所有可用的服务器IP列出来，第一个request给第一个服务器，第二个request给第二个服务器，以此类推直到回到第一个，然后循环，这种方法叫做round-robin，优点是他不需要主动询问服务器的当前状态如何</li></ul><h3 id="caching"><a class="markdownIt-Anchor" href="#caching"></a> Caching</h3><ul><li>当用户通过load balancer登录到一号服务器时，他的登录信息如果保存在一号服务器，那么在他下一个request被分配到其他服务器时，他就需要再次登录，如果他在使用一个购物网站，他将一件商品加入到一号服务器的购物车中，然后又在二号服务器登录却找不到他的购物车，也不能结帐，这就会成为一个大问题</li></ul><h3 id="shared-session-statesticky-session"><a class="markdownIt-Anchor" href="#shared-session-statesticky-session"></a> Shared Session State(Sticky session)</h3><ul><li>我们可以将session，也就是用户信息储存在另外一个服务器中</li><li>Shared Storage</li><li>FC (Fiber Channel), iSCSI, MySQL, NFS</li><li>Replicate your database, use more than one database to store sessions in case one goes down</li></ul><h3 id="cookie"><a class="markdownIt-Anchor" href="#cookie"></a> Cookie</h3><ul><li>当用户首次登陆时，load balancer可以想用户电脑中加入一个cookie，包含一些加密的服务器信息，所以当用户在短时间内再次访问时，load balancer就知道该将用户的请求发送到哪个服务器</li></ul><h3 id="load-balancer"><a class="markdownIt-Anchor" href="#load-balancer"></a> Load Balancer</h3><ul><li>Software: ELB(Amazon’s Elastic Load Balancer), HAProxy(High Availability Proxy), LVS(Linux Virtual Server)</li><li>Hardware: Barracuda, Cisco, Citrix, F5</li></ul><h3 id="php-accelerators"><a class="markdownIt-Anchor" href="#php-accelerators"></a> PHP Accelerators</h3><ul><li>当我们在调用python程序时，我们需要先将以py结尾的代码文件编译成可直接执行的文件，然后再运行可执行文件得到结果。这样做的目的是当我们想再次得到结果时，我们不需要再次编译，可以直接运行执行文件。</li><li>这样做可以提升效率，但是如果我们有任何的代码改动，我们就需要重新编译。</li><li>PHP Accelerators有一样的逻辑，用户在发送相同的请求时，网站会直接运行可执行文件以提升速度</li></ul><h3 id="caching-2"><a class="markdownIt-Anchor" href="#caching-2"></a> Caching</h3><ul><li>.html</li><li>Caching就是一种将你经常访问的数据提前保存到你的电脑上以便下次快速显示的技术。对于PHP来说，HTML网页是自动生成的，意味着每次用户访问时PHP都会重新生成一个新的重复的HTML文件。</li><li>如果我们将所有的HTML网页都事先编译好储存在服务器上，用户访问时就可以快速拿到这些静态网页，因为不需要每次都进行编译。这就是一种Caching</li><li>这样做的坏处是，当你需要更改整个网站的风格时，你就需要更改所有的HTML文件。</li><li>MySQL Query Cache：MySQL会将一些query的结果caching，第一次运行时如果你的table很大，或者你要找的column没有index，他会运行一段时间，但是下次你就会更快的看到结果</li><li>memcached</li><li>memory cache， 内存的读写要比硬盘快很多，所以我们如果有一百万个用户，服务器SQL拿到一个用户数据可能会需要很长时间，我们可以将这个用户数据保存在memory里面，下次就可以快速得到</li><li>下面是PHP将用户数据保存到memcache的代码</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$memcache &#x3D; memchache_connect(HOST, PORT);</span><br><span class="line">$user &#x3D; memcache_get($memcache, $id);</span><br><span class="line">&#x2F;&#x2F; 如果内存里面没有这个用户的id，我们就从数据库中拿取，之后把他添加到内存中</span><br><span class="line">if (is_null($user))</span><br><span class="line">&#123;</span><br><span class="line">    $bdh &#x3D; new PDO(DSN, USER, PASS;</span><br><span class="line">    $result &#x3D; $dbh-&gt;query(&quot;SELECT * FROM users WHERE id &#x3D; $id&quot;);</span><br><span class="line">    $user &#x3D; $result-&gt;fetch(PDO:FETCH_ASSOC); &#x2F;&#x2F; this is to get the associated array of data(username, email address,...)</span><br><span class="line">    memcache_set($memcache, $user[&#39;id&#39;], $user)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>如果我们一直将数据添加到内存中，内存总有一天会不够用，这时我们就需要删除一些数据来释放空间，我们可以删除最早的数据（LRU， Least Recent Used）或者最少用到的数据(LFU, Least Frequent Used)</li></ul><h3 id="data-replication-master-slave"><a class="markdownIt-Anchor" href="#data-replication-master-slave"></a> Data Replication: Master: slave</h3><ul><li>主从关系的服务器复制，所有的附属服务器要从主服务器中拿取数据，要将新数据写入主服务器，一切以主服务器为准，优点在于当主服务器down机时，我们可以自动化一个过程：因为所有服务器的数据都是一样的，我们可以将一个附属服务器晋升为新的主服务器。以保证服务不间断</li><li>适用于读多于写的网站，所有的读取都去附属服务器，所有的写入都去主服务器</li><li>缺点是当主服务器down机时，写入会短暂失效一段时间直到其中一个附属服务器成为新的主服务器</li></ul><h3>Data Replication: Master: Master</h3>- 当其中一个主服务器失效时，我们还有另外一个，从而保证不会有服务间断的时间.同样，读取请求发送到附属服务器，写入发送到主服务器<p><img src="/../images/Harvard-CS75-Web-Development/14.png" alt="" /></p><ul><li>上面的图片还是有一个缺点，就是如果load balancer失效了，整个服务还是会断开。所以我们需要有两个相同作用的load balancer</li><li>Load Balancer: active: active</li><li>每个load balancer都负责分配任务，并且他们会不断的每个一段时间向另一个load balancer发送一个heart beat，以证明自己的存在。如果任何一个load balancer没有收到另一个的心跳，他就将负责所有的流量</li><li>Load Balancer: active: passive</li><li>与之前相似，只不过一开始只有一个load balancer负责所有的流量，并且向passive的load balancer发送心跳，如果passive load balancer没有接收到心跳，他就把自己提升为active load balancer，并开始负责所有的任务。</li></ul><h3 id="partitioning"><a class="markdownIt-Anchor" href="#partitioning"></a> Partitioning</h3><p><img src="/../images/Harvard-CS75-Web-Development/15.png" alt="" /></p><ul><li>将整个服务系统复制，供多个不同的客户使用，Facebook早期将不同学校的用户分到不同的服务器中，<a href="http://xn--harvard-lr4kp4co76w.facebook.com">类似于harvard.facebook.com</a>, <a href="http://MIT.facebook.com">MIT.facebook.com</a>,以此来降低流量的压力。这样的话当你想联系不同大学的人时，就会有些困难。另外一个例子是我们可以将用户分配到不同的服务器中based on他们的名字，A-M到第一个，N-Z到第二个</li></ul><h3 id="high-availiability"><a class="markdownIt-Anchor" href="#high-availiability"></a> High Availiability</h3><p><img src="/../images/Harvard-CS75-Web-Development/16.png" alt="" /></p><ul><li>不同的服务器之间互相听取对方的心跳，并随时准备take over当另外的服务器offline</li><li>网络层和web server层之间需要load balancer web server层和DB层之间也需要load balancer，load balancer会将第一个返回的DB的信息加到Cookie中返回给用户，这样用户在Cookie过期之前都会被route到同一个服务器, 这样就保证用户不会被分配到另一个服务器里面却没有他最新的数据，服务器之间也会相互同步。 每一层之间的load balancer也需要多个以保证一个offlice不会影响全局。可以使用active active或者active passive， DB也需要多个，可以是Master Master或者Master Slave. 最后就是这样的一个Data center也需要多个，就像AWS一样在US， Aisa， Europe都会有服务器。</li></ul><h3 id="security"><a class="markdownIt-Anchor" href="#security"></a> Security</h3><ul><li>什么样的traffic可以进入data center？TCP 80和443</li><li>什么样的traffic可以从load balancer到web server？TCP 80. 我们可以在load balancer中加入证书并解密所有的traffic，然后之后的所有traffic都保持不加密的状态，因为我们已经进入到data center，不需要在担心安全问题，所以让load balancer去做揭秘这样的繁重工作，web server只负责应付无秘traffic</li><li>什么样的traffic从web server到DB？一般的SQL queries 也是 TCP 3306（port number 3306 is the default number SQL query uses）</li><li>注意web server之间并不能交流。</li><li>我们之所以设置这些规则，只让这些port的traffic进入，是因为加如其中一个web server被攻占了，那么它也只能向DB发送SQL请求，不能向其他web server发送443或者80请求，将破坏控制在最小。</li></ul><h3 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h3><ul><li><a href="https://www.youtube.com/watch?v=-W9F__D3oY4">S75 (Summer 2012) Lecture 9 Scalability Harvard Web Development David Malan</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Web Development </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Data Structures Advanced</title>
      <link href="2020/05/10/Data-Structures-Advanced/"/>
      <url>2020/05/10/Data-Structures-Advanced/</url>
      
        <content type="html"><![CDATA[<h2 id="sliding-window"><a class="markdownIt-Anchor" href="#sliding-window"></a> sliding window</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;通过两层for循环改进算法</span><br><span class="line">for (i &#x3D; 0, i &lt; n; ++i) &#123;</span><br><span class="line">    while (j &lt; n) &#123;</span><br><span class="line">        if (满足条件) &#123;</span><br><span class="line">            j++;</span><br><span class="line">            更新j状态</span><br><span class="line">        &#125; else if (不满足条件) &#123;</span><br><span class="line">            break;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    &#x2F;&#x2F;更新i状态</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>在一维字符串或者数组中找到符合条件的字串</li><li>前向型指针题目</li><li>窗口类</li><li>remove nth node from end of list</li><li>Minimum size subarray sum</li><li>Longest substring without rapeating characters</li><li>Minimum window substring</li><li>Longest Substring with at most k distinct characters</li><li>Longest Repeating Character Replacement</li><li>Longest Turbulent subarray</li><li>快慢类</li><li>find the middle of the linked list</li><li>linked list cycle 1 and 2</li><li>优化类型</li></ul><ol><li>优化思想通过两层for循环而来</li><li>外层指针依然是一次遍历</li><li>内层指针证明是否需要退回</li></ol><ul><li>two pointers题型分类</li></ul><ol><li>前向型<ol><li>窗口型</li><li>快慢型</li></ol></li><li>相向型</li><li>两个数组</li></ol><ul><li>第k大或者第k小问题</li></ul><h2 id="union-find-并查集"><a class="markdownIt-Anchor" href="#union-find-并查集"></a> Union Find 并查集</h2><ul><li>一种用来解决集合查询合并的数据结构 支持O(1) find and O(1) union，O(n) space</li></ul><ol><li>检查两个元素是否属于同一集合</li><li>合并两个集合，将root node指向另一个root node</li></ol><ul><li>可以使用array或者哈希表实现Union find</li><li>查找 find O(n) time</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public int find(int x) &#123;</span><br><span class="line">    if (father[x] &#x3D;&#x3D; x) &#123;</span><br><span class="line">    return x;</span><br><span class="line">    &#125;</span><br><span class="line">    return find(father[x]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>合并 union, O(n) time, 之合并两个root nodes，不管child nodes</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public void union(int a, int b) &#123;</span><br><span class="line">    int root_a &#x3D; find(a);</span><br><span class="line">    int root_b &#x3D; find(b);</span><br><span class="line">    &#x2F;&#x2F; 如果两个root nodes已经相等，则两个集合已经合并，不需要再操作</span><br><span class="line">    if (root_a !&#x3D; root_b) &#123;</span><br><span class="line">    father[root_a] &#x3D; root_b; &#x2F;&#x2F; 将root_a指向root_b</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>路径压缩：将find和union的时间复杂度变成O(1)</li><li>在查找元素的father的时候，第一次需要O(n)的时间，但是当找到最终的father时，将每一个路径中的father都更新成最终的father，以后在查找路径中的father就只需要O(1)</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public int find(int x) &#123;</span><br><span class="line">    if (father[x] &#x3D;&#x3D; x) &#123;</span><br><span class="line">        return x;</span><br><span class="line">    &#125;</span><br><span class="line">    return father[x] &#x3D; find(father[x]); &#x2F;&#x2F; 将当前点的father更新为最终father</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>Connecting graph 3</li><li>Connecting cities with minimum costs</li><li>Number of Operations to Make Network Connected</li><li>The Earliest Moment When Everyone Become Friends</li><li>Lexicographically Smallest Equivalent String</li><li>Number of Islands II</li></ol><ul><li>Union find问题总结</li><li>原生操作<ol><li>查询两个元素是否在用一个集合内。</li><li>合并两个元素所在的集合</li></ol></li><li>派生操作<ol><li>查询某个元素所在集合的元素个数。</li><li>查询当前集合的个数</li></ol></li></ul><h2 id="trie"><a class="markdownIt-Anchor" href="#trie"></a> Trie</h2><ul><li>常见考点</li><li><ol><li>Trie直接实现</li></ol></li><li><ol start="2"><li>利用Trie前缀特性解题</li></ol></li><li><ol start="3"><li>矩阵类里面，字符串一个一个字符，深度优先遍历的问题</li></ol></li><li>Trie和Hash拥有相同的时间复杂度，但是Trie的空间复杂度更小</li></ul><ol><li>Implement Trie</li><li>Add and search word</li><li>word search 2 -&gt; Trie + DFS</li></ol><h2 id="heap"><a class="markdownIt-Anchor" href="#heap"></a> Heap</h2><ul><li>Trapping rain water 2</li><li>怎么通过Trapping rain water 1拓展到这道题的思路</li><li>怎么样想到利用heap？</li><li>怎么想到由外向内遍历？</li><li>Find Median from Data Stream</li><li>Sliding Window Median</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Data Structures </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Think Python</title>
      <link href="2020/04/03/Think-Python/"/>
      <url>2020/04/03/Think-Python/</url>
      
        <content type="html"><![CDATA[<ol><li><a href="#chapter-1-the-first-program">Chapter 1: The First Program</a></li><li><a href="#chapter-2-variables-expressions-and-statements">Chapter 2: Variables, expressions and statements</a></li><li><a href="#chapter-3-functions">Chapter 3: Functions</a></li><li><a href="#chapter-4-conditionals-and-recursion">Chapter 4: Conditionals and recursion</a></li><li><a href="#chapter-5-fruitful-functions">Chapter 5: Fruitful functions</a></li><li><a href="#chapter-6-iteration">Chapter 6: Iteration</a></li><li><a href="#chapter-7-strings">Chapter 7: Strings</a></li><li><a href="#chapter-8-lists">Chapter 8: Lists</a></li><li><a href="#chapter-9-dictionaries">Chapter 9: Dictionaries</a></li><li><a href="#chapter-10-tuples">Chapter 10: Tuples</a></li></ol><h2 id="chapter-1-the-first-program"><a class="markdownIt-Anchor" href="#chapter-1-the-first-program"></a> Chapter 1: The First Program</h2><h3 id="python-interpreter"><a class="markdownIt-Anchor" href="#python-interpreter"></a> Python interpreter</h3><ul><li>Type python in the command line to start interpreter</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Python 3.4.0 (default, Jun 19 2015, 14:20:21)</span><br><span class="line">[GCC 4.8.2] on linux</span><br><span class="line">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure><ul><li>The first three lines contain information about the interpreter and the operating system it’s<br />running on, so it might be different for you. But you should check that the version number,<br />which is 3.4.0 in this example, begins with 3, which indicates that you are running Python 3. If it begins with 2, you are running (you guessed it) Python 2.<br />The last line is a prompt that indicates that the interpreter is ready for you to enter pre. If<br />you type a line of pre and hit Enter, the interpreter displays the result:</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; 1 + 1</span><br><span class="line">2</span><br></pre></td></tr></table></figure><h3 id="basic-arthmetic"><a class="markdownIt-Anchor" href="#basic-arthmetic"></a> Basic Arthmetic</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; 40 + 2</span><br><span class="line">42</span><br><span class="line">&gt;&gt;&gt; 43 - 1</span><br><span class="line">42</span><br><span class="line">&gt;&gt;&gt; 6 * 7</span><br><span class="line">42</span><br></pre></td></tr></table></figure><ul><li>The operator / performs division:</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; 84 &#x2F; 2</span><br><span class="line">42.0</span><br></pre></td></tr></table></figure><ul><li>You might wonder why the result is 42.0 instead of 42. I’ll explain in the next section. Finally, the operator ** performs exponentiation; that is, it raises a number to a power:</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; 6**2 + 6</span><br><span class="line">42</span><br></pre></td></tr></table></figure><ul><li>In some other languages, ^ is used for exponentiation, but in Python it is a bitwise operator called XOR. If you are not familiar with bitwise operators, the result will surprise you:</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; 6 ^ 2</span><br><span class="line">4</span><br></pre></td></tr></table></figure><h3 id="values-and-types"><a class="markdownIt-Anchor" href="#values-and-types"></a> Values and Types</h3><ul><li>If you are not sure what type a value has, the interpreter can tell you:</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; type(2)</span><br><span class="line">&lt; class &#39;int&#39;&gt;</span><br><span class="line">&gt;&gt;&gt; type(42.0)</span><br><span class="line">&lt; class &#39;float&#39;&gt;</span><br><span class="line">&gt;&gt;&gt; type(&#39;Hello, World!&#39;)</span><br><span class="line">&lt; class &#39;str&#39;&gt;</span><br></pre></td></tr></table></figure><h2 id="chapter-2-variables-expressions-and-statements"><a class="markdownIt-Anchor" href="#chapter-2-variables-expressions-and-statements"></a> Chapter 2: Variables, Expressions and Statements</h2><h3 id="statement"><a class="markdownIt-Anchor" href="#statement"></a> Statement</h3><ul><li>An assignment statement creates a new variable and gives it a value:</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; message &#x3D; &#39;And now for something completely different&#39;</span><br><span class="line">&gt;&gt;&gt; n &#x3D; 17</span><br><span class="line">&gt;&gt;&gt; pi &#x3D; 3.1415926535897932</span><br></pre></td></tr></table></figure><h3 id="expressions"><a class="markdownIt-Anchor" href="#expressions"></a> Expressions</h3><ul><li>An expression is a combination of values, variables, and operators. A value all by itself is considered an expression, and so is a variable, so the following are all legal expressions:</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; 42</span><br><span class="line">42</span><br><span class="line">&gt;&gt;&gt; n</span><br><span class="line">17</span><br><span class="line">&gt;&gt;&gt; n + 25</span><br><span class="line">42</span><br></pre></td></tr></table></figure><ul><li>When you type an expression at the prompt, the interpreter evaluates it, which means that it finds the value of the expression. In this example, n has the value 17 and n + 25 has the value 42. A statement is a unit of pre that has an effect, like creating a variable or displaying a value.</li></ul><h3 id="order-of-operations"><a class="markdownIt-Anchor" href="#order-of-operations"></a> Order of operations</h3><ul><li><p>Parentheses have the highest precedence and can be used to force an expression to evaluate in the order you want. Since expressions in parentheses are evaluated first, 2 * (3-1) is 4, and (1+1)**(5-2) is 8. You can also use parentheses to make an expression easier to read, as in (minute * 100) / 60, even if it doesn’t change the result.</p></li><li><p>Exponentiation has the next highest precedence, so <code>1 + 2**3</code> is 9, not 27, and <code>2 * 3**2</code> is 18, not 36.</p></li><li><p>Multiplication and Division have higher precedence than Addition and Subtraction. So 2*3-1 is 5, not 4, and 6+4/2 is 8, not 5.</p></li><li><p>Operators with the same precedence are evaluated from left to right (except exponentiation). So in the expression degrees / 2 * pi, the division happens first and the result is multiplied by pi. To divide by 2π, you can use parentheses or write degrees / 2 / pi.</p></li></ul><h3 id="comments"><a class="markdownIt-Anchor" href="#comments"></a> Comments</h3><ul><li>comments, and they start with the # symbol. “”“fdsfsdfsd”&quot;&quot; for multiple lines of comments</li></ul><h2 id="chapter-3-functions"><a class="markdownIt-Anchor" href="#chapter-3-functions"></a> Chapter 3: Functions</h2><ul><li><p>In the context of programming, a function is a named sequence of statements that performs a computation. When you define a function, you specify the name and the sequence of statements. Later, you can “call” the function by name.</p></li><li><p>It is common to say that a function “takes” an argument and “returns” a result. The result is also called the return value.</p></li><li><p>Python has a math module that provides most of the familiar mathematical functions. A module is a file that contains a collection of related functions. Before we can use the functions in a module, we have to import it with an import statement:</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;&gt; import math</span><br></pre></td></tr></table></figure><h3 id="adding-new-functions"><a class="markdownIt-Anchor" href="#adding-new-functions"></a> Adding new functions</h3><ul><li>So far, we have only been using the functions that come with Python, but it is also possible to add new functions. A function definition specifies the name of a new function and the sequence of statements that run when the function is called.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def print_lyrics():</span><br><span class="line">    print(&quot;I&#39;m a lumberjack, and I&#39;m okay.&quot;)</span><br><span class="line">    print(&quot;I sleep all night and I work all day.&quot;)</span><br></pre></td></tr></table></figure><ul><li><p>The first line of the function definition is called the header; the rest is called the body. The header has to end with a colon and the body has to be indented. By convention, indentation is always four spaces. The body can contain any number of statements.</p></li><li><p>A function can be inside another function</p></li></ul><h3 id="parameters-and-arguments"><a class="markdownIt-Anchor" href="#parameters-and-arguments"></a> Parameters and arguments</h3><ul><li><p>Some of the functions we have seen require arguments. For example, when you call math.sin you pass a number as an argument. Some functions take more than one argument: math.pow takes two, the base and the exponent</p></li><li><p>When you create a variable inside a function, it is local, which means that it only exists inside the function</p></li></ul><h3 id="encapsulation"><a class="markdownIt-Anchor" href="#encapsulation"></a> Encapsulation</h3><ul><li>Wrapping a piece of pre up in a function is called encapsulation. One of the benefits of encapsulation is that it attaches a name to the pre, which serves as a kind of documentation. Another advantage is that if you re-use the pre, it is more concise to call a function twice than to copy and paste the body!</li></ul><h2 id="chapter-4-conditionals-and-recursion"><a class="markdownIt-Anchor" href="#chapter-4-conditionals-and-recursion"></a> Chapter 4: Conditionals and recursion</h2><h3 id="floor-divisions-and-modulus"><a class="markdownIt-Anchor" href="#floor-divisions-and-modulus"></a> Floor divisions and modulus</h3><ul><li>The floor division operator, //, divides two numbers and rounds down to an integer</li><li>e the modulus operator, %, which divides two numbers and returns the remainder</li></ul><h3 id="boolean-expressions"><a class="markdownIt-Anchor" href="#boolean-expressions"></a> Boolean expressions</h3><ul><li>A boolean expression is an expression that is either true or false. The following examples use the operator ==, which compares two operands and produces True if they are equal and False otherwise:</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; 5 &#x3D;&#x3D; 5</span><br><span class="line">True</span><br><span class="line">&gt;&gt;&gt; 5 &#x3D;&#x3D; 6</span><br><span class="line">False</span><br></pre></td></tr></table></figure><h3 id="logical-operators"><a class="markdownIt-Anchor" href="#logical-operators"></a> Logical operators</h3><ul><li>AND</li><li>OR</li><li>NOT</li></ul><h3 id="conditional-execution"><a class="markdownIt-Anchor" href="#conditional-execution"></a> Conditional execution</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if x % 2 &#x3D;&#x3D; 0:</span><br><span class="line">    print(&#39;x is even&#39;)</span><br><span class="line">else:</span><br><span class="line">    print(&#39;x is odd&#39;)</span><br></pre></td></tr></table></figure><h3 id="chained-conditions"><a class="markdownIt-Anchor" href="#chained-conditions"></a> Chained conditions</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">if x &lt; y:</span><br><span class="line">    print(&#39;x is less than y&#39;)</span><br><span class="line">elif x &gt; y:</span><br><span class="line">    print(&#39;x is greater than y&#39;)</span><br><span class="line">else:</span><br><span class="line">    print(&#39;x and y are equal&#39;)</span><br></pre></td></tr></table></figure><h3 id="recursion"><a class="markdownIt-Anchor" href="#recursion"></a> Recursion</h3><ul><li>It is legal for one function to call another; it is also legal for a function to call itself.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def countdown(n):</span><br><span class="line">    if n &lt;&#x3D; 0:</span><br><span class="line">        print(&#39;Blastoff!&#39;)</span><br><span class="line">    else:</span><br><span class="line">        print(n)</span><br><span class="line">        countdown(n-1)</span><br></pre></td></tr></table></figure><h3 id="keyboard-input"><a class="markdownIt-Anchor" href="#keyboard-input"></a> Keyboard input</h3><ul><li>Python provides a built-in function called input that stops the program and waits for the user to type something. When the user presses Return or Enter, the program resumes and input returns what the user typed as a string</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; text &#x3D; input()</span><br><span class="line">What are you waiting for?</span><br><span class="line">&gt;&gt;&gt; text</span><br><span class="line">&#39;What are you waiting for?&#39;</span><br></pre></td></tr></table></figure><h2 id="chapter-5-fruitful-functions"><a class="markdownIt-Anchor" href="#chapter-5-fruitful-functions"></a> Chapter 5: Fruitful functions</h2><ul><li>Functions that return a value</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def absolute_value(x):</span><br><span class="line">    if x &lt; 0:</span><br><span class="line">        return -x</span><br><span class="line">    else:</span><br><span class="line">        return x</span><br></pre></td></tr></table></figure><h3 id="incremental-development"><a class="markdownIt-Anchor" href="#incremental-development"></a> Incremental development</h3><ul><li>Start with a working program and make small incremental changes. At any point, if there is an error, you should have a good idea where it is.</li></ul><h2 id="chapter-6-iteration"><a class="markdownIt-Anchor" href="#chapter-6-iteration"></a> Chapter 6: Iteration</h2><ul><li>The ability to run a block of statements repeatedly</li></ul><h3 id="the-while-statement"><a class="markdownIt-Anchor" href="#the-while-statement"></a> The while statement</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def countdown(n):</span><br><span class="line">    while n &gt; 0:</span><br><span class="line">        print(n)</span><br><span class="line">        n &#x3D; n - 1</span><br><span class="line">    print(&#39;Blastoff!&#39;)</span><br></pre></td></tr></table></figure><ol><li>Determine whether the condition is true or false.</li><li>If false, exit the while statement and continue execution at the next statement.</li><li>If the condition is true, run the body and then go back to step 1.</li></ol><h3 id="break"><a class="markdownIt-Anchor" href="#break"></a> Break</h3><ul><li>Sometimes you don’t know it’s time to end a loop until you get half way through the body. In that case you can use the break statement to jump out of the loop</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">while True:</span><br><span class="line">    line &#x3D; input(&#39;&gt; &#39;)</span><br><span class="line">    if line &#x3D;&#x3D; &#39;done&#39;:</span><br><span class="line">        break</span><br><span class="line">    print(line)</span><br><span class="line">print(&#39;Done!&#39;)</span><br></pre></td></tr></table></figure><h2 id="chapter-7-strings"><a class="markdownIt-Anchor" href="#chapter-7-strings"></a> Chapter 7: Strings</h2><ul><li>Strings are not like integers, floats, and booleans. A string is a sequence of characters, which means it is an ordered collection of other values. In this chapter you’ll see how to access the characters that make up a string, and you’ll learn about some of the methods strings provide</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; fruit &#x3D; &#39;banana&#39;</span><br><span class="line">&gt;&gt;&gt; letter &#x3D; fruit[1]</span><br><span class="line">&gt;&gt;&gt; letter</span><br><span class="line">&#39;a&#39;</span><br><span class="line">&gt;&gt;&gt; len(fruit)</span><br><span class="line">6</span><br></pre></td></tr></table></figure><h3 id="traversal-with-a-for-loop"><a class="markdownIt-Anchor" href="#traversal-with-a-for-loop"></a> Traversal with a for loop</h3><ul><li>A lot of computations involve processing a string one character at a time. Often they start at the beginning, select each character in turn, do something to it, and continue until the end. This pattern of processing is called a traversal. One way to write a traversal is with a while loop:</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">index &#x3D; 0</span><br><span class="line">while index &lt; len(fruit):</span><br><span class="line">    letter &#x3D; fruit[index]</span><br><span class="line">    print(letter)</span><br><span class="line">    index &#x3D; index + 1</span><br></pre></td></tr></table></figure><ul><li>another way to traverse is to use a for loop</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for letter in fruit:</span><br><span class="line">    print(letter)</span><br></pre></td></tr></table></figure><h3 id="strings-slices"><a class="markdownIt-Anchor" href="#strings-slices"></a> Strings slices</h3><ul><li>A segment of a string is called a slice. Selecting a slice is similar to selecting a character:</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; s &#x3D; &#39;Monty Python&#39;</span><br><span class="line">&gt;&gt;&gt; s[0:5]</span><br><span class="line">&#39;Monty&#39;</span><br><span class="line">&gt;&gt;&gt; s[6:12]</span><br><span class="line">&#39;Python&#39;</span><br></pre></td></tr></table></figure><ul><li><p>The operator [n:m] returns the part of the string from the “n-eth” character to the “m-eth” character, including the first but excluding the last</p></li><li><p>If you omit the first index (before the colon), the slice starts at the beginning of the string. If you omit the second index, the slice goes to the end of the string:</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; fruit &#x3D; &#39;banana&#39;</span><br><span class="line">&gt;&gt;&gt; fruit[:3]</span><br><span class="line">&#39;ban&#39;</span><br><span class="line">&gt;&gt;&gt; fruit[3:]</span><br><span class="line">&#39;ana&#39;</span><br><span class="line">&gt;&gt;&gt; fruit &#x3D; &#39;banana&#39;</span><br><span class="line">&gt;&gt;&gt; fruit[3:3]</span><br><span class="line">&#39;&#39;</span><br></pre></td></tr></table></figure><h3 id="strings-are-immutable"><a class="markdownIt-Anchor" href="#strings-are-immutable"></a> Strings are immutable</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; greeting &#x3D; &#39;Hello, world!&#39;</span><br><span class="line">&gt;&gt;&gt; greeting[0] &#x3D; &#39;J&#39;</span><br><span class="line">TypeError: &#39;str&#39; object does not support item assignment</span><br></pre></td></tr></table></figure><h3 id="the-in-operator"><a class="markdownIt-Anchor" href="#the-in-operator"></a> The in operator</h3><ul><li>The word in is a boolean operator that takes two strings and returns True if the first appears as a substring in the second:</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; &#39;a&#39; in &#39;banana&#39;</span><br><span class="line">True</span><br><span class="line">&gt;&gt;&gt; &#39;seed&#39; in &#39;banana&#39;</span><br><span class="line">False</span><br></pre></td></tr></table></figure><h3 id="string-comparison"><a class="markdownIt-Anchor" href="#string-comparison"></a> String comparison</h3><ul><li>Upper case letters come before lower case letters, we can use &gt; or &lt; or == to compare strings</li></ul><h2 id="chapter-8-lists"><a class="markdownIt-Anchor" href="#chapter-8-lists"></a> Chapter 8: Lists</h2><h3 id="list-is-a-sequence"><a class="markdownIt-Anchor" href="#list-is-a-sequence"></a> List is a sequence</h3><ul><li><p>Like a string, a list is a sequence of values. In a string, the values are characters; in a list, they can be any type. The values in a list are called elements or sometimes items.</p></li><li><p>There are several ways to create a new list; the simplest is to enclose the elements in square brackets ([ and ]):</p></li><li><p>The elements of a list don’t have to be the same type.</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; cheeses &#x3D; [&#39;Cheddar&#39;, &#39;Edam&#39;, &#39;Gouda&#39;]</span><br><span class="line">&gt;&gt;&gt; numbers &#x3D; [42, 123]</span><br><span class="line">&gt;&gt;&gt; empty &#x3D; []</span><br><span class="line">&gt;&gt;&gt; print(cheeses, numbers, empty)</span><br><span class="line">[&#39;Cheddar&#39;, &#39;Edam&#39;, &#39;Gouda&#39;] [42, 123] []</span><br></pre></td></tr></table></figure><h3 id="lists-are-mutable"><a class="markdownIt-Anchor" href="#lists-are-mutable"></a> Lists are mutable</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; numbers &#x3D; [42, 123]</span><br><span class="line">&gt;&gt;&gt; numbers[1] &#x3D; 5</span><br><span class="line">&gt;&gt;&gt; numbers</span><br><span class="line">[42, 5]</span><br></pre></td></tr></table></figure><h3 id="traversing-a-list"><a class="markdownIt-Anchor" href="#traversing-a-list"></a> Traversing a list</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for i in range(len(numbers)):</span><br><span class="line">    numbers[i] &#x3D; numbers[i] * 2</span><br></pre></td></tr></table></figure><h3 id="list-operations"><a class="markdownIt-Anchor" href="#list-operations"></a> List operations</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a &#x3D; [1, 2, 3]</span><br><span class="line">&gt;&gt;&gt; b &#x3D; [4, 5, 6]</span><br><span class="line">&gt;&gt;&gt; c &#x3D; a + b</span><br><span class="line">&gt;&gt;&gt; c</span><br><span class="line">[1, 2, 3, 4, 5, 6]</span><br><span class="line">&gt;&gt;&gt; [0] * 4</span><br><span class="line">[0, 0, 0, 0]</span><br><span class="line">&gt;&gt;&gt; [1, 2, 3] * 3</span><br><span class="line">[1, 2, 3, 1, 2, 3, 1, 2, 3]</span><br></pre></td></tr></table></figure><h3 id="list-slices"><a class="markdownIt-Anchor" href="#list-slices"></a> List slices</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; t &#x3D; [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;]</span><br><span class="line">&gt;&gt;&gt; t[1:3]</span><br><span class="line">[&#39;b&#39;, &#39;c&#39;]</span><br><span class="line">&gt;&gt;&gt; t[:4]</span><br><span class="line">[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;]</span><br><span class="line">&gt;&gt;&gt; t[3:]</span><br><span class="line">[&#39;d&#39;, &#39;e&#39;, &#39;f&#39;]</span><br></pre></td></tr></table></figure><h3 id="list-methods"><a class="markdownIt-Anchor" href="#list-methods"></a> List methods</h3><ul><li>append adds a new element to the end of a list:</li><li>extend takes a list as an argument and appends all of the elements:</li><li>sort arranges the elements of the list from low to high:</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; t &#x3D; [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]</span><br><span class="line">&gt;&gt;&gt; t.append(&#39;d&#39;)</span><br><span class="line">&gt;&gt;&gt; t</span><br><span class="line">[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;]</span><br><span class="line">&gt;&gt;&gt; t1 &#x3D; [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]</span><br><span class="line">&gt;&gt;&gt; t2 &#x3D; [&#39;d&#39;, &#39;e&#39;]</span><br><span class="line">&gt;&gt;&gt; t1.extend(t2)</span><br><span class="line">&gt;&gt;&gt; t1</span><br><span class="line">[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;]</span><br><span class="line">&gt;&gt;&gt; t &#x3D; [&#39;d&#39;, &#39;c&#39;, &#39;e&#39;, &#39;b&#39;, &#39;a&#39;]</span><br><span class="line">&gt;&gt;&gt; t.sort()</span><br><span class="line">&gt;&gt;&gt; t</span><br><span class="line">[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;]</span><br></pre></td></tr></table></figure><h3 id="deleting-elements"><a class="markdownIt-Anchor" href="#deleting-elements"></a> Deleting elements</h3><ul><li>If you know the index of the element you want, you can use pop:</li><li>pop modifies the list and returns the element that was removed. If you don’t provide an index, it deletes and returns the last element.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; t &#x3D; [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]</span><br><span class="line">&gt;&gt;&gt; x &#x3D; t.pop(1)</span><br><span class="line">&gt;&gt;&gt; t</span><br><span class="line">[&#39;a&#39;, &#39;c&#39;]</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line">&#39;b&#39;</span><br></pre></td></tr></table></figure><ul><li>If you don’t need the removed value, you can use the del operator:</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; t &#x3D; [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]</span><br><span class="line">&gt;&gt;&gt; del t[1]</span><br><span class="line">&gt;&gt;&gt; t</span><br><span class="line">[&#39;a&#39;, &#39;c&#39;]</span><br></pre></td></tr></table></figure><ul><li>If you know the element you want to remove (but not the index), you can use remove:</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; t &#x3D; [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]</span><br><span class="line">&gt;&gt;&gt; t.remove(&#39;b&#39;)</span><br><span class="line">&gt;&gt;&gt; t</span><br><span class="line">[&#39;a&#39;, &#39;c&#39;]</span><br></pre></td></tr></table></figure><h3 id="objects-and-values"><a class="markdownIt-Anchor" href="#objects-and-values"></a> Objects and values</h3><ul><li>In one case, a and b refer to two different objects that have the same value. In the second case, they refer to the same object.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a &#x3D; &quot;word1&quot;</span><br><span class="line">&gt;&gt;&gt; b &#x3D; &quot;word1&quot;</span><br><span class="line">&gt;&gt;&gt; a is b</span><br><span class="line">True</span><br><span class="line">&gt;&gt;&gt; a &#x3D; [1,2,3]</span><br><span class="line">&gt;&gt;&gt; b &#x3D; [1,2,3]</span><br><span class="line">&gt;&gt;&gt; a is b</span><br><span class="line">False</span><br><span class="line">&gt;&gt;&gt; a &#x3D;&#x3D; b</span><br><span class="line">True</span><br></pre></td></tr></table></figure><h3 id="aliasing"><a class="markdownIt-Anchor" href="#aliasing"></a> Aliasing</h3><ul><li>If a refers to an object and you assign b = a, then both variables refer to the same object, even for a list</li><li>Its also called shallow copy</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a &#x3D; [1, 2, 3]</span><br><span class="line">&gt;&gt;&gt; b &#x3D; a</span><br><span class="line">&gt;&gt;&gt; b is a</span><br><span class="line">True</span><br></pre></td></tr></table></figure><ul><li>For objects that may take lots of memory space, the program will prefer to only make a reference to its original object when you create another variable to points to it.</li></ul><h3 id="list-arguments"><a class="markdownIt-Anchor" href="#list-arguments"></a> List arguments</h3><ul><li>When you pass a list to a function, the function gets a reference to the list. If the function modifies the list, the caller sees the change.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def delete_head(t):</span><br><span class="line">    del t[0]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; letters &#x3D; [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]</span><br><span class="line">&gt;&gt;&gt; delete_head(letters)</span><br><span class="line">&gt;&gt;&gt; letters</span><br><span class="line">[&#39;b&#39;, &#39;c&#39;]</span><br></pre></td></tr></table></figure><h2 id="chapter-9-dictionaries"><a class="markdownIt-Anchor" href="#chapter-9-dictionaries"></a> Chapter 9: Dictionaries</h2><ul><li><p>A dictionary contains a collection of indices, which are called keys, and a collection of values. Each key is associated with a single value. The association of a key and a value is called a key-value pair or sometimes an item</p></li><li><p>The function dict creates a new dictionary with no items. Because dict is the name of a built-in function, you should avoid using it as a variable name</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; eng2sp &#x3D; dict()</span><br><span class="line">&gt;&gt;&gt; eng2sp</span><br><span class="line">&#123;&#125;</span><br><span class="line">&gt;&gt;&gt; eng2sp[&#39;one&#39;] &#x3D; &#39;uno&#39; # add an item with key &#x3D; &#39;one&#39; and value &#x3D; &#39;uno&#39;</span><br><span class="line">&gt;&gt;&gt; eng2sp</span><br><span class="line">&#123;&#39;one&#39;: &#39;uno&#39;&#125;</span><br></pre></td></tr></table></figure><ul><li><p>The order of the key-value pairs might not be the same. If you type the same example on your computer, you might get a different result. In general, the order of items in a dictionary is unpredictable. This is because when we insert items into the dictionary, it randomly put items into buckets, so it could be different everytime. (Hash)</p></li><li><p>check whether a dictionary contains some key</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; &#39;one&#39; in eng2sp</span><br><span class="line">True</span><br><span class="line">&gt;&gt;&gt; &#39;uno&#39; in eng2sp</span><br><span class="line">False</span><br></pre></td></tr></table></figure><ul><li>check whether a dictionary contains some value</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; vals &#x3D; eng2sp.values()</span><br><span class="line">&gt;&gt;&gt; &#39;uno&#39; in vals</span><br><span class="line">True</span><br></pre></td></tr></table></figure><ul><li>Python dictionaries use a data structure called a hashtable that has a remarkable property: the in operator takes about the same amount of time no matter how many items are in the dictionary. Instant lookup time!</li></ul><h3 id="dictionary-as-a-collection-of-counters"><a class="markdownIt-Anchor" href="#dictionary-as-a-collection-of-counters"></a> Dictionary as a collection of counters</h3><ul><li>Suppose you are given a string and you want to count how many times each letter appears. There are several ways you could do it</li></ul><ol><li>You could create 26 variables, one for each letter of the alphabet. Then you could traverse the string and, for each character, increment the corresponding counter, probably using a chained conditional.</li><li>You could create a list with 26 elements. Then you could convert each character to a number (using the built-in function ord), use the number as an index into the list, and increment the appropriate counter.</li><li>You could create a dictionary with characters as keys and counters as the corresponding values. The first time you see a character, you would add an item to the dictionary. After that you would increment the value of an existing item.</li></ol><ul><li>An implementation is a way of performing a computation; some implementations are better than others. For example, an advantage of the dictionary implementation is that we don’t have to know ahead of time which letters appear in the string and we only have to make room for the letters that do appear.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">def histogram(s):</span><br><span class="line">    d &#x3D; dict()</span><br><span class="line">    for c in s:</span><br><span class="line">    if c not in d:</span><br><span class="line">        d[c] &#x3D; 1</span><br><span class="line">    else:</span><br><span class="line">        d[c] +&#x3D; 1</span><br><span class="line">    return d</span><br></pre></td></tr></table></figure><h3 id="looping-and-dictionaries"><a class="markdownIt-Anchor" href="#looping-and-dictionaries"></a> Looping and dictionaries</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def print_hist(h):</span><br><span class="line">    for c in h:</span><br><span class="line">        print(c, h[c])</span><br></pre></td></tr></table></figure><ul><li>Given a dictionary d and a key k, it is easy to find the corresponding value v = d[k]. This operation is called a lookup. But what if you have v and you want to find k? You have two problems: first, there might be more than one key that maps to the value v. Depending on the application, you might be able to pick one, or you might have to make a list that contains all of them. Second, there is no simple syntax to do a reverse lookup; you have to search</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def reverse_lookup(d, v):</span><br><span class="line">    for k in d:</span><br><span class="line">        if d[k] &#x3D;&#x3D; v:</span><br><span class="line">            return k</span><br><span class="line">    raise LookupError()</span><br></pre></td></tr></table></figure><h2 id="chapter-10-tuples"><a class="markdownIt-Anchor" href="#chapter-10-tuples"></a> Chapter 10: Tuples</h2><h3 id="tuples-are-immutable"><a class="markdownIt-Anchor" href="#tuples-are-immutable"></a> Tuples are immutable</h3><ul><li>A tuple is a sequence of values. The values can be any type, and they are indexed by integers, so in that respect tuples are a lot like lists. The important difference is that tuples are immutable.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; t &#x3D; tuple()</span><br><span class="line">&gt;&gt;&gt; t</span><br><span class="line">()</span><br></pre></td></tr></table></figure><ul><li>Most list operators also work on tuples. The bracket operator indexes an element:</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; t &#x3D; (&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;)</span><br><span class="line">&gt;&gt;&gt; t[0]</span><br><span class="line">&#39;a&#39;</span><br><span class="line">&gt;&gt;&gt; t[1:3]</span><br><span class="line">(&#39;b&#39;, &#39;c&#39;)</span><br><span class="line">&gt;&gt;&gt; t[0] &#x3D; &#39;A&#39;</span><br><span class="line">TypeError: object doesn&#39;t support item assignment</span><br></pre></td></tr></table></figure><h3 id="tuples-and-return-values"><a class="markdownIt-Anchor" href="#tuples-and-return-values"></a> Tuples and return values</h3><ul><li>Strictly speaking, a function can only return one value, but if the value is a tuple, the effect is the same as returning multiple values. For example, if you want to divide two integers and compute the quotient and remainder, it is inefficient to compute x//y and then x%y. It is better to compute them both at the same time</li><li>The built-in function divmod takes two arguments and returns a tuple of two values, the quotient and remainder. You can store the result as a tuple:</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; t &#x3D; divmod(7, 3)</span><br><span class="line">&gt;&gt;&gt; t</span><br><span class="line">(2, 1)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Data Structures</title>
      <link href="2020/03/02/Data-Structures/"/>
      <url>2020/03/02/Data-Structures/</url>
      
        <content type="html"><![CDATA[<h2 id="bianry-search"><a class="markdownIt-Anchor" href="#bianry-search"></a> Bianry Search</h2><ul><li>Use O(1) to make a T(n) problem T(n/2). So the total time complexity would be O(logn).</li><li>Ignore half of the problems in O(1) time.</li><li>First Bad Version</li><li>Search in a Big Sorted Array. Double the search number every time, then serach from n to 2n</li><li>Find Minimum in Rotated Sorted Array. Divide the array into a normal sorted array and a smaller rotated sorted array.</li><li>Search in a 2D matrix. Perform Binary Search 2 times. First find the row, then perform binary search on that row.</li><li>Search for a Range. Find the target number then perform binary search on its left and right.</li><li>Maximum Number in Mountain Sequence. Check mid number to see if it is incresing or decresing, we can return any mountain value.</li></ul><h2 id="bianry-tree-and-divide-conquer"><a class="markdownIt-Anchor" href="#bianry-tree-and-divide-conquer"></a> Bianry Tree and Divide &amp; Conquer</h2><ul><li>There are 3 ways to traverse a binary tree. Pre order, In order and post order</li><li>You need to know both resursive version and iterative version.</li><li>DFS includes pre order, in order, post order, divide &amp; conquer</li><li>Bianry tree has height from O(logn) to O(n), traverse a binary tree takes O(n) time.</li><li>In order traverse a binary search tree is an increasing order traverse.</li><li>Maximum depth of Binary tree. Resursive: Divide and conquer/ traverse</li><li>Subtree with Maximum Average</li><li>Lowest Common Ancestor: Divide &amp; Conquer, check leftsubtree and rightsubtree. See if they return A or B or null</li><li>Validate Binary Search Tree. Bottom up, return max and min return to the parent node.</li><li>Convert Binary Search Tree to Doubly Linked List. Inorder traverse it into a list and convert it.</li><li>Flattern Binary Tree to Linked List. node.right = head of left subtree, tail of left subtree = head of right subtree.</li><li>Insert and delete a node from a Binary Search Tree</li></ul><h2 id="bfs"><a class="markdownIt-Anchor" href="#bfs"></a> BFS</h2><ul><li><ol><li>make a list and put all start nodes into the list</li></ol></li><li><ol start="2"><li>traverse the list to get new nodes for the next level</li></ol></li><li><ol start="3"><li>use Queue for BFS</li></ol></li><li>Graph BFS</li><li>Social Network</li><li>六度理论 你和世界上任何一个人之间最多间隔6个人 Linkedin BFS看第几层有相同好友</li><li>树和图的区别，树是单向的，图可以是双向的（或者单项）</li><li>在遍历图中，会有环，可以用HashSet检查是否曾经访问过某个节点</li><li>树的特性，树中如果有N个点，就会有N-1条边。树中的所有点连通。用Queue和Set访问并保存所有Graph中的点</li><li>构造Graph， 可以用 Map&lt;Integer, Set&lt;Integer&gt;&gt; Graph其实就是保存着（每个点和与他相邻的点的Set）的Map</li><li>BFS on a 2D-array</li><li>Number of islands</li><li>Wall and Gates</li><li>什么时候使用BFS？</li><li><ol><li>Tree的层次遍历</li></ol></li><li><ol start="2"><li>2D-array中求连通性，灌水</li></ol></li><li><ol start="3"><li>拓扑排序</li></ol></li><li><ol start="4"><li>图的最短路径</li></ol></li></ul><h2 id="dfs"><a class="markdownIt-Anchor" href="#dfs"></a> DFS</h2><ul><li>Recursion</li><li>Combination</li><li>Permutation</li><li>Graph</li><li>Non-Recursion</li><li>什么时候使用DFS？</li><li><ol><li>找所有方案，排列，组合</li></ol></li><li><ol start="2"><li>找最优方案（最短，最长）（大部分是动态规划，也有可能是DFS）</li></ol></li><li>Questions</li><li><ol><li>Combination sum</li></ol></li><li><ol start="2"><li>Palindrome Partitioning 所有的切割问题都是组合问题</li></ol></li><li>切割abc字符串，有两个切割位 a1b2c， 可以切ab之间也可以切bc之间，把数字12放入代表切割位，所以切割的方式有</li><li>a b c [1,2]</li><li>a bc [1]</li><li>ab c [2]</li><li>abc []</li><li>以上可以看出四种切割方式可以用数字表示</li><li>所以n个字母的切割问题可以看作是n - 1个数字的组合问题</li><li>Backtracking</li><li>Permutation的去重与Combination相似，可以先定义一个boolean数组存放visited信息</li><li>N皇后</li><li>每一行和每一列都是1…n的一种排列</li><li>如何判断皇后在同一斜线上： 横坐标与纵坐标之差相等，或者横坐标与纵坐标之和相等</li><li>Word Ladder: BFS, 把ListWord转换成graph的形式，对于每个word，先找到所有可能的变换，总共有单词长度*26种，然后这些变换中存在于Wordlist中的就是他的neighbor，就可以变成标准的BFS问题</li><li>Word Ladder 2：Backtracking + BFS， 先从End往Begin做BFS找到每个单词距离End的长度，保证Backtrack时不会遍历更远的单词。再从Begin往End做backtracking</li></ul><h2 id="linked-list-and-array"><a class="markdownIt-Anchor" href="#linked-list-and-array"></a> Linked List and Array</h2><ul><li>Reverse linked list</li><li>Reverse linked list in k group</li><li>Use dummy node to save the list head</li><li>画图去理解linked list的变化</li><li>dummy node practices</li></ul><ol><li>partition-list</li><li>merge two sorted list</li><li>reverse linked list 2</li><li>swap two nodes in linked list</li><li>reorder list</li><li>rotate list</li></ol><ul><li>Copy list with random pointer -&gt; similar to clone graph</li><li>Linked List Cycle 1 and 2 -&gt; Floyd’s Tortoise and Hare</li><li>Sort List -&gt; how many sort algorithm has time complexity O(nlogn)?</li></ul><ol><li>Quick Sort, with O(1) Space Complexity</li><li>Merge Sort, with O(n) space</li><li>Heap Sort</li></ol><ul><li>Merge two sorted array</li><li>Merge small array into big array</li><li>intersection of two arrays</li><li>Median of two sorted arrays -&gt; find the (m + n) / 2th number, use O(logn)</li><li>Median</li><li>Kth largest element</li><li>Merge Sort practice</li><li>Quick Sort practice</li><li>Same integers will not remain their relative order in the old list after using quick sort. Merge sort will keep the relative order of same integers</li><li>Merge sort will first split the array into two subarray until there is only one number left in the array, then sort, then merge the two sorted array back to one array. From small array to big array</li><li>Qucik sort will first pick a pivot value, sort the entire array based on the pivot value. Then sort the two small array. From big array two small array</li><li>Note in Quick Sort, when we find a value equals to the pivot value, we don’t swap it, leave it as where it is. We need to split these values as even as possible.</li><li>Quick sort while loop condition: while (left &lt;= right). Don’t forget the equal sign</li></ul><h2 id="subarray"><a class="markdownIt-Anchor" href="#subarray"></a> Subarray</h2><ul><li>PrefixSum, HashMap to store prefixsum, then linear scan, So O(n) time and space</li><li>Maximum subarray</li><li>Minimum subarray</li><li>subarray sum equals k</li><li>number of subarray equals k</li></ul><h2 id="two-pointers"><a class="markdownIt-Anchor" href="#two-pointers"></a> Two pointers</h2><ul><li>O(n) time complexity</li><li>同向双指针</li><li>Move zeros</li><li>Remove duplicate number in array</li><li>Remove duplicate numbers in sorted array -&gt; tortise and hare cycle detection</li><li>相向双指针</li><li>valid palindrome</li><li>rotate string -&gt; three step reverse, when reverse a string, one start from begin and another start from end</li><li>recover rotated sorted array -&gt; similar to above, find the rotate point, three step reverse.</li><li>Two Sum 1-7</li><li>Two Sum 1 -&gt; 最普通的Two Sum， 可以使用HashMap，或者先排序在使用相向双指针，这样可以不是用额外空间，但是时间复杂度是O(nlogn)</li><li>Two Sum 2 - Data Structure Design -&gt; HashMap</li><li>Two Sum 3 - Array is sorted -&gt; 相向双指针</li><li>Two sum 7 - unique pairs -&gt; 找到所有符合的数对,相向双指针，当找到一对时，left++,right–,并继续。如果遇到重复比如1,1,3,4,4,每次我们移动时，移动到与之前的数不一样的数为止。注意此方法要求数组是有序的。</li><li>3Sum -&gt; 使用Two sum的结果，对于array中的每一个不等的数，检查是否有一对数的和等于它的相反数。可以使用HashMap或者two pointers，记住two pointers必须先排序数组。Two pointers的速度远快于HashMap</li><li>Valid Triangle Number -&gt; 检查有多少组三个数可以组成合法的三角形的三条边。注意我们只需要检查最小的两个数的和大于第三个数即可. 从最大的数开始loop，使用Two pointers，对于每一个符合的left and right， 所有大于left的数都是符合的，所以每当我们找到一组合法的left and right，count += （right - left）. 详情查看leetcode 611</li><li>对于求2个变量如何组合的问题，可以循环其中一个变量，然后研究另外一个变量如何变化</li><li>对于求3个变量如何组合的问题，可以循环其中一个变量，然后研究另外2个变量如何变化</li><li>对于求4个变量如何组合的问题，可以循环其中两个变量，然后研究另外2个变量如何变化</li><li>Two Sum less than k</li><li>Two Sum greater than k -&gt; same as triangle count</li><li>Two Sum closest to target -&gt; two pointers start from begin and end, keep updating diff</li><li>3 Sum closest to target -&gt; similar to above, loop one value and use two sum as a template</li><li>4 Sum</li><li>Two Sum - difference equals to target -&gt; 同向双指针。两数之差等于target，先排序，两个pointers都在开始，如果他们的差大于target，小数往后移，如果他们的差小于target，大数往后移 O(n) time complexity</li><li>Partition array</li><li>move elements &lt; k to the left and elements &gt;= k to the right, this is a smaller step in quick sort</li><li>Parition array while loop condition: while (left &lt; right). No equal sign</li><li>Letters by case</li><li>Partition array by parity</li><li>Interleaving positive and negative numbers -&gt; first count positive and negative numbers, then decide starts from positive or negative, then use two pointers in the same direction.</li></ul><h3 id="sort-colors"><a class="markdownIt-Anchor" href="#sort-colors"></a> Sort Colors</h3><ol><li><p>sort 3 colors in group, we can use partition array two times, first time split one color, next split the rest two colors.</p></li><li><p>We could also count the number of each color and modify the array to match the occurance of colors</p></li><li><p>three pointers</p></li><li><p>i pointer only moves when find ones and zeros, if it finds two, it will swap it with right. Throw two to the right</p></li><li><p>so left pointer will never find two.</p></li><li><p>so when i pointer finds zero, after swap it with left pointer, throw zero to the left, left pointer will only throw one back, so they can both move to right by 1</p></li></ol><ul><li>Sort Colors 2 (rainbow sort) -&gt; 使用多次Partition， 每次将一般的颜色分到array的左右，比如只有四种颜色，一次partition将1，2分到左边，3，4分到右边。花费O（n）的时间将T(k)的问题变成T(k/2)的问题。总共的时间复杂度为O(nlogk)</li><li>这个解法有点像Quick Sort。注意Quick sort and Rainbow sort的while loop条件均为 while(left &lt; right)。可以不用要等号</li><li>其他比较高频的排序方法：</li><li>Pancake Sort</li><li>Sleep Sort</li><li>Spaghetti Sort</li><li>Bogo Sort</li></ul><h2 id="3-step-reverse"><a class="markdownIt-Anchor" href="#3-step-reverse"></a> 3 Step Reverse</h2><ul><li>Three step reverse</li><li>Recover rotated sorted array -&gt; First use 3 step reverse then two pointer reverse.</li><li>3 step reverse</li><li>First find the rotate point</li><li>Reverse the first part(before rotate point) of the String/array</li><li>Reverse the second part(after rotate point) of the String/array</li><li>Reverse the entire String/array</li></ul><h2 id="quick-select"><a class="markdownIt-Anchor" href="#quick-select"></a> Quick Select</h2><ul><li>Quick Select 快速选择算法</li><li>思想类似于快速排序,利用O(n)的时间找到前right个大数，再看k与right的关系决定下一步recursion的范围</li><li>O(n) + O(n/2) + O(n/4) +… = O(n) time</li><li>kth largest element</li><li>Median</li><li>kth smallest element</li><li>Median of two sorted arrays</li></ul><h2 id="hash-heap"><a class="markdownIt-Anchor" href="#hash-heap"></a> Hash &amp; Heap</h2><ul><li>了解他们的原理和应用</li><li>TreeMap</li><li>队列Queue</li><li>支持操作O(1) push O(1) pop O(1) top,多做跟BFS有关的题目</li><li>栈Stack</li><li>支持操作O(1) push O(1) pop O(1) top,非递归实现DFS的主要数据结构</li><li>哈希表Hash</li><li>支持操作O(1) insert O(1) find O(1) delete, Hash table / Hash map / Hash set的区别是什么</li><li>Hash Set只存key不存value</li><li>Hash map存key和value</li><li>Hash table，多线程安全，当多个线程同时访问一个Hash table时，它可以保证数据安全，Hash Map无法做到</li><li>Hash function -&gt; 对于任意的Key，得到一个固定且无规律的介于0到capacity - 1的整数</li><li>数据结构分为连续性和离散型，array为连续性，List为离散型</li><li>一些著名的Hash算法：MD5， SHA-1， SHA-2，主要用于加密</li><li>用于算法中的Hash function很想进制转换</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">int hashfun(String key) &#123;</span><br><span class="line">    int sum &#x3D; 0;</span><br><span class="line">    for (int i &#x3D; 0; i &lt; key.length(); ++i) &#123;</span><br><span class="line">        sum &#x3D; sum * 31 + (int)(key.charAt(i));</span><br><span class="line">        sum &#x3D; sum % HASH_TABLE_SIZE;</span><br><span class="line">    &#125;</span><br><span class="line">    return sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>Magic number - 31</li><li>通过经验得出31的冲突更少（Collision）</li><li>Magic number取质数更好，如果数太大影响效率，数太小冲突太多</li><li>Closed Hashing - line sweep</li><li>当哈希表发生冲突时，把新的数据插入到下一个空的位置</li><li>寻找，不断的找下一个位置直到找到value或者找到空位为止</li><li>删除，把值删除后用一个deleted标记出来，这个位置并不为空</li><li>缺点，当我们插入和删除的次数很多时，很多位置都会被标记为deleted，寻找的效率会变低</li><li>Open Hashing</li><li>每一个位置都是一个链表，当发生冲突时加到链表的开头，这样不用每次都遍历到链表末尾，寻找时搜寻整个链表</li><li>Rehashing</li><li>当hash table size不够用了怎么办？</li><li>像ArrayList那样不断倍增</li><li>怎么定义满？当实际的存储个数达到总共空间的1/10(经验值)时，我们就需要rehash</li><li>回顾ArrayList的倍增：当ArrayList满时，把size扩大两倍，把前面的所有数复制到后一半新扩大的ArrayList中</li><li>Hash Table的倍增：如果移动之前的数，会影响到hash function，所以我们会先扩大hash table， 再把hash table中的所有值重新放到hash function算出它在新的hash table中的位置，重新插入</li><li>Rehashing很慢，所以在定义hash table的时候最好提前定义一个size，让他尽量不要rehash</li><li>在存储快的和存储慢的介质之间都会存在Cache的问题，不仅在CPU和内存之间有</li><li>使用链表储存数据的的插入顺序，使用哈希表判断将要插入的数据是否已经存在于链表中</li><li>LinkedHashMap = DoublyLinkedList + HashMap</li><li>LRU Cache -&gt; 使用HashMap + DoublyLinkedList可以解决</li><li>Heap</li><li>支持操作O(logn) add O(logn) remove O(1) MIN or MAX,求最大值或最小值只可取其一</li><li>ugly number 2</li><li>top k largest number 2 -&gt; 使用PriorityQueue只保存k个数</li><li>merge k sorted list -&gt; Add all list heads to a heap, poll the smallest head, add to ans, then add next node to heap.</li><li>注意要会写heap的comparator</li><li>Practice</li></ul><ol><li>high five</li><li>k closest points</li><li>data stream median</li><li>kth smallest number in sorted matrix</li></ol><h2 id="dynamic-programming"><a class="markdownIt-Anchor" href="#dynamic-programming"></a> Dynamic Programming</h2><ul><li>动态规划的分类</li><li>Triangle -&gt; 入门题</li><li>注意以下代码中n为三角形的高度</li><li>第一种方法 DFS Traverse, Top-down</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">void traverse(int x, int y, int sum) &#123;</span><br><span class="line">    if (x &#x3D;&#x3D; n) &#123;</span><br><span class="line">    &#x2F;&#x2F; found a whole path from top to bottom</span><br><span class="line">    if (sum &lt; best) &#123;</span><br><span class="line">        best &#x3D; sum;</span><br><span class="line">    &#125;</span><br><span class="line">    return;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    traverse(x + 1, y, sum + A[x][y]);</span><br><span class="line">    traverse(x + 1, y + 1, sum + A[x][y]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">best &#x3D; MAXINT;</span><br><span class="line">traverse(0, 0, 0);</span><br></pre></td></tr></table></figure><ul><li>每一个节点都分出来两条路径，相当于一个binary tree， 它的节点个数是2^n, 所以这个方法的时间复杂度是O(2^n)</li><li>第二种方法 DFS Divide and Conquer, bottom-up</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; return minimum path from (x, y) to bottom</span><br><span class="line">int divideConquer(int x, int y) &#123;</span><br><span class="line">    if (x &#x3D;&#x3D; n) &#123;</span><br><span class="line">    return 0;</span><br><span class="line">    &#125;</span><br><span class="line">    return A[x][y] + Math.min(</span><br><span class="line">    divideConquer(x + 1, y),</span><br><span class="line">    divideConquer(x + 1, y + 1)</span><br><span class="line">    );</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">divideConquer(0, 0);</span><br></pre></td></tr></table></figure><ul><li>与之前一样，每一个节点都分出来两条路径，相当于一个binary tree， 它的节点个数是2^n, 所以这个方法的时间复杂度是O(2^n)</li><li>DFS实际上是在枚举，把所有的方案都列出来然后看哪个更好</li><li>我们做了很多重复计算，因为实际上我们只需要计算三角形所有节点（n<sup>2个）的最短路径，DFS却计算了（2</sup>n个）节点，很多节点我们计算了很多遍。所以我们需要把每个节点的结果保存下来，下次需要的时候就不需要重新算了</li><li>第三种方法 DFS Divide and conquer + Memorization</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; return minimum path from (x, y) to bottom</span><br><span class="line">int divideConquer(int x, int y) &#123;</span><br><span class="line">    &#x2F;&#x2F; row index from 0 to n - 1</span><br><span class="line">    if (x &#x3D;&#x3D; n) return 0;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; if we already got the minimum path from (x, y) to bottom, just return it</span><br><span class="line">    if (hash[x][y] !&#x3D; Integer.MAX_VALUE) return hash[x][y]</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; set before return</span><br><span class="line">    hash[x][y] &#x3D; A[x][y] + Math.min(divideConquer(x + 1, y), divideConquer(x + 1, y + 1));</span><br><span class="line"></span><br><span class="line">    return hash[x][y]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">initialize: hash[*][*] &#x3D; Integer.MAX_VALUE;</span><br><span class="line">answer: divideConquer(0, 0);</span><br></pre></td></tr></table></figure><ul><li>在每次计算节点最小值之前，先看看之前有没有算过这个节点的结果，如果有直接从数组中拿到结果并返回，没有算过我们再递归, O(n^2) time</li><li>记忆化搜索的本质：动态规划，省去了重复计算</li><li>多重循环 vs 记忆化搜索</li><li>第四种方法 多重循环，自底向上</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">int[][] dp &#x3D; new int[row][row]; &#x2F;&#x2F; dp[i][j] 表示从i， j出发走到最后一层的最小路径长度</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 初始化，终点先有值,最后一层</span><br><span class="line">for (int i &#x3D; 0; i &lt; n; ++i) &#123;</span><br><span class="line">    dp[n - 1][i] &#x3D; triangle[n - 1][i];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 循环递推求解</span><br><span class="line">for (int i &#x3D; n - 2; i &gt;&#x3D; 0; --i) &#123;</span><br><span class="line">    for (int j &#x3D; 0; j &lt;&#x3D; i; ++j) &#123;</span><br><span class="line">    dp[i][j] &#x3D; Math.min(dp[i + 1][j], dp[i + 1][j +1]) + A[i][j]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 求结果： 起点</span><br><span class="line">return dp[0][0];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>O(n^2) time,没有递归</li><li>第五种方法 多重循环，自顶向下</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">int[][] dp &#x3D; new int[row][row];</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 初始化，起点</span><br><span class="line">dp[0][0] &#x3D; triangle[0][0];</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 初始化三角形的左边和右边</span><br><span class="line">for (int i &#x3D; 1; i &lt; row; ++i) &#123;</span><br><span class="line">    dp[i][0] &#x3D; dp[i - 1][0] + triangle[i][0]; &#x2F;&#x2F; 左边</span><br><span class="line">    dp[i][i] &#x3D; dp[i - 1][i - 1] + triangle[i][i]; &#x2F;&#x2F; 右边</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; top down</span><br><span class="line">for (int i &#x3D; 1; i &lt; row; ++i) &#123;</span><br><span class="line">    for (int j &#x3D; 1; j &lt; i; ++j) &#123;</span><br><span class="line">    dp[i][j] &#x3D; Math.min(dp[i - 1][j], dp[i - 1][j - 1]) + triangle[i][j];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Math.min(dp[row - 1][0], dp[row - 1][1], dp[row - 1][2]...);</span><br></pre></td></tr></table></figure><ul><li>这个方法中dp[x][y]表示从上到下到这个点的最短路径</li><li>O(n^2) time,没有递归,但是这个方法我们必须提前算出三角形的左边和右边，因为对于三角形的每一个结点dp[x][y]，我们在计算到他的最短路径的时候，我们需要用到它前一层的两个点dp[x-1][y]和dp[x-1][y-1].但是对于每一层的最左边和最右边的点，我们再上一层找不到再靠左边或者右边的点，所以为了避免越界，我们必须提前算出两条边的所有点。</li><li>什么情况下使用动态规划？</li><li>满足下满三个条件之一：</li></ul><ol><li>求最大值最小值</li><li>判断是否可行</li><li>统计方案个数</li></ol><ul><li>上面这三个情况极有可能需要使用动态规划</li><li>什么情况下不使用动态规划？</li></ul><ol><li>求出所有具体的方案，而不是方案的个数 -&gt; palindrome-paritioning</li><li>输入数据是一个集合而不是序列,意思是如果我们可以将数据调换位置，则很有可能不使用动态规划，动态规划需要有方向性 -&gt; longest-consecutive-sequence</li><li>暴力算法的复杂度已经是多项式级别。 动态规划擅长优化指数级别的复杂度（2^n, n!）到多项式级别的复杂度(n^2, n^3)</li></ol><h3 id="动态规划四要素"><a class="markdownIt-Anchor" href="#动态规划四要素"></a> 动态规划四要素</h3><ol><li>状态，储存小规模问题的结果</li><li>方程，状态之间怎么联系</li><li>初始化，最极限的小状态是什么，起点</li><li>答案，最终的状态是什么，终点</li></ol><h3 id="动态规划的类型按照状态分类"><a class="markdownIt-Anchor" href="#动态规划的类型按照状态分类"></a> 动态规划的类型，按照状态分类</h3><ol><li>坐标型 triangle 10%</li><li>接龙型 20%</li><li>划分型</li><li>匹配型</li><li>背包型</li><li>区间型 longest palindrome</li><li>树图型 tree matrix</li><li>博弈型 判断是否可行</li></ol><ul><li>坐标型动态规划</li><li>状态</li><li>f[x]:表示我从起点走到坐标x。。。</li><li>f[x][y]:表示我从起点走到坐标x, y…</li><li>方程：研究走到x， y这个点之前的一步</li><li>practice: minimum path sum</li><li>动态规划不应该存在循环依赖，从一个状态不会回到之前的一个状态</li><li>当我们初始化一个二维数组的动态规划时，需要初始化第0行和第0列</li><li>Unique path</li><li>Unique path 2</li><li>Climbing Stairs</li><li>Jump game</li><li>Jump game 2</li><li>接龙型动态规划</li><li>告诉你一个规则然后求最长的状态可以是多少，比如数组中求最大递增子序列</li><li>Longest increasing subsequence</li><li>Russian Doll Envelopes</li><li>Largest Divisible Subset</li><li>Frog jump</li><li>总结</li><li>动态规划的实质是记忆化搜索，避免重复计算中间结果</li><li>动态规划四要素：初始化，方程，起点，终点</li><li>什么时候使用动态规划:最优，可行，方案数（而非具体方案）</li><li>什么时候不使用：求具体方案，输入数据为集合而非序列（可调整顺序），暴力算法时间复杂度已经是O(n^2, n^3)</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Data Structures </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Single Sign On Introduction</title>
      <link href="2019/10/24/Single-Sign-On-Introduction/"/>
      <url>2019/10/24/Single-Sign-On-Introduction/</url>
      
        <content type="html"><![CDATA[<h2 id="what-is-single-sign-on"><a class="markdownIt-Anchor" href="#what-is-single-sign-on"></a> What is Single Sign On?</h2><ul><li>Single-sign-on是一个很方便的东西，现在无论什么网站都需要登陆，而记住每个网站不同的用户名和密码又非常困难，那么作为一个好的产品，从用户的角度出发，就应该想到，如果我们只需要让用户登陆一次，就可以去到同一个平台下任何其他的产品，而不需要重复登陆，那该多好。</li><li>比如说Google Chrome，当你在浏览器中登陆了，那么你再去到Youtube或者Gmail等其他Google公司的产品，你将不再需要再次登陆。这是因为Google在你登陆的时候保存了</li><li>那么，这是怎么做到的呢，在single sign on with SAML的世界中，有两个非常重要的概念，一个是IDP，identity provider，另一个是SP，service provider。我们还是拿Google来举例子，当你需要登陆Youtube时，Youtube会将你跳转到一个Google登陆界面，登陆后他会保存你的登陆信息，然后再将你跳转回Youtube，你就发现你已经登陆上了，这时你需要查看Gmail，Gmail也会将你跳转到Google登陆界面，但是界面发现因为你已经登陆了Youtube，所以你所有的登陆信息已经被保存了，不需要你再次输入，于是自动把你跳转到Gmail，你就以为你什么都没做就自动登陆了Gmail。(虽然Google可能不是用SAML来登陆的)</li></ul><p><img src="/../images/Single-Sign-On-Introduction/1.png" alt="" /></p><h2 id="什么是saml"><a class="markdownIt-Anchor" href="#什么是saml"></a> 什么是SAML?</h2><ul><li>SAML可以认为是IDP和SP之间转递用户信息的一种格式规范，为了方便接收方能够理解传递过去的信息，必须规定一种规范使接收方很容易解码信息。</li></ul><h2 id="broker"><a class="markdownIt-Anchor" href="#broker"></a> Broker</h2><ul><li>现在我们要做的是一个中间人的角色，用户所有的请求都会先到我们这里，我们会检查request header，如果我们发现这是一个GET request，我们就会直接把用户跳转到SSO的登陆界面。</li><li>如果我们发现这是一个POST request，并且成功解码了一起发过来的SAML，我们就要重新加密用户信息，并把用户跳转到相应的网页，由最终的Service provider来再次解码用户信息</li><li>如果SAML解码失败，我们也会将用户跳转到SSO登陆界面。让用户再次登陆</li><li>加密信息的方法有很多，我用的是windows自带的RijndaelManaged Class</li></ul><h3 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h3><ol><li><a href="https://docs.microsoft.com/en-us/dotnet/api/system.security.cryptography.rijndaelmanaged?view=netframework-4.8">Microsoft RijndaelManaged Class</a></li><li><a href="https://developers.onelogin.com/saml">SAML</a></li><li><a href="https://dzone.com/articles/sso-login-key-benefits-and-implementation">How SSO works</a></li></ol><h2 id="one-potential-security-issue"><a class="markdownIt-Anchor" href="#one-potential-security-issue"></a> One Potential Security Issue</h2><ul><li>如果我们仔细想想这个流程，就会发现这中间存在一个安全隐患，如果用户在IDP输入完用户信息并验证通过后，IDP会把SAML response发回给SP，这时如果这个SAML被拦截并被篡改，SP并不知道这个SAML有没有被改动，还是会按照SAML上面的信息将用户登陆。</li><li>要解决这个问题，我们就需要检查SAML Response，这个检查分为两步，Signing check和Certificate check</li></ul><h3 id="signing-check"><a class="markdownIt-Anchor" href="#signing-check"></a> Signing Check</h3><ul><li>其实就是一种checksum，我们把整个SAML response转换成一种加密的text。这个text随着SAML一起返回给SP，当我们解密这个text后得到的SAML和返回的SAML对不上，我们就知道这个SAML已经被篡改过了。举个例子：我们收到了一个来自Sam的SAML response，当我们检查了signing之后，我们就能确定这个response自从从Sam手上发出后就没有被篡改过。但是另一个问题是，如果我们得信息被Tony拦截，Tony完全替换了整个SAML并发给我们，我们虽然知道SAML自从从Tony手中发出后没有被篡改，但是我们还是没有拿到正确的SAML。</li></ul><h3 id="certificate-check"><a class="markdownIt-Anchor" href="#certificate-check"></a> Certificate check</h3><ul><li>这就需要Certificate check了，他其实就是提前保存在用户电脑中的受信任的证书，当我们发现SAML来自Tony而不是Sam，Tony并没有在受信名单中，那我们还是会拒绝这个SAML。只有当response来自我们所信任的人，并且这个response自从从他手上发出后就没有更改，我们才选择接受。</li></ul><h3 id="reference-2"><a class="markdownIt-Anchor" href="#reference-2"></a> Reference</h3><ol><li><a href="https://stackoverflow.com/questions/1703301/saml-why-is-the-certificate-within-the-signature">SAML: Why is the certificate within the Signature?</a></li><li><a href="https://docs.microsoft.com/en-us/dotnet/api/system.security.cryptography.xml.signedxml.checksignature?view=dotnet-plat-ext-3.1#System_Security_Cryptography_Xml_SignedXml_CheckSignature_System_Security_Cryptography_X509Certificates_X509Certificate2_System_Boolean_">CheckSignature(X509Certificate2, Boolean)</a></li><li><a href="https://stackoverflow.com/questions/2185569/how-to-validate-a-saml-signature-value">How to validate a SAML signature value</a></li><li><a href="https://docs.microsoft.com/en-us/dotnet/standard/security/how-to-verify-the-digital-signatures-of-xml-documents">How to: Verify the Digital Signatures of XML Documents</a></li><li><a href="https://stackoverflow.com/questions/47662340/asp-net-core-saml-response-signature-validation">Asp.Net Core SAML Response Signature Validation</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> SSO </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Learn Android Apprentice in 10 days</title>
      <link href="2019/09/02/Learn-Android-Apprentice-in-10-days/"/>
      <url>2019/09/02/Learn-Android-Apprentice-in-10-days/</url>
      
        <content type="html"><![CDATA[<h2 id="开始学习使用android-studio"><a class="markdownIt-Anchor" href="#开始学习使用android-studio"></a> 开始学习使用Android Studio</h2><ul><li><p>在iOS的学习告一段落了之后，现在开始学习Android应用的开发</p></li><li><p>他总共包括六个部分，前四个部分每一部分教你编写一个app，难度从低到高。后面两部分会告诉你怎么向下兼容和发布。跟之前的iOS教程很像。</p></li></ul><ol><li><a href="#TimeFighter">TimeFighter</a></li><li><a href="#Checklist">Checklist</a></li><li><a href="#Conclusion">Conclusion</a></li></ol><h2 id="timefighter"><a class="markdownIt-Anchor" href="#timefighter"></a> TimeFighter</h2><ul><li>这个app会从怎么set up Android Studio开始，我们直接跳过，到最开始写代码的部分</li></ul><h3 id="constraint-layouts"><a class="markdownIt-Anchor" href="#constraint-layouts"></a> Constraint Layouts</h3><ul><li>和iOS App很像，手机app必须考虑到对象在手机屏幕上的位置问题，Android有提供很多种layoutdexuanze，其中Constraint是最常用的一种，他可以规定目标到屏幕的相对位置</li></ul><p><img src="/../images/Learn-Android-Apprentice-in-10-days/1.png" alt="Constraint Layouts" /></p><p><img src="/../images/Learn-Android-Apprentice-in-10-days/2.png" alt="Constraint Layouts" /></p><h3 id="activities"><a class="markdownIt-Anchor" href="#activities"></a> Activities</h3><ul><li>在确定了诸如Textview，Button等对象的位置之后，我们需要在代码层面对其进行操作，我们可以在Aciticity中创建这些变量对象，然后通过在Layout中设置的ID找到他们，Activity其实就是iOS中的ViewController。</li></ul><p><img src="/../images/Learn-Android-Apprentice-in-10-days/3.png" alt="Activities TextView and Button" /></p><p><img src="/../images/Learn-Android-Apprentice-in-10-days/4.png" alt="Activities find by id" /></p><h3 id="strings"><a class="markdownIt-Anchor" href="#strings"></a> Strings</h3><ul><li>我们会将一个app中用到的所有文字集中在一个文件中，这个文件叫做Strings.xml，这样以后本地化加其他语言或者更改一个单词，这个单词虽然在app中可能出现了很多次，但是我们只需要在Strings里面改一次就可以了</li></ul><p><img src="/../images/Learn-Android-Apprentice-in-10-days/5.png" alt="Strings" /></p><h3 id="oriendtation-changes"><a class="markdownIt-Anchor" href="#oriendtation-changes"></a> Oriendtation changes</h3><ul><li><p>在手机屏幕方向改变时，系统会做三件事，1.save properties, 2. destroys current activity, 3. recreates the activity for the new orientation by calling onCreate and resets any properties specified by the developer</p></li><li><p>所以在改变方向时，我们需要及时保存需要用到的变量，在接下来现实的Activity中显示，保证过程不会丢失。</p></li></ul><h3 id="val-and-var"><a class="markdownIt-Anchor" href="#val-and-var"></a> val and var</h3><ul><li>Basically, val and var both are used to declare a variable. var is like a general variable and can be assigned multiple times and is known as the mutable variable in Kotlin. Whereas val is a constant variable and can not be assigned multiple times and can be Initialized only single time and is known as the immutable variable in Kotlin.</li></ul><p><img src="/../images/Learn-Android-Apprentice-in-10-days/6.png" alt="Save properties" /></p><p><img src="/../images/Learn-Android-Apprentice-in-10-days/7.png" alt="pass properties to next screen" /></p><h3 id="app-colors-and-styles"><a class="markdownIt-Anchor" href="#app-colors-and-styles"></a> App colors and styles</h3><ul><li>Android project中有许多文件夹，其中res包含着app需要用到的所有资源resources，常用的Strings，Animations，Menus，Colors and Styles都在这里, 通过直接更改Colors里面颜色的hex值来改变app中元素的颜色，更方便的管理同一种类型的东西</li></ul><p><img src="/../images/Learn-Android-Apprentice-in-10-days/8.png" alt="Colors and styles" /></p><h3 id="animations"><a class="markdownIt-Anchor" href="#animations"></a> Animations</h3><ul><li>Animations也在res文件夹里，她负责调用以及调配动画，图片里的动画效果是使用内置的bounce_interpolator，在2秒钟内把目标元素增大2倍，以50%处为中心，并缩小至原来的大小。</li></ul><p><img src="/../images/Learn-Android-Apprentice-in-10-days/9.png" alt="Animations" /></p><h3 id="menu"><a class="markdownIt-Anchor" href="#menu"></a> Menu</h3><ul><li>Menu同样他也在res文件夹中，他管理所有跟系统菜单相关的元素，比如我们想在屏幕上方的菜单栏中加入一个button，就需要在这里定义</li></ul><p><img src="/../images/Learn-Android-Apprentice-in-10-days/10.png" alt="Menu" /></p><ul><li>我们加了一个Menu，当点击时会冒出一个AlertDialog</li></ul><p><img src="/../images/Learn-Android-Apprentice-in-10-days/11.png" alt="AlertDialog" /></p><p><img src="/../images/Learn-Android-Apprentice-in-10-days/12.png" alt="AlertDialog in app" /></p><ul><li>这就是第一个app所讲的全部内容了，基本就是把project中需要用到的功能讲了一遍，没有用到任何复杂的语法，更多的讲的是Android Studio这个IDE的使用。接下来进行第二个app</li></ul><h2 id="checklist"><a class="markdownIt-Anchor" href="#checklist"></a> Checklist</h2><p><img src="/../images/Learn-Android-Apprentice-in-10-days/13.png" alt="ListMaker" /></p><h3 id="recyclerview"><a class="markdownIt-Anchor" href="#recyclerview"></a> RecyclerView</h3><ul><li><ol><li>The RecyclerView asks the Adapter for an item, or a ViewHolder at a given position. 2. The Adapter reaches into a pool of ViewHolders that have been created. 3. Either a a new ViewHolder is returned, or a new one is created. 4. The Adapter then binds this ViewHolder to a data item at the given position. 5. The ViewHolder is returned back to the RecyclerView for display</li></ol></li></ul><p><img src="/../images/Learn-Android-Apprentice-in-10-days/15.png" alt="RecyclerView" /></p><ul><li><p>In general, Adapters give your RecyclerView the data it wants to show. They have a clever way to calculate how many rows of data you want to show, which you’ll cover shortly. ViewHolders are the visual containers for your item. Think of them as cells in the table. This is where you tell your RecyclerView what each item should look like. These are basically little tiny layout items used to display the data at any given position in the list of data. As you scroll through a RecyclerView, instead of creating new ViewHolders, RecyclerView will recycle ViewHolders that have moved offscreen and populate them with new data, ready to be shown at the bottom of the list. This process repeats endlessly as you scroll through your RecyclerView. This recycling of ViewHolder to display list items helps to avoid janking in your app.</p></li><li><p>RecycleView 的本质是循环使用table中的cell，当一个cell网上滑出屏幕时，我们可以让他重新出现在底部，但是显示不同的数据，这就要求我们在写代码时要把table，cell和数据分开来，每个部分各司其职</p></li></ul><p><img src="/../images/Learn-Android-Apprentice-in-10-days/16.png" alt="cell" /></p><ul><li>这个是cell部分，它由两个textview组成。对应上图中的viewHolder</li></ul><p><img src="/../images/Learn-Android-Apprentice-in-10-days/14.png" alt="table" /></p><ul><li>这个是table部分，它包含多个cell，并可以循环利用cell。对应上图中的adapter。我们需要在adapter中implement recycleview必须的成分例如包含多少个viewholder，每个viewholder的数据应该从哪里取。。</li></ul><p><img src="/../images/Learn-Android-Apprentice-in-10-days/17.png" alt="data input" /></p><ul><li><p>除了recycleview本身，我们应该把data source设置成动态的，也就是说我们可以输入自己的数据，并加进recycleview中。</p></li><li><p>下面我们在代码层面解释一下如何构建一个recycleView</p></li></ul><p><img src="/../images/Learn-Android-Apprentice-in-10-days/22.png" alt="recycleView functions" /></p><ul><li>首先我们需要继承RecyclerView Adapter并implement这三个function，RecyclerView还有很多其他function可以override但是这三个是必须的</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">override fun getItemCount(): Int &#123;</span><br><span class="line">    return accounts.size</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>getItemCount return一个Int，它表示这个表格中有几行，一般是return数据的size</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">override fun onCreateViewHolder(</span><br><span class="line">    parent: ViewGroup,</span><br><span class="line">    viewType: Int</span><br><span class="line">): CustomViewHolder &#123;</span><br><span class="line">    val view &#x3D; LayoutInflater.from(parent.context).inflate(R.layout.view_holder_custom, parent, false)</span><br><span class="line"></span><br><span class="line">    return CustomViewHolder(view)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>onCreateViewHolder定义一个table cell的layout，我们返回一个layout文件，所以对于每个不同的recyclerView，我们还需要新建一个Layout file用于储存cell的layout</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">override fun onBindViewHolder(holder: CustomViewHolder, position: Int) &#123;</span><br><span class="line">    holder.label.text &#x3D; &quot;Some text&quot;</span><br><span class="line">    holder.itemView.setOnClickListener &#123;</span><br><span class="line">        clickListener.listItemClicked(position)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>onBindViewHolder会把我们的数据放到我们新建的cell layout中，另外注意到我加了一个ClickListener，所以之后我们点击每行的时候就会运行listItemClicked function，然后在那里就可以添加另外的代码，可以跳到另一个View等。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">class CustomViewHolder(itemView: View): RecyclerView.ViewHolder(itemView) &#123;</span><br><span class="line">    val sampleData &#x3D; itemView.findViewById(R.id.sampleData) as TextView</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p>我们还需要一个class去连接table cell layout file</p></li><li><p>这样基本上一个RecyclerView就完成了，之后我们只需要将数据从Activity或者Fragment传入RecyclerView Adapter就可以了</p></li></ul><p><img src="/../images/Learn-Android-Apprentice-in-10-days/18.png" alt="data input 2" /></p><h3 id="sharedpreferences"><a class="markdownIt-Anchor" href="#sharedpreferences"></a> SharedPreferences</h3><ul><li><p>SharedPreferences lets you save small collections of key-value pairs that you can retrieve later. If you need a way to quickly save small bits of data in your app, SharedPreferences is one of the first solutions you should consider</p></li><li><p>这就需要用到sharedpreference，它类似于一个dictionary，里面由key-value pairs组成。可以储存size较小的数据。类似于表格信息</p></li></ul><p><img src="/../images/Learn-Android-Apprentice-in-10-days/19.png" alt="SharedPreferences" /></p><h3 id="edittext"><a class="markdownIt-Anchor" href="#edittext"></a> EditText</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val listTitleEditText &#x3D; EditText(this) </span><br><span class="line">listTitleEditText.inputType &#x3D; InputType.TYPE_CLASS_TEXT</span><br></pre></td></tr></table></figure><ul><li>创建一个input text field，并给它指明一个InputType， 这样Android就会显示合适的keyboard</li></ul><h3 id="intent"><a class="markdownIt-Anchor" href="#intent"></a> Intent</h3><p><img src="/../images/Learn-Android-Apprentice-in-10-days/20.png" alt="Intent communication" /></p><ul><li>当我们需要让一个页面与另一个页面进行交流时，我们需要通过Intent将数据传送过去。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">private fun showListDetail(list: TaskList) &#123;</span><br><span class="line">    val listDetailIntent &#x3D; Intent(this, ListDetailActivity::class.java)</span><br><span class="line">    listDetailIntent.putExtra(INTENT_LIST_KEY, list)</span><br><span class="line">    startActivity(listDetailIntent)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; get from other Activity</span><br><span class="line">list &#x3D; intent.getParcelableExtra(MainActivity.INTENT_LIST_KEY)</span><br></pre></td></tr></table></figure><ul><li><p>在上面这个function中，this是我们现在所在的Activity，ListDetailActivity是我们将要过去的Activity，TaskList是我们要传送的数据。</p></li><li><p>我们需要规定一个Key，这样的新的页面中我们就知道用Key来获取相应的数据。</p></li><li><p>但是还有一个问题，就是自定义的object不能直接通过intent传送，我们需要把他变成Parcelable的object</p></li></ul><h3 id="parcelable"><a class="markdownIt-Anchor" href="#parcelable"></a> Parcelable</h3><p><img src="/../images/Learn-Android-Apprentice-in-10-days/21.png" alt="Implement Parcelable" /></p><ul><li>在定义object的class中，implement parcelable，Android Studio会自动把需要的function写好</li></ul><h3 id="fragment"><a class="markdownIt-Anchor" href="#fragment"></a> Fragment</h3><ul><li>Fragment是android语言中一个非常重要的部分，他必须附属于一个Activity，Fragment的本质是可以让相同的部分用同一个Fragment表示，并在多处使用，以节省代码长度，让App保持整洁一致。</li></ul><p><img src="/../images/Learn-Android-Apprentice-in-10-days/25.png" alt="Create Fragment" /></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">class ListSelectionFragment : Fragment() &#123;</span><br><span class="line">    &#x2F;&#x2F; 1</span><br><span class="line">    private var listener: OnListItemFragmentInteractionListener? &#x3D; null</span><br><span class="line">    interface OnListItemFragmentInteractionListener &#123;</span><br><span class="line">    fun onListItemClicked(list: TaskList)</span><br><span class="line">    &#125;</span><br><span class="line">    &#x2F;&#x2F; 2</span><br><span class="line">    companion object &#123;</span><br><span class="line">    fun newInstance(): ListSelectionFragment &#123;</span><br><span class="line">    val fragment &#x3D; ListSelectionFragment()</span><br><span class="line">    return fragment</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#x2F;&#x2F; 3</span><br><span class="line">override fun onAttach(context: Context) &#123;</span><br><span class="line">    super.onAttach(context)</span><br><span class="line">    if (context is OnListItemFragmentInteractionListener) &#123;</span><br><span class="line">    listener &#x3D; context</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">    throw RuntimeException(context.toString() + &quot; must implement</span><br><span class="line">OnListItemFragmentInteractionListener&quot;)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">    &#x2F;&#x2F; 4</span><br><span class="line">    override fun onCreate(savedInstanceState: Bundle?) &#123;</span><br><span class="line">    super.onCreate(savedInstanceState)</span><br><span class="line">    &#125;</span><br><span class="line">    &#x2F;&#x2F; 5</span><br><span class="line">    override fun onCreateView(inflater: LayoutInflater, container:</span><br><span class="line">ViewGroup?,</span><br><span class="line">    savedInstanceState: Bundle?): View? &#123;</span><br><span class="line">    return inflater.inflate(R.layout.fragment_list_selection, container,</span><br><span class="line">false)</span><br><span class="line">    &#125;</span><br><span class="line">    &#x2F;&#x2F; 6</span><br><span class="line">    override fun onDetach() &#123;</span><br><span class="line">    super.onDetach()</span><br><span class="line">    listener &#x3D; null</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="/../images/Learn-Android-Apprentice-in-10-days/26.png" alt="Fragment lifecycle" /></p><ul><li>Fragment由几个重要部分组成，首先，当Fragment第一次被附属于某个Activity时onAttach会被执行。然后onCreate， 在这两个地方你可以initialize一些变量等</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">override fun onCreate(savedInstanceState: Bundle?) &#123;</span><br><span class="line">    super.onCreate(savedInstanceState)</span><br><span class="line"></span><br><span class="line">    transactions &#x3D; arguments?.getParcelableArrayList&lt;WestpacTransaction&gt;(&quot;Transactions&quot;)!!</span><br><span class="line">    refundedAmount &#x3D; arguments?.getDouble(&quot;RefundedAmount&quot;)!!</span><br><span class="line">    refundAmount &#x3D; arguments?.getDouble(&quot;RefundAmount&quot;)!!</span><br><span class="line">    updatedBalance &#x3D; arguments?.getDouble(&quot;UpdatedBalance&quot;)!!</span><br><span class="line">    primaryAccount &#x3D; paperCutAccountManager.readPrimaryAccount()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>之后onCreateView，这个地方会把数据等object显示在View中，所以需要在这里把变量和UI object绑定。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">override fun onCreateView(</span><br><span class="line">    inflater: LayoutInflater, container: ViewGroup?,</span><br><span class="line">    savedInstanceState: Bundle?</span><br><span class="line">): View? &#123;</span><br><span class="line">    val activity &#x3D; activity as AppCompatActivity?</span><br><span class="line">    if (activity !&#x3D; null) &#123;</span><br><span class="line">        activity.supportActionBar!!.show()</span><br><span class="line">        activity.supportActionBar?.setDisplayHomeAsUpEnabled(false)</span><br><span class="line">        activity.supportActionBar?.title &#x3D; &quot;Refund Complete&quot;</span><br><span class="line">        activity.nav_view.isVisible &#x3D; false</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; Inflate the layout for this fragment</span><br><span class="line">    val view &#x3D; inflater.inflate(R.layout.fragment_refund_complete, container, false)</span><br><span class="line">    view.AccountNameLabel.text &#x3D; primaryAccount.AccountName</span><br><span class="line">    view.AccountBalanceLabel.text &#x3D; &quot;$&quot; + &quot;%.2f&quot;.format(updatedBalance)</span><br><span class="line">    view.refundAmount.text &#x3D; &quot;$&quot; + &quot;%.2f&quot;.format(refundedAmount)</span><br><span class="line">    view.DoneButton.setOnClickListener &#123; v -&gt;</span><br><span class="line">        doneButtonPressed()</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    view.refundCompleteTable.adapter &#x3D; RefundCompleteTableViewAdapter(transactions, this)</span><br><span class="line">    view.refundCompleteTable.layoutManager &#x3D; LinearLayoutManager(activity)</span><br><span class="line"></span><br><span class="line">    return view</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>之后是Companion object，当这个Fragment被创建时，如果你需要给它传值，它需要在这里被定义，有点像是Fragment的Constructor</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">companion object &#123;</span><br><span class="line">    val TAG &#x3D; RefundCompleteFragment::class.java.simpleName</span><br><span class="line">    @JvmStatic</span><br><span class="line">    fun newInstance(transactions: ArrayList&lt;WestpacTransaction&gt;, refundedAmount: Double, refundAmount: Double, updatedBalance: Double): RefundCompleteFragment &#123;</span><br><span class="line">        val fragment &#x3D; RefundCompleteFragment()</span><br><span class="line">        val args &#x3D; Bundle()</span><br><span class="line">        args.putParcelableArrayList(&quot;Transactions&quot;, transactions)</span><br><span class="line">        args.putDouble(&quot;RefundedAmount&quot;, refundedAmount)</span><br><span class="line">        args.putDouble(&quot;RefundAmount&quot;, refundAmount)</span><br><span class="line">        args.putDouble(&quot;UpdatedBalance&quot;, updatedBalance)</span><br><span class="line">        fragment.arguments &#x3D; args</span><br><span class="line">        return fragment</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Kotlin </tag>
            
            <tag> Android Studio </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Swift tips and tricks</title>
      <link href="2019/08/16/Swift-tips-and-tricks/"/>
      <url>2019/08/16/Swift-tips-and-tricks/</url>
      
        <content type="html"><![CDATA[<h2 id="passing-messages-around-view-controllers"><a class="markdownIt-Anchor" href="#passing-messages-around-view-controllers"></a> Passing messages around view controllers</h2><ul><li>三种在view controllers中传递参数的方法，Delegation pattern, Notifications, Closures and action handlers。可以在<a href="https://www.appcoda.com/data-passing-ios/">这篇帖子</a>中找到。</li></ul><h2 id="cs193p-open-course-notes"><a class="markdownIt-Anchor" href="#cs193p-open-course-notes"></a> CS193P open course notes</h2><ol><li><a href="#mvc">MVC</a></li><li><a href="#swift-programming-language">Swift Programming Language</a></li><li><a href="#more-swift">More Swift</a></li></ol><ul><li>Please find all relevant materials for Standford Programming course cs193p in <a href="https://github.com/hellcy/cs193p-Fall-2017">here</a></li></ul><p><img src="/../images/Swift-tips-and-tricks/1.png" alt="MVC communication" /></p><h2 id="mvc"><a class="markdownIt-Anchor" href="#mvc"></a> MVC</h2><ul><li>Controller can talk to both Model and View. But Model and View should never speak to each other. For the View, it can communicate to the Controller, but in certain ways. Because View are all generic UI objects, to change some of its properties to fits the app’s objective, we need to send the UI objects, like buttons and labels back to the controller, let controller to implement its properties like background color, label content etc… so we use Action method to target the function that will be calling when certain UI objects are triggered. Another way to talk to controller is to use Delegate, for more complicated objects like scroll view or tables, we need to let controller know what we are doing at the moment, and controller is responsible for implementing the extra tasks while we are doing this things. Another important thing is that views do not own the data they display, they ask for the controller and controller grab the data from Data source and give it to the View, because if you have 50000 songs in a table, if table owns the data, it will be too big and costy to create such table object. So instead we use Data Source to provide data to the view.</li></ul><p><img src="/../images/Swift-tips-and-tricks/2.png" alt="MVC communication" /></p><ul><li>What about Model, can Model talk to the Controller? Yes, but not directly, because Model is UI independent, and Controller is UI dependent, so if a Model is updated and he wants everybody that is interested to be informed, it will broadcast this information to all the controllers, and those controllers that are listening will be notified and talk to Model and grab the changes. This way is called notifications</li></ul><p><img src="/../images/Swift-tips-and-tricks/3.png" alt="MVC communication" /></p><ul><li>One MVC model usually controls one screen on iPhone, and when multiple MVCs are talking to each other, they often treats other MVC as its View. So when one Screen wants to talk to another Screen, it uses delegate!</li></ul><p><img src="/../images/Swift-tips-and-tricks/4.png" alt="MVC communication" /></p><ul><li>Do not implement your app this way!</li></ul><h3 id="struct-and-class"><a class="markdownIt-Anchor" href="#struct-and-class"></a> struct and class</h3><ul><li><p>They are similar, contains methods and variables, but struct has no inheritance, Another difference is structs are value types, and classes are reference types, so when we assign it to another variable, it gets copied. Arrays, ints, strings, dictionary are all structs, but swift doesn’t make a copy of all of them when we need it, it only copy them when a user modifies it. It’s called copy-on-write semantics. For classes, we do not make a copy of it when we need it, we make a reference to the class, so when we modify the properties of that class, the real class gets modified too.</p></li><li><p>Try not to use initialiser in the view controller</p></li></ul><p><img src="/../images/Swift-tips-and-tricks/5.png" alt="stride" /></p><h3 id="stride"><a class="markdownIt-Anchor" href="#stride"></a> stride</h3><ul><li>In swift, we don’t have for(; 😉 structrue, so we need stride method for a range with specific count value</li></ul><p><img src="/../images/Swift-tips-and-tricks/6.png" alt="tuples" /></p><h2 id="swift-programming-language"><a class="markdownIt-Anchor" href="#swift-programming-language"></a> Swift Programming Language</h2><h3 id="tuples"><a class="markdownIt-Anchor" href="#tuples"></a> tuples</h3><ul><li>They are nothing but a group of values, different types of values could be inside the same tuple, vars and methods are not allowed in tuples, its good for return multiple values from a method because a method can only return a single thing.</li></ul><p><img src="/../images/Swift-tips-and-tricks/7.png" alt="Computed properties" /></p><ul><li><p>stored properties(normal properties) and computed properties</p></li><li><p>Computed properties are properties with get and set methods, you can have read only computed properties, which only has get method. get and set part will be executed when we get or set the variable.</p></li><li><p>we use computed property because sometimes we can derive property from other place, like indexOfOneAndOnlyFaceUpCard GET can be derived by looking at all the cards and see if you can get only one card facing up and return that index. And SET can give the card that is facing up to the property. You can omit the GET word if it is a read only computed property</p></li></ul><p><img src="/../images/Swift-tips-and-tricks/8.png" alt="Access control" /></p><h3 id="access-control"><a class="markdownIt-Anchor" href="#access-control"></a> Access control</h3><ul><li><p>Protecting our internal implementations, by only give other people names of the methods that are allowed to be called.</p></li><li><p>Internal: usable by any object in my app or framwork, its default</p></li><li><p>private: callable only within this object</p></li><li><p>private(set): means its only readable from outside the object, but not settable</p></li><li><p>filePrivate: accessiable by any object in this source file</p></li><li><p>public(for frameworks only): can be used by object outside this framework</p></li><li><p>open(for frameworks only): public AND can sub-class(override)</p></li><li><p>assertion: a method that in your program when you assert something is true, is not, the app will crash. It is a good way to protect your API.</p></li></ul><h3 id="extension"><a class="markdownIt-Anchor" href="#extension"></a> Extension</h3><ul><li><p>Add vars and methods to other classes even if you don’t have the source.</p></li><li><p>But there are restrictions: you can’t re-implement the methods that are already there. You can only add new ones. And, properties you add can have no stroage associated with them.(computed only)</p></li></ul><h3 id="enum"><a class="markdownIt-Anchor" href="#enum"></a> Enum</h3><ul><li>Another variety of data structrue apart from struct and class. It can only have discrete states. Enum is a VALUE type, like structs, so it gets copied as it is passed around. Enum in Swift can have an associated data.</li></ul><p><img src="/../images/Swift-tips-and-tricks/9.png" alt="Enum with associated value" /></p><ul><li>Enum with associated value</li></ul><p><img src="/../images/Swift-tips-and-tricks/10.png" alt="Enum" /></p><ul><li>Checking enum’s state with Switch cases syntax</li></ul><p><img src="/../images/Swift-tips-and-tricks/11.png" alt="Enum" /></p><ul><li>using associated value in switch cases</li></ul><p><img src="/../images/Swift-tips-and-tricks/12.png" alt="Enum" /></p><ul><li>Enum can have methods, and you can test a enum’s state within that method with self keyword</li></ul><p><img src="/../images/Swift-tips-and-tricks/13.png" alt="Enum" /></p><ul><li>You can even change the enum’s state in its methods, by giving that method a mutating keyword to let Swift know.</li></ul><h3 id="optionals"><a class="markdownIt-Anchor" href="#optionals"></a> Optionals</h3><ul><li>Optional is just an enum, it has two cases, one is nil, which measns it is not set yet, the other is some, which means it has some associated value with it. If you are trying to force unwrap an optional, what Swift really do it just throw an exception when that enum is in case nil, and do whatever you want to do with that enum in case ‘some’.</li></ul><p><img src="/../images/Swift-tips-and-tricks/14.png" alt="Optional" /><br /><img src="/../images/Swift-tips-and-tricks/15.png" alt="Optional" /><br /><img src="/../images/Swift-tips-and-tricks/16.png" alt="Optional" /><br /><img src="/../images/Swift-tips-and-tricks/17.png" alt="Optional" /></p><h3 id="memory-management"><a class="markdownIt-Anchor" href="#memory-management"></a> Memory Management</h3><p><img src="/../images/Swift-tips-and-tricks/18.png" alt="Class" /></p><ul><li><p>Automatic reference counting: Reference types are stored in the heap, everytime you create a pointer to a reference type in the heap, Swift will add One to a counter for that reference type, everytime when a pointer goes out of scope, Swift decrement the counter. And when the counter decrement to zero, Swift will instantly remove that reference type out of heap.</p></li><li><p>Influence ARC by using ‘strong’, ‘weak’ and ‘unowned’</p></li></ul><p><img src="/../images/Swift-tips-and-tricks/19.png" alt="structs" /></p><ul><li>structs</li></ul><h2 id="more-swift"><a class="markdownIt-Anchor" href="#more-swift"></a> More Swift</h2><p><img src="/../images/Swift-tips-and-tricks/20.png" alt="protocol" /></p><ul><li>Protocol is the fourth data structure in Swift. It is basically a type, which contains a list of variables and a list of methods, without implementation. Any class or structs or enum that want to inherit protocol must implement all methods declared in that protocol. But, for objective C methods, implementations are optional. This is why when we override some will, did, set methods for some UI obejcts, we dont need to implement all methods from that protocol.</li></ul><p><img src="/../images/Swift-tips-and-tricks/21.png" alt="protocol mutating" /></p><ul><li>Mutating functions: in protocol, some functions may be marked as mutating, when structs trying to inherit a protocol, because structs are value types, so structs get copied when we want to use it. However, it would be very inefficient if we make a copy every time we see it. So Swift uses copy-on-write system, we only make a copy of that struct when we are trying to modify it, in other words, mutating it. So we a struct is trying to change something in a function, and that function is inherted from a protocol, then this function has to be marked as mutating.</li></ul><p><img src="/../images/Swift-tips-and-tricks/22.png" alt="protocol init" /></p><p><img src="/../images/Swift-tips-and-tricks/23.png" alt="protocol init required" /></p><ul><li>Init: init functions are allowed to exist in protocol, however, in a class inherited that protocol, we need to add requried keyword before init function, this is because this class could have some other subclasses, and these classes also have to implement init function.</li></ul><p><img src="/../images/Swift-tips-and-tricks/24.png" alt="protocol type" /></p><ul><li>Use protocol as a type</li></ul><p><img src="/../images/Swift-tips-and-tricks/25.png" alt="protocol delegation" /></p><ul><li>Delegation: a very important use of protocol is delegation.</li></ul><p><img src="/../images/Swift-tips-and-tricks/27.png" alt="protocol multiple inheritance" /></p><ul><li>Mutiple inheritance: if you want to use certain functions in some protocols, you could inherit that protocol and implement the functions you want to use.</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Swift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS Overview</title>
      <link href="2019/08/05/AWS-Overview/"/>
      <url>2019/08/05/AWS-Overview/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是aws"><a class="markdownIt-Anchor" href="#什么是aws"></a> 什么是AWS？</h2><ul><li>AWS是Amazon的云服务，我现在用到的是其中的API Gateway和Lambda，API Gateway就是API网关，当网关收到request时，可以运行对应的Lambda function，生成response，然后返回。</li></ul><ol><li><a href="#lambda-function-and-api-gateway">Lambda function and API Gateway</a><ol><li>Introduction</li><li><a href="#create-aws-serverless-application">Create AWS Serverless Application</a></li><li><a href="#%E6%9B%B4%E6%94%B9API%E5%9F%9F%E5%90%8D-custom-domain-names">更改API域名 Custom Domain Names</a></li><li><a href="#change-lambda-function-outbound-ip-address-to-static">change lambda function outbound IP address to static</a></li></ol></li><li><a href="#use-iam-to-restrict-api">Use IAM to restrict API</a></li><li><a href="#use-s3-to-host-webpage">Use S3 to host webpage</a></li><li><a href="#aws-simple-email-services">AWS Simple Email Services</a></li></ol><h2 id="lambda-function-and-api-gateway"><a class="markdownIt-Anchor" href="#lambda-function-and-api-gateway"></a> Lambda function and API Gateway</h2><p><img src="/../images/AWS-Overview/1.png" alt="create API Gateway" /></p><p><img src="/../images/AWS-Overview/2.png" alt="API Gateway Overview" /></p><h3 id="api-gateway"><a class="markdownIt-Anchor" href="#api-gateway"></a> API Gateway</h3><ul><li>他总共分成6个部分，第一个部分是Test，也就是send test request的地方，sample request会先到达Method Request，在这里你可以往request里面加入Query string parameters, Http headers, Request body来让request符合Lambda的要求。</li></ul><p><img src="/../images/AWS-Overview/3.png" alt="Proxy integration" /></p><ul><li>再下一个部分是Integration Request，在这里可以选择对应的Lambda function，让request知道该去往哪个Lambda，并且可以勾选Use Lambda Proxy integration, 如果勾选，它代表着AWS会帮你把request中的信息(包括query parameter, header, body等)保存到一个类似Dictionary的结构中，在lambda里面可以直接通过key name调用，不用手动提取信息。在下一部分就是运行相应的Lambda function了，这个在接下来的Lambda部分中讲。当Lambda运行完之后会生成一个response，如果勾选了之前的Proxy integration，这个地方就是灰色的，不能查看，因为它会帮你把response里的信息自动填充到header，body。。。并且使用自带的response template model，所以你就不用操心这个了。不然的话你可以手动设置response的格式。最后一个部分是Method response，当设置好reponse格式之后，你可以把response status code，连同optional的header和body返回给用户。还可以设置body的格式，比如JSON。</li></ul><h3 id="lambda-function"><a class="markdownIt-Anchor" href="#lambda-function"></a> Lambda function</h3><ul><li>这里是你真正处理请求并返回数据的地方，AWS支持很多种语言的function。</li></ul><p><img src="/../images/AWS-Overview/5.png" alt="Lambda function" /></p><p><img src="/../images/AWS-Overview/12.png" alt="Lambda Runtime language" /></p><ul><li><p>我是用C#，这需要在Visual Studio中安装AWS package，在unget manager里面搜索AWS就可以找到AWS SDK了。安装之后就可以新建AWS solution并publish到AWS Lambda中。</p></li><li><p>这次我需要写的function就是调用Westpac API，所以其实是用户先调用AWS API，然后这个API再调用Westpac API。。。</p></li><li><p>如果request中含有parameter或者body信息，那么在function中的APIGatewayProxyRequest中就会含有这些参数信息，这就是之前勾选了proxy integration的好处</p></li></ul><p><img src="/../images/AWS-Overview/6.png" alt="code1" /></p><p><img src="/../images/AWS-Overview/7.png" alt="code2" /></p><ul><li>在上传时新建一个Lambda function，另外下面的Method name要对应刚刚C#中的method name，因为有时候我们会在一个solution中写多个method，连接多个Lambda function，所以要一一对应。</li></ul><p><img src="/../images/AWS-Overview/9.png" alt="upload Lambda function" /></p><h3 id="test-api-gateway-and-lambda-function"><a class="markdownIt-Anchor" href="#test-api-gateway-and-lambda-function"></a> Test API Gateway and Lambda function</h3><ul><li>之后就是用AWS测试刚刚写好的API了，注意测试之前要先deploy API Gateway，确保与Lambda function对应，这个可以在lambda function中的API Gateway endpoint里看到，如果能看到endpoint url，就说明对应成功了。</li></ul><p><img src="/../images/AWS-Overview/4.png" alt="API Gateway endpoint url" /></p><ul><li>测试的时候可以加query strings，就是request中的parameters，右边可以看到测试结果，因为这个是GET request，所以我们不能加Request Body。在POST request中是可以的。</li></ul><p><img src="/../images/AWS-Overview/8.png" alt="test API Gateway" /></p><ul><li>这个是另外一个POST request with JSON body</li></ul><p><img src="/../images/AWS-Overview/11.png" alt="POST request with JSON body" /></p><h3 id="create-aws-serverless-application"><a class="markdownIt-Anchor" href="#create-aws-serverless-application"></a> Create AWS Serverless Application</h3><p><img src="/../images/AWS-Overview/29.png" alt="AWS Serverless Application" /></p><ul><li>这更像是一个Lambda project，可以让API gateway一次连接多个Lambda functions，也可以在Visual Studio里调整API Gateway的一些设置</li></ul><p><img src="/../images/AWS-Overview/30.png" alt="API gatewat settings" /></p><ul><li>这是project包含的template文件，我们可以设置API的类型，Request的类型，路径，以及这个API对AWS的可操作权限等</li></ul><p><img src="/../images/AWS-Overview/31.png" alt="API Gateway sturcture" /></p><ul><li><p>发布后在API Gateway中就可以看到这个层级结构和template是完全一样的</p></li><li><p>之前讲到我们可以在API Gateway中测试API，其实在Visual Studio里，发布之前我们就可以debug他，就是debug所在的位置，只不过现在显示的是Mock test tool</p></li></ul><p><img src="/../images/AWS-Overview/32.png" alt="Mock test tool" /></p><ul><li><p>他长这个样子</p></li><li><p>其中有两个需要注意的地方，第一个是我们需要调用的function，因为这是一个lambda projects，包含多个lambda functions，所以调用哪一个必须提前声明</p></li></ul><p><img src="/../images/AWS-Overview/33.png" alt="execute lambda function" /></p><ul><li><p>还有一个就是input，因为我使用的proxy，所以在列表中选择proxy，会生成一个template，然后我们需要什么input就在相应的地方加就可以了</p></li><li><p>比如如果要在request body里加，就找到body所在的位置，query parameter和path parameter同理</p></li></ul><p><img src="/../images/AWS-Overview/34.png" alt="proxy template" /></p><ul><li>最后说一下如何发布，跟之前的lambda function一样，只不过我们需要创建一个S3 bucket来存放所有的历史版本。</li></ul><p><img src="/../images/AWS-Overview/35.png" alt="publish S3 bucket" /></p><ul><li>他会自动清理之前旧版的project，当状态显示的是update complete，我们就知道他已经可以使用了</li></ul><p><img src="/../images/AWS-Overview/36.png" alt="publish complete" /></p><h3 id="calling-trusted-frame-from-swift"><a class="markdownIt-Anchor" href="#calling-trusted-frame-from-swift"></a> Calling trusted frame from swift</h3><ul><li>另外一个任务是，因为我们不能经受任何信用卡信息，所以我们需要用到westpac trusted frame，通过调用这个Javascript library来让用户将信用卡信息直接发送到westpac的服务器，然后处理westpac的response就可以了。但是有一个问题是，我们希望用户能在我们的手机app上也可以调用westpac API，可以这个trusted frame是一个只支持web application的Javascript library，这就需要我们在Swift中加入WebKit，同时在用户在含有trusted frame的web page中submit form时，将返回的信息发送到Swift的某个Method中。简而言之，我们需要在javascript中调用Swift</li></ul><h3 id="更改api域名-custom-domain-names"><a class="markdownIt-Anchor" href="#更改api域名-custom-domain-names"></a> 更改API域名 Custom Domain Names</h3><ul><li>AWS API的标准名字是这样的格式</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https:&#x2F;&#x2F;api-id.execute-api.region.amazonaws.com&#x2F;stage</span><br></pre></td></tr></table></figure><ul><li>这很复杂而且跟API的功能也没有任何联系</li><li>我们可以更改他的域名，让他的名字更有意义</li></ul><p><img src="/../images/AWS-Overview/37.png" alt="Costom domain name" /></p><ul><li><p>在新建域名时，我们可以给域名增加certificate，这需要通过在AWS ACM(certificate manager)中新增certificate来实现</p></li><li><p>我们还需要在internet中新建一个我们想要的域名，然后用route 53来把这个域名和API关联起来，上图中的Target domain name就是自定义域名需要关联的域名。在route 53中找到hosted zones，然后新增一行record，把target domain name填入，再自定义一个域名就可以了</p></li></ul><p><img src="/../images/AWS-Overview/38.png" alt="domain settings" /></p><ul><li>AWS API分为两种，一种是Edge Optimized，另一个是Regional，在API Gateway中每一个API的settings中可以看到，也可以更改其Endpoint type</li></ul><p><img src="/../images/AWS-Overview/39.png" alt="API Endpoint Type" /></p><ul><li>最后测试一下看看域名是不是成功了，记住route 53需要一点时间才能把域名建好并且go live，所以等几分钟再试</li></ul><p><img src="/../images/AWS-Overview/40.png" alt="test domain" /></p><ul><li>本节参考了这些文章，可以点击以获取更多信息。</li></ul><ol><li><a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-custom-domains.html">Set Up a Custom Domain Name for an API in API Gateway</a></li><li><a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-edge-optimized-custom-domain-name.html">How to Create an Edge-Optimized Custom Domain Name</a></li></ol><h3 id="change-lambda-function-outbound-ip-address-to-static"><a class="markdownIt-Anchor" href="#change-lambda-function-outbound-ip-address-to-static"></a> change lambda function outbound IP address to static</h3><ul><li><p>我们还可以设置API outbound request的IP，有些时候，当我们需要调用外部API时，他们会有IP地址的限制，只有来自特定whitelist的IP地址发送的请求才会被接受。所以我们需要设置我们发送API时请求的IP地址。因为Lambda function是通过AWS发送的，在被发送时它的IP地址是随机的，虽然不是动态IP，但是每次发送的地址都不一样，我们没办法把所有的IP都加近whitelist。</p></li><li><p>针对这个问题，我们可以通过把lambda function加入VPC来解决，VPC可以看作是包含一组IP地址的内部云，我们给它加上一个出口，让所有在此VPC的请求都通过这个出口发送出去，这样所有的lambda都会只有一个我们指定的IP了。</p></li><li><p>我们具体来解释一下AWS VPC的构造</p></li><li><p>如果AWS EC2是一个云服务器，那么VPC就是这个云服务器的网络层，负责设备之间的信息传输。它由几个重要部分构成</p></li></ul><p><img src="/../images/AWS-Overview/44.png" alt="VPC" /></p><ol><li>Subnet: 包含一组指定范围的IP，IP格式参照<a href="https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing">CIDR</a></li><li>Route table: 包含信息传输的规则，什么地方来的请求应该到什么地方去，类似一个交通枢纽，负责指挥数据的方向</li><li>Internet gateway: VPC的一个重要组成部分，负责VPC内部信息和外部网络的交流，就是这个VPC的出口</li><li>Elastic IP: 一个公开的IPv4地址，我们要把它赋给NAT，这样就可以让外部和NAT内部通过这个公开IP进行交流</li><li>NAT Gateway: Network Address Translator Gateway, 与Internet Gateway类似，不同的是它可以让private subnet中的数据通过它与外部网络交流</li></ol><h3 id="具体做法"><a class="markdownIt-Anchor" href="#具体做法"></a> 具体做法</h3><ol><li>新建一个VPC</li><li>新建一个Internet Gateway，与VPC相连</li><li>新建一个Public subnet，并在route table中新建一个规则，让所有通过这个public subnet的数据流向Internet Gateway</li><li>新建一个Elastic IP</li><li>新建一个NAT Gateway，把Elastic IP赋给它，并将它放入public subnet中</li><li>新建一个private subnet，并在route table中新建一个规则，让所有通过这个private subnet的数据流向NAT Gateway</li><li>将lambda function放入private subnet</li></ol><ul><li><p>这样一切就设置完成了，当lambda被执行时，数据会通过private subnet，根据route table的规则流向NAT gateway</p></li><li><p>NAT Gateway将数据赋予Elastic IP，因为NAT在public subnet中，根据route table规则流向Internet Gateway</p></li><li><p>Internet Gateway将数据发给外部网络，此时所有数据都会来自同一个Elastic IP</p></li></ul><h3 id="需要注意的点"><a class="markdownIt-Anchor" href="#需要注意的点"></a> 需要注意的点</h3><ul><li>在将lambda function放入subnet时，只给它private subnet，不要给public subnet，因为这样他就有可能不通过NAT gateway</li></ul><p><img src="/../images/AWS-Overview/41.png" alt="add VPC to lambda" /></p><ul><li>给lambda function加VPC需要一个AWS permission</li></ul><p><img src="/../images/AWS-Overview/42.png" alt="add VPC permission to lambda" /></p><ul><li>可以创建另一个lambda function，只接受特定IP来测试整个流程是否成功。图为限制IP的policy</li></ul><p><img src="/../images/AWS-Overview/43.png" alt="whitelist ip" /></p><h3 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h3><ol><li><a href="https://medium.com/@matthewleak/aws-lambda-functions-with-a-static-ip-89a3ada0b471">AWS Lambda functions with a static IP</a></li><li><a href="https://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html">Configuring a Lambda Function to Access Resources in a VPC</a></li><li><a href="https://medium.com/awesome-cloud/aws-vpc-difference-between-internet-gateway-and-nat-gateway-c9177e710af6">AWS — Difference between Internet gateway and NAT gateway</a></li><li><a href="https://docs.aws.amazon.com/vpc/latest/userguide/what-is-amazon-vpc.html">What Is Amazon VPC?</a></li><li><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts.html">What Is Amazon EC2?</a></li><li><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html">Elastic IP Addresses</a></li></ol><h2 id="use-iam-to-restrict-api"><a class="markdownIt-Anchor" href="#use-iam-to-restrict-api"></a> Use IAM to restrict API</h2><ul><li><p>HTTP basic authentication是一种保护API免受外界攻击的方式，当我们尝试打开某些URL时，有时会出现这个界面让我们输入用户名和密码，这就是一种Basic authentication<br /><img src="/../images/AWS-Overview/13.png" alt="browser pop up authentication window" /></p></li><li><p>这种机制依赖于HTTP Authentication Framework，他的步骤是：</p></li></ul><ol><li>某些人尝试访问一个受保护的URL</li><li>服务器返回401未授权的HTTP code，包括一个WWW-Authenticate header with value Basic</li><li>浏览器弹出要求用户输入用户名和密码的窗口</li><li>请求再次被发送，包括用户输入的授权信息在header中</li></ol><p><img src="/../images/AWS-Overview/14.png" alt="API authentication procedure" /></p><ul><li><p>那么这个简单的API authentication怎么实现呢？</p></li><li><p>首先我们去到已经建好的API Gateway中，点击Gateway responses选项，选中Unauthorized，在这里我们可以设置返回什么样的信息给用户当他们尝试访问这个URL时。</p></li></ul><p><img src="/../images/AWS-Overview/15.png" alt="set 401 response" /></p><ul><li>当我们添加了WWW-Authenticate header，浏览器就会弹出窗口要求用户自证身份</li></ul><p><img src="/../images/AWS-Overview/20.png" alt="test pop up window" /></p><ul><li>之后我们需要写一个Lambda function去检查用户提交的信息是否是正确的，也就是检查用户名和密码。这个function也叫做custom authorizer</li></ul><p><img src="/../images/AWS-Overview/16.png" alt="authentication lambda function" /></p><ul><li>接下来我们需要让我们的API知道当他接收到Authentication信息时需要调用哪个lambda function来检查，所以去到API gateway的Authorizer选项，新建一个Authorizer，在lambda function中选中我们刚刚写好的lambda function</li></ul><p><img src="/../images/AWS-Overview/17.png" alt="create authorizer" /></p><ul><li>最后我们还需要让API gateway知道哪个URL endpoint是需要保护的，因为一个API gatewat往往包括很多个URL，我们需要指定一个或多个URL调用刚刚新建的Authorizer</li></ul><p><img src="/../images/AWS-Overview/18.png" alt="set authorizer" /></p><ul><li><p>最后别忘了Deploye API，不然所有的设置并不会生效</p></li><li><p>我们可以测试一下看看访问相同的URL，如果不添加authentication information的话，服务器就会返回401 Unauthorized</p></li></ul><p><img src="/../images/AWS-Overview/19.png" alt="test Unauthorized" /></p><ul><li>除了使用自定义的Authorizer，AWS也内置有IAM (Identity Access Management),在之前的Method Request如果我们选择使用AWS_IAM的话，也可以限制用户对于API的访问</li></ul><p><img src="/../images/AWS-Overview/21.png" alt="AWS_IAM" /></p><ul><li>但是我们必须在request中添加AWS signature，这需要使用到AWS给每个account的access key和secret key，其中secret key只有在一开始generate的时候才会看到，之后就看不到了，所以一定要保存在一个安全的地方，要不然的话只能重新generate一对新的key</li></ul><p><img src="/../images/AWS-Overview/22.png" alt="AWS access key" /></p><p><img src="/../images/AWS-Overview/24.png" alt="AWS signature" /></p><ul><li>另外我们可以在resource policy中限制可以访问API的ip address，所以即使用户输入了正确的Authentication information，我们也不能让没有权限的区域访问API</li></ul><p><img src="/../images/AWS-Overview/23.png" alt="resource policy" /></p><ul><li><p>这种IP address limitation也可以在自定义的lambda function中使用</p></li><li><p>另外，如果要blacklist or whitelist a range of ip addresses，可以使用CIDR notation net mask，在ip address后面加一个斜杠和一个数字，数字表示从左往右有多少bit是在范围外的。</p></li><li><p>例如“110.142.216.1/24&quot; 就表示了ip range from 110.142.216.1 to 110.142.216.255</p></li></ul><h3 id="reference-2"><a class="markdownIt-Anchor" href="#reference-2"></a> Reference</h3><ol><li><a href="https://medium.com/@Da_vidgf/http-basic-auth-with-api-gateway-and-serverless-5ae14ad0a270">HTTP Basic Auth with API Gateway and Serverless</a></li><li><a href="https://aws.amazon.com/blogs/compute/control-access-to-your-apis-using-amazon-api-gateway-resource-policies/">Control access to your APIs using Amazon API Gateway resource policies</a></li><li><a href="https://aws.amazon.com/premiumsupport/knowledge-center/api-gateway-resource-policy-whitelist/">How do I use a resource policy to whitelist certain IP addresses to access my API Gateway API?</a></li><li><a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-resource-policies-examples.html#apigateway-resource-policies-source-ip-address-example">API Gateway Resource Policy Examples</a></li><li><a href="https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing">Classless Inter-Domain Routing</a></li></ol><h2 id="use-s3-to-host-webpage"><a class="markdownIt-Anchor" href="#use-s3-to-host-webpage"></a> Use S3 to host webpage</h2><ul><li>S3是一个储存文件的服务，一般来说我们需要把网页放到服务器里去host它，但是S3也提供了host webpage的功能，我们只需要新建一个bucket。</li></ul><p><img src="/../images/AWS-Overview/1.png" alt="AWS S3 create bucket" /><br /><img src="/../images/AWS-Overview/25.png" alt="" /></p><ul><li>上传我们需要host的webpage</li></ul><p><img src="/../images/AWS-Overview/26.png" alt="AWS S3 upload file" /></p><ul><li>注意在设置里面关闭block public access，毕竟我们需要访问它来获得数据</li></ul><p><img src="/../images/AWS-Overview/27.png" alt="AWS S3 block access" /></p><ul><li>最后我们需要打开hosting</li></ul><p><img src="/../images/AWS-Overview/28.png" alt="AWS S3 hosting" /></p><ul><li>这样的话我们就可以通过AWS S3来host webpage，不需要使用自己的服务器了</li></ul><h3 id="reference-3"><a class="markdownIt-Anchor" href="#reference-3"></a> Reference</h3><ol><li><a href="https://docs.aws.amazon.com/AmazonS3/latest/gsg/GetStartedWithS3.html">AWS S3 Getting Started</a></li><li><a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/Welcome.html">What is AWS S3?</a></li></ol><h2 id="aws-simple-email-services"><a class="markdownIt-Anchor" href="#aws-simple-email-services"></a> AWS Simple Email Services</h2><ul><li><p>使用AWS发送Email是一件非常简单的事情，通过以下步骤可以创建一个AWS User with email sending policyies并使用C#发送邮件</p></li><li><p>首先我们需要创建一个AWS User，拿到发送Email的Credentials</p></li></ul><p><img src="/../images/AWS-Overview/45.png" alt="SMTP Credentials" /></p><ul><li>然后我们需要设置想用什么邮箱地址发送邮件，我们需要验证，并登陆对应邮箱点击验证链接</li></ul><p><img src="/../images/AWS-Overview/46.png" alt="Verify sender Email address" /></p><ul><li>之后我们可以测试一下能不能发送Test Email，这里不需要用到Credentials</li></ul><p><img src="/../images/AWS-Overview/47.png" alt="Send Test Emails" /></p><ul><li>然后我们就可以看代码了</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">public void SendEmail()</span><br><span class="line">    &#123;</span><br><span class="line">        String FROM &#x3D; &quot;sender email address&quot;;</span><br><span class="line">        String FROMNAME &#x3D; &quot;Your Name&quot;;</span><br><span class="line">        String TO &#x3D; &quot;receiver email address&quot;;</span><br><span class="line">        String SMTP_USERNAME &#x3D; &quot;Credentials Username&quot;;</span><br><span class="line">        String SMTP_PASSWORD &#x3D; &quot;Credentials Password&quot;;</span><br><span class="line">        String HOST &#x3D; &quot;Your AWS host location&quot;;</span><br><span class="line">        int PORT &#x3D; 587;</span><br><span class="line">        String SUBJECT &#x3D; &quot;Email Subject&quot;;</span><br><span class="line"></span><br><span class="line">        String BODY &#x3D;</span><br><span class="line">            &quot;&amp;lth1&amp;gtEmail Title&amp;lt&#x2F;h1&amp;gt&quot; +</span><br><span class="line">            &quot;&amp;ltp&amp;gtEmail Content&amp;lt&#x2F;p&amp;gt&quot;;</span><br><span class="line"></span><br><span class="line">        MailMessage message &#x3D; new MailMessage();</span><br><span class="line">        message.IsBodyHtml &#x3D; true;</span><br><span class="line">        message.From &#x3D; new MailAddress(FROM, FROMNAME);</span><br><span class="line">        message.To.Add(new MailAddress(TO));</span><br><span class="line">        message.Subject &#x3D; SUBJECT;</span><br><span class="line">        message.Body &#x3D; BODY;</span><br><span class="line"></span><br><span class="line">        using (var client &#x3D; new System.Net.Mail.SmtpClient(HOST, PORT))</span><br><span class="line">        &#123;</span><br><span class="line">            client.UseDefaultCredentials &#x3D; false;</span><br><span class="line">            client.Credentials &#x3D; new NetworkCredential(SMTP_USERNAME, SMTP_PASSWORD);</span><br><span class="line">            client.EnableSsl &#x3D; true;</span><br><span class="line"></span><br><span class="line">            try</span><br><span class="line">            &#123;</span><br><span class="line">                Console.WriteLine(&quot;Attempting to send email...&quot;);</span><br><span class="line">                client.Send(message);</span><br><span class="line">                Console.WriteLine(&quot;Email sent!&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">            catch (Exception ex)</span><br><span class="line">            &#123;</span><br><span class="line">                Console.WriteLine(&quot;The email was not sent.&quot;);</span><br><span class="line">                Console.WriteLine(&quot;Error message: &quot; + ex.Message);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><ul><li>执行这个function几次看看能不能收到邮件，如何可以的话就成功了</li></ul><p><img src="/../images/AWS-Overview/49.png" alt="Emails" /></p><ul><li><p>AWS 还有统计邮件成功率的工具，也在SES tab里面</p></li><li><p>另外就是Configuration set是一个optional的设置，可以在AWS里面添加</p></li><li><p>除了用SMTP，我们还可以用AWS SDK发送邮件，这里就不介绍了，大致都是一样的，代码需要改一下</p></li></ul><p><img src="/../images/AWS-Overview/48.png" alt="Configuration Sets" /></p><ul><li>当你新建一个AWS用户时，你的邮件功能可以会受到限制，也就是说在Sandbox里面，收发数量，频率都会受限，可以给Amazon发送请求移除Sandbox，具体做法可以参考下面链接</li></ul><h3 id="reference-4"><a class="markdownIt-Anchor" href="#reference-4"></a> Reference</h3><ol><li><a href="https://docs.aws.amazon.com/ses/latest/DeveloperGuide/send-an-email-from-console.html">Sending a test email</a></li><li><a href="https://docs.aws.amazon.com/ses/latest/DeveloperGuide/send-using-smtp-net.html">Send an email using SMTP</a></li><li><a href="https://docs.aws.amazon.com/ses/latest/DeveloperGuide/using-configuration-sets.html">Using AWS SES Configuration sets</a></li><li><a href="https://docs.aws.amazon.com/ses/latest/DeveloperGuide/request-production-access.html">Moving out of sandbox</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> AWS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Payment Gateway API</title>
      <link href="2019/07/23/Payment-Gateway-API/"/>
      <url>2019/07/23/Payment-Gateway-API/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是pci-compliance"><a class="markdownIt-Anchor" href="#什么是pci-compliance"></a> 什么是PCI compliance？</h2><ul><li>现在很多公司都允许客户通过信用卡在网上直接付款购买公司的服务和产品，那么必不可少的就是公司需要对用户输入的信用卡信息和其他个人隐私保护，使得外人不能窃取这些信息，<a href="https://www.cio.com.au/article/400300/what_pci_compliance_/">PCI DSS</a>是一种数据安全协议，通过参与这个协议，客户就可以放心的将信用卡信息填在公司的网站上而不用担心泄露。因为如果客户的信息泄露了，公司将会受到严重的利息损失，其他客户也将不再愿意相信此公司的信誉。</li></ul><p><img src="/../images/Payment-Gateway-API/1.jpg" alt="PCI compliance" /></p><ul><li>WestPac QuickStream是一个第三方的payment gateway。我们可以使用这个API来管理用户的付款，他们提供一种trusted frame，使用它，所有的敏感信息将不会经过公司的服务器，而是直接从用户的电脑到Westpac的服务器，由他们来负责保护这些关键信息。</li></ul><p><img src="/../images/Payment-Gateway-API/2.png" alt="Westpac quickstream" /></p><ul><li>Trusted Frame将用户信息加密(tokenize)，并将加密后的token发送到公司服务器，这样即使公司也无法知道用户信息了。</li></ul><p><img src="/../images/Payment-Gateway-API/3.png" alt="Trusted frame" /></p><ul><li>详细的API使用可以在<a href="https://quickstream.westpac.com.au/docs/quickstreamapi/v1/transactions/#transactions-api">这里</a>找到。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> API </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Learn iOS apprentice in 10 days</title>
      <link href="2019/07/03/Learn-iOS-apprentice-in-10-days/"/>
      <url>2019/07/03/Learn-iOS-apprentice-in-10-days/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是ios-apprentice"><a class="markdownIt-Anchor" href="#什么是ios-apprentice"></a> 什么是iOS apprentice？</h2><hr /><ul><li>在完成了上一个任务之后，我总算迎来了又一个更加巨大的挑战，这次直接换了一个新的平台：iOS。我从来没有接触过iOS的编程，之前只是听说过Swift和Cocoa Touch，但是Xcode完全没有用过。于是经过一番上网查找，我发现了一个非常适合新手入门的教材： raywenderlich的iOS apprentice！</li></ul><p><img src="/../images/iOS-Apprentice/1.png" alt="iOS apprentice book" /></p><ul><li>他总共包括四个部分，每一个部分教你编写一个app，难度从低到高。</li></ul><ol><li><a href="#bulls-eye">Bull’s Eye</a></li><li><a href="#checklist">Checklist</a></li><li><a href="#mylocation">MyLocation</a></li><li><a href="#storesearch">StoreSearch</a></li><li><a href="#conclusion">Conclusion</a></li></ol><h2 id="bulls-eye"><a class="markdownIt-Anchor" href="#bulls-eye"></a> Bull’s Eye</h2><hr /><p><img src="/../images/iOS-Apprentice/2.png" alt="Bull Eye app" /></p><p><img src="/../images/iOS-Apprentice/3.png" alt="Bull Eye app" /></p><ul><li>从怎么样创建一个新的single view app说起，非常容易上手</li></ul><p><img src="/../images/iOS-Apprentice/4.png" alt="Project Navigator" /></p><ul><li>Project Navigator</li></ul><p><img src="/../images/iOS-Apprentice/5.png" alt="Obejct Library" /></p><ul><li>Obejct Library</li></ul><p><img src="/../images/iOS-Apprentice/6.png" alt="Drag item to view" /></p><ul><li>Drag item to view</li></ul><p><img src="/../images/iOS-Apprentice/7.png" alt="Make connections from object item to View Controller" /></p><ul><li>Make connections from object item to View Controller</li></ul><p><img src="/../images/iOS-Apprentice/8.png" alt="Attributes Inspector" /></p><ul><li>Attributes Inspector</li></ul><p><img src="/../images/iOS-Apprentice/9.png" alt="Item Outlet" /></p><p><img src="/../images/iOS-Apprentice/10.png" alt="Item Outlet 2" /></p><ul><li>Item Outlet</li></ul><p><img src="/../images/iOS-Apprentice/11.png" alt="Another view controller" /></p><ul><li>Another view controller</li></ul><p><img src="/../images/iOS-Apprentice/12.png" alt="Segue" /></p><ul><li>Segue</li></ul><p><img src="/../images/iOS-Apprentice/13.png" alt="Add Constraints" /></p><ul><li><p>Add Constraints</p></li><li><p>第一个app基本上解决了很多界面上的问题，storyboard和editor之前的交流也讲了很多，@IBAction， @IBOutlet，segue等等一切都有涉及。之后第二个app就会更深层次的接触到iOS特有的模式了，比如delegate，还有一切经典的design pattern，比如MVC</p></li></ul><h2 id="checklist"><a class="markdownIt-Anchor" href="#checklist"></a> Checklist</h2><hr /><ul><li>第二个app就没有那么简单了，他先讲了table view和navigation bar</li></ul><p><img src="/../images/iOS-Apprentice/14.png" alt="table view and navigation bar" /></p><ul><li>跟普通的view不同的是它由一行行的cell组成，这些cell可以被重复使用，当用户往下滑动时，更多的内容会被显示但是并不是每一行data都被存放在一个新的table cell里。离开显示范围的cell会重新出现在底部，并显示出新的data。</li></ul><p><img src="/../images/iOS-Apprentice/15.png" alt="UITable view protocol" /></p><h3 id="protocol"><a class="markdownIt-Anchor" href="#protocol"></a> Protocol</h3><ul><li>什么是protocol？他其实是一种已经被写好了的methods的集合，UITableView就是一个protocol，我们通过它来显示table view，但是如果我们想改变一些显示方式，让他更适应我们自己的app，那么就要override其中一些method，这很常见</li></ul><p><img src="/../images/iOS-Apprentice/16.png" alt="UITableView method override" /></p><ul><li>一般让一个table view更好的显示，我们需要override三个methods</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">override func tableView(_ tableView: UITableView, numberOfRowsInSection section: Int) -&gt; Int</span><br><span class="line"></span><br><span class="line">override func tableView(_ tableView: UITableView, cellForRowAt indexPath: IndexPath) -&gt; UITableViewCell</span><br><span class="line"></span><br><span class="line">override func tableView(_ tableView: UITableView, didSelectRowAt indexPath: IndexPath)</span><br></pre></td></tr></table></figure><h3 id="mvc-model"><a class="markdownIt-Anchor" href="#mvc-model"></a> MVC model</h3><ul><li>MVC model是一种常见的设计模式，将代码分割成三个部分，每一个部分只负责他自己的任务，这样让程序结构更清晰。Model主要负责储存数据，view负责显示数据给用户，而controller负责显示正确的数据，包括运算等等</li></ul><p><img src="/../images/iOS-Apprentice/17.png" alt="MVC model" /></p><h3 id="array"><a class="markdownIt-Anchor" href="#array"></a> Array</h3><ul><li>这个app将table cells中的数据储存在一个array中，新建了一个checklistItem model,这样的话每次如果有数据变动就只需要增加和删除array中的数据。</li></ul><h3 id="initializer"><a class="markdownIt-Anchor" href="#initializer"></a> Initializer</h3><ul><li>在Swift语言中，所有的variable， obejct都必须被初始化，所以很多时候我们需要一个初始化器来负责检查漏掉的变量。注意当我们有两个view controller需要传递data时，method的执行顺序是：假设A呼叫B</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">init() from B</span><br><span class="line">prepare() from A</span><br><span class="line">viewDidLoad() from B</span><br></pre></td></tr></table></figure><p><img src="/../images/iOS-Apprentice/18.png" alt="Initializer" /></p><h3 id="delegates"><a class="markdownIt-Anchor" href="#delegates"></a> Delegates</h3><ul><li>Delegates是ios编程中非常重要的一个概念，当你需要把一些值从一个view传到另一个view时，你通常不希望这两个view相互知道太多除了需要值之外的其他东西，如果两个view之间的联系太紧密，那么他们和其他view再建立关联就会更麻烦。所以一种通常的办法是写一个protocol，包含所有delegate methods，再让另外一个view成为它的delegate。这种办法称为loose coupling。 A是B的delegate，然而B根本不知道A的存在，只知道他有一个delegate可以接受他想要传递的值。</li></ul><p><img src="/../images/iOS-Apprentice/19.png" alt="Delegate" /></p><h3 id="建立delegate的步骤"><a class="markdownIt-Anchor" href="#建立delegate的步骤"></a> 建立delegate的步骤</h3><ol><li>在B中建立delegate protocol</li><li>在B中建立一个delegate optional variable</li><li>在B中，需要传递信息时呼叫delegate method</li><li>在A中conformB的delegate protocol（inheritance</li><li>告诉B，A是自己的delegate，一般在A的prepare method中做这一步</li></ol><h3 id="optionals"><a class="markdownIt-Anchor" href="#optionals"></a> Optionals</h3><ul><li>Optional variable在declare的时候用？来表示，表明这个变量有可能是nil，在使用的时候也需要加？在varibale name的后面，如果使用了exclamation mark叹号！，则表示在此时不管变量是什么，强行取得其中的值，此时程序员保证变量在此时不可能是nil，风险也由程序员承担。是用叹号叫做force unwrapping</li></ul><h3 id="weak"><a class="markdownIt-Anchor" href="#weak"></a> Weak</h3><ul><li>Weak表示两个objects之间的关系，当A对B的关系是strong时表示A是B的owner。当两个obejcts之间都是strong的关系我们可能会产生ownership cycle的问题从而导致memroy leak，因为没有人有资格destroy它的owner。所以我们尽量要维护一种一强一弱的对应关系。</li></ul><p><img src="/../images/iOS-Apprentice/20.png" alt="strong-strong relationship" /></p><p><img src="/../images/iOS-Apprentice/21.png" alt="strong-weak relationship" /></p><ul><li>一般来说，A如果是B的owner，A给B传值时在A的prepare method中，此时B的instance已经被建立，A很容易把值传给B的properties，并指认成为B的delegate，B给A传值则需要在合适的时候呼叫delegate methods</li></ul><p><img src="/../images/iOS-Apprentice/22.png" alt="Views pass value" /></p><h3 id="save-data"><a class="markdownIt-Anchor" href="#save-data"></a> Save data</h3><ul><li>app会在合适的时候将用户数据保存到手机本地，每一个app都有一个属于自己的folder，也叫做sandbox，每个sandbox之间不能访问，这就预防了一些恶意软件在用户不知情的情况下窃取保存在用户手机其他地方的数据。</li></ul><p><img src="/../images/iOS-Apprentice/23.png" alt="Saving data" /></p><ul><li>数据一般会保存在这样的一个path中，我们可以看到application后面接着一串32的字母的应用ID</li></ul><p><img src="/../images/iOS-Apprentice/24.png" alt="data path" /></p><h3 id="plist-file"><a class="markdownIt-Anchor" href="#plist-file"></a> .plist file</h3><ul><li>什么是.plist文件？它是一种ios用来储存数据的文件，它遵循XML格式，每一个app都有一个info.plist file，他就是用来保存这个app的配置信息</li></ul><h3 id="special-comments"><a class="markdownIt-Anchor" href="#special-comments"></a> Special comments</h3><ul><li>在编写代码时我们可以使用 // MARK：- 的形式来告诉Xcode我们开始了一个section，这样在jump bar中我们就可以快速定位variable，methods的位置。</li></ul><p><img src="/../images/iOS-Apprentice/25.png" alt="MARK comments" /></p><p><img src="/../images/iOS-Apprentice/26.png" alt="Jump bar for MARK comments" /></p><h3 id="type-casts"><a class="markdownIt-Anchor" href="#type-casts"></a> Type casts</h3><ul><li>我们使用 as! 来给一个variable赋予一种data type，告诉Swift以后把它当成某一种type来处理，因为有时候我们知道它的type，可是Swift却不知道。</li></ul><p><img src="/../images/iOS-Apprentice/27.png" alt="Type casts" /></p><h3 id="array-of-arrays"><a class="markdownIt-Anchor" href="#array-of-arrays"></a> Array of arrays</h3><ul><li>当app的结构变得复杂时，数据的结构也要相应的变化以适应这些变化，我们可以使用嵌套的array来储存更多的数据</li></ul><p><img src="/../images/iOS-Apprentice/28.png" alt="nested arrays" /></p><h3 id="appdelegateswift"><a class="markdownIt-Anchor" href="#appdelegateswift"></a> AppDelegate.swift</h3><ul><li>这个文件用来负责当app刚启动时或快要结束时的一些情况，我们不需要每过一会就储存数据，只需要每当用户退出app或者切换app时，所以这些method需要在AppDelegate里面修改</li></ul><p><img src="/../images/iOS-Apprentice/29.png" alt="AppDelegate file" /></p><h3 id="dictionary"><a class="markdownIt-Anchor" href="#dictionary"></a> Dictionary</h3><ul><li>和array类似，dictionary也是一种储存数据的类型，只不过它是将数据按照key-value pair来排列的，当需要拿到某一个数据时，我们需要给dictionary相应的key。</li></ul><p><img src="/../images/iOS-Apprentice/30.png" alt="dictionary" /></p><h3 id="user-defaults"><a class="markdownIt-Anchor" href="#user-defaults"></a> User Defaults</h3><ul><li>User Defaults就是一个dictionary类型的数据储存文件，它包含户用的配置信息，我们使用它储存一些app刚开始时的默认配置。</li></ul><h3 id="local-notifications"><a class="markdownIt-Anchor" href="#local-notifications"></a> Local Notifications</h3><ul><li>当获得用户许可后，app可以定时在app不活跃时像互用手机发送提醒</li></ul><p><img src="/../images/iOS-Apprentice/31.png" alt="Notification authorization" /></p><p><img src="/../images/iOS-Apprentice/32.png" alt="Permission dialog" /></p><p><img src="/../images/iOS-Apprentice/33.png" alt="Notification message" /></p><ul><li>这些基本就是第二个app的全部内容了，关于代码的部分可以在我的github的iOSApprenticePratice里面找到，下面是整个app的final storyboard</li></ul><p><img src="/../images/iOS-Apprentice/34.png" alt="final storyboard" /></p><h2 id="mylocation"><a class="markdownIt-Anchor" href="#mylocation"></a> MyLocation</h2><h3 id="app-overview"><a class="markdownIt-Anchor" href="#app-overview"></a> App Overview</h3><ul><li>第三个app我们要做一个可以通过GPS显示当前位置信息，并可以储存，增加照片和类别，在以后可以查看的app。完成之后的效果如下</li></ul><p><img src="/../images/iOS-Apprentice/3-1.png" alt="app overview" /></p><h3 id="tabbed-application"><a class="markdownIt-Anchor" href="#tabbed-application"></a> Tabbed Application</h3><ul><li>之前的checklist我们学会了如何制作一个有navigation bar的app，这回我们要在app中增加一个tab bar，就是下屏幕最低端有一个导航条，可以切换不同的页面。许多主流的app都有类似的功能。</li></ul><p><img src="/../images/iOS-Apprentice/3-2.png" alt="create tab bar" /><br /><img src="/../images/iOS-Apprentice/3-3.png" alt="tab bar" /><br /><img src="/../images/iOS-Apprentice/3-4.png" alt="tab bar storyboard" /></p><h3 id="corelocation-and-ask-for-permission"><a class="markdownIt-Anchor" href="#corelocation-and-ask-for-permission"></a> CoreLocation and ask for permission</h3><ul><li>要想让app获得GPS信息，我们需要现象用户获得许可，如果用户拒绝让app使用GPS，我们则无法获得权限。我们需要在info.plist里面增加一个record，表示我们需要获得许可，之后我们还会请求照片查看和地图view的许可。</li></ul><p><img src="/../images/iOS-Apprentice/3-5.png" alt="GPS service permission" /></p><h3 id="reverse-geocoding"><a class="markdownIt-Anchor" href="#reverse-geocoding"></a> Reverse geocoding</h3><ul><li>当我们获得了GPS信息，也就是当前位置的经纬度之后，我们还需要将他们转换成地址信息，否则用户也无法直接通过经纬度对当前位置有什么具体的概念。我们要做的是使用swift内置的CLGeocoder.reverseGeocodeLocation来转换。然后我们就可以得到地址信息了。</li></ul><p><img src="/../images/iOS-Apprentice/3-6.png" alt="reverse geocoder" /></p><h3 id="auto-resizing"><a class="markdownIt-Anchor" href="#auto-resizing"></a> Auto-resizing</h3><ul><li>自动调整尺寸大小是一个非常重要的功能，现在市面上的iPhone屏幕尺寸很多，我们如果想对每一个尺寸做优化，为非常耗时，所以使用auto-resizing，让swift知道element在屏幕上的相对位置，比如距离屏幕底端100px，宽度等于屏幕宽度。这样swift就可以画出他的坐标，对于不同大小的屏幕也不会超出屏幕之外。</li></ul><p><img src="/../images/iOS-Apprentice/3-7.png" alt="Auto-resizing" /><br /><img src="/../images/iOS-Apprentice/3-8.png" alt="Auto-resizing" /></p><h3 id="class-inheritance-overriding-and-casts"><a class="markdownIt-Anchor" href="#class-inheritance-overriding-and-casts"></a> Class Inheritance, overriding and casts</h3><ul><li>现在我们来说一下OOP中非常重要的一个概念，class。object就是class的一个具象，而class是这个具象的类。inheritance就是子类可以继承他的parent class的信息。而overriding是说子类可以改变parent class的一些信息，让他有自己的特点。比如汽车是一个parent class，而公交车就是汽车这个class的一个子类，汽车如果有一个property是说自己的轮子个数为4.那么公交车就可以overr这个property，将轮子个数改为8，或者12，或任意。。。casts则是说某些时候swift并不知道现在的变量到底是什么类，只知道他是属于哪个大类的，那么我们如果要使用只存在于子类的properties，我们就需要将这个变量cast成我们想要的类。一般用as!</li></ul><h3 id="tag-location-screen"><a class="markdownIt-Anchor" href="#tag-location-screen"></a> Tag Location Screen</h3><ul><li>接下来我们看看怎么给现在获得的位置信息添加一些其他的信息，比如description，photo，category。那么我们就需要一个table，这个table我们知道他会有多少行，所以不需要使用prototype cells，使用static cells就可以了。制作一个这样的table非常基本，description用text view，image picker我们之后会讲，category使用disclosure indicator，其他cell就用right detailed就可以。</li></ul><p><img src="/../images/iOS-Apprentice/3-9.png" alt="tag location screen" /></p><h3 id="the-unwind-segue"><a class="markdownIt-Anchor" href="#the-unwind-segue"></a> The unwind segue</h3><ul><li>当我们点击category时会进入到另一个table with prototype cells。再选一个category后就会回到之前的这个tag location screen，像这种返回式的我们可以使用unwind segue来实现</li></ul><p><img src="/../images/iOS-Apprentice/3-10.png" alt="unwind segue" /></p><h3 id="hud"><a class="markdownIt-Anchor" href="#hud"></a> HUD</h3><ul><li>heads-up display是一种popover view，其实他就是一种view，只不过正常的view现实时其他的view会先被destory以节省memory，但是HUD往往会将背景设置成本透明并保留之前的view，让app有一种层叠的感觉。</li></ul><p><img src="/../images/iOS-Apprentice/3-11.png" alt="HUD" /></p><h3 id="core-data"><a class="markdownIt-Anchor" href="#core-data"></a> Core Data</h3><ul><li>Core Data相当于储存在本地的数据，swift使用SqlLite数据库储存本地数据，我们需要将所有的location信息储存在Core Data中，以便以后打开app时查看之前tag的地点</li></ul><p><img src="/../images/iOS-Apprentice/3-12.png" alt="Core Data" /></p><h3 id="notification-center"><a class="markdownIt-Anchor" href="#notification-center"></a> Notification center</h3><ul><li>跟iPhone提醒不一样的是，swift有一个Notification center可以让开发者方便的listen从app任何地方发出的notification。比如我想在用户任何时候对储存在Core Data里的Locations信息进行读取，增加，删除，修改的时候得到提醒，我就可以在appDelegate里设置一个notification method，任何地方发出的LocationsUpdatedNotification都会被我捕捉到，并在这个method里面进行相应的操作。</li></ul><p><img src="/../images/iOS-Apprentice/3-13.png" alt="notification center" /></p><ul><li>The Locations Tab: 这个view就是显示所有储存在Core Data Locations里面的信息。基本的table with prototype cells，难点在于将Core Data信息提取并转换成相应的type，还有就是在不关闭app的状态下，新增的location可以马上更新到Core Data并显示在此view中，不过有了notification center相信各位也知道怎么做了。</li></ul><p><img src="/../images/iOS-Apprentice/3-14.png" alt="The locations tab" /></p><ul><li><p>Custom table view cell: 将一个cell的layout写在一个新的文件中，使得代码更易读。跟写在LocationsTabViewController是一样的，只不过拉outlets的时候选新的文件就好了。</p></li><li><p>Map Kit View: 我们可以在info.plist里增加map view来获得显示apple map的许可。</p></li></ul><p><img src="/../images/iOS-Apprentice/3-15.png" alt="map view plist" /><br /><img src="/../images/iOS-Apprentice/3-16.png" alt="map view" /></p><ul><li>Image Picker: 同样，请求获取照片查看器的许可</li></ul><p><img src="/../images/iOS-Apprentice/3-17.png" alt="image picker plist" /></p><h3 id="ownership-cycle-in-closure"><a class="markdownIt-Anchor" href="#ownership-cycle-in-closure"></a> Ownership cycle in closure</h3><ul><li>先复习一下什么是closure，他其实就是一个method，没什么特殊的，只不过他需要依附于另一个method才能存在。在某些条件被满足时，closure block里面的代码会被执行，比如一段时间过后，api返回成功之后等等。在执行closure时，我们往往会用到被依附的method的property，这时我们需要使用self来显式调用。然而这表示我们对这个property有一种strong reference，并可能导致在closure被执行之前，即使被依附的method所在的class无法被destory，造成memory leak，这是我们就需要使用weak self来破坏ownership cycle。</li></ul><p><img src="/../images/iOS-Apprentice/3-18.png" alt="closure ownership cycle" /></p><ul><li>剩下的就是一些外观，音效和动画的改变了，这里就不赘述了。</li></ul><h2 id="storesearch"><a class="markdownIt-Anchor" href="#storesearch"></a> StoreSearch</h2><h3 id="app-overview-2"><a class="markdownIt-Anchor" href="#app-overview-2"></a> App Overview</h3><ul><li>这本书的最后一个app将用到向apple store发送request获取信息，使用version contorl tools，对iPad等大屏幕设备的适配，异步通信以及把app上传到app store，可以说是一个简单的软件开发流程了。最终完成的结果如下</li></ul><p><img src="/../images/iOS-Apprentice/4-1.png" alt="final storyboard" /></p><h3 id="git-version-control"><a class="markdownIt-Anchor" href="#git-version-control"></a> Git version control</h3><ul><li>是一个代码管理软件，当我们完成一个阶段的代码后，希望把他保存成一个副本，以后可以随时返回到这个地方。Xcode可以接连到github等网站进行更好的代码管理，也可以使用terminal。我比较喜欢使用terminal，常用的几个指令是：</li></ul><p><img src="/../images/iOS-Apprentice/4-2.png" alt="Xcode git version control" /><br /><img src="/../images/iOS-Apprentice/4-3.png" alt="terminal version control" /></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git add *</span><br><span class="line">git commit -m <span class="string">&quot;commit message&quot;</span></span><br><span class="line">git push -u origin master</span><br></pre></td></tr></table></figure><ul><li>当我们想在已经工作的代码中新加一些功能却又害怕出错，然后又改不回来，我们可以使用git创建一个新的branch，然后在新的branch中肆意更改，不用害怕出问题，这就相当于一个副本，如果改不会去了可以直接删掉，git会保存最后工作的版本。若果一切顺利，也可以将新的branch与master合并</li></ul><p><img src="/../images/iOS-Apprentice/4-15.png" alt="git merch branch" /></p><ul><li>当我们在View Controller中创建outlet时，应该使用weak relationship，这是因为每一个view都基本是从另一个super view中继承而来的，所以如果使用strong relationship，将导致view无法被摧毁。</li></ul><p><img src="/../images/iOS-Apprentice/4-4.png" alt="view relationship" /></p><h3 id="create-branch-and-merge"><a class="markdownIt-Anchor" href="#create-branch-and-merge"></a> Create branch and merge</h3><ul><li>NeXT Interface Builder: nib file or xib file, 是一种局部storyboard，比如如果我们想设计一种table cell，就可以创建一个新的nib file，然后将这种custom table cell发给任何一个storyboard中的table view， nib file给我们提供多的灵活性</li></ul><p><img src="/../images/iOS-Apprentice/4-5.png" alt="create new nib file" /><br /><img src="/../images/iOS-Apprentice/4-6.png" alt="nib storyboard" /></p><h3 id="debug-using-xcode"><a class="markdownIt-Anchor" href="#debug-using-xcode"></a> Debug using Xcode</h3><ul><li>与其他IDE相似，可以设置breakpoint来暂停程序，查看此时各个变量的值。在debug console中输入p instanceName 可以print出想要查看的object的值</li></ul><p><img src="/../images/iOS-Apprentice/4-7.png" alt="Xcode debug" /><br /><img src="/../images/iOS-Apprentice/4-8.png" alt="debug console" /></p><h3 id="calling-the-web-service"><a class="markdownIt-Anchor" href="#calling-the-web-service"></a> Calling the web service</h3><ul><li>这个app的第一个重头戏就是send API request, 这也是软件开发中最常见的也是必不可少的技能，API request最常见的有两种，GET 和 POST， GET一般用来从远端提取数据，POST一般用来添加或改变远端数据，而API就是本地程序和远端数据连接的接口。本书使用了最简单的没有任何限制的GET request。</li></ul><p><img src="/../images/iOS-Apprentice/4-9.png" alt="call web service" /><br /><img src="/../images/iOS-Apprentice/4-10.png" alt="data response" /></p><ul><li>encode the url text to escape special characters: 在向API发送请求时我们经常需要一同发送一些parameters，但是space和很多其他它特殊符号都是不能被正常处理的，所以我们需要encode url再发送</li><li>Parse JSON data: 返回的数据一般是以JSON的形式组成的，所以我们需要deserilize，Swift有提供官方的decoder可以直接使用</li></ul><p><img src="/../images/iOS-Apprentice/4-11.png" alt="JSON format" /></p><ul><li>using network link conditioner: 从发送API请求到收到数据总会有那么几秒钟时间，这时如果你的程序是在主线程上，你将无法执行任何操作。直到获取数据。如果网络速度很慢，那么结果将非常糟糕，我们可以使用network link conditioner这一额外开发工具来模拟网速极慢的状态。</li></ul><p><img src="/../images/iOS-Apprentice/4-12.png" alt="network link conditioner" /></p><h3 id="asychronous-networking"><a class="markdownIt-Anchor" href="#asychronous-networking"></a> Asychronous networking</h3><ul><li>那么如果解决这几秒钟的类似于死机的状态呢？我们可以使用多线程，并将API请求的操作放到另外一个线程中，这样主线程将不受影响，注意，所有和界面变化相关的操作都应该放在主线程。所以即使数据没有收到，用户也可以进行其他操作，比如取消请求。。。</li></ul><p><img src="/../images/iOS-Apprentice/4-14.png" alt="asynchronous networking overview" /><br /><img src="/../images/iOS-Apprentice/4-13.png" alt="asynchronous networking code" /></p><ul><li>URLSession: 这是一个专门用来负责多线程的API。他可以负责下载请求，数据请求等很多工作。本书使用URLSession来处理异步通信问题。</li><li>Segmented Control: 这是一个很常用的UI模块, 每次切换时可以把segmentedIndex的值传给controller来负责update UI</li></ul><p><img src="/../images/iOS-Apprentice/4-16.png" alt="segmented control" /></p><h3 id="downloadtask"><a class="markdownIt-Anchor" href="#downloadtask"></a> DownloadTask</h3><ul><li>Show DetailView with Present Modally segue: 当点击每个table cell时，会出现这样的一个显示详细信息的窗口，并且也可以看到下面的table view，这个做法其实很简单，每当swift切换到一个新的view时，之前的view默认会被摧毁，但是我们可以改变delegate method，让之前的view保留，并把新的view背景设置成透明。</li></ul><p><img src="/../images/iOS-Apprentice/4-17.png" alt="details view" /></p><ul><li>Dynamic type text: 一些app的字体可以根据用户的系统设置而改变，这就要求我们使用默认字体大小，类似于headline</li></ul><p><img src="/../images/iOS-Apprentice/4-18.png" alt="dynamic type" /></p><ul><li>对于一款手机app来说，好的排版是非常重要的，因为涉及到不同的屏幕尺寸，使用auto-resizing让排版适应所有类型的手机可以扩大目标受众，而不是只为一款手机开发</li></ul><p><img src="/../images/iOS-Apprentice/4-19.png" alt="app constraints" /><br /><img src="/../images/iOS-Apprentice/4-20.png" alt="detail popup view" /></p><h3 id="landscape"><a class="markdownIt-Anchor" href="#landscape"></a> Landscape</h3><ul><li>对于像iPad和iPhone Plus的机型来说，很多时候我们会把手机横置，这个时候因为屏幕的宽度和高度变化，我们希望app可以呈现出另一种不同的layout以适应变化的屏幕。</li></ul><p><img src="/../images/iOS-Apprentice/4-21.png" alt="landscape mode" /></p><ul><li>对于这种情况，swift定义了size classes，我们可以通过查看size class区分手机什么时候是横置的。拿iPhone 6 Plus来举例。如下图，当手机竖置的时候，手机屏幕的高度（vertical）是regular模式，而宽度是compact模式，而当手机处于横置的状态时，手机的高度变成了compact模式，而宽度变成了regular模式。这样，我们在写代码的时候，就可以对每一种situation，制定不同的显示模式了。</li></ul><p><img src="/../images/iOS-Apprentice/4-22.png" alt="size classes" /></p><ul><li>Enums with associated values: 在StoreSearch这个app中，用户有没有perform search action一共有四种状态，1.还没有search。 2.正在searching。 3. search结束，并且没有找到任何结果。 4.search结束，并且找到了至少一种结果。 那么对于这样一种状态，与其定义四个变量然后在viewcontroller里面查看这四个变量的true/false值，不如直接定义一个enum然后只需查看这一个enum的值即可。</li></ul><p><img src="/../images/iOS-Apprentice/4-23.png" alt="enum code" /><br /><img src="/../images/iOS-Apprentice/4-24.png" alt="enum code" /></p><h3 id="internationalization"><a class="markdownIt-Anchor" href="#internationalization"></a> Internationalization</h3><ul><li>有时候，我们希望让我们的app被来自不同国家使用不同语言的人使用，那么我们就需要将我们的app翻译成不同的语言。我们可以在info tab里新加一种语言。</li></ul><p><img src="/../images/iOS-Apprentice/4-25.png" alt="localization add a new language" /></p><ul><li>另外，针对不同的view，我们还需要对每个view新加对应的语言文件。</li></ul><p><img src="/../images/iOS-Apprentice/4-26.png" alt="add new language file for each view" /></p><ul><li>至于那些不在storyboard里显示的语言信息，我们需要使用NSLocalizedString把所有的语言文本标记出来，再添加到strings文件中去</li></ul><p><img src="/../images/iOS-Apprentice/4-27.png" alt="localized strings" /></p><ul><li>split view contorlle for iPad: split view是大屏幕设备常用的显示模式，例如iPad和iPhone plus。它可以轻松的利用空间，显示出原本需要两个view才能显示出的内容。</li></ul><p><img src="/../images/iOS-Apprentice/4-28.png" alt="split view" /><br /><img src="/../images/iOS-Apprentice/4-29.png" alt="split view app" /></p><ul><li>config elements in storyboard based on size class: 但如果我们用之前的view size，在iPad等设备上就会显得很小，所以我们需要针对大屏幕设备进行优化。我们可以在attribute tab找到constant，点击加号来增加一个针对不同情况的尺寸，之前说到iPad设备在横置模式（landscape）下高度和宽度都是regular的，所以这里wR hR就是width Regular, height Regular。这种情况下我们将view size改为500.</li></ul><p><img src="/../images/iOS-Apprentice/4-30.png" alt="wR hR constant size" /></p><ul><li>popovers view controller: 如图所示，这是一个在一个view之上的popover view,可以用来表示一个新的menu</li></ul><p><img src="/../images/iOS-Apprentice/4-31.png" alt="popover view" /></p><ul><li>email compose sheet: 这是一个可以在app中打开的内建email系统，提前设置好标题和收件人，当用户执行这个method，直接输入email的内容，就可以发送到开发者的邮箱，前提是用户必须提前设置好email账户。</li></ul><p><img src="/../images/iOS-Apprentice/4-32.png" alt="email sheet" /></p><ul><li>beta testing (test flight): 当你完成一个app之后，可以把它发布到app store，这需要几个步骤，首先你需要提交一个build，在进入iTunes connect查看提交的app，在这里你可以分配给同一个team的其他测试者，这一步称为internal testing，如果一切都没问题，你可以submit app to app store. 如果app通过apple的审查，就可以进行external testing，将app的测试码发给任何人，他们可以通过测试码下载并测试app。</li></ul><p><img src="/../images/iOS-Apprentice/4-33.png" alt="distributing app to store" /></p><h2 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> Conclusion</h2><ul><li><p>本来想用10天的时间看完这本将近1100页的书，最后用了将近20天才完成。在做最后一个app的时候又有其他的工作加进来，周末又一直有活动，才又延长了这么长时间，不过完成了就是好的，对于一个对iOS没有任何经验的人来说，的确是一本不可多得的好书，如果对自己的编程能力有信心，之前又接触过Java或者C++,直接读这本是没有任何问题的，不过如果没有任何编程经验，从另外一本Swift Apprentice开始更好，从了解swift语言基本开始，使用Xcode playground。</p></li><li><p>这四个app基本解决了我制作其他app时的所有问题，常用的storyboard object都用了，constraints，delegate, extension, custom with nib, localizition, API calling, local library, local database, simple animation, multi-threading, git, debug到最后app publish都有涉及。</p></li><li><p>不过在跟着做完所有app之后，我觉得还是需要自己制作一个app，在脱离了guide之后，靠自己的能力解决所有过程中的问题，能使学到的知识更加牢固。</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> iOS </tag>
            
            <tag> Swift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mifare card read and write</title>
      <link href="2019/06/24/Mifare-card-read-and-write/"/>
      <url>2019/06/24/Mifare-card-read-and-write/</url>
      
        <content type="html"><![CDATA[<h2 id="mifare-card-families"><a class="markdownIt-Anchor" href="#mifare-card-families"></a> Mifare card families</h2><ul><li>Mifare卡片有很多种类，每一种卡都有不用的读写方式</li></ul><ol><li>Mifare Classic</li><li>Mifare Plus</li><li>Mifare Ultralight</li><li>Mifare DESFire</li></ol><h2 id="classic-and-mitools"><a class="markdownIt-Anchor" href="#classic-and-mitools"></a> Classic and Mitools</h2><ul><li>Mifare Classic卡是一种卡片类型，它的安全等级不是特别的高，现在已经有可以破解的软件，Mitools就是其中一种。它的界面如下</li></ul><p><img src="/../images/Mifare-card-read-and-write/1.png" alt="Mitools" /></p><ul><li>Mifare卡片总共有16个sector，每一个sector中又有4个block，其中第一个sector是用来卡片生产的过程中记录卡片信息的，一般来说我们不去动他。剩下的15个sector可以给我们用来记录我们想要的信息，其中每个sector的前3个block可以自由使用，而第4个block是用来记录两个密码Key A和Key B。中间的7为则用来记录密码的形式，一般我们也不去动他。密码层在图中用粉色表示。</li></ul><p><img src="/../images/Mifare-card-read-and-write/2.png" alt="Mitools read" /></p><ul><li>这是其中一张卡片读取后显示的信息</li><li>现在我们来看看怎么从sector7中提取出这张卡片的site code和card number</li></ul><p><img src="/../images/Mifare-card-read-and-write/3.png" alt="Mitools read" /></p><ul><li>可以看到第一个block中含有我们需要的信息，而剩下的block2，block3都是0.</li></ul><p><img src="/../images/Mifare-card-read-and-write/4.png" alt="Mitools read" /></p><ul><li><p>我们需要做的就是拿出block1中的信息，这个信息是Hexadecimal也就是16进制的，所以我们先把它变成2进制。1101 1000 1010 0011 1111 1000 0000 0000‬</p></li><li><p>因为我们用的是 <a href="https://www.identisource.net/26_bit_format_layout.cfm">26 bit format</a> 所以取前26位数</p></li><li><p>除去第一位even parity，取第二位往后8位：1011 0001，换成十进制就是177</p></li><li><p>再往后取16位：0100 0111 1111 0000. 十进制就是18416</p></li><li><p>这样我们就得到了site code: 177, card number: 18416</p></li></ul><h2 id="ultralight-card"><a class="markdownIt-Anchor" href="#ultralight-card"></a> Ultralight card</h2><ul><li>与Classic相似的是，Ultralight卡也有很多可以读写的分区，只是不叫sector，而叫做page，从第四个到第15个page是提供给使用者读写的，其他则是与卡本身相关的信息。</li><li>每一个page可以保存四个byte的信息</li><li>需要注意的是，page2的第2，3个byte保存有lock bits，可以lock其他的page，而且一旦lock，就不能在改变回unlock的状态，比如，0是unlock，1是lock，如果把第二个byte中的第4个bit从0改变为1，那么page4就会被lock，我们不再拥有write page4的权利，但是可以read，page2中的lock bit也无法从1再变回成0.</li></ul><h2 id="desfire-card"><a class="markdownIt-Anchor" href="#desfire-card"></a> DESFire card</h2><ul><li>DESFire卡的保护机制更加复杂，其中存储信息的空间叫做application，我们需要先选择正确的application和adpu command，然后伴随sw1, sw2两个parameter，最后还有加上一个expected response length</li><li>如果要write，就要再加上想要写入的data和数据长度。随着iOS13对于NFC的开放，使用iphone读写DESFire card有可能实现。</li></ul><h2 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h2><ol><li><a href="https://stackoverflow.com/questions/34198923/mifare-ultralight-lock-specific-pages">Mifare Ultralight lock bits</a></li><li><a href="https://www.eftlab.com/knowledge-base/complete-list-of-apdu-responses">APDU response code list</a></li><li><a href="https://stackoverflow.com/questions/40663460/use-apdu-commands-to-get-some-information-for-a-card">Use APDU commands to get some information for a card</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Mifare </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Deploy api to IIS manager</title>
      <link href="2019/06/20/Deploy-api-to-IIS-manager/"/>
      <url>2019/06/20/Deploy-api-to-IIS-manager/</url>
      
        <content type="html"><![CDATA[<h2 id="publish-api-using-visual-studio"><a class="markdownIt-Anchor" href="#publish-api-using-visual-studio"></a> Publish API using visual studio</h2><ul><li>API 完成之后，我们还需要把它deploy到client server里。所以我们先用visual studio publish它</li></ul><p><img src="/../images/Deploy-api-to-IIS-manager/1.png" alt="API publish" /></p><ul><li>go to Build-&gt;Publish API, 然后点publish，记住publis的路径</li></ul><p><img src="/../images/Deploy-api-to-IIS-manager/2.png" alt="API publish files" /></p><ul><li>这些文件就是一会要copy到client server的文件，也就是api</li><li>用remote desktop连接到client server</li></ul><p><img src="/../images/Deploy-api-to-IIS-manager/3.png" alt="remote desktop connection" /></p><ul><li>这个就是client server的IIS manager了，可以看到已经有很多API和app在列表中了</li></ul><p><img src="/../images/Deploy-api-to-IIS-manager/4.png" alt="client server IIS manager" /></p><ul><li>接下来新建一个app connection，路径上新建一个文件夹，把刚才的api文件放进去</li></ul><p><img src="/../images/Deploy-api-to-IIS-manager/5.png" alt="client server app connection" /></p><ul><li>更改一下web.config，连接到正确的client database，database name也要一致</li><li>测试一下，api有反应，那么就算deploy成功了</li></ul><p><img src="/../images/Deploy-api-to-IIS-manager/6.png" alt="Postman test" /></p>]]></content>
      
      
      
        <tags>
            
            <tag> API </tag>
            
            <tag> IIS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>How to use Gatling load testing tool</title>
      <link href="2019/06/18/How-to-use-Gatling-load-testing-tool/"/>
      <url>2019/06/18/How-to-use-Gatling-load-testing-tool/</url>
      
        <content type="html"><![CDATA[<h2 id="what-is-load-testing"><a class="markdownIt-Anchor" href="#what-is-load-testing"></a> What is load testing</h2><ul><li><p>load and stress testing. Load testing verifies how the system function under a heavy number of concurrent clients sending requests over a certain period of time. However, the main goal of that type of tests is to simulate the standard traffic similar to that, which may arise on production. Stress testing takes load testing and pushes your app to the limits to see how it handles an extremely heavy load.</p></li><li><p>使用一些load testing tool往往比自己写一个console application来test要有效，不单单是因为它提供很多可视化的图标可以参考在正常情况下用户的访问情况，还因为它对用户访问处理的算法也更好，可以模拟同时访问的情况而不同我们自己写平行运算。</p></li></ul><h2 id="gatling"><a class="markdownIt-Anchor" href="#gatling"></a> Gatling</h2><ul><li>这次我选的是<a href="https://gatling.io/">Gatling</a>. 一是因为它是免费的，二是因为它提供很多可视化图表</li></ul><p><img src="/../images/How-to-use-Gatling-load-testing-tool/1.png" alt="Gatling directory" /></p><ul><li>文件解压后可以看到这些文件夹，其中bin包含程序本身的运行文件。conf是程序的配置文件config，results会有每次测试的报告，一开始应该是空的。user_file是用户的测试配置文件，里面有两个文件夹，一个是resources，所有用到的关联文件类似csv file都应该放在里面。还有就是simulations，这个就是每次测试的配置文件，使用scala写的。但是也很容易懂。</li></ul><p><img src="/../images/How-to-use-Gatling-load-testing-tool/2.png" alt="simulation scala" /></p><ul><li><p>scala文件就长这个样子，需要注意的就是baseUrl，feeder file students.csv，get后面的url剩余部分，还有就是setup里面的同时访问数量。现在我们没有用到任何csv file，但是如果有用到就把他放在resources文件夹里</p></li><li><p>然后进入bin并运行gatling.bat</p></li></ul><p><img src="/../images/How-to-use-Gatling-load-testing-tool/3.png" alt="select simulation" /></p><ul><li>选择一个simulation</li></ul><p><img src="/../images/How-to-use-Gatling-load-testing-tool/4.png" alt="console output" /></p><ul><li>我们可以看到100个request都完成了</li></ul><p><img src="/../images/How-to-use-Gatling-load-testing-tool/5.png" alt="Gatling report" /></p><ul><li>图表也非常丰富</li><li>接下来我们看看如果模拟1000个不同的用户在接下来的20秒，因为不需要同时接受1000个用户，所以我们更改setup，使用rampUser</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setUp(scn.inject(rampUsers(1000) over (20 seconds)).protocols(httpProtocol))</span><br></pre></td></tr></table></figure><ul><li>运行报错，但是用console看起来太不方便了。我们更改下config让他把error log导出到一个文件中</li></ul><p><img src="/../images/How-to-use-Gatling-load-testing-tool/6.png" alt="export error log" /></p><ul><li><p>找到logback.xml,然后更改成这样，这样每次报错就会生成gatling.log</p></li><li><p>打开log发现他说：value over is not a member of io.gatling.core.Predef.RampBuilder。 说明没有识别关键词over，google一下这句话。发现是因为这个是旧版本的语法了。。。可是官方guide居然还没有更新。。。</p></li><li><p>好吧找到migration guide，发现over被替换成during了。。嗯。。真好</p></li></ul><p><img src="/../images/How-to-use-Gatling-load-testing-tool/7.png" alt="migration guide" /></p><ul><li>重新运行一下gatling.bat，现在行了，还挺像模像样的</li></ul><p><img src="/../images/How-to-use-Gatling-load-testing-tool/8.png" alt="gatling console output" /></p><ul><li>现在大部分request都小于800ms</li></ul><p><img src="/../images/How-to-use-Gatling-load-testing-tool/9.png" alt="gatling report" /></p><ul><li>细看的话，同时在线人数基本在50以上，我们用不到那么多。。。并且将近一半的request其实只用了36ms。。</li></ul><p><img src="/../images/How-to-use-Gatling-load-testing-tool/10.png" alt="gatling report 2" /></p><ul><li>ok，还有一个问题就是这个report中response time的上下限太高了，我们平均都不会超过100所以要更改一下上下限</li><li>同样，还是去gatling.conf</li></ul><p><img src="/../images/How-to-use-Gatling-load-testing-tool/11.png" alt="gatling config" /></p><ul><li>改一下lowerBound, higherBound, 记住一定要把#去掉，不然这会被算作comment而没有实际作用</li></ul><p><img src="/../images/How-to-use-Gatling-load-testing-tool/12.png" alt="gatling config guide" /></p><p><img src="/../images/How-to-use-Gatling-load-testing-tool/13.png" alt="gatling report with updated Time Bound" /></p><ul><li>可以看到现在图表中的response time变成100ms何200ms了</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Load Testing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Create a Restful api using C#</title>
      <link href="2019/06/13/Create-a-Restful-api-using-C-Sharp/"/>
      <url>2019/06/13/Create-a-Restful-api-using-C-Sharp/</url>
      
        <content type="html"><![CDATA[<h2 id="今天拿到了一个任务"><a class="markdownIt-Anchor" href="#今天拿到了一个任务"></a> 今天拿到了一个任务</h2><p><img src="/../images/Create-a-Restful-api-using-C-Sharp/1.PNG" alt="Wrike Restful api Task" /></p><ul><li>要写一个API，要求是每次学生登陆之后可以看到他的学生卡的相关信息，包括卡号，有效期，余额，还有可不可以自动充值等等。</li><li>那么我们就要先写一个stored procedure把相关信息提取出来,这些信息牵扯到4个table来自于两个database。</li></ul><p><img src="/../images/Create-a-Restful-api-using-C-Sharp/2.png" alt="Stored Procedure" /></p><ul><li>随便打一个StudentID试一下看看能不能成功运行</li></ul><p><img src="/../images/Create-a-Restful-api-using-C-Sharp/3.png" alt="Stored Procedure" /></p><ul><li>接着在Microsoft Doc tutorial可以帮助我们写一个简单的api模版。在用connectionString连接上database然后用postman测试一下</li></ul><p><img src="/../images/Create-a-Restful-api-using-C-Sharp/4.png" alt="Postman request" /></p><ul><li>这样基本上api就算写的差不多了，接下来还要把格式改成要求的样子</li></ul><p><img src="/../images/Create-a-Restful-api-using-C-Sharp/5.png" alt="Required format" /></p><ul><li>所以把它改成JSON Object这样好改一点，刚才都是直接return DataTable。</li></ul><p><img src="/../images/Create-a-Restful-api-using-C-Sharp/6.png" alt="VS Object structure" /></p><ul><li>结构基本就是这样，然后再测试一下看看能不能拿到相同的格式</li></ul><p><img src="/../images/Create-a-Restful-api-using-C-Sharp/7.png" alt="Postman test" /></p><ul><li>要求中还说到要有基本的authentication。有可能就是在function前面加上authorize attribute，等下周问问leader。另外就是要log所有的api calls。包括api整个的运行时间（response time），StudentID，现在的系统时间。用stopwatch计算出每次call所需的时间，其他的都好弄。我先把output写在debug console里了，回头再改看看要不要直接output到一个file里面。</li></ul><p><img src="/../images/Create-a-Restful-api-using-C-Sharp/8.png" alt="log in debug screen" /></p><ul><li><p>接下来就是要写一个console application来call我们的api了，毕竟不能一直用postman做测试啊。</p></li><li><p>用HttpClient去call api，已经成功了，但是有两个问题，一个是如果连续call10次的话每次用的时间都很长，用postman的时候很多时候只有20ms，但是现在有上千。。。第二个问题就是我还需要做一个simultaneously call。</p></li></ul><h2 id="一个周末过去了"><a class="markdownIt-Anchor" href="#一个周末过去了"></a> 一个周末过去了。。</h2><p><img src="/../images/Create-a-Restful-api-using-C-Sharp/9.png" alt="call api in a console app" /></p><ul><li>然后就是每次同时call10次api，这个的话我上网查了查，同样只要改await就可以.</li></ul><p><img src="/../images/Create-a-Restful-api-using-C-Sharp/10.png" alt="async await" /></p><ul><li>这个async，await的意思是：如果task前面有await，那么程序会暂停直到拿到task的返回值或task结束运行之后才会继续。而如果task前面没有await，意味着在它被创建的时候程序可以继续运行之后的代码，只要它们不依靠task的结果。所以我们可以创建10个没有await的task，最后在一起await然后output。</li></ul><p><img src="/../images/Create-a-Restful-api-using-C-Sharp/11.png" alt="simultaneous api call" /></p><ul><li>这样的话虽然每次api call的时间比一次一次call要长很多但是如果计算500次call的总时间的话平行运算还是有优势的</li></ul><p><img src="/../images/Create-a-Restful-api-using-C-Sharp/12.png" alt="simultaneous api call time" /></p><ul><li>平行运算时每次api call的时间</li></ul><p><img src="/../images/Create-a-Restful-api-using-C-Sharp/13.png" alt="simultaneous call total time" /></p><ul><li>500次call的总时间，总共算了10次，基本在8秒左右</li></ul><p><img src="/../images/Create-a-Restful-api-using-C-Sharp/14.png" alt="single api call time" /></p><ul><li>单次运算时每次api call的时间</li></ul><p><img src="/../images/Create-a-Restful-api-using-C-Sharp/15.png" alt="single api call total time" /></p><ul><li><p>单次运算时每500次的总时间，总共算了10次，基本都超过了10秒</p></li><li><p>关于在api中加入basic authenticaiton：To access the web API method, we have to pass the user credentials in the request header. If we do not pass the user credentials in the request header, then the server returns 401 (unauthorized) status code indicating the server supports Basic Authentication.</p></li><li><p>新建一个class， inhert from IHttpModule，这样就可以让api support <a href="https://docs.microsoft.com/en-us/aspnet/web-api/overview/security/basic-authentication">basic authentication</a>了。但是我们还要让console在request中加入auth header。</p></li></ul><p><img src="/../images/Create-a-Restful-api-using-C-Sharp/16.png" alt="add authentication to header" /></p><ul><li>试了一下可以运行，那么这个task到现在就基本完成了。看看leader有什么别的要求再说吧。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> C# </tag>
            
            <tag> API </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
