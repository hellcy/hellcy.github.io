{"meta":{"title":"Hexo","subtitle":"","description":"","author":"Yuan Cheng","url":"http://hellcy.github.io","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2021-02-26T12:08:47.158Z","updated":"2021-02-26T12:08:47.158Z","comments":false,"path":"/404.html","permalink":"http://hellcy.github.io/404.html","excerpt":"","text":""},{"title":"书单","date":"2021-02-26T12:08:47.159Z","updated":"2021-02-26T12:08:47.159Z","comments":false,"path":"books/index.html","permalink":"http://hellcy.github.io/books/index.html","excerpt":"","text":""},{"title":"分类","date":"2021-02-26T12:08:47.159Z","updated":"2021-02-26T12:08:47.159Z","comments":false,"path":"categories/index.html","permalink":"http://hellcy.github.io/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2021-02-26T12:08:47.457Z","updated":"2021-02-26T12:08:47.457Z","comments":true,"path":"links/index.html","permalink":"http://hellcy.github.io/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2021-02-26T12:08:47.457Z","updated":"2021-02-26T12:08:47.457Z","comments":false,"path":"repository/index.html","permalink":"http://hellcy.github.io/repository/index.html","excerpt":"","text":""},{"title":"About","date":"2021-02-26T12:08:47.159Z","updated":"2021-02-26T12:08:47.159Z","comments":false,"path":"about/index.html","permalink":"http://hellcy.github.io/about/index.html","excerpt":"","text":""},{"title":"标签","date":"2021-02-26T12:08:47.457Z","updated":"2021-02-26T12:08:47.457Z","comments":false,"path":"tags/index.html","permalink":"http://hellcy.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Polymorphism in Java","slug":"Polymorphism-in-Java","date":"2022-02-10T05:16:18.000Z","updated":"2022-02-10T14:10:26.530Z","comments":true,"path":"2022/02/10/Polymorphism-in-Java/","link":"","permalink":"http://hellcy.github.io/2022/02/10/Polymorphism-in-Java/","excerpt":"","text":"编译时多态 设计时多态方法重载 运行时多态 程序运行时动态决定调用那个方法 必要条件 满足继承关系 父类引用指向子类对象 向上转型 父类引用指向子类实例，可以调用子类重写父类的方法以及父类派生的方法，无法调用子类独有的方法 父类中的静态方法无法被子类重写，所以向上转型之后，只能调用到父类原有的静态方法 向下转型 子类引用指向父类对象，此处可以使用instanceof进行检查，避免类型转换时的安全性问题 可以调用子类独有的方法 抽象类 abstract class 限制实例化 只能被继承 应用场景： 某个父类只是知道其子类应该包含怎样的方法，但无法准确知道这些子类如何实现这些方法 抽象方法 abstract method 不能有方法体 必须由子类实现 子类如果没有重写父类的所有抽象方法，则也要定义为抽象类 接口 Interface 当多个类具有相同能力的时候，可以使用接口抽象出相同的能力 接口定义了某一批类所需要遵守的规范 接口不关心这些类的内部数据，也不关心这些类里的方法的实现细节，它只规定这些类里必须提供某些方法 接口方法可以不写abstract关键字，并且默认为public的访问权限 当类实现接口时，需要去实现接口中的所有抽象方法，否则需要将该类设置为抽象类 接口中可以定义常量，默认为public static final 默认方法 自JDK1.8之后，接口中可以存在默认方法，使用default关键字定义 默认方法可以带方法体，子类实现接口时可以不用实现默认方法 子类可以重写默认方法，并可以通过接口的引用调用 静态方法 自JDK1.8之后，接口中可以存在静态方法，使用static关键字定义 静态方法可以带方法体，子类可以通过使用接口名访问接口的静态方法 多重实现 子类可以继承一个父类，但是可以实现多个接口 当多个接口中具有相同签名的方法时，子类需要重写方法 当父类和接口具有相同签名的方法时，父类方法具有优先权 当父类和接口具有相同名字的变量时，子类需要重新定义该变量，父类中的变量不具有优先权 接口的继承 接口也可以实现继承关系 接口可以继承多个父接口 1234567891011public interface ParentOne &#123;&#125;public interface ParentTwo &#123;&#125;public interface Child extends ParentOne, ParentTwo &#123;&#125; 内部类 内部类提供了更好的封装，不允许其他外部类访问内部类的信息 成员内部类 最常见的内部类，也称为普通内部类 内部类在外部使用时，无法直接实例化，需要借由外部类信息才能完成实例化 内部类的访问修饰符，可以是任意的，但是访问权限会受到修饰符的影响 内部类可以直接访问外部类的成员（包括成员属性和成员方法），如果出现同名属性，优先访问内部类中定义的 外部类访问内部类的信息需要通过内部类的实例，无法直接访问 内部类编译后得class文件名：外部类$内部类.class 获取内部类对象实例 new 外部类.new 内部类 1Person.Heart myHeart &#x3D; new Person().new Heart(); 外部类对象.new 内部类 1myHeart &#x3D; myPerson.new Heart(); 外部类对象.获取方法 1myHeart &#x3D; myPerson.getHeart(); 静态内部类 静态内部类中，只能直接访问外部类的静态成员 需要使用外部类的实例对象来访问非静态成员 访问静态内部类对象实例时，可以不依赖于外部类对象 获取静态内部类实例 1Person.Heart myHeart &#x3D; new Person.Heart(); 方法内部类 定义在外部类方法中的内部类，也成为局部内部类 方法内部类中无法定义静态成员 类中可以使用final，abstract成员 和方法内部成员使用规则一样，class前面不可以添加public，private，protected，static等关键字 匿名内部类 将类的定义和类的创建放在一起完成，程序只会用到一次类的实例，所以类名无关紧要 对于抽象类Person来说，如果我们想调用其中的抽象方法，一种做法是创建一个实现read方法的子类 但是如果这个子类只会被用到一次，那这个子类的名字就不重要，就可以使用匿名内部类来解决 123456789101112131415161718192021public abstract class Person &#123; public abstract void read();&#125;public class PersonTest &#123; public void getRead(Person person) &#123; person.read(); &#125; public static void main(String[] args) &#123; PersonTest personTest &#x3D; new PersonTest(); personTest.getRead(new Person() &#123; @Override public void read() &#123; System.out.println(&quot;implement read method in Person parent abstract class&quot;); &#125; &#125;) &#125;&#125;","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://hellcy.github.io/tags/Java/"}]},{"title":"TCP/IP","slug":"TCP-IP","date":"2021-05-26T06:17:17.000Z","updated":"2021-05-26T08:00:46.307Z","comments":true,"path":"2021/05/26/TCP-IP/","link":"","permalink":"http://hellcy.github.io/2021/05/26/TCP-IP/","excerpt":"","text":"","categories":[],"tags":[{"name":"TCP/IP","slug":"TCP-IP","permalink":"http://hellcy.github.io/tags/TCP-IP/"}]},{"title":"C# LINQ","slug":"C-LINQ","date":"2021-04-20T13:07:27.000Z","updated":"2021-05-24T07:27:02.658Z","comments":true,"path":"2021/04/20/C-LINQ/","link":"","permalink":"http://hellcy.github.io/2021/04/20/C-LINQ/","excerpt":"","text":"LINQ SQL-like syntax in C# and Visual Basic Query any type of collection (IEnumerable&lt;T&gt;) Query external data sources (xml, databases, JSON, CSV) SQL Query vs LINQ Query Syntax SQL LINQ SELECT * FROM Products FROM prod IN Products SELECT prod SELECT Name FROM Products FROM prod in Products SELECT prod.Name SELECT * FROM Products WHERE ListPrice &gt; 10 FROM prod in Products WHERE prod.ListPrice &gt; 10 SELECT prod Two LINQ Syntaxes Query Method FROM prod in Products SELECT prod Products.Select(prod =&gt; prod) FROM prod in Products SELECT prod.Name Products.Select(prod =&gt; prod.Name) FROM prod in Products WHERE prod.ListPrice &gt; 10 SELECT prod Products.Where(prod =&gt; prod.ListPrice &gt; 10).Select(prod =&gt; prod) LINQ Operations Select Projection (Change shape, select only certain properties from an object) Order (ascending/descending) Get an Element (find, first, last, single) Filter (where) Iteration/Partioning (foreach, skip, take) Quantify (any, all, contains) Set Comparison (equal, except, intersection) Set Operations (union, concat) Joining (inner joins, outer joins) Grouping (groupby, subquery, groupjoin) Distinct Sets (distinct) Aggregation (count, sum, min, max, average) Select and Order Operations Projection (only select specific columns from an object) 123456789101112131415161718192021if (UseQuerySyntax)&#123; &#x2F;&#x2F; Query Syntax Products &#x3D; (from prod in Products select new Product &#123; ProductID &#x3D; prod.ProductID, Name &#x3D; prod.Name, Size &#x3D; prod.Size, &#125;).ToList();&#125;else&#123; &#x2F;&#x2F; Method Syntax Products &#x3D; Products.Select(prod &#x3D;&gt; new Product &#123; ProductID &#x3D; prod.ProductID, Name &#x3D; prod.Name, Size &#x3D; prod.Size &#125;).ToList();&#125; Projection with Anonymous Class 12345678910111213141516171819202122232425262728293031323334353637if (UseQuerySyntax)&#123; &#x2F;&#x2F; Query Syntax var products &#x3D; (from prod in Products select new &#123; Identifier &#x3D; prod.ProductID, ProductName &#x3D; prod.Name, ProductSize &#x3D; prod.Size &#125;); &#x2F;&#x2F; Loop through anonymous class foreach (var prod in products) &#123; sb.AppendLine($&quot;Product ID: &#123;prod.Identifier&#125;&quot;); sb.AppendLine($&quot; Product Name: &#123;prod.ProductName&#125;&quot;); sb.AppendLine($&quot; Product Size: &#123;prod.ProductSize&#125;&quot;); &#125;&#125;else&#123; &#x2F;&#x2F; Method Syntax var products &#x3D; Products.Select(prod &#x3D;&gt; new &#123; Identifier &#x3D; prod.ProductID, ProductName &#x3D; prod.Name, ProductSize &#x3D; prod.Size &#125;); &#x2F;&#x2F; Loop through anonymous class foreach (var prod in products) &#123; sb.AppendLine($&quot;Product ID: &#123;prod.Identifier&#125;&quot;); sb.AppendLine($&quot; Product Name: &#123;prod.ProductName&#125;&quot;); sb.AppendLine($&quot; Product Size: &#123;prod.ProductSize&#125;&quot;); &#125;&#125; Ordering Data When using Method Syntax to order data, the .Select() method is optional when you are simply selecting the complete object as the return value 123456789101112131415public void OrderBy()&#123; if (UseQuerySyntax) &#123; &#x2F;&#x2F; Query Syntax Products &#x3D; (from prod in Products orderby prod.Name select prod).ToList(); &#125; else &#123; &#x2F;&#x2F; Method Syntax Products &#x3D; Products.OrderBy(prod &#x3D;&gt; prod.Name).ToList(); &#125; ResultText &#x3D; $&quot;Total Products: &#123;Products.Count&#125;&quot;;&#125; Order by Descending 123456789101112131415public void OrderByDescending()&#123; if (UseQuerySyntax) &#123; &#x2F;&#x2F; Query Syntax Products &#x3D; (from prod in Products orderby prod.Name descending select prod).ToList(); &#125; else &#123; &#x2F;&#x2F; Method Syntax Products &#x3D; Products.OrderByDescending(prod &#x3D;&gt; prod.Name).ToList(); &#125; ResultText &#x3D; $&quot;Total Products: &#123;Products.Count&#125;&quot;;&#125; Order by Two Fields 123456789101112131415public void OrderByTwoFields()&#123; if (UseQuerySyntax) &#123; &#x2F;&#x2F; Query Syntax Products &#x3D; (from prod in Products orderby prod.Color descending, prod.Name).ToList(); &#125; else &#123; &#x2F;&#x2F; Method Syntax Products &#x3D; Products.OrderByDescending(prod &#x3D;&gt; prod.Color).ThenBy(prod &#x3D;&gt; prod.Name).ToList(); &#125; ResultText &#x3D; $&quot;Total Products: &#123;Products.Count&#125;&quot;;&#125; Extract Multiple or Single Elements Where Expression 123456789101112131415161718public void WhereExpression()&#123; string search &#x3D; &quot;L&quot;; if (UseQuerySyntax) &#123; &#x2F;&#x2F; Query Syntax Products &#x3D; (from prod in Products where prod.Name.StartsWith(search) select prod).ToList(); &#125; else &#123; &#x2F;&#x2F; Method Syntax Products &#x3D; Products.Where(prod &#x3D;&gt; prod.Name.StartsWith(search)).ToList(); &#125; ResultText &#x3D; $&quot;Total Products: &#123;Products.Count&#125;&quot;;&#125; Where with multiple fields 123456789101112131415161718public void WhereTwoFields()&#123; string search &#x3D; &quot;L&quot;; decimal cost &#x3D; 100; if (UseQuerySyntax) &#123; &#x2F;&#x2F; Query Syntax Products &#x3D; (from prod in Products where prod.Name.StartsWith(search) &amp;&amp; prod.StandardCost &gt; cost).ToList(); &#125; else &#123; &#x2F;&#x2F; Method Syntax Products &#x3D; Products.Where(prod &#x3D;&gt; prod.Name.StartsWith(search) &amp;&amp; prod.StandardCost &gt; cost).ToList(); &#125; ResultText &#x3D; $&quot;Total Products: &#123;Products.Count&#125;&quot;;&#125; Using Custom Extension Method Extension Method Extension methods enable you to “add” methods to existing types without creating a new derived type, recompiling, or otherwise modifying the original type. Extension methods are static methods, but they’re called as if they were instance methods on the extended type. The most common extension methods are the LINQ standard query operators that add query functionality to the existing System.Collections.IEnumerable and System.Collections.Generic.IEnumerable&lt;T&gt; types. Extension methods are defined as static methods but are called by using instance method syntax. Their first parameter specifies which type the method operates on. The parameter is preceded by the this modifier. Extension method is just a static method under the hood. In the example, the result of (from prod in Products select prod) is an IEnumerable&lt;Product&gt; which is why ByColor() can be applied to this 12345678910111213141516public static IEnumerable&lt;Product&gt; ByColor( this IEnumerable&lt;Product&gt; query, string color)&#123; return query.Where(prod &#x3D;&gt; prod.Color &#x3D;&#x3D; color);&#125;if (UseQuerySyntax)&#123; &#x2F;&#x2F; Query Syntax Products &#x3D; (from prod in Products select prod).ByColor(search).ToList();&#125;else&#123; &#x2F;&#x2F; Method Syntax Products &#x3D; Products.ByColor(search).ToList();&#125; Select a Single Item First, will throw an Exception if item not found. Last, same as First 12345678910111213141516171819try&#123; if (UseQuerySyntax) &#123; &#x2F;&#x2F; Query Syntax value &#x3D; (from prod in Products select prod).First(prod &#x3D;&gt; prod.Color &#x3D;&#x3D; search); &#125; else &#123; &#x2F;&#x2F; Method Syntax value &#x3D; Products.First(prod &#x3D;&gt; prod.Color &#x3D;&#x3D; search); &#125; ResultText &#x3D; $&quot;Found: &#123;value&#125;&quot;;&#125;catch&#123; ResultText &#x3D; &quot;Not Found&quot;;&#125; FirstOrDefault, value will be null if item not found, will not throw an Exception LastOrDefault, same as FirstOrDefault 12345678910111213141516171819if (UseQuerySyntax)&#123; &#x2F;&#x2F; Query Syntax value &#x3D; (from prod in Products select prod).First(prod &#x3D;&gt; prod.Color &#x3D;&#x3D; search);&#125;else&#123; &#x2F;&#x2F; Method Syntax value &#x3D; Products.First(prod &#x3D;&gt; prod.Color &#x3D;&#x3D; search);&#125;if (value &#x3D;&#x3D; null)&#123; ResultText &#x3D; &quot;Not Found&quot;;&#125;else&#123; ResultText &#x3D; $&quot;Found: &#123;value&#125;&quot;;&#125; Single, will throw an Exception if item not found or multiple items found. Single is supposed to be used to found a unique item, like primary key. The Exception thrown if multiple items are found is InvalidOperationException. 12345678910111213141516171819try&#123; if (UseQuerySyntax) &#123; &#x2F;&#x2F; Query Syntax value &#x3D; (from prod in Products select prod).Single(prod &#x3D;&gt; prod.ProductID &#x3D;&#x3D; search); &#125; else &#123; &#x2F;&#x2F; Method Syntax value &#x3D; Products.Single(prod &#x3D;&gt; prod.ProductID &#x3D;&#x3D; search); &#125; ResultText &#x3D; $&quot;Found: &#123;value&#125;&quot;;&#125;catch&#123; ResultText &#x3D; &quot;Not Found, or multiple elements found&quot;;&#125; SingleOrDefault, value will be NULL if no item found, but will still throw an Exception if multiple items found. 1234567891011121314151617181920212223242526try&#123; if (UseQuerySyntax) &#123; &#x2F;&#x2F; Query Syntax value &#x3D; (from prod in Products select prod).SingleOrDefault(prod &#x3D;&gt; prod.ProductID &#x3D;&#x3D; search); &#125; else &#123; &#x2F;&#x2F; Method Syntax value &#x3D; Products.SingleOrDefault(prod &#x3D;&gt; prod.ProductID &#x3D;&#x3D; search); &#125; if (value &#x3D;&#x3D; null) &#123; ResultText &#x3D; &quot;Not Found&quot;; &#125; else &#123; ResultText &#x3D; $&quot;Found: &#123;value&#125;&quot;; &#125;&#125;catch&#123; ResultText &#x3D; &quot;Multiple elements found&quot;;&#125; Extract Distinct Values, Assign Values and Partition Collections Set Operations Iterate over entire collection Set a property value in collection (similar to a SQL UPDATE) In this example, the object has a NameLength property and we need to assign the value prop.Name.Length to this prop.NameLength property. For the Query approach, we need to declare a tmp variable because it has to be a statement, not an assignment. But the Method approach doesn’t have this issue. 123456789101112131415161718public void ForEach()&#123; if (UseQuerySyntax) &#123; &#x2F;&#x2F; Query Syntax Products &#x3D; (from prod in Products let tmp &#x3D; prod.NameLength &#x3D; prod.Name.Length select prod).ToList(); &#125; else &#123; &#x2F;&#x2F; Method Syntax Products.ForEach(prod &#x3D;&gt; prod.NameLength &#x3D; prod.Name.Length); &#125; ResultText &#x3D; $&quot;Total Products: &#123;Products.Count&#125;&quot;;&#125; In this example we have a Sales object, and we need to calculate how many item we have sold for a certain product. 12345private decimal SalesForProduct(Product prod)&#123; return Sales.Where(sale &#x3D;&gt; sale.ProductID &#x3D;&#x3D; prod.ProductID) .Sum(sale &#x3D;&gt; sale.LineTotal);&#125; We could then use this to set the TotalSales property for each Product 123456789101112if (UseQuerySyntax)&#123; &#x2F;&#x2F; Query Syntax Products &#x3D; (from prod in Products let tmp &#x3D; prod.TotalSales &#x3D; SalesForProduct(prod) select prod).ToList();&#125;else&#123; &#x2F;&#x2F; Method Syntax Products.ForEach(prod &#x3D;&gt; prod.TotalSales &#x3D; SalesForProduct(prod));&#125; Take Specific Amount of Elements Take the first 5 elements from the list 123456789101112if (UseQuerySyntax)&#123; &#x2F;&#x2F; Query Syntax Products &#x3D; (from prod in Products orderby prod.Name select prod).Take(5).ToList();&#125;else&#123; &#x2F;&#x2F; Method Syntax Products &#x3D; Products.OrderBy(prod &#x3D;&gt; prod.Name).Take(5).ToList();&#125; TakeWhile(): take elements while condition is true 123456789101112if (UseQuerySyntax)&#123; &#x2F;&#x2F; Query Syntax Products &#x3D; (from prod in Products orderby prod.Name select prod).TakeWhile(prod &#x3D;&gt; prod.Name.StartsWith(&quot;A&quot;)).ToList();&#125;else&#123; &#x2F;&#x2F; Method Syntax Products &#x3D; Products.OrderBy(prod &#x3D;&gt; prod.Name).TakeWhile(prod &#x3D;&gt; prod.Name.StartsWith(&quot;A&quot;)).ToList();&#125; Skip specific amount of elements 123456789101112if (UseQuerySyntax)&#123; &#x2F;&#x2F; Query Syntax Products &#x3D; (from prod in Products orderby prod.Name select prod).Skip(20).ToList();&#125;else&#123; &#x2F;&#x2F; Method Syntax Products &#x3D; Products.OrderBy(prod &#x3D;&gt; prod.Name).Skip(20).ToList();&#125; Skip elements while condition is true 123456789101112if (UseQuerySyntax)&#123; &#x2F;&#x2F; Query Syntax Products &#x3D; (from prod in Products orderby prod.Name select prod).SkipWhile(prod &#x3D;&gt; prod.Name.StartsWith(&quot;A&quot;)).ToList();&#125;else&#123; &#x2F;&#x2F; Method Syntax Products &#x3D; Products.OrderBy(prod &#x3D;&gt; prod.Name).SkipWhile(prod &#x3D;&gt; prod.Name.StartsWith(&quot;A&quot;)).ToList();&#125; Select Distinct Values 12345678910if (UseQuerySyntax)&#123; &#x2F;&#x2F; Query Syntax colors &#x3D; (from prod in Products select prod.Color).Distinct().ToList();&#125;else&#123; &#x2F;&#x2F; Method Syntax colors &#x3D; Products.Select(prod &#x3D;&gt; prod.Color).Distinct().ToList();&#125; Identify What Kind of Data is Contained in Collections All() will return a true or false value to see if all items meet the requirement. 12345678910if (UseQuerySyntax)&#123; &#x2F;&#x2F; Query Syntax value &#x3D; (from prod in Products select prod).All(prod &#x3D;&gt; prod.Name.Contains(search));&#125;else&#123; &#x2F;&#x2F; Method Syntax value &#x3D; Products.All(prod &#x3D;&gt; prod.Name.Contains(search));&#125; Any() will return true if any of the item meet the requirement. And will return false will all items doesn’t meet the requirement. 12345678910if (UseQuerySyntax)&#123; &#x2F;&#x2F; Query Syntax value &#x3D; (from prod in Products select prod).Any(prod &#x3D;&gt; prod.Name.Contains(search));&#125;else&#123; &#x2F;&#x2F; Method Syntax value &#x3D; Products.Any(prod &#x3D;&gt; prod.Name.Contains(search));&#125; Contains can be used in primitive types and objects 12345678910111213bool value &#x3D; true;List&lt;int&gt; numbers &#x3D; new List&lt;int&gt; &#123; 1, 2, 3, 4, 5 &#125;;if (UseQuerySyntax)&#123; &#x2F;&#x2F; Query Syntax value &#x3D; (from num in numbers select num).Contains(3);&#125;else&#123; &#x2F;&#x2F; Method Syntax value &#x3D; numbers.Contains(3);&#125; When using Contains() on a collection of objects. We need to use EqualityComparer, because by default objects are compared by reference not value. 123456789public class ProductIdComparer : EqualityComparer&lt;Product&gt; &#123; public override bool Equals(Product x, Product y) &#123; return (x.ProductID &#x3D;&#x3D; y.ProductID); &#125;&#125;public override int GetHashCode(Product obj) &#123; return obj.ProductID.GetHashCode();&#125; Now when calling Contains() method, we pass in the Comparer object, so it will loop through all products and compare each one with our prodToFind Product. The Comparer will use prodToFind as the first parameter and each Product as the second parameter. 123456789101112131415int search &#x3D; 744;bool value &#x3D; true;ProductIdComparer pc &#x3D; new ProductIdComparer();Product prodToFind &#x3D; new Product &#123; ProductID &#x3D; search &#125;;if (UseQuerySyntax)&#123; &#x2F;&#x2F; Query Syntax value &#x3D; (from prod in Products select prod).Contains(prodToFind, pc);&#125;else&#123; &#x2F;&#x2F; Method Syntax value &#x3D; Products.Contains(prodToFind, pc);&#125; Compare and Union Two Collections SequenceEqual() Compares two collections for equlity. For Simple data types (int, decimal, boolean…) it checks values For object data types checks reference If you want to compare values in objects, you need to create a comparer class to check the values inside each properties. 1234567891011121314151617&#x2F;&#x2F; Use SequenceEqual on primitivesbool value &#x3D; true;&#x2F;&#x2F; Create a list of numbersList&lt;int&gt; list1 &#x3D; new List&lt;int&gt; &#123; 1, 2, 3, 4, 5 &#125;;&#x2F;&#x2F; Create a list of numbersList&lt;int&gt; list2 &#x3D; new List&lt;int&gt; &#123; 1, 2, 3, 4, 5 &#125;;if (UseQuerySyntax)&#123; &#x2F;&#x2F; Query Syntax value &#x3D; (from num in list1 select num).SequenceEqual(list2);&#125;else&#123; &#x2F;&#x2F; Method Syntax value &#x3D; list1.SequenceEqual(list2);&#125; If we want to compare each object in a collection by value, we need to create a new Comparer override the Compare method. 1234567891011121314151617181920bool value &#x3D; true;ProductComparer pc &#x3D; new ProductComparer();&#x2F;&#x2F; Load all Product DataList&lt;Product&gt; list1 &#x3D; ProductRepository.GetAll();&#x2F;&#x2F; Load all Product DataList&lt;Product&gt; list2 &#x3D; ProductRepository.GetAll();&#x2F;&#x2F; Remove an element from &#39;list1&#39; to make the collections differentlist1.RemoveAt(0);if (UseQuerySyntax)&#123; &#x2F;&#x2F; Query Syntax value &#x3D; (from num in list1 select num).SequenceEqual(list2, pc);&#125;else&#123; &#x2F;&#x2F; Method Syntax value &#x3D; list1.SequenceEqual(list2, pc);&#125; Except It finds all values in one list, but not the other, returns a collection of items. Similar to Contains and SequenceEqual, if we are comparing primitive types, we can just use it, but if we are comparing objects values, we need to create a Comparer class and override the Compare method. 12345678910111213141516List&lt;int&gt; exceptions &#x3D; new List&lt;int&gt;();&#x2F;&#x2F; Create a list of numbersList&lt;int&gt; list1 &#x3D; new List&lt;int&gt; &#123; 1, 2, 3, 4 &#125;;&#x2F;&#x2F; Create a list of numbersList&lt;int&gt; list2 &#x3D; new List&lt;int&gt; &#123; 3, 4, 5 &#125;;if (UseQuerySyntax)&#123; &#x2F;&#x2F; Query Syntax exceptions &#x3D; (from num in list1 select num).Except(list2).ToList();&#125;else&#123; &#x2F;&#x2F; Method Syntax exceptions &#x3D; list1.Except(list2).ToList();&#125; Using Except on a collection of objects 1234567891011121314151617181920ProductComparer pc &#x3D; new ProductComparer();&#x2F;&#x2F; Load all Product DataList&lt;Product&gt; list1 &#x3D; ProductRepository.GetAll();&#x2F;&#x2F; Load all Product DataList&lt;Product&gt; list2 &#x3D; ProductRepository.GetAll();&#x2F;&#x2F; Remove all products with color &#x3D; &quot;Black&quot; from &#39;list2&#39;&#x2F;&#x2F; to give us a difference in the two listslist2.RemoveAll(prod &#x3D;&gt; prod.Color &#x3D;&#x3D; &quot;Black&quot;);if (UseQuerySyntax)&#123; &#x2F;&#x2F; Query Syntax Products &#x3D; (from prod in list1 select prod).Except(list2, pc).ToList();&#125;else&#123; &#x2F;&#x2F; Method Syntax Products &#x3D; list1.Except(list2, pc).ToList();&#125; Intersect It finds all values in common between both lists Similar to Contains, SequenceEqual and Except, it compares values for primitive types and references for objects. We need to create comparer class to check values in properties. 123456789101112131415161718192021ProductComparer pc &#x3D; new ProductComparer();&#x2F;&#x2F; Load all Product DataList&lt;Product&gt; list1 &#x3D; ProductRepository.GetAll();&#x2F;&#x2F; Load all Product DataList&lt;Product&gt; list2 &#x3D; ProductRepository.GetAll();&#x2F;&#x2F; Remove &#39;black&#39; products from &#39;list1&#39;list1.RemoveAll(prod &#x3D;&gt; prod.Color &#x3D;&#x3D; &quot;Black&quot;);&#x2F;&#x2F; Remove &#39;red&#39; products from &#39;list2&#39;list2.RemoveAll(prod &#x3D;&gt; prod.Color &#x3D;&#x3D; &quot;Red&quot;);if (UseQuerySyntax)&#123; &#x2F;&#x2F; Query Syntax Products &#x3D; (from num in list1 select num).Intersect(list2, pc).ToList();&#125;else&#123; &#x2F;&#x2F; Method Syntax Products &#x3D; list1.Intersect(list2, pc).ToList();&#125; Unions It adds the contents of two lists together. Union() checks for duplicates Concat() does not check for duplicates Use comparer class with objects Union() need Comparer to eliminate duplicates 12345678910111213141516ProductComparer pc &#x3D; new ProductComparer();&#x2F;&#x2F; Load all Product DataList&lt;Product&gt; list1 &#x3D; ProductRepository.GetAll();&#x2F;&#x2F; Load all Product DataList&lt;Product&gt; list2 &#x3D; ProductRepository.GetAll();if (UseQuerySyntax)&#123; &#x2F;&#x2F; Query Syntax Products &#x3D; (from num in list1 select num).Union(list2, pc).OrderBy(prod &#x3D;&gt; prod.Name).ToList();&#125;else&#123; &#x2F;&#x2F; Method Syntax Products &#x3D; list1.Union(list2, pc).OrderBy(prod &#x3D;&gt; prod.Name).ToList();&#125; Concat() Adds the contents of two collections with duplicates 123456789101112131415&#x2F;&#x2F; Load all Product DataList&lt;Product&gt; list1 &#x3D; ProductRepository.GetAll();&#x2F;&#x2F; Load all Product DataList&lt;Product&gt; list2 &#x3D; ProductRepository.GetAll();if (UseQuerySyntax)&#123; &#x2F;&#x2F; Query Syntax Products &#x3D; (from num in list1 select num).Concat(list2).OrderBy(prod &#x3D;&gt; prod.Name).ToList();&#125;else&#123; &#x2F;&#x2F; Method Syntax Products &#x3D; list1.Concat(list2).OrderBy(prod &#x3D;&gt; prod.Name).ToList();&#125; Joining Two Collections Together Inner Join 12345678910111213var query &#x3D; Products.Join(Sales, prod &#x3D;&gt; prod.ProductID, sale &#x3D;&gt; sale.ProductID, (prod, sale) &#x3D;&gt; new&#123; prod.ProductID, prod.Name, prod.Color, prod.StandardCost, prod.ListPrice, prod.Size, sale.SalesOrderID, sale.OrderQty, sale.UnitPrice, sale.LineTotal,&#125;); Inner Join with two fields 12345678910111213141516171819short qty &#x3D; 6;var query &#x3D; Products.Join( Sales, prod &#x3D;&gt; new &#123; prod.ProductID, Qty &#x3D; qty &#125;, sale &#x3D;&gt; new &#123; sale.ProductID, Qty &#x3D; sale.OrderQty &#125;, (prod, sale) &#x3D;&gt; new &#123; prod.ProductID, prod.Name, prod.Color, prod.StandardCost, prod.ListPrice, prod.Size, sale.SalesOrderID, sale.OrderQty, sale.UnitPrice, sale.LineTotal &#125;); Aggregating Data in Collections Count() 1234value &#x3D; Products.Count(prod &#x3D;&gt; prod.Color &#x3D;&#x3D; &quot;Yellow&quot;);&#x2F;&#x2F; Another way using Wherevalue &#x3D; Products.Where(prod &#x3D;&gt; prod.Color &#x3D;&#x3D; &quot;Yellow&quot;).Count(); Min() and Max() 1value &#x3D; Products.Min(prod &#x3D;&gt; prod.ListPrice); 1value &#x3D; Products.Max(prod &#x3D;&gt; prod.ListPrice); Average() and Sum() 1value &#x3D; Products.Average(prod &#x3D;&gt; prod.ListPrice); 1value &#x3D; Products.Sum(prod &#x3D;&gt; prod.ListPrice); Custom Calculation using Aggregate() The first parameter initialize an internal variable, which setup the start value. The second parameter is an anonymous function which you pass the initial value and loop through each item in the collection Aggregate Sum 1value &#x3D; Products.Aggregate(0m, (sum, prod) &#x3D;&gt; sum +&#x3D; prod.ListPrice); Aggregate Multiply 1value &#x3D; Products.Aggregate(0m, (sum, prod &#x3D;&gt; sum +&#x3D; prod.ListPrice * prod.Qty)); Aggregate with GroupBy and Having 1234567891011var stats &#x3D; Products.GroupBy(sale &#x3D;&gt; sale.Size) .Where(sizeGroup &#x3D;&gt; sizeGroup.Count() &gt; 0) .Select(sizeGroup &#x3D;&gt; new &#123; Size &#x3D; sizeGroup.Key, TotalProducts &#x3D; sizeGroup.Count(), Max &#x3D; sizeGroup.Max(s &#x3D;&gt; s.ListPrice), Min &#x3D; sizeGroup.Min(s &#x3D;&gt; s.ListPrice), Average &#x3D; sizeGroup.Average(s &#x3D;&gt; s.ListPrice) &#125;) .OrderBy(result &#x3D;&gt; result.Size) .Select(result &#x3D;&gt; result); Deferred Execution A LINQ query is a data structure ready to execute Query is not executed until a value is needed The execution happens with one of the folloing functions (foreach(), Count(), ToList(), OrderBy()…) Streaming Operators Results can be returned prior to the entire collection is read Examples: Distinct(), GroupBy(), Join(), Select(), Skip(), Take(), Union(), Where() Non-Streaming Operators All data in collection must be read before a result can be returned Examples: Except(), GroupBy(), GroupJoin(), Intersect(), Join(), OrderBy(), ThenBy() The yield keyword When write our own Filter function, we could use yield to make the function to be Streaming. So it returns data while looping through the collection. 1234567public static IEnumrable&lt;T&gt; Filter&lt;T&gt; (this IEnumrable&lt;T&gt; source, Func&lt;T, bool&gt; predicate) &#123; foreach(var item in source) &#123; if (predicate(item)) &#123; yield return item; &#125; &#125;&#125; In the below example, Where and Take are both Streaming Operators, so this query will loop through the collection until the requirement is met. That is when it found the first item that has Color red. It doesn’t need to go through the entire collection. 1Products &#x3D; Products.Where(prod &#x3D;&gt; prod.Color &#x3D;&#x3D; &quot;red&quot;).Take(1).ToList(); However, in this example, because OrderBy() is an non-streaming operator, so it will loop through the entire list first, order them by prod.Name, then apply the Where condition. Non-streaming operator will go before the Streaming operator. 1Products &#x3D; Products.Where(prod &#x3D;&gt; prod.Color &#x3D;&#x3D; &quot;red&quot;).OrderBy(prod &#x3D;&gt; prod.Name).ToList();","categories":[],"tags":[{"name":"LINQ","slug":"LINQ","permalink":"http://hellcy.github.io/tags/LINQ/"}]},{"title":"Entity Framework Core 5","slug":"Entity-Framework-Core-5","date":"2021-04-20T12:54:33.000Z","updated":"2021-05-24T07:27:02.659Z","comments":true,"path":"2021/04/20/Entity-Framework-Core-5/","link":"","permalink":"http://hellcy.github.io/2021/04/20/Entity-Framework-Core-5/","excerpt":"","text":"Microsoft’s cross-platform data access framework for .NET ORM (Object Relational Mapper) EF Core is an ORM, it is designed to reduce the friction between how data is structure in a relational database and how you define your classes. Without ORM, we need to write lots of code to transform database results to instances of the types in our software.","categories":[],"tags":[{"name":"Entity Framework","slug":"Entity-Framework","permalink":"http://hellcy.github.io/tags/Entity-Framework/"}]},{"title":"Building GraphQL APIs with ASP.NET Core","slug":"Building-GraphQL-APIs-with-ASP-NET-Core","date":"2021-04-20T12:21:54.000Z","updated":"2021-05-24T07:27:02.657Z","comments":true,"path":"2021/04/20/Building-GraphQL-APIs-with-ASP-NET-Core/","link":"","permalink":"http://hellcy.github.io/2021/04/20/Building-GraphQL-APIs-with-ASP-NET-Core/","excerpt":"","text":"The consumer of a GraphQL API defines the data structure it want to receive in a query First, let us see how a REST API works. On the far right, there is data, for example in the form of a database, and there are entity classes. Each instance of an entity class represents one row of data in the table. An object-relational mapper like Entity Framework may take care of instantiating and populating these objects, but you don’t want to expose these entities directly. So they are converted to models or data transfer objects, objects that have a data structure that is easy to consume for clients, and maybe have some validation built in using attributes. Once you have the model, it’s the controller’s job to make it available to the outside world. There’s typically a controller for each type of model. For example, it could be a product controller, an order controller, etc. What controller is activated when a request comes in is determined by routing, which maps the URL to a certain controller, and all of these controllers react to HTTP methods. Each HTTP method triggers a different operation in the controller. A GET gets data, a POST introduces new data, etc. So there are typically quite a few controllers that have quite a few operations. With GraphQL, there are typically no models, there is something called Schema. This Schema declares what a consumer of the API can access. The Schema also knows how to get the data. The API support GET or POST request, and there is always a query in the request. Queries Determines what happens in the API Not tied to HTTP. HTTP is just a transport used to get the quert to the API Downside: HTTP Caching: when using HTTP, because now each request is not at a unique URL anymore, it is now difficult to do HTTP caching.","categories":[],"tags":[{"name":"GraphQL","slug":"GraphQL","permalink":"http://hellcy.github.io/tags/GraphQL/"}]},{"title":"Design Patterns - Repository","slug":"Design-Patterns-Repository","date":"2021-04-19T06:44:53.000Z","updated":"2021-05-24T07:27:02.659Z","comments":true,"path":"2021/04/19/Design-Patterns-Repository/","link":"","permalink":"http://hellcy.github.io/2021/04/19/Design-Patterns-Repository/","excerpt":"","text":"A repository encapsulates the data access so the consumer on longer has to know about the underlying data structure Why this Design is Problematic The controller is tightly coupled with the data access layer it is difficult to write a test for the controller without side effects Hard to extend entities with domain specific behavior Benefits of the Repository Pattern The consumer(controller) is now separated (decoupled) from the data access Easy to write a test without side-effects In production, we use the Repository Pattern to communicate with the Data layer. In Test, we replace the Repository with a faked local Data store. This can be done using Strategy Pattern. Modify and extend entities before they are passed on to the consumer A sharable abstraction resulting in less duplication of code Improved maintainability","categories":[],"tags":[{"name":"Design Patterns","slug":"Design-Patterns","permalink":"http://hellcy.github.io/tags/Design-Patterns/"}]},{"title":"Design Patterns - Proxy","slug":"Design-Patterns-Proxy","date":"2021-04-19T04:19:43.000Z","updated":"2021-05-24T07:27:02.659Z","comments":true,"path":"2021/04/19/Design-Patterns-Proxy/","link":"","permalink":"http://hellcy.github.io/2021/04/19/Design-Patterns-Proxy/","excerpt":"","text":"Problem Need to control access to a type for performance, security or other reasons. Client should not know if they were calling the real service or a proxy. Proxy also gives us time to do necessary things before sending request to real service and before sending response back to client.(like logging, caching, encrypt/decrypt…) Proxy has similar structure as the Decorator Pattern, but the intent is different, Decorator pattern is for adding extra funcationalities to the original class whereas Proxy is focusing on control the access to the object. This is another implementation of the Proxy Pattern, it doesn’t have the interface so we need to compose the RealService object in Proxy Class. One thing to notice is that the RealService properties and methods need to be marked as virtual for the Proxy Class to override them. Proxy Variants Virtual Proxy stand in for expensive to create objects Remote Proxy Hide the detail to work with remote data or services. Smart Proxy Performs additional actions when a resource is accessed Protective Proxy controls access to a sensitive resource by checking for whether or not the client is authorized to perform those operations. Virtual Proxy Stands in for an expensive-to-create object. Typically responsible for getting real object. UI placeholders. Lazy-loaded Entity Properties. 123456789101112131415public class ExpensiveToFullyLoad : BaseClassWithHistory&#123; public static ExpensiveToFullyLoad Create() &#123; return new VirtualExpensiveToFullyLoad(); &#125; public virtual IEnumerable&lt;ExpensiveEntity&gt; HomeEntities &#123; get; protected set; &#125; public virtual IEnumerable&lt;ExpensiveEntity&gt; AwayEntities &#123; get; protected set; &#125; protected ExpensiveToFullyLoad() &#123; History.Add(&quot;Constructor called.&quot;); &#125;&#125; When you have some expensive properties. You don’t want to create them when you don’t need them. So we could create a Proxy Class(VirtualExpensiveToFullyLoad), which will only create the property when its getting called. 12345678910111213141516171819202122232425262728public class VirtualExpensiveToFullyLoad : ExpensiveToFullyLoad&#123; public override IEnumerable&lt;ExpensiveEntity&gt; AwayEntities &#123; get &#123; if(base.AwayEntities &#x3D;&#x3D; null) &#123; base.AwayEntities &#x3D; ExpensiveDataSource.GetEntities(this); &#125; return base.AwayEntities; &#125; protected set &#x3D;&gt; base.AwayEntities &#x3D; value; &#125; public override IEnumerable&lt;ExpensiveEntity&gt; HomeEntities &#123; get &#123; if (base.HomeEntities &#x3D;&#x3D; null) &#123; base.HomeEntities &#x3D; ExpensiveDataSource.GetEntities(this); &#125; return base.HomeEntities; &#125; protected set &#x3D;&gt; base.HomeEntities &#x3D; value; &#125;&#125; When we test the class, we can see object history will only increase after we get the Entities from the class. 123456789101112[Fact]public void LogsCollectionLoadingToHistory()&#123; var obj &#x3D; ExpensiveToFullyLoad.Create(); var list &#x3D; obj.HomeEntities; Assert.Equal(2, obj.History.Count()); var anotherList &#x3D; obj.AwayEntities; Assert.Equal(3, obj.History.Count());&#125; We could also use the C# Lazy&lt;T&gt; type which will handle the lazy instantiation and thread-safe for use 123456789101112131415public class LazyExpensiveToFullyLoad : BaseClassWithHistory&#123; private Lazy&lt;IEnumerable&lt;ExpensiveEntity&gt;&gt; _homeEntities; public IEnumerable&lt;ExpensiveEntity&gt; HomeEntities &#123; get &#123; return _homeEntities.Value; &#125; &#125; private Lazy&lt;IEnumerable&lt;ExpensiveEntity&gt;&gt; _awayEntities; public IEnumerable&lt;ExpensiveEntity&gt; AwayEntities &#123; get &#123; return _awayEntities.Value; &#125; &#125; public LazyExpensiveToFullyLoad() &#123; History.Add(&quot;Constructor called.&quot;); _homeEntities &#x3D; new Lazy&lt;IEnumerable&lt;ExpensiveEntity&gt;&gt;(() &#x3D;&gt; ExpensiveDataSource.GetEntities(this)); _awayEntities &#x3D; new Lazy&lt;IEnumerable&lt;ExpensiveEntity&gt;&gt;(() &#x3D;&gt; ExpensiveDataSource.GetEntities(this)); &#125;&#125; Remote Proxy Client works with proxy as if remote resource were local. Hides network details from client. Centralizes knowledge of network details. Smart Proxy Performs additional logic around resource access. Example: Resource counting, Cache management, Locking shared resources Here we are trying to open the same file two times, normally this will throw an exception. 123456789101112var fs &#x3D; new FileSmartProxy();byte[] outputBytes1 &#x3D; Encoding.ASCII.GetBytes(&quot;1. ardalis.com\\n&quot;);byte[] outputBytes2 &#x3D; Encoding.ASCII.GetBytes(&quot;2. weeklydevtips.com\\n&quot;);using var file &#x3D; fs.OpenWrite(_testFile);using var file2 &#x3D; fs.OpenWrite(_testFile);file.Write(outputBytes1);file2.Write(outputBytes2);file.Close();file2.Close(); But we are using FileSmartProxy() Class, when we catch the exception, we will check if the file is already opened, and return the same reference to the file stream. 123456789101112131415161718192021222324252627public class FileSmartProxy : IFile&#123; Dictionary&lt;string, FileStream&gt; _openStreams &#x3D; new Dictionary&lt;string, FileStream&gt;(); public FileStream OpenWrite(string path) &#123; try &#123; var stream &#x3D; File.OpenWrite(path); _openStreams.Add(path, stream); return stream; &#125; catch (IOException) &#123; if(_openStreams.ContainsKey(path)) &#123; var stream &#x3D; _openStreams[path]; if(stream !&#x3D; null &amp;&amp; stream.CanWrite) &#123; return stream; &#125; &#125; throw; &#125; &#125;&#125; Protective Proxy Manages access to a resource based on authorization rules. Eliminates repetitive security checks from client code and othe resource itself. Acts as a gatekeeper around a resource Summary If we are not using the Proxy Pattern, we often end up mixing the concerns of access control, or lazy loading or other funcationality in the resource class itself. Every client the consume this class must perform this work. The concerns of access control are mixed with the concerns of client or the resource. Proxy Pattern helps us to separate this. Usually Proxy Pattern has built in class that support it.(Remote Proxy) Related Patterns Decorator: the structure is similar, but the intent of Decorator Pattern is to add funcationality. Whereas the intent of Proxy Pattern is to control access. Prototype: Prototype and Virtual Proxy Pattern both deal with objects that are expensive to create. But Virtual Proxy Pattern only provides a placeholder of the object and fetch it when required. The Prototype Pattern keeps a copy of the object on hand and can clone it when required. Adapter: similar structure, but the intent of the Adapter Pattern is to convert an incompatible interface into one that works for the client. Flyweight: designed to manage many reference to a shared instance.","categories":[],"tags":[{"name":"Design Patterns","slug":"Design-Patterns","permalink":"http://hellcy.github.io/tags/Design-Patterns/"}]},{"title":"Design Patterns - Adapter","slug":"Design-Patterns-Adapter","date":"2021-04-18T16:27:56.000Z","updated":"2021-05-24T07:27:02.658Z","comments":true,"path":"2021/04/19/Design-Patterns-Adapter/","link":"","permalink":"http://hellcy.github.io/2021/04/19/Design-Patterns-Adapter/","excerpt":"","text":"Problem Incompatible interfaces between a client and a service provider. Adapters convert the interface of one class into an interface a client expects. Two Kinds of Adapters Object Adapters Hold an instance of the Adaptee Implement or inherit the adapter type Use composition and single inheritance C# doesn’t support multiple inheritance, and a design principle of C# is to prefer composition over inheritance. So C# is prefer object adapter. The Client is calling method on an adapter abstraction(IAdapter). A specific adapter is created for each specific adaptee. Class Adapters Inherit from the adaptee Implement the adapter interface The Client is calling a target class’s particular method, but it wants to use a different implementation(incompatibleMethod) now. The adapter class inherits from both classes and overrides the SomeMethod() call, so that instead of doing what it did in the target class, it now calls the IncompatibleMethod() and does any work necessary to make it compatible with the SomeMethod() interface. What C# can do is to implement the interface the Client is calling and rather than holding onto an instance of the concrete adaptee type, we can inherit from it. SomeMethod() calls IncompetibleMethod() and does any necessary work to modify it to work with the SomeMethod() interface. Example: We are going to read a list of People and there are two ways of doing it. First, we could read People from a file. Second, we could call a Web API. IAdapter interface will only have a method, GetCharacters(), get it returns a list of Peoson 1234public interface ICharacterSourceAdapter&#123; Task&lt;IEnumerable&lt;Person&gt;&gt; GetCharacters();&#125; Get list of Person from a web API is easy. 1234567891011public async Task&lt;List&lt;Person&gt;&gt; GetCharacters()&#123; using (var client &#x3D; new HttpClient()) &#123; string url &#x3D; &quot;https:&#x2F;&#x2F;swapi.co&#x2F;api&#x2F;people&quot;; string result &#x3D; await client.GetStringAsync(url); var people &#x3D; JsonConvert.DeserializeObject&lt;ApiResult&lt;Person&gt;&gt;(result).Results; return people; &#125;&#125; But get list of Person from a file need a parameter (filename) 123456public async Task&lt;List&lt;Person&gt;&gt; GetCharactersFromFile(string filename)&#123; var characters &#x3D; JsonConvert.DeserializeObject&lt;List&lt;Person&gt;&gt;(await File.ReadAllTextAsync(filename)); return characters;&#125; To make it work with the GetCharacters() method, we need to create an Adapter Class 12345678910111213141516public class CharacterFileSourceAdapter : ICharacterSourceAdapter&#123; private string _fileName; private readonly CharacterFileSource _characterFileSource; public CharacterFileSourceAdapter(string fileName, CharacterFileSource characterFileSource) &#123; _fileName &#x3D; fileName; _characterFileSource &#x3D; characterFileSource; &#125; public async Task&lt;IEnumerable&lt;Person&gt;&gt; GetCharacters() &#123; return await _characterFileSource.GetCharactersFromFile(_fileName); &#125;&#125; It implements the IAdapter interface, and inside GetCharacters() method, it calls the GetCharactersFromFile(_filename) method to make it compatible with our interface method. When we use it, it doesn’t need to know anything about the filename or which way we choose to get the list of Person. 1var people &#x3D; await _characterSourceAdapter.GetCharacters(); Related Patterns Decorator: has a similar structure, but the intent of a decorator is to add functionality. Bridge: has a similar structure, but it allows interfaces and their implementations to vary independently from one another. Proxy: similar structure, but its intent is to control access to a resource, not to convert an incompatible interface Repository: sometimes it acts an adapter, providing a common interface for persistence that can map various incompatible interfaces to a single common data access strategy Strategy: very frequently used with Adapter pattern as a way of injecting different implementations of behavior into a particular client class. Facade: the intent of facade is similar to the adapters in that it alters an interface to make it easier for a client to use. The difference is Facade often sits in front of multiple different types and its goal is to simplify a complex set of operation Summary An Adapter converts an incompatible interface into a compatible one In C#, the Adapter pattern uses composition and is known as an object adapter. It means that your adapter implementation will contain instances of the incompatible type and will delegate calls to this instalce’s incompatible methods or properties. Adapters can work with service providers but can also wrap result types.","categories":[],"tags":[{"name":"Design Patterns","slug":"Design-Patterns","permalink":"http://hellcy.github.io/tags/Design-Patterns/"}]},{"title":"Design Patterns - Decorator","slug":"Design-Patterns-Decorator","date":"2021-04-18T11:26:18.000Z","updated":"2021-05-24T07:27:02.658Z","comments":true,"path":"2021/04/18/Design-Patterns-Decorator/","link":"","permalink":"http://hellcy.github.io/2021/04/18/Design-Patterns-Decorator/","excerpt":"","text":"Decorator Pattern A structural design pattern used for dynamically adding behavior to a class without making changes to that class. The Decorator Class will take an object implementing the same interface. This allows us to pass the object being decorated into the decorator object and allows the decorator object to act as a wrapper around this original object. The Decorator object will keep a reference of the object being decorated(the component object). Because the decorator object implement the same interface as the original component object, it now has a chance to intercept any method calls on the interface and inject some additional behavior into those calls. Decorator Class and be nested. This is the Example we are going to use. Using Decorator Objects 12345678&#x2F;&#x2F; Standard component instantiationIWeatherService weatherService &#x3D; new WeatherService();&#x2F;&#x2F; Instantiation with decorator objectsIWeatherService weatherService &#x3D; new CachingDecorator( new LogginDecorator( new WeatherService())); To achieve this, we need to make sure the original component class and all the decorator classes need to implement from the same interface. And all decortor classes need to take the object of type IWeatherService in their constructors. Logging Decorator Log how often a method was called, how long it took, parameters and responses. 123456public interface IWeatherService&#123; CurrentWeather GetCurrentWeather(String location); LocationForecast GetForecast(String location);&#125; This is the interface for our original WeatherService Class and our new Decorator Class 12345678910111213141516171819202122232425262728293031323334public class WeatherServiceLoggingDecorator : IWeatherService&#123; private IWeatherService _weatherService; private ILogger&lt;WeatherServiceLoggingDecorator&gt; _logger; public WeatherServiceLoggingDecorator(IWeatherService weatherService, ILogger&lt;WeatherServiceLoggingDecorator&gt; logger) &#123; _weatherService &#x3D; weatherService; _logger &#x3D; logger; &#125; public CurrentWeather GetCurrentWeather(string location) &#123; Stopwatch sw &#x3D; Stopwatch.StartNew(); CurrentWeather currentWeather &#x3D; _weatherService.GetCurrentWeather(location); sw.Stop(); long elapsedMillis &#x3D; sw.ElapsedMilliseconds; _logger.LogWarning(&quot;Retrieved weather data for &#123;location&#125; - Elapsed ms: &#123;&#125; &#123;@currentWeather&#125;&quot;, location, elapsedMillis, currentWeather); return currentWeather; &#125; public LocationForecast GetForecast(string location) &#123; Stopwatch sw &#x3D; Stopwatch.StartNew(); LocationForecast locationForecast &#x3D; _weatherService.GetForecast(location); sw.Stop(); long elapsedMillis &#x3D; sw.ElapsedMilliseconds; _logger.LogWarning(&quot;Retrieved weather data for &#123;location&#125; - Elapsed ms: &#123;&#125; &#123;@locationForecast&#125;&quot;, location, elapsedMillis, locationForecast); return locationForecast; &#125;&#125; This is our new Decorator Class, we implement from the IWeatherService Interface, it is taking the interface as a parameter in the constructor, and implemented two methods. In the GetCurrentWeather() method, it logs the time it takes to run the method, then calling the original _weatherService.GetCurrentWeather() method. Caching Decorator Cache weather conditions, forecasts for a city to reduce the number of external API calls. 12345678910111213141516171819202122232425262728293031323334353637383940414243public class WeatherServiceCachingDecorator : IWeatherService&#123; private IWeatherService _weatherService; private IMemoryCache _cache; public WeatherServiceCachingDecorator(IWeatherService weatherService, IMemoryCache cache) &#123; _weatherService &#x3D; weatherService; _cache &#x3D; cache; &#125; public CurrentWeather GetCurrentWeather(string location) &#123; &#x2F;&#x2F; if we can found value in the cache, return it &#x2F;&#x2F; otherwise get the current weather then add it to the cache for 30 mins string cacheKey &#x3D; $&quot;WeatherConditions::&#123;location&#125;&quot;; if (_cache.TryGetValue&lt;CurrentWeather&gt;(cacheKey, out var currentWeather)) &#123; return currentWeather; &#125; else &#123; var currentConditions &#x3D; _weatherService.GetCurrentWeather(location); _cache.Set&lt;CurrentWeather&gt;(cacheKey, currentConditions, TimeSpan.FromMinutes(30)); return currentConditions; &#125; &#125; public LocationForecast GetForecast(string location) &#123; string cacheKey &#x3D; $&quot;WeatherForecast::&#123;location&#125;&quot;; if (_cache.TryGetValue&lt;LocationForecast&gt;(cacheKey, out var forecast)) &#123; return forecast; &#125; else &#123; var locationForecast &#x3D; _weatherService.GetForecast(location); _cache.Set&lt;LocationForecast&gt;(cacheKey, locationForecast, TimeSpan.FromMinutes(30)); return locationForecast; &#125; &#125;&#125; And meanwhile in the HomeController, we need to build this onion like structure from inside to outside. 12345IWeatherService weatherService &#x3D; new WeatherService(apiKey);IWeatherService withLoggingDecorator &#x3D; new WeatherServiceLoggingDecorator(weatherService, _loggerFactory.CreateLogger&lt;WeatherServiceLoggingDecorator&gt;());IWeatherService withCachingDecorator &#x3D; new WeatherServiceCachingDecorator(withLoggingDecorator, memoryCache);_weatherService &#x3D; withCachingDecorator; The call stack will be: CachingDecorator =&gt; LoggingDecorator =&gt; WeatherService Decorator Summary Multiple decorators can be used in conjunction with one another Each decorator can focus on a single task, promoting separation of concerns Decorator classes allow functionality to be added dynamically Decorator Pattern Characteristics Implement the same base interface as the original object Take a instance of the original object as part of their constructor Add new behaviors to the original object they are wrapping Using Decorators with Dependency Injection Container .NET Core has built in IoC container which will help us to create WeatherService object when we need it and manage the lifetime of object. We could simplify the HomeController constructor to this 123456private readonly IWeatherService _weatherService;public HomeController(ILogger&lt;HomeController&gt; logger, IWeatherService weatherService)&#123; _weatherService &#x3D; weatherService;&#125; And in the startUp.cs, we configure the IoC container to this 12345678910111213141516171819202122public void ConfigureServices(IServiceCollection services)&#123; services.AddControllersWithViews(); services.AddMemoryCache(); String apiKey &#x3D; Configuration.GetValue&lt;String&gt;(&quot;OpenWeatherMapApiKey&quot;); services.AddScoped&lt;IWeatherService&gt;(serviceProvider &#x3D;&gt; &#123; String apiKey &#x3D; Configuration.GetValue&lt;String&gt;(&quot;OpenWeatherMapApiKey&quot;); var logger &#x3D; serviceProvider.GetService&lt;ILogger&lt;WeatherServiceLoggingDecorator&gt;&gt;(); var memoryCache &#x3D; serviceProvider.GetService&lt;IMemoryCache&gt;(); IWeatherService weatherService &#x3D; new WeatherService(apiKey); IWeatherService withLoggingDecorator &#x3D; new WeatherServiceLoggingDecorator(weatherService, logger); IWeatherService withCachingDecorator &#x3D; new WeatherServiceCachingDecorator(withLoggingDecorator, memoryCache); return withCachingDecorator; &#125;);&#125; Now whenever we need a IWeatherService object, it will be created and provided to us with this structure. (CachingDecorator =&gt; LoggingDecorator =&gt; WeatherService) When to use Decorator Pattern Cross cutting concerns Logging, Performance Tracking(Timer, StopWatch…), Caching, Authorization Manipulate data going to/from component object we need to encrypt and decrypt before being passed to a component Question: What if your component does not have an interface/extend from a base class? Extract an interface from the class What if you can’t modify the class? Adapter Pattern To put a class in front of your component and extract an interface from the Adapter Class Summary Design Patterns are about ideas Interfaces allow us to create loosely coupled designs the decorator pattern adds the ability to dynamically add behavior This is accomplished by wrapping around the original object and intercepting methods","categories":[],"tags":[{"name":"Design Patterns","slug":"Design-Patterns","permalink":"http://hellcy.github.io/tags/Design-Patterns/"}]},{"title":"Design Patterns - Factory and Abstract Factory","slug":"Design-Patterns-Factory-and-Abstract-Factory","date":"2021-04-17T13:40:29.000Z","updated":"2021-05-24T07:27:02.658Z","comments":true,"path":"2021/04/17/Design-Patterns-Factory-and-Abstract-Factory/","link":"","permalink":"http://hellcy.github.io/2021/04/17/Design-Patterns-Factory-and-Abstract-Factory/","excerpt":"","text":"What is Factory Pattern A factory is an object for creating objects Factory Pattern Variations Simple Factory Factory Method Abstract Factory Factory Pattern Characteristics Client: Asks for a created product Shopping cart Creator: Facilitates a creation ShippingProviderFactory Product: The product of the creation ShippingProvider Instance The Client no longer needs to know how to create an object or exactly what flavor of that class it will use Simple Factory Example We have a ShoppingCart Class and inside this Class we create a shippingProvider object. It will create different shippingProvider based on order’s sender country 123456789101112if (order.Sender.Country &#x3D;&#x3D; &quot;Australia&quot;)&#123; &#x2F;&#x2F;Australia Post Shipping Provider&#125;else if (order.Sender.Country &#x3D;&#x3D; &quot;Sweden&quot;)&#123; &#x2F;&#x2F;Swedish Postal Service Shipping Provider&#125;else&#123; throw new NotSupportedException(&quot;No shipping provider found for origin country&quot;);&#125; But the shippingProvider object should not be created inside the ShoppingCart Class, ShoppingCart Class should just ask a ShippingProviderFactory Class for a shippingProvider object, and it will be provided one. So we should moved the code to a new ShippingProviderFactory Class and invoke this class’s Creation method. 1var shippingProvider &#x3D; ShippingProviderFactory.CreateShippingProvider(order.Sender.Country); One problem is not we are still hardcoding the Country inside our ShippingProviderFactory Class. We should add another layer of abstraction between the ShippingProviderFactory and the implementation of the ShippingProvider. Factory Method The Factory Method Pattern is introduced to allow for a flexible and extensible application 123456789101112131415public abstract class ShippingProviderFactory &#123; public abstract ShippingProvider CreateShippingProvider(string country); public ShippingProvider GetShippingProvider(string country) &#123; var provider &#x3D; CreateShippingProvider(country) &#x2F;&#x2F; we may want to do some common changes on the shippingProvider created &#x2F;&#x2F; before we return it back to the caller (ShoppingCart) if (country &#x3D;&#x3D; &quot;Sweden&quot; &amp;&amp; provider.InsuranceOptions.ProviderHasInsurance) &#123; provider.RequireSignature &#x3D; false; &#125; return provider; &#125;&#125; It contains two methods. The CreateShippingProvider() method will be implemented by its subclasses with different implementations. The GetShippingProvider() method will allow user to decide what’s passed into the creation. And it allows user to do additional common interactions with the result of the creation before it’s being passed back to the caller(ShoppingCart). Now we can create different implementations of the creation of a shippingProvider based on the input parameter(country). 123456789101112131415public class StandardShippingProviderFactory : ShippingProviderFactory&#123; public override ShippingProvider CreateShippingProvider(string country) &#123; return new StandardShippingProviderFactory(); &#125;&#125;public class GlobalExpressShippingProviderFactory : ShippingProviderFactory&#123; public override ShippingProvider CreateShippingProvider(string country) &#123; return new GlobalExpressShippingProvider(); &#125;&#125; In the caller Class (ShoppingCart) we can inject ShippingProviderFactory 123456&#x2F;&#x2F; inject ShippingProviderFactory into the ShoppingCart Constructorpublic ShoppingCart(Order order, ShippingProviderFactory shippingProviderFactory)&#123; this.order &#x3D; order; this.shippingProviderFactory &#x3D; shippingProviderFactory;&#125; Also compose the ShippingProviderFactory object on app start 1var cart &#x3D; new ShoppingCart(order, new StandardShippingProviderFactory()); Abstract Factory Pattern The abstract factory pattern provides a way to encapsulete a group of individual factories that have a common theme without specifying their concrete classes. It adds another layer of abstraction which allow users to choose which factory to use on app start. Different factories have the same methods but with different implementations 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public interface IPurchaseProviderFactory&#123; ShippingProvider CreateShippingProvider(Order order); IInvoice CreateInvoice(Order order); ISummary CreateSummary(Order order);&#125;public class AustraliaPurchaseProviderFactory : IPurchaseProviderFactory&#123; public IInvoice CreateInvoice(Order order) &#123; return new GSTInvoice(); &#125; public ShippingProvider CreateShippingProvider(Order order) &#123; var shippingProviderFactory &#x3D; new StandardShippingProviderFactory(); return shippingProviderFactory.GetShippingProvider(order.Sender.Country); &#125; public ISummary CreateSummary(Order order) &#123; return new CSVSummary(); &#125;&#125;public class SwedenPurchaseProviderFactory : IPurchaseProviderFactory&#123; public IInvoice CreateInvoice(Order order) &#123; if (order.Recipient.Country !&#x3D; order.Sender.Country) &#123; return new NoVATInvoice(); &#125; return new VATInvoice(); &#125; public ShippingProvider CreateShippingProvider(Order order) &#123; ShippingProviderFactory shippingProviderFactory; if (order.Sender.Country !&#x3D; order.Recipient.Country) &#123; shippingProviderFactory &#x3D; new GlobalExpressShippingProviderFactory(); &#125; else &#123; shippingProviderFactory &#x3D; new StandardShippingProviderFactory(); &#125; return shippingProviderFactory.GetShippingProvider(order.Sender.Country); &#125; public ISummary CreateSummary(Order order) &#123; return new EmailSummary(); &#125;&#125; Client (ShoppingCart) Class doesn’t need to know which factory to use, it just needs to know when to create a product using the factory. 1234567891011121314151617181920public ShoppingCart(Order order, IPurchaseProviderFactory purchaseProviderFactory) &#123; this.order &#x3D; order; this.purchaseProviderFactory &#x3D; purchaseProviderFactory;&#125;public string Finalize()&#123; var shippingProvider &#x3D; purchaseProviderFactory.CreateShippingProvider(order); var invoice &#x3D; purchaseProviderFactory.CreateInvoice(order); var summary &#x3D; purchaseProviderFactory.CreateSummary(order); summary.Send(); order.ShippingStatus &#x3D; ShippingStatus.ReadyForShippment; return shippingProvider.GenerateShippingLabelFor(order);&#125; The concrete factory object will be instantiated on app starts(or based on user input). 12345678910111213141516IPurchaseProviderFactory purchaseProviderFactory;if (order.Sender.Country &#x3D;&#x3D; &quot;Sweden&quot;)&#123; purchaseProviderFactory &#x3D; new SwedenPurchaseProviderFactory();&#125;else if (order.Sender.Country &#x3D;&#x3D; &quot;Australia&quot;)&#123; purchaseProviderFactory &#x3D; new AustraliaPurchaseProviderFactory();&#125;else&#123; throw new Exception(&quot;Country not supported.&quot;);&#125;var cart &#x3D; new ShoppingCart(order, purchaseProviderFactory); Factory Pattern in Testing Extract creation of mocked, facked or commonly oused intances in tests. We could use the Factory Pattern in our Unit Tests. it will be easier to test the parts that use them as you can inhect faked or mocked implementations 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public abstract class OrderFactory&#123; protected abstract Order CreateOrder(); public Order GetOrder() &#123; var order &#x3D; CreateOrder(); order.LineItems.Add( new Item(&quot;testA&quot;, &quot;testB&quot;, 100m), 1 ); order.LineItems.Add( new Item(&quot;TestC&quot;, &quot;TestD&quot;, decimal.MaxValue), 1 ); return order; &#125;&#125;public class StandardOrderFactory : OrderFactory&#123; protected override Order CreateOrder() &#123; var order &#x3D; new Order &#123; Recipient &#x3D; new Address &#123; To &#x3D; &quot;Yuan&quot;, Country &#x3D; &quot;Australia&quot; &#125;, Sender &#x3D; new Address &#123; To &#x3D; &quot;Someone else&quot;, Country &#x3D; &quot;Australia&quot; &#125; &#125;; return order; &#125;&#125;public class InternationalOrderFactory : OrderFactory&#123; protected override Order CreateOrder() &#123; var order &#x3D; new Order &#123; Recipient &#x3D; new Address &#123; To &#x3D; &quot;Yuan&quot;, Country &#x3D; &quot;Australia&quot; &#125;, Sender &#x3D; new Address &#123; To &#x3D; &quot;Someone else&quot;, Country &#x3D; &quot;Sweden&quot; &#125; &#125;; return order; &#125;&#125; Summary Separates the client(ShoppingCart) from the creation Introduce subclasses (StandardShippingProviderFactory, GlobalExpressShippingProviderFactory) and concrete implementations to add functionality. Factory Pattern is very common when writing tests","categories":[],"tags":[{"name":"Design Patterns","slug":"Design-Patterns","permalink":"http://hellcy.github.io/tags/Design-Patterns/"}]},{"title":"Design Patterns - Command","slug":"Design-Patterns-Command","date":"2021-04-16T08:15:56.000Z","updated":"2021-05-24T07:27:02.658Z","comments":true,"path":"2021/04/16/Design-Patterns-Command/","link":"","permalink":"http://hellcy.github.io/2021/04/16/Design-Patterns-Command/","excerpt":"","text":"Command Pattern Characteristics Command Holds the instructions and references to things that it needs in order for it to be executed Receiver Command will execute Receiver Invoker Invoker will execute Command, and will also keep track of all executed commands Client Client decides which command to schedule for execution A command contains all the data to process the request now or at a later time. This means we could execute the command right away once the client schedule that command, or we could schedule all the commands to be executed later on in the lifetime of our application. Example: AddToCartCommand The product which should be added to the cart The shopping cart A way to check stock availability ICommand Interface Because we may need to implement different command, we should create a ICommand interface. It contains three methods. Execute() will execute the command. CanExecute() will check if a command can be execute of not. Undo() will undo all commands we executed before (using a Stack to maintain all executed commands) 123456public interface ICommand&#123; void Execute(); bool CanExecute(); void Undo();&#125; Next we need to implement CommandManager, which is the Invoker component. It contains a Stack Data Structure to maintain the Commands list. When the Client (UI Button) adds a command to the CommandManager, it will be added to the list. (We can also add extra feature like introduce a delay of executing commands or redo all commands later). 12345678910111213141516171819202122public class CommandManager&#123; private Stack&lt;ICommand&gt; commands &#x3D; new Stack&lt;ICommand&gt;(); public void Invoke(ICommand command) &#123; if (command.CanExecute()) &#123; commands.Push(command); command.Execute(); &#125; &#125; public void Undo() &#123; while (commands.Count &gt; 0) &#123; var command &#x3D; commands.Pop(); command.Undo(); &#125; &#125;&#125; Next we start to implement a command AddToCartCommand 1public class AddToCartCommand : ICommand It takes a shoppingCartRepository object, a productRepository object and a product 12345678public AddToCartCommand(IShoppingCartRepository shoppingCartRepository, IProductRepository productRepository, Product product)&#123; this.shoppingCartRepository &#x3D; shoppingCartRepository; this.productRepository &#x3D; productRepository; this.product &#x3D; product;&#125; Just a reminder, the Repository is a pattern for abstracting data access. We could have access the data store from a SQL DB, a web service or a CSV file, but our application doesn’t need to know that. In our case, the shoppingCartRepository and the productRepository are both just a local Dictionary data structure. 123456public bool CanExecute()&#123; if (product &#x3D;&#x3D; null) return false; return productRepository.GetStockFor(product.ArticleId) &gt; 0;&#125; CanExecute() will check if our productRepository actually has the required product. 12345678public void Execute()&#123; if (product &#x3D;&#x3D; null) return; productRepository.DecreaseStockBy(product.ArticleId, 1); shoppingCartRepository.Add(product);&#125; Execute() will decrease the product quantity by one and add it to shoppingCartRepository 12345678910public void Undo()&#123; if (product &#x3D;&#x3D; null) return; var lineItem &#x3D; shoppingCartRepository.Get(product.ArticleId); productRepository.IncreaseStockBy(product.ArticleId, lineItem.Quantity); shoppingCartRepository.RemoveAll(product.ArticleId);&#125; Undo() will put the product from shoppingCartRepository back to the productRepository 123456789101112131415161718192021var shoppingCartRepository &#x3D; new ShoppingCartRepository();var productsRepository &#x3D; new ProductsRepository();var product &#x3D; productsRepository.FindBy(&quot;SM7B&quot;);var addToCartCommand &#x3D; new AddToCartCommand(shoppingCartRepository, productsRepository, product);var increaseQuantityCommand &#x3D; new ChangeQuantityCommand( ChangeQuantityCommand.Operation.Increase, shoppingCartRepository, productsRepository, product);var manager &#x3D; new CommandManager();manager.Invoke(addToCartCommand);manager.Invoke(increaseQuantityCommand);manager.Invoke(increaseQuantityCommand);manager.Invoke(increaseQuantityCommand);manager.Invoke(increaseQuantityCommand); Finally we just need to compose all the necessary objects on app starts. And add the commands to CommandManager. Command Pattern in WPF 123456789101112131415161718192021222324252627282930public interface ICommand&#123; &#x2F;&#x2F; &#x2F;&#x2F; Summary: &#x2F;&#x2F; Occurs when changes occur that affect whether or not the command should execute. event EventHandler CanExecuteChanged; &#x2F;&#x2F; &#x2F;&#x2F; Summary: &#x2F;&#x2F; Defines the method that determines whether the command can execute in its current &#x2F;&#x2F; state. &#x2F;&#x2F; &#x2F;&#x2F; Parameters: &#x2F;&#x2F; parameter: &#x2F;&#x2F; Data used by the command. If the command does not require data to be passed, &#x2F;&#x2F; this object can be set to null. &#x2F;&#x2F; &#x2F;&#x2F; Returns: &#x2F;&#x2F; true if this command can be executed; otherwise, false. bool CanExecute(object parameter); &#x2F;&#x2F; &#x2F;&#x2F; Summary: &#x2F;&#x2F; Defines the method to be called when the command is invoked. &#x2F;&#x2F; &#x2F;&#x2F; Parameters: &#x2F;&#x2F; parameter: &#x2F;&#x2F; Data used by the command. If the command does not require data to be passed, &#x2F;&#x2F; this object can be set to null. void Execute(object parameter);&#125; WPF application has built in ICommand interface. If we want to use our Command implementation (RemoveAllFromCartCommand) with this ICommand interface. We could bind the method with a UI button, then create a RelayCommand Class, which will invoke RemoveAllFromCartCommand method. UI Button -&gt;(bind)-&gt; ICommand method -&gt;(invoke)-&gt; RelayCommand -&gt;(invoke)-&gt; RemoveAllFromCartCommand 1&lt;Button Margin&#x3D;&quot;0 5 5 0&quot; Command&#x3D;&quot;&#123;Binding RemoveAllFromCartCommand&#125;&quot;&gt;Clear&lt;&#x2F;Button&gt; 1public System.Windows.Input.ICommand RemoveAllFromCartCommand &#123; get; private set; &#125; 123456789RemoveAllFromCartCommand &#x3D; new RelayCommand( execute: () &#x3D;&gt; &#123; removeAllFromCartCommand.Execute(); Refresh(); &#125;, canExecute:() &#x3D;&gt; removeAllFromCartCommand.CanExecute()); 1234567891011121314151617181920212223242526272829303132public class RelayCommand : System.Windows.Input.ICommand&#123; private readonly Action execute; private readonly Func&lt;bool&gt; canExecute; public RelayCommand(Action execute, Func&lt;bool&gt; canExecute) &#123; this.execute &#x3D; execute; this.canExecute &#x3D; canExecute; &#125; public bool CanExecute(object parameter) &#123; return canExecute?.Invoke() ?? false; &#125; public void Execute(object parameter) &#123; execute?.Invoke(); &#125; public event EventHandler CanExecuteChanged &#123; add &#123; CommandManager.RequerySuggested +&#x3D; value; &#125; remove &#123; CommandManager.RequerySuggested -&#x3D; value; &#125; &#125; public void RaiseCanExecuteChanged() &#123; CommandManager.InvalidateRequerySuggested(); &#125;&#125; Summary Command Pattern converts the request from Client to an object(ICommand). And the children implementation of the ICommand (AddToCartCommand) will take the Receiver as one of its input parameters (ShoppingCartRepository, ProductRepository). And it will implement the Execute() method, decide what should the Receiver do in Execute() method. And the Receiver should have all the needed information about the request(Product)","categories":[],"tags":[{"name":"Design Patterns","slug":"Design-Patterns","permalink":"http://hellcy.github.io/tags/Design-Patterns/"}]},{"title":"Design Patterns - Strategy","slug":"Design-Patterns-Strategy","date":"2021-04-16T05:34:42.000Z","updated":"2021-05-24T07:27:02.659Z","comments":true,"path":"2021/04/16/Design-Patterns-Strategy/","link":"","permalink":"http://hellcy.github.io/2021/04/16/Design-Patterns-Strategy/","excerpt":"","text":"Strategy pattern is also called Policy pattern Strategy Pattern Characteristics Context: has a reference to a strategy and invokes it Calls IStrategy.Method(object); IStrategy: Defines the interface for the given strategy Defines the contract Method(object) Strategy: A concrete implementation of the strategy Implementation of Method(object) Select an implementation at runtime based on user input without having to extend the class. Example: ISalesTaxStrategy is an interface. We have multiple different implementations of Strategies to calculate tax. They all implement the ISalesTaxStrategy interface. The code below doesn’t need to know what Strategy is chosen at this step. It only needs to invoke the GetTaxFor() Method. 123456public ISalesTaxStrategy SalesTaxStrategy &#123; get; set; &#125;public decimal GetTax()&#123; return SalesTaxStrategy &#x3D;&#x3D; null ? 0m : SalesTaxStrategy.GetTaxFor(this);&#125; What did we achieve? A more extensible, object oriented and dynamic implementation Easily add new strategies without affecting existing ones Cleaner approach with single responsiblity in mind Another thing we could do is to pass the interface to the GetTax() method. 123public decimal GetTax(ISalesTaxStrategy salesTaxStrategy) &#123; return salesTaxStrategy &#x3D;&#x3D; null ? 0m : salesTaxStrategy.GetTaxFor(this);&#125; And the concrete implementation of the strategy could be determined when we invoke the GetTax() Method 1order.GetTax(new SwedenSalesTaxStrategy() This is still meaning we have a hard dependency between the Order and the SalesTaxStrategy Strategy Pattern with Dependency Injection Pass the already created SalesTaxStrategy to the Order Contructor will help us remove the hard dependency between the Order and the Strategy. 12345678910private ISalesTaxStrategy _salesTaxStrategy;private IInvoiceStrategy _invoiceStrategy;private IShippingStrategy _shippingStrategy;public Order(ISalesTaxStrategy salesTaxStrategy, IInvoiceStrategy invoiceStrategy, IShippingStrategy shippingStrategy)&#123; _salesTaxStrategy &#x3D; salesTaxStrategy; _invoiceStrategy &#x3D; invoiceStrategy; _shippingStrategy &#x3D; shippingStrategy;&#125; Then Order(Context in Strategy Pattern) just need to invoke Strategy implementations without having to know which imeplementation it is invoking. 12345678910111213141516171819public decimal GetTax()&#123; return _salesTaxStrategy &#x3D;&#x3D; null ? 0m : _salesTaxStrategy.GetTaxFor(this);&#125;public void FinalizeOrder()&#123; if (SelectedPayments.Any(x &#x3D;&gt; x.PaymentProvider &#x3D;&#x3D; PaymentProvider.Invoice) &amp;&amp; AmountDue &gt; 0 &amp;&amp; ShippingStatus &#x3D;&#x3D; ShippingStatus.WaitingForPayment) &#123; _invoiceStrategy.Generate(this); ShippingStatus &#x3D; ShippingStatus.ReadyForShippment; &#125; else if (AmountDue &gt; 0) &#123; throw new Exception(&quot;Unable to finalize order&quot;); &#125; _shippingStrategy.Ship(this);&#125; On Application start we create different Strategies based on user input 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950switch (origin)&#123; case EnumTaxStrategy.Sweden: salesTaxStrategy &#x3D; new SwedenSalesTaxStrategy(); break; case EnumTaxStrategy.USA: salesTaxStrategy &#x3D; new USAStateSalesTaxStrategy(); break; default: salesTaxStrategy &#x3D; new SwedenSalesTaxStrategy(); break;&#125;switch (inputInvoiceStrategy)&#123; case EnumInvoiceStrategy.Email: invoiceStrategy &#x3D; new EmailInvoiceStrategy(); break; case EnumInvoiceStrategy.File: invoiceStrategy &#x3D; new FileInvoiceStrategy(); break; case EnumInvoiceStrategy.PrintOnDemand: invoiceStrategy &#x3D; new PrintOnDemandInvoiceStrategy(); break; default: invoiceStrategy &#x3D; new FileInvoiceStrategy(); break;&#125;switch (inputShippingStrategy)&#123; case EnumShippingStrategy.DHL: shippingStrategy &#x3D; new DHLShippingStrategy(); break; case EnumShippingStrategy.Fedex: shippingStrategy &#x3D; new FedexShippingStrategy(); break; case EnumShippingStrategy.SwedishPostalService: shippingStrategy &#x3D; new SwedishPostalServiceShippingStrategy(); break; case EnumShippingStrategy.UPS: shippingStrategy &#x3D; new UPSShippingStrategy(); break; case EnumShippingStrategy.USPS: shippingStrategy &#x3D; new UnitedStatesPostalServiceShippingStrategy(); break; default: shippingStrategy &#x3D; new DHLShippingStrategy(); break;&#125; Summary One of the most commonly used patterns Decouple the context and the concrete implementation Allows for a cleaner implementation in the context Easily extend with additional startegies without affecting current implementations Makes testing a lot easier as you can write mocked implementations to inject Identify existing implementations and where you have used the pattern before","categories":[],"tags":[{"name":"Design Patterns","slug":"Design-Patterns","permalink":"http://hellcy.github.io/tags/Design-Patterns/"}]},{"title":"Design Patterns - Singleton","slug":"Design-Patterns-Singleton","date":"2021-04-15T12:03:02.000Z","updated":"2021-05-24T07:27:02.659Z","comments":true,"path":"2021/04/15/Design-Patterns-Singleton/","link":"","permalink":"http://hellcy.github.io/2021/04/15/Design-Patterns-Singleton/","excerpt":"","text":"A singleton is a class designed to only ever have one instance. Singleton Features At any time, only 0 or 1 instance of the Singleton class exists in the application Singleton classes are created without parameters Assume lazy instantiation as the default A single, private, parameterless constructor Sealed class A private, static field holds the only reference to the instance A public static method provides access to the field Naive implementation of Singleton 1234567891011121314151617181920212223namespace Singleton&#123;#nullable enable public sealed class Singleton &#123; private static Singleton? _instance; public static Singleton Instance &#123; get &#123; &#x2F;&#x2F; lazy instantiate Logger.Log(&quot;Instance called&quot;); return _instance ??&#x3D; new Singleton(); &#125; &#125; private Singleton() &#123; &#x2F;&#x2F; cannot be created except within this class Logger.Log(&quot;Constructor invoked&quot;); &#125; &#125;&#125; The problem of this native implementation is Thread safety. In multi-thread environment, the If block can be reached by multiple threads concurrently, resulting in multiple instantiations of Singleton. Thread Safe Singleton One way to make sure the Singleton Instance will not be created in a multiple thread environment is to use a lock 1private static readonly object padlock &#x3D; new object(); This lock is a private static readonly object that will be shared by all references to the Singleton instance 1234567&#x2F;&#x2F; this lock is used on every reference to Singletonlock (padlock)&#123; Logger.Log(&quot;Instance called.&quot;); &#x2F;&#x2F; lazy instantiation return _instance ??&#x3D; new Singleton();&#125; A slight better way to add lock is to use the double check locking pattern, this gives us a better performance because we don’t need to check lock very often 1234567891011if (_instance &#x3D;&#x3D; null)&#123; &#x2F;&#x2F; this lock is used on every reference to Singleton lock (padlock) &#123; Logger.Log(&quot;Instance called.&quot;); &#x2F;&#x2F; lazy instantiation _instance &#x3D; new Singleton(); &#125;&#125;return _instance; Locking adds thread safety First version imposes lock on every access, not just first time Second version is better, but has some issues with the ECMA CLI spec that may be a concern Neither approach works as well as the next ones Static Constructors C# static constructors only run once per app domain static constructors are called when any static member of a type is referenced Make sure you use an explicit static constructor to avoid issue with C# compiler and beforefieldinit (beforefieldinit is a hint the compiler uses to let it know static initializers can be called sooner, and this is the default if the type does not have an explicit static constructor. Adding an explicit static constructor avoids having beforefieldinit applied, which helps make our singleton behavior lazier) 123456789101112131415161718192021222324252627282930public sealed class StaticConstructorSingleton : ISingleton&#123; &#x2F;&#x2F; reading this will initialize the instance public static readonly string GREETING &#x3D; &quot;Hi!&quot;; public static StaticConstructorSingleton Instance &#123; get &#123; Logger.Log(&quot;Instance called&quot;); return Nested._instance; &#125; &#125; private class Nested &#123; &#x2F;&#x2F;Tell C# compiler not to mark type as beforefieldinit static Nested() &#123; &#125; internal static readonly StaticConstructorSingleton _instance &#x3D; new StaticConstructorSingleton(); &#125; private StaticConstructorSingleton() &#123; &#x2F;&#x2F; cannot be created except within this class Logger.Log(&quot;Constructor invoked.&quot;); &#125;&#125; This approach is Thread-safe, no locks (good performance), but is complex and non-intuitive. Lazy One difference between this approach and the naive approach is that the private static readonly field is type of Lazy&lt;Singleton&gt; rather than just Singleton, this field is initilized at construction to create a new Lazy&lt;T&gt; instance, and a lambda function is passed into the Lazy&lt;T&gt; constructor with the logic needed to create the singleton instance. 1234567891011121314151617181920public sealed class LazyTSingleton&#123; &#x2F;&#x2F; reading this will initilize the instance private static readonly Lazy&lt;LazyTSingleton&gt; _lazy &#x3D; new Lazy&lt;LazyTSingleton&gt;(() &#x3D;&gt; new LazyTSingleton()); public static LazyTSingleton Instance &#123; get &#123; Logger.Log(&quot;Instance called.&quot;); return _lazy.Value; &#125; &#125; private LazyTSingleton() &#123; &#x2F;&#x2F; cannot be created except within this class Logger.Log(&quot;Constructor invoked.&quot;); &#125;&#125; This approach is very easy to understand and has the performance and thread safe feature. Singletons vs Static Classes Singletons Static Classes Can implement interfaces No interfaces Can be passed as an argument Cannot be passed as arguments Can be assigned to variables Cannot be assigned Support polymorphism Purely procedural Can have state Can only access global state Can be serialized No support for serialization Singleton Behavior Using Containers(IoC) .NET Core has built-in support for IoC Containers Classes request dependencies via constructor Classes should follow Explicit Dependencies Principle Container manages abstraction-implementation mapping Container manages instnace lifetime Manage Lifetime Using Container, not Class Design Easily manage and modify individual class lifetimes using an IoC container Can also be used by any service, console application, etc… 1234567public void ConfigureService(ServiceCollection services) &#123; services.AddTransient&lt;IOrderService, OrderService&gt;(); services.AddScoped&lt;IOrderRepository, OrderRepository&gt;(); services.AddSingleton&lt;IConnectionManager, ConnectionManager&gt;(); services.AddSingleton&lt;SomeInstance&gt;(new SomeInstance);&#125; Transient: A new instance of the type is provided any time a class requests that type as a dependency. Scope: Define a scope and any instance requested within that scope will be shared if it’s requested again within that socpe. The first request will get a new instance and all subsequent requests in that scope will get that same instance. Singleton: only one instance will be created and shared by all references. Just like the Singleton pattern. IoC containers are probably the best approach in systems that already use them. Otherwise, Laszy&lt;T&gt; provides an elegant, easily understood approach. Summary A Singleton class is designed to only ever have one instance created. The Singleton pattern makes the class itself responsible for enforcing Singleton behavior It’s easy to get the pattern wrong when implementing by hand Lazy&lt;T&gt; is one of the better ways to apply the pattern Singletons are different from Static Classes IoC/DI containers are usually a better place to manage instance lifetime in .NET applications.","categories":[],"tags":[{"name":"Design Patterns","slug":"Design-Patterns","permalink":"http://hellcy.github.io/tags/Design-Patterns/"}]},{"title":"Creating Automated Browser Tests with Selenium in C#","slug":"Creating-Automated-Browser-Tests-with-Selenium-in-C","date":"2021-04-14T04:20:04.000Z","updated":"2021-05-24T07:27:02.658Z","comments":true,"path":"2021/04/14/Creating-Automated-Browser-Tests-with-Selenium-in-C/","link":"","permalink":"http://hellcy.github.io/2021/04/14/Creating-Automated-Browser-Tests-with-Selenium-in-C/","excerpt":"","text":"What is Selenium? Selenium is a portable framework for testing web applications. The tests can then run against most modern web browsers. Selenium runs on Windows, Linux, and macOS. Some of the features we can do using Selenium WebDriver Navigate to a specific page/forware/back Click the button with an ID Type text into the &lt;input&gt; Get the text content of the SPAN that has a CSS class Choose a radio button Check a tick box Get the title of the current page Maximum the browser window Take a screenshot Selenium WebDriver Testing Architecture The Limitations of Automated Browser Tests Slower than other types of tests (unit tests) Not a replacement of all manuall testing Additional dependencies (Selenium, WebDriver…) Setting up the test project Install NuGet Packages Selenium.WebDriver Selenium.WebDriver.ChromeDriver Your first test case The Web App has to be running for Selenium to work 1234567891011121314151617181920212223242526272829private string baseUrl &#x3D; &quot;http:&#x2F;&#x2F;localhost:29128&#x2F;&quot;;[Test][Category(&quot;Login&quot;)]public void ShouldLogin()&#123; using (IWebDriver driver &#x3D; new ChromeDriver()) &#123; driver.Navigate().GoToUrl(baseUrl); var userNameBox &#x3D; driver.FindElement(By.Id(&quot;username&quot;)); userNameBox.SendKeys(&quot;admin&quot;); Thread.Sleep(1000); var passwordBox &#x3D; driver.FindElement(By.Id(&quot;password&quot;)); passwordBox.SendKeys(&quot;admin&quot;); Thread.Sleep(1000); var submitButton &#x3D; driver.FindElement(By.Id(&quot;submit&quot;)); submitButton.Click(); Thread.Sleep(1000); var currentPageTitle &#x3D; driver.Title; Assert.That(currentPageTitle, Is.EqualTo(&quot;identityOne - Home Page&quot;)); &#125;&#125; Get Page Title 1234567891011[Test][Category(&quot;Test&quot;)]public void GetPageTitle()&#123; using (IWebDriver driver &#x3D; new ChromeDriver()) &#123; driver.Navigate().GoToUrl(baseUrl); Assert.That(&quot;identityOne - Home Page&quot;, driver.Title); &#125;&#125; Read current URL 1234567891011[Test][Category(&quot;Test&quot;)]public void ReadCurrentUrl()&#123; using (IWebDriver driver &#x3D; new ChromeDriver()) &#123; driver.Navigate().GoToUrl(baseUrl); Assert.That(baseUrl, driver.Url); &#125;&#125; Reload current page / go backward/forward 12345678910111213[Test][Category(&quot;Test&quot;)]public void ReloadCurrentPage()&#123; using (IWebDriver driver &#x3D; new ChromeDriver()) &#123; driver.Navigate().GoToUrl(baseUrl); driver.Navigate().Refresh(); driver.Navigate().Back(); driver.Navigate().Forward(); &#125;&#125; Manipulating HTML Elements 1234567891011121314151617181920212223242526272829303132333435363738394041[Test][Category(&quot;Test&quot;)]public void ReloadCurrentPage()&#123; using (IWebDriver driver &#x3D; new ChromeDriver()) &#123; driver.Navigate().GoToUrl(baseUrl); IWebElement textElement &#x3D; driver.FindElement(By.Id(&quot;username&quot;)); &#x2F;&#x2F; find element by ID string usernameText &#x3D; textElement.Text; &#x2F;&#x2F; Get HTML element text IWebElement buttonElement &#x3D; driver.FindElement(By.Name(&quot;button&quot;)); &#x2F;&#x2F; find element by Name buttonElement.Click(); &#x2F;&#x2F; Click a button or link IWebElement linkElement &#x3D; driver.FindElement(By.LinkText(&quot;link&quot;)); &#x2F;&#x2F; find element by LinkText linkElement.Click(); &#x2F;&#x2F; Click a button or link IWebElement buttonElement &#x3D; driver.FindElement(By.CssSelector(&quot;body&quot;)); &#x2F;&#x2F; find element by CssSelector IWebElement buttonElement &#x3D; driver.FindElement(By.ClassName(&quot;TestClass&quot;)); &#x2F;&#x2F; find element by class name IWebElement textElement &#x3D; driver.FindElement(By.TagName(&quot;td&quot;)); &#x2F;&#x2F; find element by tag name IWebElement linkElement &#x3D; driver.FindElement(By.PartialLinkText(&quot;Partial Text&quot;)); &#x2F;&#x2F; find element by PartialLinkText IWebElement linkElement &#x3D; driver.FindElement(By.XPath(&quot;&#x2F;html&#x2F;body&#x2F;div[4]&#x2F;p&#x2F;a&quot;)); &#x2F;&#x2F; find element by XPath &#x2F;&#x2F; this relative XPath will find all &lt;a&gt; elements with its text contains &#39;some text&#39; IWebElement linkElement &#x3D; driver.FindElement(By.XPath(&quot;&#x2F;&#x2F;a[text()[contains(.,&#39;some text&#39;)]]&quot;)); &#x2F;&#x2F; find element by Relative XPath &#x2F;&#x2F; WebDriverWait is given a timeout value indicating how long to wait for the condition. WebDriverWait wait &#x3D; new WebDriverWait(driver, TimeSpan.FromSeconds(1)); &#x2F;&#x2F; Selenium will try to find the linkElement until the timeout value is reached IWebElement linkElement &#x3D; wait.Until(d &#x3D;&gt; d.FineElement(By.LinkText(&quot;some text&quot;))); &#x2F;&#x2F; Selecting multiple elements ReadOnlyCollection&lt;IWebElement&gt; tableCells &#x3D; driver.FindElements(By.TagName(&quot;td&quot;)); Assert.That(&quot;first cell&quot;, tableCells[0].Text); &#125;&#125;","categories":[],"tags":[{"name":"Selenium","slug":"Selenium","permalink":"http://hellcy.github.io/tags/Selenium/"},{"name":"Functional Tests","slug":"Functional-Tests","permalink":"http://hellcy.github.io/tags/Functional-Tests/"}]},{"title":"Dependency Injection in .NET","slug":"Dependency-Injection-in-NET","date":"2021-04-12T11:05:18.000Z","updated":"2021-05-24T07:27:02.658Z","comments":true,"path":"2021/04/12/Dependency-Injection-in-NET/","link":"","permalink":"http://hellcy.github.io/2021/04/12/Dependency-Injection-in-NET/","excerpt":"","text":"What is dependency injection? Dependency injection is a programming technique that makes a class independent of its dependencies. It achieves that by decoupling the usage of an object from its creation. This helps you to follow SOLID’s dependency inversion and single responsiblity principles. Benefits of Loose Coupling Easy to extend Easy to test Easy to maintain Facilitates parallel development (rare conflict) Facilitates late binding (runtime data binding) Dependency Injection Patterns Constructor Injection Property Injection Method Injection Ambient Context Service Locator Application Overview The application contains four layers View (UI elements) such as the buttons and the list box Presentation (UI logic): functions that the buttons call and the property that the data bound to the list box in the UI. Data Access: Code that knows how to interact with the data store. It knows how to make a web service call, and then translate the results into objects that the Presentation layer can use. Data Store: where we get the actual data, in this case, the web service. Tight Coupled Code In the initial code, all four layers are tightly coupled. In the view layer, it creates PeopleViewModel() 123456public PeopleViewerWindow()&#123; InitializeComponent(); viewModel &#x3D; new PeopleViewModel(); this.DataContext &#x3D; viewModel;&#125; In the Presentation layer, it creates serviceReader() 1234public PeopleViewModel()&#123; DataReader &#x3D; new ServiceReader();&#125; In the Data Access layer, it hardcoded the web service url 12345public class ServiceReader&#123; WebClient client &#x3D; new WebClient(); string baseUri &#x3D; &quot;http:&#x2F;&#x2F;localhost:9874&#x2F;api&#x2F;people&quot;;&#125; Potential problems Hard to create unit test. If I want to test UI element (like a button), I have to run the web services because they are tightly coupled. (PeopleViewerWindow needs PeopleViewModel which needs ServiceReader which needs WebClient). Hard to extend If I want to add another Data Store like read data from a CSV file or SQL DB, and I also want to have the option to choose to use cached data store. Then in the PeopleViewModel I need to write something like this 12345678910111213141516public PeopleViewModel() &#123; switch(dataReaderType) &#123; case &#39;service&#39;: DataReader &#x3D; new ServiceReader(); break; case &#39;service_cached&#39;: DataReader &#x3D; new CachedServiceReader(); break; case &#39;text&#39;: DataReader &#x3D; new CSVReader(); break; case &#39;text_cached&#39;: DataReader &#x3D; new CachedCSVReader(); break; case &#39;sql&#39;: DataReader &#x3D; new SQLReader(); break; case &#39;sql_cached&#39;: DataReader &#x3D; new CachedSQLReader(); break; &#125;&#125; This breaks the Single Responsibility Principle, which is one of the SOLID principles. Because it is now doing too many things Presentation logic Picking the data source (hardcoded web service url) Managing object lifetime Deciding when to use a cache Repository Pattern Mediates between the domain and data mapping layers using a collection-like interface for accessing domain objects. It separates our application from the data storage technology. In other words, we can say that a Repository Design Patternacts as a middleman or middle layer between the rest of the application and the data access logic. That means a repository pattern isolates all the data access code from the rest of the application. The advantage of doing so is that, if you need to do any change then you need to do in one place. Another benefit is that testing your controllers becomes easy because the testing framework need not run against the actual database access code. The idea is that the repository knows how to communicate with the data store whether it is using HTTP, reading a file from the file system, or making a database call. It then takes the data that comes back and turns it into normal C# objects that the rest of the application can understand. This is exactly what the service reader does now. It makes a HTTP request to the web service, then parses the JSON result into Person objects that the application can use. CRUD Repository The Interface Segregation Principle says that interfaces should only contain what the client needs. Normally a Repository should contain all Create, Read, Update and Delete. But in this case we only need Read. Using Dependency Injection to Build Loosely-coupled Application Create a new interface 12345public interface IPersonReader&#123; IEnumerable&lt;Person&gt; GetPeople(); Person GetPerson(int id);&#125; In the Presentation layer, inject IPersonReader 1234public PeopleViewModel(IPersonReader dataReader)&#123; DataReader &#x3D; dataReader;&#125; Now we don’t create new ServiceReader in the Presentation layer, instead we make it someone else’s responsibility by adding IPersonReader to a contrcutor parameter. IPersonReader could be ServiceReader or SQLReader or CSVReader but PeopleViewModel doesn’t care. IPersonReader need to be created before creating PeopleViewModel. In the UI layer, inject PeopleViewModel 123456public PeopleViewerWindow(PeopleViewModel peopleViewModel)&#123; InitializeComponent(); viewModel &#x3D; peopleViewModel; this.DataContext &#x3D; viewModel;&#125; Similar things happened in UI layer, now we don’t create new PeopleViewModel, instead we inject it to the constrctor. PeopleViewModel need to be created before creating PeopleViewerWindow but it doesn’t care, as long as it is being passed to the constructor. Dependency Inversion Principle This is Dependency Inversion Principle in action, now the View Model and the Viewer Window are no longer responsible for creating or managing the lifetime of the dependencies. Instead, the dependency, the data reader, is given to the View Model and the Viewer Window to use. Object composition 123456private static void ComposeObjects()&#123; var serviceReader &#x3D; new ServiceReader(); var peopleViewModel &#x3D; new PeopleViewModel(serviceReader); Application.Current.MainWindow &#x3D; new PeopleViewerWindow(peopleViewModel);&#125; The ServiceReader and PeopleViewModel objects have been created when the app starts. This code will run OnAppStarts. Get Data from CSV file Because now the presentation layer and the data access layer are loosely coupled, if we want to change the data source, we could just create a CSVReader() instead of ServiceReader() 1234567private static void ComposeObjects()&#123; &#x2F;&#x2F;var serviceReader &#x3D; new ServiceReader(); var serviceReader &#x3D; new CSVReader(); var peopleViewModel &#x3D; new PeopleViewModel(serviceReader); Application.Current.MainWindow &#x3D; new PeopleViewerWindow(peopleViewModel);&#125; We just need to implement CSVReader class and create a new CSV object. We don’t need to change any existing code. Decorator pattern Wrap an existing interface to add functionality The idea is we wrap an existing data reader, add the caching functionality and then expose the same data reader interface to the outside world. Our service reader implements the IPersonReader interface. We take that service reader and wrap it in a caching reader. This adds the caching funcationality that we need. The caching reader is also an IPersonReader. So it looks just like any other data reader to the rest of the application. By using a Decorator, we can wrap any of our existing data readers. 1234567891011121314151617181920212223public class CachingReader : IPersonReader&#123; private IPersonReader _wrappedReader; private TimeSpan _cacheDuration &#x3D; new TimeSpan(0, 0, 30); private IEnumerable&lt;Person&gt; _cachedItems; private DateTime _dataDateTime; public CachingReader(IPersonReader wrappedReader) &#123; _wrappedReader &#x3D; wrappedReader; &#125; public IEnumerable&lt;Person&gt; GetPeople() &#123;...&#125; public Person GetPerson(int id) &#123;...&#125; private bool IsCacheValid &#123;...&#125; private void ValidateCache() &#123;...&#125; private void InvalidateCache() &#123;...&#125;&#125; In this implementation, CachingReader implements IPersonReader, so it also has GetPeople and GetPerson functions. But it has some other functions (extra caching funcationality). 1234567private static void ComposeObjects()&#123; var wrappedReader &#x3D; new ServiceReader(); var reader &#x3D; new CachingReader(wrappedReader); var peopleViewModel &#x3D; new PeopleViewModel(reader); Application.Current.MainWindow &#x3D; new PeopleViewerWindow(peopleViewModel);&#125; When we want to use the CachingReader, we could first create a ServiceReader, so it has GetPeople and GetPerson function, and we inject this ServiceReader to the CachingReader’s contructor, which adds the extra caching funcationality. This follows the Open/Closed Principle. Existing data readers can be extended without being modified. This also follows the Liskov substitution principle. This principle says that descendent classes (CachingReader) should behave the same way the base class (ServiceReader) behave. Meaning we could substitude a child class (CachingReader) for a base class (ServiceReader) in our application, and the application does not know the difference. We have extended the behavior in the child class, but the calling code does not know the difference. Unit Testing with Dependency Injection Before when we need to test the ViewModel, the data service needs to run. Because of the old code looks like this. 1234567public PeopleViewModel() &#123; DataReader &#x3D; new ServiceReader();&#125;public class ServiceReader() &#123; WebClient client &#x3D; new WebClient();&#125; Now we can just create a fake Reader and provide some fake Person data. The test of ViewModel is isolated from the Data Store. 123456789101112[Test]public void Test() &#123; &#x2F;&#x2F; Arrange IPersonReader reader &#x3D; GetFakeReader(); var viewModel &#x3D; new PeopleViewModel(reader); &#x2F;&#x2F; Act viewModel.RefreshPeople(); &#x2F;&#x2F; Assert ...&#125; Below is the real unit test code. By passing the FakeReader() to the PeopleViewModel(), we don’t need to create WebClient any more, which makes it easier to write unit test. 1234567891011121314[TestMethod]public void People_OnRefreshPeople_IsPopulated()&#123; &#x2F;&#x2F; Arrange var reader &#x3D; new FakeReader(); var viewModel &#x3D; new PeopleViewModel(reader); &#x2F;&#x2F; Act viewModel.RefreshPeople(); &#x2F;&#x2F; Assert Assert.IsNotNull(viewModel.People); Assert.AreEqual(2, viewModel.People.Count());&#125; Next we want to test CSVReader(), but we need to put a real CSV data file in the project directory to make it work because it is expecting a filePath. 12345public CSVReader()&#123; string filePath &#x3D; AppDomain.CurrentDomain.BaseDirectory + &quot;People.txt&quot;; FileLoader &#x3D; new CSVFileLoader(filePath);&#125; Luckly, the FileLoader is a public property which can be overrided. 1public ICSVFileLoader FileLoader &#123; get; set; &#125; So we could create a FakeFileReader that provides the fake data. We override the property with our own behavior so it doesn’t depend on the file system. This is called Property Injection 12345678910[TestMethod]public void GetPeople_WithGoodRecords_ReturnsAllRecords()&#123; var reader &#x3D; new CSVReader(); reader.FileLoader &#x3D; new FakeFileLoader(&quot;Good&quot;); var result &#x3D; reader.GetPeople(); Assert.AreEqual(2, result.Count());&#125; Property Injection Class property is initialized for standard behavior. By default, the standard behavior is used. Property can be set to provide alternate behavior. One question is, why not use Constructor Injection like what we did in the previous charpter? Instead of creating CSVFileLoader in the CSVReader constructor, we could inject FileLoader. This is because we only use FakeFileLoader when doing unit test. In production, it will use CSVFileLoader 100% of the time. So Constructor injection is only good for when we want to force a decision on a dependency. Property injection is good for when we have a default dependency (CSVFileLoader) that we want to use most of the time. Dependency Injection Containers Autofac Ninject Unity Castle Windsor Spring.NET","categories":[],"tags":[{"name":"Dependency Injection","slug":"Dependency-Injection","permalink":"http://hellcy.github.io/tags/Dependency-Injection/"}]},{"title":"SQL Fundamentals","slug":"SQL-Fundamentals","date":"2021-04-11T10:05:17.000Z","updated":"2021-05-24T07:27:02.660Z","comments":true,"path":"2021/04/11/SQL-Fundamentals/","link":"","permalink":"http://hellcy.github.io/2021/04/11/SQL-Fundamentals/","excerpt":"","text":"WHERE 1SELECT * FROM Table WHERE ColumnName &lt;&gt; &#39;Some value&#39;. This Query will not return Null values. To return Null values we need to check if Column is NULL 1SELECT * FROM Table WHERE ColumnName IS NULL LIKE If a column has type varchar(50), and in one row its value doesn’t have length 50. Spaces will be added to the end. So WHERE ColumnName LIKE '%SomeValue' will return nothing. You can write the query like this. WHERE ColumnName LIKE '%SomeValue%' Functions LEFT(): return the left most char from string RIGHT(): return the right most char from string LTRIM(): remove the spaces on the left of string RTRIM(): remove the spaces on the right of string GROUP BY and HAVING GROUP BY will group values into different groups. HAVING can filter out some values after GROUP BY. JOIN INNER JOIN The default JOIN, rows will be returned if they appear in both tables CROSS JOIN Will return the combination of rows from Table A and Table B. If Table A has 4 rows and Table B has 10 row, it will return 40 rows. OUTER JOIN LEFT OUTER JOIN (LEFT JOIN) The OUTER keyword is optional. LEFT OUTER JOIN is the same as LEFT JOIN. Values will be returned if it appear in the LEFT table. It doesn’t need to be in the RIGHT table. RIGHT OUTER JOIN (RIGHT JOIN) RIGHT OUTER JOIN is the same as RIGHT JOIN. Values will be returned if it appear in the RIGHT table. It doesn’t need to be in the LEFT table. FULL OUTER JOIN (FULL JOIN) Values will be returned if they appear in either LEFT table or RIGHT table. UNION UNION can be placed between SELECT queries. Rows will be appended for each SELECT. Each SELECT must have same number of Columns and DataType needs to match. UNION ALL If SELECT queries return same rows, they will all be returned. INSERT INSERT SELECT The values returned from SELECT will be inserted immediately. Works will multiple rows. 123INSERT INTO TableA(ColumnA, ColumnB)SELECT ColumnA, ColumnBFROM TableB UPDATE and DELETE If we want to delete some value in a row, we could SET it to NULL 1UPDATE Table SET ColumnName &#x3D; NULL WHERE RowId &#x3D; 1 CREATE TABLE 123456CREATE TABLE TableName (ProductId int NOT NULL,Quantity int NOT NULL DEFAULT 1,ProductName varchar(10) NULL); CREATE VIEW 1234CREATE VIEW ViewName AS SELECT *FROM TableWHERE ... VIEW is a temp Table, it can save complex SELECT queries and can be reused later. TRANSACTION If there is error in the middle of a TRANSACTION, it will not COMMIT 123BEGIN TRANSACTION-- Multiple UPDATE&#x2F;INSERT&#x2F;DELETE queriesCOMMIT TRANSACTION SAVEPOINT and ROLLBACK If error happens in the middle of a TRANSACTION and we don’t want to ROLLBACK to the start. We can create SAVEPOINT and let it ROLLBACK to that point. 1234567891011BEGIN TRANSACTIONINSERT INTO Table(ColumnA, ColumnB) VALUES (1, 2);SAVE TRANSACTION PointOne;INSERT INTO Table(ColumnA, ColumnB) VALUE (1, 2);If @@ERROR &lt;&gt; 0 ROLLBACK TRANSACTION PointOne;COMMIT TRANSACTION In the above code, if the second INSERT failed, @@ERROR will return a non-zero value, it will ROLLBACK to SAVEPOINT PointOne. Constraint Primary key 1234CREATE TABLE Table ( RowId int NOT NULL PRIMARY KEY); Foreign key 12345CREATE TABLE Table ( RowId int NOT NULL PRIMARY KEY, ForeignId int NOT NULL REFERENCES TableB(Id)); Foreign Key values must come from Primary key in the other table. Primary key records cannot be deleted unless all Foreign key records were deleted first. Some DBMS support CASCADE DELETE, which will delete the Primary key record and related Foreign key record in other tables. UNIQUE One table could have multiple UNIQUE Constraint. CHECK Further restrict values in this Column 12345CREATE TABLE Table ( quantity int NOT NULL CHECK (quantity &gt; 0), gender varchar(1) NOT NULL CHECK (gender LIKE &#39;[MF]&#39;)); INDEX If you create an index on a Column, DB will sort this Column and store it. Next time you SELECT by this Column, DB will search faster (binary search) because it is sorted. But add index to a Column will decrease the efficiency of doing UPDATE/INSERT/DELETE on those Columns. Because DB needs to update INDEX on those Columns. 12CREATE INDEX Table_Column_IndexON Table (Column); TRIGGER TRIGGER will be execute when certain changes happen to a table 1234567CREATE TRIGGER Table_triggerON TableFOR INSERT, UPDATEAS UPDATE TableSET ColumnName &#x3D; Upper(ColumnName)WHERE Table.Id &#x3D; inserted.Id","categories":[],"tags":[{"name":"SQL","slug":"SQL","permalink":"http://hellcy.github.io/tags/SQL/"}]},{"title":".NET with NUnit Test","slug":"NET-with-NUnit-Test","date":"2021-04-08T13:06:15.000Z","updated":"2021-05-24T07:27:02.659Z","comments":true,"path":"2021/04/08/NET-with-NUnit-Test/","link":"","permalink":"http://hellcy.github.io/2021/04/08/NET-with-NUnit-Test/","excerpt":"","text":"What is NUnit? NUnit is a unit-testing framework for all .Net languages. Initially ported from JUnit, the current production release, version 3, has been completely rewritten with many new features and support for a wide range of .NET platforms. NuGet Packages NUnit NUnit3TestAdapter Microsoft.NET.Test.Sdk Your First NUnit Test Case Add [TestFixture] and [Test] to mark code as tests Test can be run in Test Explorer and in Command Line Why Write Automated Tests? Help to find defects and regressions. When we make a change to the project, we may find that unintentionally break one of the existing tests. Something that once working is no longer working. Automated Tests give us greater confidence that the software is working as it should. Understanding the NUnit Test Framework NUnit Library Attributes e.g. [Test] Assertions Test Runner Recognizes attributes Execute test methods Report test results Test explorer donet test NUnit attributes Overview [TestFixture]: Mark a class that contains tests [Test]: Mark a method as a test [Category]: Organize tests into categories [TestCase]: Data driven test cases [Values]: Data driven test parameters [Sequential]: How to combine test data [SetUp]: Run code before each test [OneTimeSetUp]: Run code before first test in class NUnite Assertions Overview 123&#x2F;&#x2F; Constraint Model of assertions (newer)Assert.That(sut.Years, Is.EqualTo(1));Assert.That(test result, constraint instance); This Classic Model is still supported but since no new features have been added to it for some time. the constraint-based model must be used in order to have full access to NUnit’s capabilities. 1234Classic Model of assertions (older)Assert.AreEqual(1, sut.Years);Assert.NotNull(sut.Years);Assert.xyz(...); The Logical Arrange, Act, Assert Test Phases Arrange: Set up test objects, initialize test data Act: call methods, set property, to cause some effect in the project Assert: compare returned value/end state with expected Qualities of Good Tests Fast Repeatable Isolated: One Test should not depend on others to run Trustworthy Valuable Asserting on Different Types of Results Asserts: Evaluate and verify the outcome of a test based on a returned result, final object state, or the occurence of events observed during execution. An assert should either pass or fail. How many asserts per test? A single test usually focuses on testing a single ‘behaviour’. Multiple asserts are usually ok if all the asserts are related to testing this single behaviour. Asserting on Equality 1234567&#x2F;&#x2F; compare valueAssert.That(a, Is.EqualTo(...));Assert.That(a, Is.Not.EqualTo(...));&#x2F;&#x2F; compare referenceAssert.That(a, Is.SameAs(...));Assert.That(a, Is.Not.SameAs(...)); Adding custom failure message 1Assert.That(a, Is.EqualTo(...), &quot;Custom Error Message&quot;); Asserting on Floating Numbers 12Assert.That(a, Is.EqualTo(0.33).Within(0.001));Assert.That(a, Is.EqualTo(0.33).Within(10).Percent); Asserting on Null Values 1234string name &#x3D; &quot;yuan&quot;;Assert.That(name, Is.Null); &#x2F;&#x2F; failAssert.That(name, Is.Not.Null); &#x2F;&#x2F; pass Asserting on String Values 12345678910111213141516171819string name &#x3D; &quot;yuan&quot;;Assert.That(name, Is.Empty); &#x2F;&#x2F; failAssert.That(name, Is.Not.Empty); &#x2F;&#x2F; passAssert.That(name, Is.EqualTo(&quot;yuan&quot;)); &#x2F;&#x2F; passAssert.That(name, Is.EqualsTo(&quot;YUAN&quot;)); &#x2F;&#x2F; fail, case-sensitiveAssert.That(name, Is.EqualTo(&quot;YUAN&quot;).IgnoreCase); &#x2F;&#x2F; passAssert.That(name, Does.StartWith(&quot;yu&quot;)); &#x2F;&#x2F; passAssert.That(name, Does.EndWith(&quot;an&quot;)); &#x2F;&#x2F; passAssert.That(name, Does.Contain(&quot;ua)); &#x2F;&#x2F; passAssert.That(name, Does.Not.Contain(&quot;kk&quot;)); &#x2F;&#x2F; passAssert.That(name, Does.StartWith(&quot;yu&quot;) .And .EndWith(&quot;an&quot;)); &#x2F;&#x2F; passAssert.That(name, Does.StartWith(&quot;kk&quot;) .Or .EndWith(&quot;an&quot;)); &#x2F;&#x2F; pass Asserting on Boolean Values 12345678910bool isTrue &#x3D; true;Assert.That(isTrue); &#x2F;&#x2F; passAssert.That(isTrue, Is.True); &#x2F;&#x2F; passbool isFalse &#x3D; false;Assert.That(isFalse &#x3D;&#x3D; false); &#x2F;&#x2F; passAssert.That(isFalse, Is.False); &#x2F;&#x2F; passAssert.That(isFalse, Is.Not.True); &#x2F;&#x2F; pass Asserting within Ranges 1234567891011121314int i &#x3D; 42;Assert.That(i, Is.GreaterThan(42)); &#x2F;&#x2F; failAssert.That(i, Is.GreaterThanOrEqualTo(42)); &#x2F;&#x2F; passAssert.That(i, Is.LessThan(42)); &#x2F;&#x2F; failAssert.That(i, Is.GreaterThanOrEqualTo(42)); &#x2F;&#x2F; passAssert.That(i, Is.InRange(40, 50)); &#x2F;&#x2F; passDateTiem d1 &#x3D; new DateTime(2021, 2, 20);DateTiem d2 &#x3D; new DateTime(2021, 2, 25);Assert.That(d1, Is.EqualTo(d2)); &#x2F;&#x2F; failAssert.That(d1, Is.EqualTo(d2).Within(4).Days); &#x2F;&#x2F; failAssert.That(d1, Is.EqualTo(d2).Within(5).Days); &#x2F;&#x2F; pass Asserting on Objects 123456789101112131415161718192021222324252627class Product &#123; int ProductId &#123;get; set;&#125; string ProductName &#123;get; set;&#125; Product(int ProductId, string ProductName) &#123; this.ProductId &#x3D; ProductId; this.ProductName &#x3D; ProductName; &#125;&#125;var products &#x3D; new List&lt;Product&gt; &#123; new Product(1, &quot;a&quot;), new Product(2, &quot;b&quot;),&#125;;Assert.That(products, Has.Exactly(2).Items); &#x2F;&#x2F; passAssert.That(products, Is,Unique); &#x2F;&#x2F; passAssert.That(products, Has.Exactly(1) .Property(&quot;ProductName&quot;).EqualTo(&quot;a&quot;) .And .Property(&quot;ProductId).EqualTo(1));Assert.That(products, Has.Exactly(1) .Matches&lt;Product&gt;( item &#x3D;&gt; item.ProductName &#x3D;&#x3D; &quot;a&quot; &amp;&amp; item.ProductId &#x3D;&#x3D; 1 )); Controlling Test Execution Use [Ignore] to skip tests. [Ignore] could also be put before class to skip the entire test class 12345[Test][Ignore(&quot;Custom reason why we need to skip this test&quot;)]public void TestWillNotRun() &#123;&#125; Use [Category] to add test cases to categories, we can only run tests for certain category. In Test Explorer, we can group tests by Traits, which is just another name for Category One Test Case can belongs to multiple [Category]. [Category] can be applied to Class 12345[Test][Category(&quot;Category 1&quot;)]public void TestInCategoryOne() &#123;&#125; [SetUp] code will be executed before each test. So it is a good place to define variables and objects. 1234567891011121314public class TestClass &#123; private List&lt;Product&gt; products; private string test; [SetUp] public void Setup() &#123; products &#x3D; new List&lt;Products&gt; &#123; new Product(1, &quot;a&quot;), new Product(2, &quot;b&quot;), &#125;; test &#x3D; &quot;test&quot;; &#125;&#125; [TearDown] code will be executed after each test, it is the place to dispose all unnecessary objects 12345678public class TestClass &#123; [TearDown] public void Setup() &#123; if (products !&#x3D; null) &#123; ((IDisposable)products).Dispose(); &#125; &#125;&#125; [OneTimeSetUp] code will be executed once before the first test case. Define objects that will not be modified by test cases here. [OneTimeTearDown] code will be executed once after the last test case. Dispose any objects here. Data Driven Tests and Reducing Code Duplication [TestCase]: If we want to run the same test but with different data, we could pass different variables into the test function. 12345678910111213[Test][TestCase(200_000, 6.5, 30, 1264.14)][TestCase(200_000, 10, 30, 1755.14)][TestCase(500_000, 10, 30, 4387.86)]public void CalculateCorrectMonthlyRepayment(decimal principal, decimal interestRate, int termInYears, decimal expectedMonthlyPayment)&#123; var sut &#x3D; new LoanRepaymentCalculator(); var monthlyPayment &#x3D; sut.CalculateMonthlyRepayment( new LoanAmount(&quot;USD&quot;, principal), interestRate, new LoanTerm(termInYears)); Assert.That(monthlyPayment, Is.EqualTo(expectedMonthlyPayment));&#125; 12345678910[Test][TestCase(200_000, 6.5, 30, ExpectedResult &#x3D; 1264.14)][TestCase(200_000, 10, 30, ExpectedResult &#x3D; 1755.14)][TestCase(500_000, 10, 30, ExpectedResult &#x3D; 4387.86)]public decimal CalculateCorrectMonthlyRepayment_SimplifiedTestCase(decimal principal, decimal interestRate, int termInYears)&#123; var sut &#x3D; new LoanRepaymentCalculator(); return sut.CalculateMonthlyRepayment(new LoanAmount(&quot;USD&quot;, principal), interestRate, new LoanTerm(termInYears));&#125; Create Test Case from Centralized Data Class [TestCaseSource(typeof(Class_Name), &quot;Function_Name&quot;)] 1234567891011[Test][TestCaseSource(typeof(MonthlyRepaymentTestData), &quot;TestCases&quot;)]public void CalculateCorrectMonthlyRepayment_Centralized(decimal principal, decimal interestRate, int termInYears, decimal expectedMonthlyPayment)&#123; var sut &#x3D; new LoanRepaymentCalculator(); var monthlyPayment &#x3D; sut.CalculateMonthlyRepayment( new LoanAmount(&quot;USD&quot;, principal), interestRate, new LoanTerm(termInYears)); Assert.That(monthlyPayment, Is.EqualTo(expectedMonthlyPayment));&#125; Create Test Case with Data from File 1234567891011[Test][TestCaseSource(typeof(MonthlyRepaymentCsvData), &quot;GetTestCases&quot;, new object[] &#123; &quot;Data.csv&quot; &#125;)]public void CalculateCorrectMonthlyRepayment_Csv(decimal principal, decimal interestRate, int termInYears, decimal expectedMonthlyPayment)&#123; var sut &#x3D; new LoanRepaymentCalculator(); var monthlyPayment &#x3D; sut.CalculateMonthlyRepayment( new LoanAmount(&quot;USD&quot;, principal), interestRate, new LoanTerm(termInYears)); Assert.That(monthlyPayment, Is.EqualTo(expectedMonthlyPayment));&#125; Create Test Cases with Values, Sequential and Range Without [Sequential], it will create 3 * 3 * 3 = 27 test cases With [Sequential], it will only create 3 test cases 1234567891011[Test][Sequential]public void CalculateCorrectMonthlyRepayment_Combinatorial( [Values(100_000, 200_000, 500_000)] decimal principal, [Values(6.5, 10, 20)] decimal interestRate, [Values(10, 20, 30)] int termInYears)&#123; var sut &#x3D; new LoanRepaymentCalculator(); var monthlyPayment &#x3D; sut.CalculateMonthlyRepayment(new LoanAmount(&quot;USD&quot;, principal), interestRate, new LoanTerm(termInYears));&#125; Create Custom Category Attribute 123[AttributeUsage(AttributeTargets.Method | AttributeTargets.Class, AllowMultiple &#x3D; false)]class ProductComparisonAttribute : CategoryAttribute&#123;&#125; Then we can use Custom Attribute like this 12345[Test][ProductComparison]public void CustomAttributeTest() &#123; &#125;","categories":[],"tags":[{"name":"Unit Tests","slug":"Unit-Tests","permalink":"http://hellcy.github.io/tags/Unit-Tests/"},{"name":".NET","slug":"NET","permalink":"http://hellcy.github.io/tags/NET/"}]},{"title":"JavaScript Fundamentals","slug":"JavaScript-Fundamentals","date":"2021-04-02T23:31:11.000Z","updated":"2021-05-24T07:27:02.659Z","comments":true,"path":"2021/04/03/JavaScript-Fundamentals/","link":"","permalink":"http://hellcy.github.io/2021/04/03/JavaScript-Fundamentals/","excerpt":"","text":"Data Types undefined Boolean Number String Symbol null object undefined and null in JavaScript undefined mean a variable has been declared but not yet been assigned a value. The data type of undefined variable is also undefined. (undefined is a data type). 123var x;alert(x); &#x2F;&#x2F; undefinedalert(typeof x); &#x2F;&#x2F; undefined null is an assignment value, it can be assigned to a variable as a representation of no value. The data type of null variable is an object. 123var x &#x3D; null;alert(x); &#x2F;&#x2F; nullalert(typeof x); &#x2F;&#x2F; object undefined and null are equal in value but different in type. 12345typeof undefined; &#x2F;&#x2F; undefinedtypeof null; &#x2F;&#x2F; objectnull &#x3D;&#x3D;&#x3D; undefined; &#x2F;&#x2F; falsenull &#x3D;&#x3D; undefined; &#x2F;&#x2F; true Declare variable var: normal way to declare a variable. let: the variable you declared will only be used within the scope of where you declare it. const: the variable value will never change Scope Local scope Global scope JavaScript has function scope, each function creates a new scope. Scope determines the accessibility of these variables. Variables defined inside a function are not accessible from outside the function Array push: Add anitem to the end of the array pop: Remove an item from the end of the array shift: Remove an item from the beginning of an array unshift: Add an item to the beginning of an array indexOf: find the index of an item in the array splice: Remove items from an index position. 12345678910111213141516let vegetables &#x3D; [&#39;Cabbage&#39;, &#39;Turnip&#39;, &#39;Radish&#39;, &#39;Carrot&#39;]console.log(vegetables)&#x2F;&#x2F; [&quot;Cabbage&quot;, &quot;Turnip&quot;, &quot;Radish&quot;, &quot;Carrot&quot;]let pos &#x3D; 1let n &#x3D; 2let removedItems &#x3D; vegetables.splice(pos, n)&#x2F;&#x2F; this is how to remove items, n defines the number of items to be removed,&#x2F;&#x2F; starting at the index position specified by pos and progressing toward the end of array.console.log(vegetables)&#x2F;&#x2F; [&quot;Cabbage&quot;, &quot;Carrot&quot;] (the original array is changed)console.log(removedItems)&#x2F;&#x2F; [&quot;Turnip&quot;, &quot;Radish&quot;] slice: copy an array Object.freeze const: creates an immutable binding, you cannot re-assign a new value to the binding. But if you delcare a const array or object. You can set new value to the element in the array or object object.freeze: makes an object immutable, so you cannot change its properties. Object Dynamic Properties The property ‘test’ is a dynamic property, it’s value will be evaluated during runtime. So obj will have a property name ‘test’ with value 52. 12345678910const test &#x3D; &#39;answer&#39;;const obj &#x3D; &#123; p1:10, p2:20, [test]: 52&#125;;console.log(obj.test);console.log(obj.answer); Anonymous function functions without name. You can also pass that function to a variable 123var magic &#x3D; function() &#123; return new Date();&#125; Arrow function You can convert anonymous function to arrow function 12345var magic &#x3D; () &#x3D;&gt; &#123; return new Date();&#125;var magic &#x3D; () &#x3D;&gt; new Date(); Arrow function with parameters 1var myConcat &#x3D; (var1, var2) &#x3D;&gt; arr1.concat(arr2); Example: Filter the array with only positive numbers and return the square of all remain elements in a new array Array.filter: The filter() method creates a new array with all elements that pass the test implemented by the provided function. Array.map: The map() method creates a new array populated with the results of calling a provided function on every element in the calling array. 123456789101112131415const array &#x3D; [1,2,-3,4,-5,6,7];const squareList &#x3D; arr &#x3D;&gt; &#123; const squaredList &#x3D; arr.filter(function callback(num) &#123; return Number.isInteger(num) &amp;&amp; num &gt; 0; &#125;).map(function square(num) &#123; return num * num; &#125;); return squaredList;&#125;const squaredIntegers &#x3D; squareList(array);console.log(squaredIntegers); Using Arrow functions 123456789const array &#x3D; [1,2,-3,4,-5,6,7];const squareList &#x3D; arr &#x3D;&gt; &#123; const squaredList &#x3D; arr.filter(num &#x3D;&gt; Number.isInteger(num) &amp;&amp; num &gt; 0).map(num &#x3D;&gt; num * num); return squaredList;&#125;const squaredIntegers &#x3D; squareList(array);console.log(squaredIntegers); Example: Write a function that takes multiple parameters and add them up 123456function sum(x, y, z) &#123; args &#x3D; [x, y, z]; return args.reduce((accumulator, currentValue) &#x3D;&gt; accumulator + currentValue, 0);&#125;console.log(sum(1,2,3)); Regular functions give access to their calling environment while arrow functions give access to their defining environment The value of the ‘this’ keyword inside a regular function depends on HOW the function was CALLED (the OBJECT that made the call) In arrow functions, this keyword doesn’t mean the caller of the arrow function. The value of the ‘this’ keyword inside an arrow function depends on WHERE the function was DEFINED (the scope that defined the function). This makes it great for delayed execution cases like events and listeners. 1234567891011121314const test &#x3D; (function test () &#123; const testerObj &#x3D; &#123; func1: function() &#123; console.log(&#39;func1&#39;, this); &#125;, func2: () &#x3D;&gt; &#123; console.log(&#39;func2&#39;, this); &#125;, &#125;; testerObj.func1(); testerObj.func2(); &#125;)() Using Rest operator to represent multiple parameters Rest Operator: The rest parameter syntax allows a function to accept an indefinite number of arguments as an array, Reduce: The reduce() method executes a reducer function (that you provide) on each element of the array, resulting in single output value. The reducer function takes four arguments: Accumulator Current Value Current Index Source Array Your reducer function’s returned value is assigned to the accumulator, whose value is remembered across each iteration throughout the array, and ultimately becomes the final, single resulting value. 12345function sum(...args) &#123; return args.reduce((accumulator, currentValue) &#x3D;&gt; accumulator + currentValue, 0);&#125;console.log(sum(1,2,3,4)); Spread syntax Spread syntax (…) allows an iterable such as an array expression or string to be expanded in places where zero or more arguments (for function calls) or elements (for array literals) are expected, or an object expression to be expanded in places where zero or more key-value pairs (for object literals) are expected. 123456789101112const arr1 &#x3D; [&#39;JAN&#39;, &#39;FEB&#39;, &#39;MAR&#39;, &#39;APR&#39;, &#39;MAY&#39;];let arr2;(function () &#123; &#x2F;&#x2F; spread arr1 into individual elements and create a new array by surrond it with [] arr2 &#x3D; [...arr1]; arr1[0] &#x3D; &#39;potato&#39;;&#125;)();&#x2F;&#x2F; arr2[0] will still be &#39;JAN&#39;console.log(arr2); Destructuring assignment The destructuring assignment syntax is a JavaScript expression that makes it possible to unpack values from arrays, or properties from objects, into distinct variables. 12345var obj &#x3D; &#123;x:3.6, y:7.4, z:6.5&#125;;const &#123;x : a, y: b, z: c&#125; &#x3D; obj;console.log(&#96;$&#123;a&#125; $&#123;b&#125; $&#123;c&#125;&#96;); Destructuring Assignment: Nested Objects 123456789101112const LOCAL_FORECAST &#x3D; &#123; today: &#123;min : 72, max: 83&#125;, tomorrow : &#123;min : 73.3, max: 84.6&#125;&#125;;function getMaxOfTmw(forecast) &#123; const &#123;tomorrow : &#123;max : maxOfTomorrow &#125;&#125; &#x3D; forecast; return maxOfTomorrow;&#125;console.log(getMaxOfTmw(LOCAL_FORECAST)); Destructuring Assignment: Arrays 12const[x, y, , z] &#x3D; [1,2,3,4,5,6];console.log(x, y, z); Destructuring Assignment: Pass an object 1234567891011121314const stats&#x3D; &#123; max: 56.7, standard_deviation: 4.34, median: 34.54, mode: 23.5, min: -0.4, average: 45.6&#125;function half(&#123;max, min&#125;) &#123; return (max + min) &#x2F; 2.0;&#125;console.log(half(stats)); Object Literal Declarations Using Simple Fields 123const createPerson &#x3D; (name, age, gender) &#x3D;&gt; ( &#123;name, age, gender&#125; )console.log(createPerson(&#39;Yuan Cheng&#39;, 27, &#39;male&#39;)); Functions in Objects 123456789const bicycle &#x3D; &#123; gear : 2, setGear: function(newGear) &#123; this.gear &#x3D; newGear; &#125;&#125;;bicycle.setGear(3);console.log(bicycle.gear); we could remove the ‘function’ keyword 123456789const bicycle &#x3D; &#123; gear : 2, setGear(newGear) &#123; this.gear &#x3D; newGear; &#125;&#125;;bicycle.setGear(3);console.log(bicycle.gear); class syntax 123456var SpaceShuttle &#x3D; function(targetPlanet) &#123; this.targetPlanet &#x3D; targetPlanet;&#125;var zeus &#x3D; new SpaceShuttle(&#39;Jupiter&#39;);console.log(zeus.targetPlanet); Using Class and Constructor 12345678class SpaceShuttle &#123; constructor(targetPlanet) &#123; this.targetPlanet &#x3D; targetPlanet; &#125;&#125;var zeus &#x3D; new SpaceShuttle(&#39;Jupiter&#39;);console.log(zeus.targetPlanet); getters and setters 123456789101112131415class Book &#123; constructor(author) &#123; this._author &#x3D; author; &#125; &#x2F;&#x2F; getter get writer() &#123; return this._author; &#125; &#x2F;&#x2F; setter set writer(updatedAuthor) &#123; this._author &#x3D; updatedAuthor; &#125;&#125; import vs require import functions from other js files 1import &#123;capitalzeString&#125; from &quot;string_function&quot; export The export statement is used when creating JavaScript modules to export live bindings to functions, objects, or primitive values from the module so they can be used by other programs with the import statement. Bindings that are exported can still be modified locally; when imported, although they can only be read by the importing module the value updates whenever it is updated by the exporting module. below code is saved in a js file: string_function 1export const capitalizeString &#x3D; str &#x3D;&gt; str.toUpperCase(); * to import import * will import every functions you export in the other file to a object 1import * as capitalizeStrings from &quot;capitalize_strings&quot;; Named export vs export default Named export: With named exports, one can have multiple named exports per file. Then import the specific exports they want surrounded in braces. The name of imported module has to be the same as the name of the exported module. Export default: One can have only one default export per file. The naming of import is completely independent in default export and we can use any name we like. No curly braces needed when import Promises A promise is an object that might deliver data at a later point in the program. Fetch API will return a promise, to consume that promise, we do a .then call on the result of fetch and supply a callback function. The Fetch API will have a raw response ‘resp’, you need to call the .json method on that response object. The json method is also a asynchronous function. It also returns a promise. So we do another .then call on the result of the json function 123456789const fetchData &#x3D; () &#x3D;&gt; &#123; fetch(&#39;https:&#x2F;&#x2F;api.github.com&#39;).then(resp &#x3D;&gt; &#123; resp.json().then(data &#x3D;&gt; &#123; console.log(data); &#125;); &#125;);&#125;;fetchData(); The above code works, but it is difficult to read. We could use async/await. 123456789const fetchData &#x3D; async () &#x3D;&gt; &#123; const resp &#x3D; await fetch(&#39;https:&#x2F;&#x2F;api.github.com&#39;); const data &#x3D; await resp.json(); console.log(data);&#125;;fetchData(); the async function is another way for us to consume promises without having us to use .then calls","categories":[],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://hellcy.github.io/tags/JavaScript/"}]},{"title":"AWS SAA Architecting For Performance Efficiency","slug":"AWS-SAA-Architecting-for-Performance-Efficiency","date":"2021-03-16T04:36:37.000Z","updated":"2021-05-24T07:27:02.657Z","comments":true,"path":"2021/03/16/AWS-SAA-Architecting-for-Performance-Efficiency/","link":"","permalink":"http://hellcy.github.io/2021/03/16/AWS-SAA-Architecting-for-Performance-Efficiency/","excerpt":"","text":"Part One: Understanding the Design Principles Part Two: Considering Compute Performance Options Part Three: Reviewing Storage Performance Options Part Four: Examing Database Performance Options Part Five: Evaluating Network Performance Options Part Six: Preparing to Improve Your Architecture Part Seven: Monitoring Your Architecture Part Eight: Understanding the Trade-offs Part One: Understanding the Design Principles There are three main differences compare traditional on premises application and cloud application. 1. Cost. 2. Security and 3. Performance. We are going to focus on number three. Performance. Cloud services are changing fast. Go global: AWS have many regions, deploy application to the region that close to the user to reduce the latancy. Go global: local region will comply to the laws and regulations Go global Think serverless Use new technologies Experiment often Right tool for the task Part Two: Considering Compute Performance Options What does compute performance includes? Processing -&gt; CPU Capacity -&gt; Storage Scaling Responsive Economical Understand your workload Undetstand AWS compute Need to gather and analyze data, and testing AWS compute options EC2 Elastic Cloud Compute The default option, virtualized servers. IssA (infrustructure as a service) Choose resources. You own the OS.(You are responsible for patching the OS and config all aspects of it.) EC2 General resources vCPUs Memory Storage Network EC2 extra features Burstable: if your EC2 is not using its full compute power, you gain credits which you can use in the future when you need it to burst the compute power of your instance for a short period of time. GPU FPGA (Filled Programmable Gate Arrays): Allows you to create customized hardware accelerators Instance Types General Purpose: Standard, balanced Compute optimized: high compute power Memory optimized: for memory intensive workloads Accelerated computing: GPU or FPGA Storage optimized: high storage Bare metal EC2 Auto Scaling Metrics based: scale up or down based on the metric you choose Schedule based: scale up or down for a booked time Health based: replace unhealthy instances ECS Elastic Container Service Similar workloads as EC2 Migrate apps to the cloud, long running apps, batch processing, Microservices Better utilize resources. Can run multiple containers on a single instance. ELB, balance traffic to each container, Autoscaling. AWS Fargate: manages the instances on which your containers run. you don’t need to manage the server instances. AWS Lambda FaaS (Function as a service). Serverless computing. Backend processing, Event processing, Stream processing, Data processing AWS resource triggers: other resources can trigger Lambda functions You can choose memory needed for a lambda function Advantages: Simply execute code. We don’t need to worry about the servers that run our Lambda codes. Automatic scaling for Lambda function. Fault tolerant: if a function fails, AWS will trigger the function again Pay for usage Applying our knowledge 1. A company called Globomantics wants to move their application to cloud. They have customers globally. The first application they want to move to cloud is an app that collections data from clinical trails. Doctors enter information each time they do checkings. Considerations for Choice First app of many Time should be fast Predicatable usage They want to use ECS. Lift and shift: Easy to containerize the app. Able to scale. Able to choose instance sizes. Allows them to leverage for future applications. Different containers in a single instance. Save costs 2. They also want to build a new web application for the cloud. Allow people to register medical devices. Share medical devices globally. Considerations for Choice Manage costs Global reach Minimal maintenance They want to go with Lambda. Services behind a static site to save costs. Only pay for runtime. Lambda scales besed on demand. Can be deployed to multiple regions. No servers to maintain. Part Three: Reviewing Storage Performance Options S3 data is encrypted. Access Managemenet(IAM), Lifecycle management. Query in place.(Don’t need to move the data to query it using SQL like command) Shared Access Low latency High thoughput: move data in or out S3 quickly High Availability: available for multiple availability zones High durability: data is duplicated across multiple availability zones Standard Intelligent Tier Standard Infrequent Access(IA)(high latency) One-Zone Infrequent Access(low availability, low durability) Glacier Immutable, data do not change once they are in Glacier. Durable Query stored data without retrieval. Archival storage Encrypted Access Control Audit logging Latency options. Expedited. latency in minutes. Standard. Default, number of hours to get data back. Bulk. cheaper and takes longer. Economical, put data in Glacier is cheap and high durable. Deep Archive. The cheapest and longest. normally 6-12 hours. Do not access data frequently, 2-3 times a year. EBS (Elastic Block Storage) Attached to EC2 instances. Multi-Attach, storage volumn can be attached to up to 16 instances. Instances must be in same availability zone. Data is Replicated to multiple availbility zones. high availability and durability Access control. Provisioned IOPS SSD Standard Purpose IOPS SSD Cold HDD Thoughput optimized HDD Snapshots: a snapshots of a storage in that time and can be shared to other zones. Elastic volumes. pay for what actually stored. EFS General Purpose MAX I/O Same example as before. Migrating to AWS storage. It is one of the web applications. It requires global access. Data will be collected from clinical trials. And some data will be entered on daliy basis. They need shared access of data. Data must be durable. Data will be stored in a long term basis. S3 and Glacier: high durable. Access from ECS containers. Multiple access. Long term storage. New application. Provide medical devices to people who need it. Global user base. Lower cost. Local access. Non-critical images(could be lost, no big problem). S3: single region. Reduced Redundancy Storage(RRD). Part Four: Examing Database Performance Options Install on EC2 we could choose to install a Database on a EC2 instance. But that means we need to do all the backup, restore ourselves. We are not using the serverless managed services provided by AWS. But in some cases, we have to choose this way. Situations like: 1. Control Environment. we want to control everything. 2. Certified. Maybe the services in AWS are not certified by the customer. 3. Specific tools. Our application needs some tools that have to work with standalone database. RDS DynamoDB Redshift RDS Default choice. Complex queries. Consistent transactions. Multi-AZ Read replicas Encryption Backups and snapshots Instance type Storage type Network setup Backup DynamoDB Flexible structure Flexible structure Less complex queries: You are able to query on particular keys, the partition key and any secondary keys that you define. Can’t join tables. Low latency Transactions Global tables: store data in multiple regions Encryption Evolving schema: supports changes and growth in your application(add/remove columns…) Integration with Lambda Partition key: store data on different nodes of the database Secondary indexes Provisioned capacity: number of reads and writes. Dynamodb will auto scale on-demand capacity: pay for what you use. No auto scaling. Redshift Large scale analytics Setup in minutes Warehouse and data lake Encryption Scale to petabytes Query S3 Economical Node type Dense compute: fast CPUs, large RAM and SSD for fast performance Dense storage Same example as before. They want to have minimum effort to do the migration They want to leverage managed services Improve availability They have decided to use RDS. Using SQL server. Structured data. No servers to manage. High availability New application. DynamoDB. Flexible data structure(NoSQL). Trigger action(Lambda integration). Flexible cost structure(On-demand pricing). Global tables. Part Five: Evaluating Network Performance Options Region and AZ Regions are geographical area. One region may have multiple AZs that are also isolated to each other. While the AZs are isolated geographically, they are connected by AWS that allows data to be transferred between each zones. Local Zones Some users still think the regions provided by AWS have high latency. They can choose to use local zones. They are built in large cities and connected to near by regions with low latency, high throughput connectivity. Local zones don’t have all the services provided by AWS as normal AZs. Why do we choose one region over another? Laws and Regulations: e.g. Some governments required that any data of their citizens remain in their countries User location: put application closer to your end users. Data location Cost CloudFront Global network: CloudFront is outside of AWS regions, that deliver our applications to end users Content delivery: Similar to CDN Static content: static content is cached to the place closer to end users to reduce latency Dynamic content: AWS also supported Dynamic content (intelligent caching) Intelligent: you can setup geo-restrictions to not allow edge content to deliver content to certain geo-locations Programmable: Lambda at edge: create serverless functions at edge locations. Put compute power closer to your end users. Route53 DNS solution for AWS: translate a user-friendly URL to the IP address Private DNS: Route53 supports private DNS, you can setup friendly names for your internal services Traffic flow If you deploy your solution to multiple regions, you can config so that your users only send requests to their regions. Latency routing: Traffic flow will determine the region that will be serving the content with the least latency Geographic routing: route users to the cloest region. Health based routing: not route users to a region that with unhealthy status. Round robin routing: route user to the next region available. Route traffic evenly to all regions. Direct Connect Instead of going through public internet, AWS will create a dedicated line for users to connect from AWS to your data center. It is encrypted and you can config the speed. VPC endpoints Normally, if your VPC wants to connect to other AWS services, it can only go through public internet, but with VPC endpoints, it can connect to other AWS services directly through the private internet AWS network EC2 instance types some EC2 instance types have better internet performance than others. Pay attention to it before you launch the EC2 instance. Choose the type that suitable for your applications. Apply our knowledge They want their application to be deployed in a single region but to multiple AZs. They use AWS ECS(elastic container service) to manage their application. And use AWS Fargate to manage their containers. They also choose to use Multi-AZ RDS for their DB. They also want their Data to be stored in S3. So they want a VPC endpoint for S3 to reduce latency. So when they want to access data in S3. they don’t need to go through public internet. They also have a new application that they want to have a friendly domain name. Reduced latency and managed cost. So they have decided to use Route53. because the application is hosted on S3 buckets. They need to register domain names for each S3 bucket. And configure Route 53 to route traffic to right S3 bucket using their domain names. They also want to have a global portal that has links to each deployed regions. Part Six: Preparing to Improve Your Architecture CI/CD pipeline (Continuous Integration/ Continuous Deployment) We need to have repeatable builds, repeatable infrastructrue and Controlled tests CloudFormation Infrastructure template(JSON or YAML) Automate creation Ensure consistency CloudFormation templates Format version Description Parameters Resources Output Part Seven: Monitoring Your Architecture Monitor Resources Application Operations Respond Ignore Manually Automate Modify CloudWatch Metrics Application Infrastructure AWS or on-premises Actions: Autoscaling. Actions: Messages Actions: Lambda functions can be triggered from CloudWatch Analytics: CloudWatch can store months of histoical data for you to analyse Create a log to delete S3 object Create CloudTrail Trail Create Lambda function Create CloudWatch Rule Create a CloudTrail Trail Create a Lambda function Create CloudWatch Rule Part Eight: Understanding the Trade-offs Time Cost Memory Efficiency Complexity Possible Trade-offs Queuing Partitioning Caching Compression Queuing AWS SQS (simple queuing service) Decouple (producer, consumer) Scale independently (add producer or delete consumer) Acceptable delay Time vs Efficiency Data Paritioning For example: RDBMS doesn’t have partition. so we need to consider what data goes into which instance of database, that increase complexity. Whereas many NoSQL DB already has partition. In DynamoDB, we have partition key for each table. The data that has the same partition key will go into the same node. So when choose a partition key, choose a key that roughly evenly distributed across the data. Complexity / consistency vs Time RDBMS vs NoSQL Distribution Maintenance Caching Cache: heavliy used data will be stored in memory. Read Replics: if you have a read replica of your DB, users can go into read replica if they only read. Reduce the traffic of your primary server. CDN: take data and store data closer to users place. Memory/ consistency vs Time Compression Code assets: reduce the size of source code to reduce the time to load the application Files: same. redurce the size of file will reduce the transfer time Time vs memory","categories":[],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://hellcy.github.io/tags/AWS/"}]},{"title":"React Overview","slug":"React-Overview","date":"2021-03-16T00:22:53.000Z","updated":"2021-05-24T07:27:02.660Z","comments":true,"path":"2021/03/16/React-Overview/","link":"","permalink":"http://hellcy.github.io/2021/03/16/React-Overview/","excerpt":"","text":"Setting up a Development Environment Create folder and package.json file 123mkdir diy-reactcd diy-reactnpm init --y Install Main Dependencies Install Express 1npm i express Install React and React-dom 1npm i react react-dom Install webpack 1npm i webpack webpack-cli Webpack is a module bunlder. A react application usually contains multiple modules and depends on many external modules too. When we ship the application to the browser we need to bundle all necessary files into a single bundle and ship it to the browser. Install Babel 1npm i babel-loader @babel&#x2F;core @babel&#x2F;node @babel&#x2F;preset-env @babel&#x2F;preset-react Babel is the package that compiles JSX into regular React API calls. Install Development Dependencies Install nodemon 1npm i -D nodemon nodemon is a package that lets us automatically restart node when we change things in node. Install ESLint 1npm i -D eslint babel-eslint eslint-plugin-react eslint-plugin-react-hooks ESLint will immediately analyze your code and tell you the problems, you can have consistent styling to your code by using ESLint. Configure ESLint Go to your project directory, create a new file called ‘.eslintrc.js’ and paste the below code. 12345678910111213141516171819202122232425262728293031323334module.exports &#x3D; &#123; parser: &#39;babel-eslint&#39;, env: &#123; browser: true, commonjs: true, es6: true, node: true, jest: true, &#125;, parserOptions: &#123; ecmaVersion: 2020, ecmaFeatures: &#123; impliedStrict: true, jsx: true, &#125;, sourceType: &#39;module&#39;, &#125;, plugins: [&#39;react&#39;, &#39;react-hooks&#39;], extends: [ &#39;eslint:recommended&#39;, &#39;plugin:react&#x2F;recommended&#39;, &#39;plugin:react-hooks&#x2F;recommended&#39;, ], settings: &#123; react: &#123; version: &#39;detect&#39;, &#125;, &#125;, rules: &#123; &#x2F;&#x2F; You can do your customizations here... &#x2F;&#x2F; For example, if you don&#39;t want to use the prop-types package, &#x2F;&#x2F; you can turn off that recommended rule with: &#39;react&#x2F;prop-types&#39;: [&#39;off&#39;] &#125;, &#125;; Configure Jest jest is the package to test React applications 1npm i -D jest babel-jest react-test-renderer Basic React application structure 123456789diy-react&#x2F; dist&#x2F; main.js src&#x2F; index.js components&#x2F; App.js server&#x2F; server.js dist: for distribution, webpack will put production-ready files to here src: for React code files components: for React components server: for server files Configure Webpack and Babel Under project root directory, create a new file called ‘babel.config.js’ and paste the below code 123module.exports &#x3D; &#123; presets: [&#39;@babel&#x2F;preset-env&#39;, &#39;@babel&#x2F;preset-react&#39;],&#125;; Under project root directory, create a new file called ‘webpack.config.js’ and paste the below code This will tell webpack to invoke babel for all files that end with .js. This is to convert JSX code to regular React API calls. 12345678910111213module.exports &#x3D; &#123; module: &#123; rules: [ &#123; test: &#x2F;\\.js$&#x2F;, exclude: &#x2F;node_modules&#x2F;, use: &#123; loader: &#39;babel-loader&#39;, &#125;, &#125;, ], &#125;,&#125;; Create npm scripts for development 1&quot;dev:server&quot;: &quot;nodemon --exec .&#x2F;node_modules&#x2F;.bin&#x2F;babel-node src&#x2F;server&#x2F;server.js --ignore dist&#x2F;&quot;, This script will run nodemon command, which is run babel-node on a server.js file 1&quot;dev:bundler&quot;: &quot;webpack -w --mode&#x3D;development&quot; This script will run the webpack command, in Watch mode(readable code, not minified) and in development node Reference Setting up React Development Environment For Angular, Vue and Ember they put fake JS in HTML. Whereas React put fake HTML in JS (JSX), React is Javascript-centric, makes JS more powerful to handle HTML React is lightweighted, you can slowly migrate your app from other technologies to React React is lean and you only import the package you want to use. React is one way data binding, it required more code, you need to expilictly declare a change handler. But this gives you more control and east to debug The Basics React’s Basic Concepts Components Like functions Input: props, state | Output: UI Reusable and composable Can be used as normal HTML tags &lt;Component /&gt; Can manage a private state Reactive updates When the state of a React component, the input, changes, the user interface it represents, the output, changes as well Virtual views in memory We don’t write HTML when building applications using React. We generate HTML using Javascript Build smaller components such as buttons, forms, then build more complex components using the smaller components. Each component consist of HTML and JS. Tradeoffs Framework vs Library Frameworks offer more opinion and standardization, but React’s library approach allows you to select only the tools that you need and pick the best tools for your use case. Data Binding Other frameworks strive to be concise, using techniques like two‑way binding and abstractions over JavaScript operations. But React is explicit, so code is more readable and scalable at the admitted expense of doing a little more typing on the keyboard. JS Centric React chooses to be JavaScript‑centric instead of template‑centric. React’s JavaScript‑centric approach is easier to understand and debug and requires learning less unique syntax, but at the cost of requiring modern JavaScript knowledge. Separate vs Single File Many frameworks utilize a separate template file. In contrast, each React component is a single autonomous file that you can work with and test in isolation. Standard vs Non-standard The web component standard has been around for years, yet it continues to lack broad adoption. Non‑standard approaches, like React and Angular, remain more popular because they offer the same power, more rapid innovation, and a superior developer experience. Community vs Corporate And React is corporate‑backed, which means its design is influenced by Facebook’s needs. But Facebook continues to accept input from the community and has evolved React into a highly flexible and well‑supported system. Decisions to make Develop environment - create-react-app Classes or Functions - Functions Types - PropTypes, TypeScript, Flow TypeScript is a superset of JavaScript that adds strong typing support and compiles down to plain JavaScript Flow: adding static type checking to JavaScrWipt States - Plain React, Flux, Redux, MobX Component State: Plain React Centralized State: Flux, Redux Observable State: MobX Styling - Plain CSS/Sass/Less, CSS in JS W","categories":[],"tags":[{"name":"React","slug":"React","permalink":"http://hellcy.github.io/tags/React/"}]},{"title":"ASP.NET Core with SignalR","slug":"ASP-NET-Core-with-SignalR","date":"2021-03-11T10:03:57.000Z","updated":"2021-05-24T07:27:02.657Z","comments":true,"path":"2021/03/11/ASP-NET-Core-with-SignalR/","link":"","permalink":"http://hellcy.github.io/2021/03/11/ASP-NET-Core-with-SignalR/","excerpt":"","text":"Understanding the Real-time Web Polling Clients periodically ask the server if there’s an update. For each poll, a HTTP request is made, and the server either responds with a new status or 204 No Content Long Polling Clients send HTTP request to the server. But the server will not complete the request but leave it until there’s an update. When there’s no update within a certain timeframe, the request will time out. When that happens, the client will just start the process again by issuing a new request. Long Polling is more efficient than polling, but it is still using HTTP requests to ask for updates. Server Sent Events (SSE) a HTML5 feature, the server creats an HTTP connection to the client(browser) with Server Sent Events. The browser will listen for messages that will come in as a stream. The connection will remain open until it is actively closed. The browser will use an object called EventSource that has an event onmessage to process incoming messages. Using simple HTTP Auto reconnects No support for older browsers Easily polyfilled Maximum HTTP connections issue (6 connections at most) Only support text messages One-way connection Web Sockets A standardized way to use one TCP socket through which messages can be sent from server to client and vice versa and without the latency of HTTP. A TCP socket typically remains open for as long as the stream of the messages are not done. SignalR will use WebSockets most of the time because its the most efficient transport. Full duplex messaging (client to server and vice versa) No 6 connections limit For most browsers, the connection limit for web sockets is about 50 connections Multi data type support (text, binary) TCP socket upgrade (Regular HTTP request uses a TCP socket as well) The WebSockets standards uses a handshake mechanism to upgrade an existing socket used for HTTP traffic to a WebSocket. After that, messages can travel through the socket until the socket is actively closed. When closing, a reason for closing is communicated. Every WebScoket starts its life as a simple HTTP socket, A GET HTTP call is made to the server, requesting an upgrade of the socket. If the server agrees, the socket becomes a WebSocket from that point onwards. SignalR SignalR is an open source framework that wraps the complexity of real-time web transports. You don’t need to worry about the lower level transports like long polling, Server Sent Event or WebSockets. Transports WebSockets, Server Sent Events, Long Polling Requires client and server that supports transport Fallback mechanism (if browser doesn’t support WebSocket, then use SSE instead, etc…) Remote Procedure Call (RPC) Server can call a function in the Client and vice versa Hub A hub is a server-side class that sends messages to and receives messages from clients by utilizing RPC. A hub protocol is a format used to serialize parameters to and deserialize parameters from Differences with Classic SignalR Simplified connection model Single hub per connection Async Binary and custom protocols No jQuery dependency for JavaScript client Sticky session required Scaling Out Running on muiltiple servers Load Balancer picks server Problem with non-WebSockets transport, it could send the first request to the first server, then send the second request to the second server, who doesn’t know anything about the context of the message. We could solve this problem by using sticky sessions. As part of the response of the first request, the load balancer sets a cookie in the browser, indicating the server that was used. On subsequent request, the load balancer then reads the cookie and assigns the request to the same server. (IIS using Application Request Routing Affinity (ARR Affinity)) Another problem, let’s say a user is working on a web document using Office 365, and she invites others to join her, the other might end up at another server. When user 1 on the server changes the document, a message has to be sent to the others, but server 1 doesn’t know about users that are connected to hubs in other servers. To solve this, the servers need a way to share data. This can be done using a Database, but a faster alternative would be to use a Redis cache.","categories":[],"tags":[{"name":"ASP.NET Core","slug":"ASP-NET-Core","permalink":"http://hellcy.github.io/tags/ASP-NET-Core/"}]},{"title":"ASP.NET Core Fundamentals","slug":"ASP-NET-Core-Fundamentals","date":"2021-03-07T10:41:24.000Z","updated":"2021-05-24T07:27:02.657Z","comments":true,"path":"2021/03/07/ASP-NET-Core-Fundamentals/","link":"","permalink":"http://hellcy.github.io/2021/03/07/ASP-NET-Core-Fundamentals/","excerpt":"","text":"","categories":[],"tags":[{"name":"ASP.NET Core","slug":"ASP-NET-Core","permalink":"http://hellcy.github.io/tags/ASP-NET-Core/"}]},{"title":"C# Fundamentals","slug":"C-Fundamentals","date":"2021-03-04T12:26:26.000Z","updated":"2021-05-24T07:27:02.658Z","comments":true,"path":"2021/03/04/C-Fundamentals/","link":"","permalink":"http://hellcy.github.io/2021/03/04/C-Fundamentals/","excerpt":"","text":"dotnet CLI Create new dotnet project 12dotnet new consoledotnet new xunit Add unget package 1dotnet add package xunit --version 2.4.1 Add reference to another project in .csproj file 1dotnet add reference projectName.csproj Run unit test project 1dotnet test Run main project 1dotnet run Create solution file to include all projects 1dotnet new sln Add project into the solution file 1dotnet sln add PathToProjectFile.csproj Build all project in solution 1dotnet build C# passes variables by value unless you use keyword e.g. ref, out C# has garbage collector Auto property 12345678public string Name &#123; get &#123; return name; &#125; set &#123; name &#x3D; value &#125;&#125; This code can be simplified to 1public string Name &#123; get; set; &#125; difference between auto property and field 123public string Name &#123;get; set;&#125;public string Name; You can specify custom code in getter and setter functions. When serialize objects, fields may not be counted. readonly 1readonly public string category; readonly can only be assigned in constructor. const 1const public string CATEGORY const is more strict than readonly, you can’t assign it in constructor, it is not a variable. Once you initialized it, you can’t change its value. And when you access it. You can access it from the class name, not the object name. Because every object instance will have the same value for this const. So its better to access it from the class. Its more clear. 1234567&#x2F;&#x2F; Book is a class&#x2F;&#x2F; CATEGORY is a const in Book&#x2F;&#x2F; Category is a readonly field in BookConsole.WriteLine(Book.CATEGORY); &#x2F;&#x2F; constvar book1 &#x3D; new Book();Console.WriteLine(book1.Category); &#x2F;&#x2F; readonly field Delegate A delegate is a type that represents references to methods with a particular parameter list and return type. When you instantiate a delegate, you can associate its instance with any method with a compatible signature and return type. You can invoke (or call) the method through the delegate instance. 1234567891011121314151617public delegate string WriteLogDelegate (string logMessage);&#x2F;&#x2F; reference the main project to the test project in .csprojpublic class TypeTests&#123; [Fact] public void WriteLogDelegateCanPointToMethod() &#123; WriteLogDelegate log &#x3D; new WriteLogDelegate(ReturnMessage); var result &#x3D; log(&quot;Hello!&quot;); Assert.Equal(&quot;Hello!&quot;, result); &#125; private string ReturnMessage(string message) &#123; return message; &#125;&#125; Multi-Cast Delegate One delegate variable can points to multiple methods, and by invoking that delegate variable, all subscribed methods will be invoked too 1234567891011121314151617181920212223242526public delegate string WriteLogDelegate (string logMessage);&#x2F;&#x2F; reference the main project to the test project in .csprojpublic class TypeTests&#123; int count &#x3D; 0; [Fact] public void WriteLogDelegateCanPointToMethod() &#123; WriteLogDelegate log &#x3D; new WriteLogDelegate(ReturnMessage); log +&#x3D; IncrementCounter; var result &#x3D; log(&quot;Hello!&quot;); Assert.Equal(2, count); &#125; private string ReturnMessage(string message) &#123; count++; return message; &#125; private string IncrementCounter(string message) &#123; count++; return message.Tolower(); &#125;&#125; Event Sometimes after we have done someting, we want to broadcast it to all people that are interested. The broadcast delegate usually takes two parameters, the object sender and EventArgs. object is the base type in C#, all types and classes can be fitted into object. 123456789101112131415161718192021public delegate void GradeAddedDelegate(object sender, EventArgs eventArgs);public class Book &#123; public event GradeAddedDelegate GradeAdded; public void AddGrade(double grade) &#123; if (grade &lt;&#x3D; 100 &amp;&amp; grade &gt;&#x3D; 0) &#123; grades.Add(grade); &#x2F;&#x2F; broadcast &#x2F;&#x2F; if GradeAdded is null, then no one is listening to this event &#x2F;&#x2F; so there is no need to invoke the delegate. if (GradeAdded !&#x3D; null) &#123; GradeAdded(this, new EventArgs()) &#125; &#125; else &#123; throw new ArgumentException($&quot;Invalid &#123;nameof(grade)&#125;&quot;); &#125; &#125;&#125; In program.cs where we are trying to use this Book object 1234567891011121314class Program&#123; static void Main(string[] args) &#123; var book &#x3D; new Book(&quot;Yuan&#39;s Grade Book&quot;); &#x2F;&#x2F; add OnGradeAdded to this delegate book.GradeAdded +&#x3D; OnGradeAdded; &#125; static void OnGradeAdded(object sender, EventArgs e) &#123; Console.WriteLine($&quot;A grade was added.&quot;); &#125;&#125; OOP Inheritance 1234567891011121314151617181920212223242526public class NamedObject &#123; &#x2F;&#x2F; Name field public string Name &#123;get; set;&#125; &#x2F;&#x2F; constructor public NamedObject(string name) &#123; Name &#x3D; name; &#125;&#125;&#x2F;&#x2F; inherit from NamedObject base classpublic class BookBase : NamedObject &#123; public BookBase(string name) : base(name) &#123; Name &#x3D; name; &#125;&#125;public Program clas &#123; static void Main(string[] args) &#123; &#x2F;&#x2F; when you create a new instance of Book &#x2F;&#x2F; you assign the new name Book 1 to Book class &#x2F;&#x2F; Book class will pass the same name to its base class Book book1 &#x3D; new Book(&quot;Book 1&quot;); &#125;&#125; When you want to use some attributes or functions from a base class, instead of rewrite the code, you can inherit the base class. The constructor of the child class will also need to pass in the variable to its base class Polymophism 12345public abstract class BookBase : NamedObject &#123; public BookBase (string name) : base(name) &#123;&#125; public abstract void AddGrade(double grade);&#125; The abstract modifier indicates that the thing being modified has a missing or incomplete implementation. And it will be implemented by its child class. Child class who inherit the base class will need to add an override keyword to implement the abstract function Base class can have different implementations of it. A Car base class may have Truck and Sport Car as its children class and they have some same base field and functions but also many different. Interface Where abstract may content actual implementation of some field and functions (some is missing). The Interface class doesn’t have any implementations. 123456789namespace GradeBook&#123; public interface IBook &#123; void AddGrade(double grade); string Name &#123;get;&#125; event GradeAddedDelegate GradeAdded; &#125;&#125; Virtual For base class, there may be some functions that already have an implementation. But Virtual keyword meaning its children class may choose to override it. Difference between Virtual and Abstract Virtual methods have an implementation and provide the derived classes with the option of overriding it. Abstract methods do not provide an implementation and force the derived classes to override the method. So, abstract methods have no actual code in them, and subclasses HAVE TO override the method. Virtual methods can have code, which is usually a default implementation of something, and any subclasses CAN override the method using the override modifier and provide a custom implementation. using When we are writing text to file, we need to open the file and close it after finish. But if the program crashes when we editing the file, we will leave the file open. One thing we can do is to use the try catch block to catch the exception and close the file finally. C# has a short keyword for this purpose, the using keyword. It will call Dispose() function in IDisposable -&gt; TextWriter -&gt; StreamWriter to free up the memory and close the file. 1234using (var writer &#x3D; File.AppendText($&quot;&#123;Name&#125;.txt&quot;))&#123; writer.WriteLine(grade);&#125;","categories":[],"tags":[{"name":"C#","slug":"C","permalink":"http://hellcy.github.io/tags/C/"}]},{"title":"AWS SAA - Design Cost-Optimized Architectures","slug":"AWS-SAA-Design-Cost-Optimized-Architectures","date":"2021-02-27T23:10:25.000Z","updated":"2021-03-05T14:00:55.637Z","comments":true,"path":"2021/02/28/AWS-SAA-Design-Cost-Optimized-Architectures/","link":"","permalink":"http://hellcy.github.io/2021/02/28/AWS-SAA-Design-Cost-Optimized-Architectures/","excerpt":"","text":"Part One: Understanding Cost Effective Storage in AWS Part Two: Understanding Cost Effective Compute in AWS Part Three: Understanding Database Pricing and Cost Optimization Part Four: Understanding Cost Optimized Network Architectures Part Five: Making Cost-optimized Decisions Part One: Understanding Cost Effective Storage in AWS Globomantics Global health care organization Been using AWS for some time Most core service such as EC2, RDS, S3 etc. We have been asked to identify solutions that will help reduce costs maintain the same level of service and availability Module Overview S3 Using S3 storage classes to reduce costs S3 glacier When to use S3 glacier and S3 glacier heep archieve EBS storage EBS pricing points and storage options S3 Storage Classes Influences availability, durability and cost for objects stored in S3 Applied at an object level, each S3 bucket can host objects with different classes An objects storage class can be changed throughout its lifetime Using the wrong storage class will lead to unnecessary spending Standard: Charged based on object size Standard - IA: Charged based on object size and retrieval One Zone - IA: Stores objects in a single AZ S3 Glacier: Used as an additional S3 storage class Intelligent - Tiering: Transitions objects between classes based on their access frequencies Lifecycle rules Use lifecycle rules to transition objects between classes and expire objects Caching Downloading objects cost money, use caching to avoid unnecessary downloads and reduce S3 costs Globomantics Requirements Use an appropriate storage class for each object Avoid one zone -IA as it reduces availability (store data we can reproduce in OZ - IA) Use lifecycle rules Transition to standard - IA Transition to S3 Glacier Expire objects(delete) S3 Glacier and Deep Archive Globomantics Requirements Need to store some data long term for compliance Data must be stored for at least 10 years Meet the following requirements Stored as cheaply as possible Still be highly durable and available Must be secure Data won’t be needed again except for compliance requests S3 Glacier Long term archival storage Two classes S3 Glacier and Deep Archive Using S3 glacier we can retrieve archives in minutes Using S3 glacier deep archive we can retrieve data within 12 hours Data in S3 glacier are not available to you. You need to request a retrival. Comparing Storage Costs S3 Standard - 10TB - eu-west-1 $245.64 S3 Glacier - 10TB - eu-west-1 $46.08 S3 Glacier Deep Archive - 10TB - eu-west-1 $18.44 EBS Storage Block storage for EC2 virtual machines Persistent storage of up to 16TB per disk SSD backed and HDD backed volumes Provisioned storage priced at a GB per month rate You are charged for the entire volume as soon as you created it. You can create a smaller EBS than increase it when you need it in the future Options Cold HDD volumes, $0.025 per GB per month Throughput optimized HDD volumes, $0.045 per GB per month General purpose SSD volumes, $0.10 per GB per month Provisioned IOPS SSD volumes, $0.125 per GB per month and $0.065 per provisioned IOPS per month EBS Snapshots Snapshots consist of the used space in an EBS volume not the provisioned space Charged on a per GB per month basis Additional cost for EBS fast snapshot restore If you have a 1000 GB provisioned EBS and only used 100 GB space, when you create a snapshot of this EBS, you will only be charged of 100 GB. Summary Use S3 storage classes to reduce costs Use S3 Glacier and its role in reducing costs EBS storage pricing Part Two: Understanding Cost Effective Compute in AWS Module Overview Discuss EC2 payment types Discuss right sizing EC2 to optimize costs Introduce cost benefits of serverless compute Pricing points EC2 instance uptime EBS storage Data transfer out Instance types On Demand instances Charged by the hour or second (minimum 60 seconds) No upfront commitment, billed when instances are in a running state Great when you want uninterrupted compute Reserved Instances 1-year or 3-year commitment pay all, parital or no upront (the more you pay upfront, the bigger discount you will get) Convertible RIs available Capacity reservation with Zonal RIs Instance size flexibility Up to 72% saving Spot Instances You are biding on unused capacity in an AZ If your bid is higher than the spot price you pay the lower amount Spot, Spot fleets (multiple machines, only launch when all of them can be launched at the same time), and spot blocks (multiple machines, only launch them when they can be running for a certain peroid of time) are available When you loose the spot bid 2-minute warning (to transfer your data) instance terminate/hibernate/stop depend on your choice In addition Scheduled reserved instance: Useful if you are only running your instance periodically Savings plans: Alternative to reserved instances, useful if you have mixed EC2 instance, AWS fargate and AWS lambda Globomantics Requirements Use a minture of EC2 instances sizes and types Currently only on-demand instance type used EC2 instance characteristic Some instances run 24/7 and are expected to do so for at least 1 year (reserved instances with 1-year commitment) Some instances are brought online for 48 hours every week to run weeekly batch jobs (scheduled reserved instances) Other instances are brought online as needed to run short processes that must be completed within 2 hours (on-demand or spot block) Note using spot block you might need to wait for some time (when your bid is higher) before your instances can be launched Right Sizing EC2 to Optimize Costs Eight instance familes: Groups of instances such as general purpose, compute optimized and memory optimized Instance sizes: Each family has a range of instance sizes that offer different combinations of resources Burstable and Fixed performance instances Fixed performance (e.g. M5) offers fixed compute Burstable performance (e.g. T3) provide a baseline level of CPU (e.g. 20%) with the ability to burst above the baseline. Standard and unlimited: For burstable instances, if you are not using your CPU, you will get tokens(credit) which you can use later when you need extra CPU power. For Standard, your compute power will reduce to original when you use up your tokens. For unlimited, you will be charged the on-demand price for the compute power but can still use the extra CPU power for as long as you need. Tools for Right EC2 Sizing Amazon CloudWatch: Monitor CPU, network throughput, disk I/O AWS Cost Explorer: Monitor your spending and view resource optimization recommendations AWS Trusted Advisor: Best practice advice including advice on reduing costs AWS Serverless Platform Compute: AWS lambda, AWS fargate Storage: S3 Data Stores: DynamoDB, Aurora API Proxy: Amazon API Gateway Integration: Amazon SNS, Amazon SQS Benefits of Serverless Compute No server management: No need to provision administer or maintain EC2 instance Flexible scaling: Scale automatically without downtime by adjusting capacity High availability: Built for automated high availability and fault tolerance Globomantics Requirements Deployed a 2-tier customer facing web application to AWS Deployed using EC2 and RDS MySQL Interested to know how this application would be deployed using serverless services? Would there be cost benefits? Summary Discussed different ways to pay for EC2 Demonstrated EC2 savings plans Discussed right sizing of EC2 Discussed how serverless compute can help reduce costs Part Three: Understanding Database Pricing and Cost-optimization Module Overview Discuss RDS Pricing Discuss DynamoDB Pricing RDS Pricing Points Instance type and size Database storage Data transfer out between AZs and between regions Backup storage Amazon RDS Instance Types General purpose: Including M4 and M5, good balance between computer memory and network resources Memory optimized: Including R4 and R5, designed for memory-intensive database workloads Burstable performance: Offering a baseline level of CPU with the ability to burst above the baseline RDS Payment Options On-Demand: Pay as you go, no upfront payments Reserved instances: 1-year or 3-year commitment for up to 69% saving RDS Storage General purpose SSD: From 20GB to 64GB prices at a $ per GB per month Provisioned IOPS SSD: Priced on a $ per GB per month plus $ per IOPS per month Magnetic storage: Cheapest storage, not recommended for new deployments Amazon Aurora Faster than MySQL and PostgreSQL Offers additional features like Aurora serverless Cheaper than both MySQL and PostgreSQL DynamoDB Pricing Points On-demend: Charged foe the data reads and writes your application performs Provisioned capacity: You buy the read and write capacity units that you need for your application DynamoDB Capacity Units WCU(Write Capacity Units) Each WCU is equivalent to one 1KB write per second. e.g. If each of your record is 10KB, and you need to write 5 records per second, then you need 50 WCU RCU(Read Capacity Units) Eventual &lt; Strongly &lt; transactional consistency Each RCU is equivalent to one 4KB strongly consistent read per second. Each RCU is equivalent to two 4KB eventual consistent read per second Each RCU is equivalent to 0.5 transactional consistent read per second DynamoDB auto scaling: Dynamically adjusts provisioned throughput in response to traffic patterns Reserved capacity: Purchase RCUs and WCUs with a 1-year or 3-year commitment at a reduced rate Additional DynamoDB Costs Global secondary indexes need their own capacity units Global DynamoDB tables will need additional capacity units DynamoDB backups will increase costs Summary Discussed RDS pricing options Discussed DynamoDB pricing options Part Four: Understanding Cost-optimized Network Architectures Module Overview Discuss using ELB and Auto Scale to reduce costs Discuss VPC routing and hybrid connectivity cost decisions Discuss using offloading to reduce costs ELB and Auto Scaling Globomantics Requirements Deployed a 3-tier customer facing web application to AWS Deployed using EC2 and RDS MySQL Peak time for the application is Friday and Saturday where up to two times the amount of compute is needed Right size the EC2 instances and RDS instances Introduce EC2 auto scale for the web and app tier Introduce load balancing for the app tier Auto Scaling Saves Money With auto scaling we design for the normal Auto scaling leads to better cost management Integrate with load balancing to make use of launched instance Using min and max values allow us to better predict costs VPC Routing and Hybrid Connectivity Decisions Globalmantics Requirements Connect Globalmantics HQ and smaller regional offices to their AWS deployed VPC Connect resources in their AWS deployed VPC to S3 Connect Globalmantics application VPC to a VPC that contains monitoring servers Cost is a major factor, all designs should balance performance, funcationality and cost For connecting HQ to AWS VPC, we can use Direct connect or site-to-site VPN, Direct connect will give us better performance but more expensive. For connecting Branch offices to AWS VPC, site-to-site VPN should be good enough considering offices are small. For connecting Application VPC to Monitoring VPC, we could use VPC peering, it will only charge us for data transfer. The others options are: Transit Gateway and site-to-site VPNs (more expensive). For connecting Application VPC to S3, we could use VPC endpoints. Other option is to use public gateway but that is less secure(need to go through public internet). AWS Connectivity Keep as much traffic as possible on the AWS backbone Consider using Direct Connect hosted connections Use AWS services to reduce development and management costs Balance performance, functionality and cost Offloading with CloudFront How can deploying a additional technology like CloudFront reduce costs? S3 charges a retrieval fee per GB and fees based on the type of request CloudFront charges a retrieval fee and a fee for HTTP or HTTPS requests CloudFront fees are cheaper than S3 fees Serving content from CloudFront can be cheaper then serving content from S3 Summary Learned how ELB and auto scale can help reduce costs Discussed VPC routing and hybrid connectivity options Learned how offloading can help reduce costs Part Five: Making Cost-optimized Decisions Overview Discuss factors that can affect costs Work with AWS tools to monitor and estimate costs Some factors that can affect cost AWS region and zone: Resource are priced per-region and per-availability zone EC2 size and type: Instance type and size will have a big impact on the cost of your compute S3 storage class: Choose the correct class for the objects you are storing Tips to Help Save Money in AWS EC2 Payment: Use the correct payment model Databases: Use reservation for RDS and DynamoDB Tag Everything: Introduce and effective tagging policy Intriduce SCPs(Service Control Policy): Use SCPs to restrict available features Monitor everything: Use all the monitoring tools available to you AutoScale: Implement AutoScale to avoid planning for peak Offloading: Use offloading in your architectures (CloudFront, ElasticCache, RDS Read Replicas) Turn things off: Shutdown and delete resources that you are not using Course Summary Storage and Compute S3 Storage classes S3 lifecycle rules EBS storage options EC2 pricing EC2 right sizing Serverless compute Databases and networks RDS pricing and optimization DynamoDB pricing and optimization Cost optimized networks ELB and autoscale Hybrid connectivity VPC connectivity Offloading with CloudFront","categories":[],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://hellcy.github.io/tags/AWS/"}]},{"title":"Java Learning Path","slug":"Java-Learning-Path","date":"2021-02-21T01:50:46.000Z","updated":"2021-02-26T12:08:47.159Z","comments":true,"path":"2021/02/21/Java-Learning-Path/","link":"","permalink":"http://hellcy.github.io/2021/02/21/Java-Learning-Path/","excerpt":"","text":"入坑Java开发的学习之路 基础知识 编程语言： Java Python C 基本算法 基本网络知识： TCP/IP HTTP HTTPS 基本设计模式 工具方面 操作系统： Linux (CentOS/Ubuntu…) 代码管理： SVN / Git 持续集成(CI/CD): Jenkins Java项目管理工具： Maven / Gradle 框架方面 应用层框架 ssh: spring + structs + hibernate ssm: spring + spring mvc + mybatis spring boot 中间件 MQ 消息队列 RPC 通信框架 gRPC thrift dubbo spring cloud Elasticsearch 数据库 搜索引擎 数据库 SQL: MySQL / Postgre SQL NoSQL: Redis Memcached mongoDB elasticsearch 架构方面 分布式/微服务架构 spring cloud dubbo RPC通信 虚拟化/容器化 Docker k8s kubernetes 关注源码/性能 JDK源码以及部分设计思想 Spring源码 JVM 细节与排错","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://hellcy.github.io/tags/Java/"}]},{"title":"AWS SAA - Design Secure Applications and Architectures","slug":"AWS-SAA-Design-Secure-Applications-and-Architectures","date":"2021-02-15T11:06:03.000Z","updated":"2021-03-05T13:13:34.682Z","comments":true,"path":"2021/02/15/AWS-SAA-Design-Secure-Applications-and-Architectures/","link":"","permalink":"http://hellcy.github.io/2021/02/15/AWS-SAA-Design-Secure-Applications-and-Architectures/","excerpt":"","text":"Part One: Protecting AWS Credentials Part Two: Capturing and Analyzing Logs Part Three: Protecting Network and Host-level Boundaries Part Four: Protecting Data at Rest Part Five: Protecting Data in Transit Part Six: Configuring Data Backup, Replication, and Recovery Part One: Protecting AWS Credentials Security is about protecting data. The CIA Triad Confidentiality Integrity Availability Confidentiality: Only authorized parties can access data. (ACLs and encryption) Integrity: Data has not been improperly modified. Includes knowing if data has been modified. Availability: Authorized parties have access to data when they need it. Includes protecting systems that store, process, and deliver data. Defense in depth: Protecting the confidentiality, integrity, and availability of data by securing everything that touches the data, including storage, compute and networking Levels of Architecture: AWS services, Operating systems, Applications AWS Credentials Root User: Full access to all AWS resources. Only one root user per account. IAM principal: Any entity(could be a user or an application) that can perform actions on AWS services and resources. Policies determine what permissions a principal has Locking down the Root user: Enable MFA. Don’t use the root user for administrative tasks. Use a non-root IAM user with administrative permissions IAM Principal: The foundation of IAM. An entity that can take an action on an AWS service. Often used as a synonym for identity. Principles include users and roles A non-root principal has no permissions by default. Policies determine what permission a principal has You must grant permissions to a principal by associating it with a policy. Policy and Permission: A policy consists of multiple permission statements. A permission statement consists of 4 elements. Effect (allow or deny) Service (etc: EC2) Action/Operation (RunInstances) Resource (image/ami-fjdfjfsdk) Request condition(MFA, IP range, time…) (198.51.100.0/24) This permission will allow a principal to run an EC2 instance with certain AMI, when it is in certain IP range. AWS managed policies: AWS has many managed policies created for us to use. (they are updated regularly to include new services) The deny effect always takes precedence over the allow effect (deny &gt; allow) We can create inline policy for a user to deny he’s access to terminate any EC2 instances. This is the JSON representation of the policy We could use policy simulator to check the effectiveness of the policy. We could also create inline policy for a group. Summary Implement MFA for the root user User an administrative user instead of root user AWS managed policies are updated as new services and actions are added A policy permission consists of an effect, service, action/operation and resource A user policy is an inline policy embedded in a user A group policy is embedded in a group Customer Managed policies work like AWS managed policies, but are created and managed by you Part Two: Capturing and Analyzing Logs Module Overview Capturing events with CloudTrail Viewing Logs with CloudWatch Logs Creating alerts with CloudWatch Alarms Searching logs with Athena Tracking changes with AWS config CloudTrail logs are stored in S3. Limit what you log to control costs CloudTrail event types Management: Configuration changes to AWS services. Reading resources. Logging into the management console. Assuming a role. Data: Access to S3 objects. Lambda function execution CloudTrail: Logs AWS actions. Stores logs in S3 CloudWatch Logs: Aggregates logs from CloudTrail and non-AWS sources. Provides interface to view and search logs Create IAM service role Contains inline service policy that grants CloudTrail permissions to send logs to CloudWatch Logs Contains trust policy that allows CloudTrail to assume the role Role is an IAM principal for CloudTrail to use to authenticate to CloudWatch Logs Demo Create a log group in CloudWatch Logs Create an IAM role for CloudTrail to assume. The Role will have two permission statements. It can create log streams and it can put the log into CloudWatch Log groups. The CloudTrail and the Role have a trusted relationship. If we have a look at the JSON policy. It will allow CloudTrail to assume the Role. The Role will give its permissions to CloudTrail. Create CloudWatch Alarm we need to select a metric, in this case, IncomingLogEvents. We define the alarm so that it triggers the alarm if CloudTrail send more than 1 log to CloudWatch Logs within 1 minute period of time. We also created new topic with an email address so I will get notified if this happens. After the alarm has been created, the status is OK because we didn’t receive any logs in the last 1 minutes. And we treat missing logs as Good. When there is logs coming in, the status will be changed to In alarm for that 1 minute period and will be changed back to OK the next minute. Notice the alarm logs are not in real time. There maybe a couple of minutes delay. Why Athena? Maybe you don’t want to use CloudWatch Logs. You can use SQL like queries to search thought logs and all S3 objects. If the files are in correct format (e.g. csv, JSON, CloudTrail logs stored in S3 are in JSON format) Athena usrs SQL, so to search files in s3, we need to provide the schema. AWS provides the schema for CloudTrail Logs Demo Note you need to create a save location for the Athena search result in S3 before run the query. Tracking Configuration Changes in AWS Config Tracks configuration changes over time. AWS config can tell you the stats of all AWS services of any point of time in the past. Records changes in S3. Notifies of changes Summary CouldTrail tracks events ClousdWatch Logs aggregates logs from different sources CloudWatch Alarms trigger based on specific log activity Athena performs SQL queries against objects in S3 AWS Config tracks configuration states over time Part Three: Protecting Network and Host-level Boundaries Tic-tac-toe web application Host-level boundary is the default security group between the public subnet and the EC2 instance(auto created). NACL(netwoek access control list): controls traffic in and out the subnet having both the security group and NACL gives you layers of security around your instance. The game data stored in DynamoDB, to communicate with it, we have two options We can go over the public internet via igw(internet gateway) We can also use a VPC endpoint, which is a non-internet private connection Module Overview Creating a public subnet Creating and using an IAM instance profile Using SSH key pairs Using VPC endpoints Network access control lists Demo Create VPC Create subnet Create igw Attach igw to VPC Add routes in VPC’s main route table Add VPC’s inbound rules Create IAM role to allow access to DynamoDB Role will contain a trust policy to allow EC2 instances to assume the role Launch instance and attach instance profile Create VPC Create public subnet, we use the CIDR block the same as our VPC because we are only going to create one subnet for this VPC Create internet gateway Attach internet gateway to VPC Edit the main route table, add another record. Route all traffic to igw. By doing this we make our subnet a public subnet Add two inbound rules in our VPC’s default security group. Use my home IP as source. So only at my home can I access the VPC services by HTTP or SSH. Create IAM role to access DynamoDB Create a role and attach the policy to it. Because we choose EC2 as the service that will be using this role, the trusted entity is EC2. It also creates an instance profile for us. Create an EC2 instance 1ssh ec2-user@13.55.117.52 -i .\\hellcyAWSkey.pem Access EC2 instance via SSH You need to go to your private key location (pem) and change the access level to 400(linux) or change the Owner to yourself and remove all other groups and users. Check here 1sudo yum -y install git python2-pip.noarch install the app 1git clone https:&#x2F;&#x2F;github.com&#x2F;benpiper&#x2F;dynamodb-tictactoe-example-app clone the repo from github 1sudo pip install flask boto install dependecies 1sudo python application.py cd to the application folder and run the app. You can play the game with other people who logs in 1curl 169.254.169.254&#x2F;latest&#x2F;meta-data&#x2F;iam&#x2F;security-credentials&#x2F;tic-tac-toe-app this is the secret token generated by AWS STS(Security Token Service) using instance profile(from the role) to allow our instance to access DynamoDB. Using VPC Endpoints Now we are going to change our traffic to go through a private link via VPC endpoint. Demo Block outbound internet access from the instance Configure VPC endpoint 1nslookup dynamodb.ap-southeast-2.amazonaws.com look up the ip address of DynamoDB at our current AWS region 1sudo netstat -tp | grep python check outbound connection from our EC2 instance to DynamoDB. Note our application needs to be running for this to work. Create VPC Endpoint New route rules will be added to the route table. This is to change the traffic sent to the DynamoDB from the private VPC endpint instead of the public igw Note it is required to create a policy for this VPC endpoint. The policy controls what the requests can do to the DynamoDB. Remember we already created a policy for a role and attached that role to our EC2 instance. They are two different policies. One for EC2, One for VPC endpoint. in the VPC’s security group. We need to remove the outbound rule for accessing public internet. Add a new rule to access DynamoDB endpoint. Note that we can access to the EC2 instance because we still have the inbound rules. Security Groups are stateful. They track the state of the connections to and from your instance. If you allow the traffic into your instance, then the security group will automatically allow the instance to reply to that traffic. Note there is a file bootstrap-responsive.css missing in the course app. I used FlieZilla uploaded this file to EC2. Below is the FlieZilla connection settings. Note port is 22. Network Access Control Lists Security Group controls in/out traffic for a EC2 instance. While NACL controls all traffic in the subnet. They are two layers of security. Differences between Security Group and NACL Security Group Instance Level Stateful Unnumbered rules (rules don’t have order) NACL Subnet level Stateless Numbered rules (rules have order) Stateful means security groups will automatically allow reply traffic. Stateless means if you only have inbound rule to access the instance. But do not have the outbound rule. Then the traffic can not leave the subnet. You have to setup both in/out rules to access an instance in the subnet. Numbered rules means each rule will have a number. Smaller number rules will be applied first(high priority). Summary A public subnet has a default route to an internet gateway Use an IAM instance profile to grant an instance access to an AWS service Decide whether to connect to AWS endpoints via the internet or a VPC endpoint Security groups and network access control lists act as firewalls but differ in significant ways Part Four: Protecting Data at Rest Data at Rest is the data stored in a place(hard drive) Data in Transit is the data being sent in public internet Access Permissions Bucket policies User policies Access Control lists Encryption Requires access to a key to encrypt and decrypt data if the key is gone. so is the data! Module Overview Create a customer master key(CMK) Encrypt an EBS volumn S3 access control lists, bucket policies, and user policies Securely grant anonymous access to S3 object Encrypt S3 object Demo Create a customer master key using KMS Assign a key alias(friendly name) Define key administrators (people who manages the key) Define key users (people who will be using the key) Demo Encrypt the data on an unencrypted EBS volume Stop the web1 instance (tic-tac-toe) Take a snapshot of the root volume Make an encrypted copy of the snapshot Create an AMI(instance image) using the encrypted snapshot Launch another instance using the new AMI Demo S3 Access Permissions Create an S3 bucket Configure bucket access control lists Create a bucket policy There are two types of policies identity based policy we set this up in IAM, we can grant policy to a IAM user resource based policy we set this up in resource page. We can add IAM users to the policy to let the resource know that these people can access it. Create a folder in the new S3 bucket and try to access this folder using another IAM user who only has read access to S3 buckets. Then try to use the new user to create another folder in S3 (will fail). Note folder in S3 is just another object(just look like a folder). So it requires the same permission as objects. using Bucket inline policy generator, we can add another IAM user to the access list in S3 policy. Need to specify the IAM user ARN and S3 bucket ARN. After doing this we can create another folder using another IAM user. Demo CloudFront Origin Access Identity Create an S3 bucket Create an origin access identity(OAI) Grant OAI access to the bucket Create a CloudFront distribution Note to grant OAI access to the S3 bucket, we need to create an inline policy for the S3 bucket. Tell the bucket to let our OAI user have the read access. Now only through the CloudFront can we access the bucket files. 123456789101112131415161718192021# Load named profileexport AWS_PROFILE&#x3D;ben# Create S3 bucketaws s3api create-bucket --bucket yuan.com-cloudfront# Create and uplaod index.html documentecho &quot;Hello, world!&quot; &gt; index.htmlaws s3 cp index.html s3:&#x2F;&#x2F;yuan.com-cloudfront&#x2F;# Create the origin access identity (OAI)aws cloudfront create-cloud-front-origin-access-identity --cloud-front-origin-access-identity-config CallerReference&#x3D;&quot;demo&quot;,Comment&#x3D;&quot;OAI for yuan.com-cloudfront&quot;# Apply a bucket policy granting read access to the OAIaws s3api put-bucket-policy --bucket yuan.com-cloudfront --policy file:&#x2F;&#x2F;bucketpolicy.json# Verify bucket policyaws s3api get-bucket-policy --bucket yuan.com-cloudfront# Create a CloudFront distributionaws cloudfront create-distribution --distribution-config file:&#x2F;&#x2F;dist-config.json Demo Granting Anonymous Access with Object ACLs and Bucket Policies Grant anonymous access to an individual S3 object Grant read permissions to everyone using the object’s ACL (Resources based policy) Use a bucket policy to grant everyone permission to perform the GetObject action against the object (identity based policy) Note even if we logged as the IAM who has full access to S3 object (owner). When we try to access a certain file in S3 bucket. We will still get Access Denied response. Why is that? Because when we click the link to access S3 object, our browser will make an anonymous request to the object, which doesn’t not include any authentication information with it. Note if you are trying to modify bucket policy to give public access to a file. You have to make the bucket public first. Encrypting S3 Objects with KMS-managed Keys Generate a new CMK Enable encryption on our S3 bucket (existing files in bucket will not be encrypted) Verify that unauthorized users can’t decrypt data Summary Use KMS to create customer master keys Use the key policy to grant principals permission to use the key To encrypt data on an existing EBS volume, snapshot the volume, and make an encrypted copy of a snapshot Enabling KMS encryption on an S3 bucket doesn’t encrypt existing objects. Don’t delete a key that’s being used to encrypt or decrypt data! (you can’t decrypt data after key’s deleted) To control access to S3, you can use access control lists, bucket policies, or user policies(identity based policies) Use object ACLs to grant anonymous access to individual objects Bucket policies contain the principal element while user policies don’t Part Five: Protecting Data in Transit Encrypting data between users in public internet and AWS cloud Transport Layer Security (TLS) People sometimes incorrectly call this SSL(secure sockets layer, which is the old technology that nobody uses anymore) HTTPS uses TLS (S stands for security which the underlying protocol is TLS) Configure application to use TLS Application-dependent configuration independent of AWS Application Load Balancer (We use this in this course) Configure AWS application load balancer to use TLS Force all clients through the load balancer We are going to create a load balancer and a TLS certificate using AWS ACM, then install the certificate on the load balancer. All users need to access the load balancer to access our instances (which hosted the tic-tac-toe application). And all traffic between users and load balancer are encrypted. Module Overview Prepare the infrastructure to support an applicatioin load balancer Create a secure Application load balancer Demo Preparing for the Load Balancer Create a new subnet in a different zone (load balancer requires instances to be at different AZs) Bring up an instance named web2 Launch the application Reconfigure security group (permit access to/from load balancer) Demo Creating a Secure Application Load Balancer Use the AWS Certificate Manager to create a TLS certificate Create an Application Load Balancer Create a DNS record for the application Browse to the application using HTTPS If you use Route53 to control the DNS records of your domain. You can let AWS create the CNAME record for you. To create a load balancer, you need to specify the following Load Balancer type: HTTPS, internet facing VPC AZs (tic-tac-toe) Security groups (tic-tac-toe) Routing (new target group HTTP:80 to both instances) Register both instance as load balancer targets DNS name is the load balancer name we can browse to Create an A record in Route53 convert load balancer DNS name to a friendly domain name. Now you can browse to the URL using HTTPS Summary Choose where to terminate the TLS connection Individual instances (you need to configure TLS connection of your application and install TLS certificate on each instance) Application Load Balancer (only need to install one TLS certificate on the load balancer) ALB requires two availability zones ACM requires you to verify control of the domain name in the certificate Part Six: Configuring Data Backup, Replication, and Recovery Module Overview Versioning Lifecycle rules Cross-region replication Demo Versioning Versioning prevents accidental deletion and overwriting of data Enable versioning Upload object Restoring versions After you enabling the versioning of a S3 bucket, when you deleted a file. AWS will not delete the file but instead hide it and give the file a deletion marker. In the version list, you can see all versions of the same file. And if you delete the version with deletion marker, you can bring the deleted files back. Lifecycle Management Different storage classes provide different levels of redundency Standard is the default storage class Automatically migrate older objects to a cheaper class Automatically delete old objects Demo Liftcycle Management Examine object storage classes Create a lifecycle rule This image explains the current lifecycle I set up for the bucket. On day 30, objects will be moved to One-Zone IA On day 31, objects will be added a delete marker and become previous versions On day 32, objects will be moved to Glacier On day 39, objects will be deleted permenately Note, small objects in Glacier will have higher costs (objects &lt; 128KB) Demo Cross-Region Replication Congifure cross-region replication Replication doesn’t include existing objects When enable replication rules choose destination bucket choose keys to decrypt data in source bucket choose keys to encrypt data in destination bucket Summary Versioning Every change results in a new object version deleting an object creates a marker delete the marker to restore the object Lifecycle Management Move objects to different classes delete objects Cross-region replication Synchronously copy new objects to a different bucket Replicating to a different region offers protection against local catastrophes Couse Summary Remember that the goal of security is protect the confidentiality, integrity, and availability of data. It’s that CIA triad. Protecting AWS Credentials: At the start of this course, you learned how to configure identity and access management. This is like the building security system. It controls who can enter the building, what rooms they can go into, and so on. Capturing and Analyzing Logs: After that, you learned how to capture and analyze logs using CloudTrail and CloudWatch. In a physical building, this would be the building’s cameras, security guards, and log books. You’re not just concerned with what should happen, but what did happen. You want to know everything that’s going on inside that building. Protecting Network and Host-level Boundaries: However, perhaps the nature of your particular building is such that it’s not practical to identify everyone that exits and enters. If you’ve got a business that has clients coming in and out all the time, making them sign in and sign out can be a burden. In that case, you need a different way of controlling access to the building. This is analogous to protecting network and host-level boundaries in your AWS environment. Think of security groups and network access control lists. You’ll let strangers in your building, but you’re going to be strict about where they can go and what they can do. Protecting Data at Rest: Next, you learned how to protect at rest using encryption and access controls. Think of a combination safe that contains a secret message. The safe is locked in a room that you have to use a badge to gain access to. First, you swipe your badge to get into the room, and then once in the room, you must possess the correct combination to open the safe. Protecting Data in Transit: Next, you’ll learn how to protect data in transit by way of, yes, encryption. Again, if you want to take a top secret document out of the building and deliver it to someone, you might stick it in a locked briefcase or perhaps hire an armored courier to transport it for you. As long as the document is outside of the building, it remains under lock and key until it gets to its destination. Configuring Data Backup, Replication and Recovery: Lastly, we looked at how to perform data backup, replication, and recovery. Basically, if all else fails and your data does get destroyed, at least it’s not gone forever. You can get it back.","categories":[],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://hellcy.github.io/tags/AWS/"}]},{"title":"AWS SAA - Architecting for Reliability on AWS","slug":"AWS-SAA-Architecting-for-Reliability-on-AWS","date":"2020-10-15T03:30:54.000Z","updated":"2021-05-24T07:27:02.657Z","comments":true,"path":"2020/10/15/AWS-SAA-Architecting-for-Reliability-on-AWS/","link":"","permalink":"http://hellcy.github.io/2020/10/15/AWS-SAA-Architecting-for-Reliability-on-AWS/","excerpt":"","text":"AWS SAA C02 exam will include 4 topic Resilience Performance Security Cost-Optimization Chapter One: Resilience Section One: Availability Resiliency: The ability of an application to avoid and recover from failure. Availability: The percentage of time that an application is performing as expected. Poor performance implies low availablility. Uptime isn’t the same as availability. The service level agreement(SLA) for each service includes its annual availability. The availability of a single EC2 instance is 90% The availability of an ELB(Elastic Load Balancer) and EFS(Elastic File System) is 99.99% The availability of a RDS(Relational DataBase System) multi-AZ(multi-Availability Zone) is 99.95% The availability of a Lambda is 99.95% The availability of a S3 is 99.9% The availability of a DynamoDB with Global Tables (replicates our database across multiple regions) is 99.999% Traditional web application: can be convert to AWS web application without having to change the code. For example, a traditional video processing application can use Elastic File System(EFS) to store video data. But it cannot use S3 to store video data. Because that requires changes of code. EFS provides a network file system (NFS) volume, NFS is an established standard that most Linux distributions support. For DB: we can use (Relational Database Service)RDS. It offers managed database engines (MySQL, MariaDB, PostgreSQL, Microsoft SQL server, Oracle…). AWS manages database infrastructure and backups. Loose Coupling One component doesn’t depend on a specific component (e.g. URL points to ELB, not a specific EC2), one-to-many relationship is EFS a single point of failure? No, Elastic services are always composed of redundant components, they just hide it. Elastic services are always loosely coupled with other services like EC2. Loose Coupling helps Performance: If our application’s performance is low and we want to upgrade our EC2 instances, because they are loose coupled, we can upgrade EC2 instances one by one and our application will still be available, ELB will just route traffic to other instances. Performance and Availability are linked. Simple Queue Service The concept of Loose Coupling can be applied to the application level too. For example, we have a video processing application, we can create two components for this application, the web interface part and the video processing part. Users go to the webpage and submit a request of a video with differnt options, and video processing part gets the request and start processing. But because processing videos take much more time than sending requests. We need a Message Queue Service to save all the requests in order. Simple Queue Service(SQS) is one option with high availability. Elastic Container Service Container helps you to deploy web serices easier. Build an image of your container, deploy the image to an instance, and launch the containser in the image. E.g. Docker You can have multiple containers in one instance, so it is like you are running multiple web services for the price of one instance. Also, if one container is down, the other containers on that instance will still be running. (Processes running inside the container are isolated from the host.) Cloud Native Applications Depend on a cloud service that can’t be deployed on-premises Examples: SQS, S3, DynamoDB Lambda, S3 and DynamoDB are three main serverless components. Rather than running the video processing function on a service on a EC2 instance, we could write a Lambda function to do that. Lambda is a serverless service (they are running on a server of course, but the server is managed by AWS and we don’t need to worry about it, so we call it serverless.) Advantages of using Cloud Native Architecture: Scalability, Performance, Convenience Disadvantages: Could vendor lock-in (have to use AWS services), Slightly lower availability (Cloud services are hard dependencies). However, because of the scalability of Cloud Applications, if we deploy the application to two different regions, we could improve the availability. (introduce more redundence) Trusted Advisor Where you can found the number of limits for all services on AWS. Section One Summary Availability is not cheap, we need to found the balance between availability and cost. We can achieve high availability use Redundancy and Loose Coupling The Simple Queue Service can act as a go-between for loosely coupled services. 1. Sending service places message in a queue. 2. Receiving service polls the queue for new messages. E.g. Online voting service The Elastic Container Service deploys microservices using Docker containers, can improve availability by running multiple containers on a single instance. Section Two: Setting up AWS Environment AWS Budget In the Billing section, you can create an AWS Budget and setup an email alert, AWS will send you an email when the budget amount has been reached. There are more options. AWS IAM AWS has two account types, Root User account and IAM account. We can setup a password policy for AWS accounts. AWS provides MFA for Root User account in case someone else knows your AWS account credentials. Delete root user access keys: if someone knows your root user access key, he can use CLI to do anything. MFA will not be required to use CLI if he knows root user access key. So it is recommanded to create an IAM user and create access key for IAM users. You can create IAM accounts and Groups and assign Policies to Users or Groups, IAM users will use Root account ID or Alias and their account details to login. CloudTrail: where AWS logs all events such as: user login, user create new resources, user attach policy to its account etc… Configure AWS account using AWS CLI. This command can also be used to change default AWS credentials in .aws folder. 1aws configure TLS Certificate TLS(Transport Layer Security): Make sure messages being transferred between Load Balancer and Clients are secure. ACM(Amazon Certificate Manager): we ask ACM to issue us a TLS certificate Route 53: when you purchase a domain, you need to config the DNS records, you can do this in the service where you purchased the domain (e.g. GoDaddy) or in Route 53. Note: Once your TLS certificate has been issued, you still can’t visit your website via https, you have to link your TLS certificate to other AWS services like CloudFront or ELB Section Two Summary Set up budget alert Create IAM policy Set up MFA for the root user Create IAM user View CloudTrail event history Configure AWS CLI Create a TLS certificate using ACM Section Three: VPC networks AWS managers underlying VPC infrastructrue and is responsible for reliability of VPC network components. You don’t need to worry about VPC failures. There are many redundencies built in. VPC contains one or more subnets. A subnet exists in an availability zone. An instance exists in a subnet. Because one instance only exists in one subnet which exists in one availability zone, it lacks of redundency and availability is not high. If the zone fails, the instance will fail. Availability zones: they are basically the data centers in different locations. if you have your instances running in different availability zones, it is highly unlikely that all zones fail. Client(me) can access a VPC via three ways: 1. Internet Gateway, 2. VPN network, 3. Direct Connect link provided by AWS. Transit Gateway: high availability service that can connect two networks together (two VPCs) Elastic IP Address EIP allows an instance to retain the same public IP address. EIP is bound to an ENI(Elastic Network Interface), which is attached to an instance. You can move an EIP to differnt ENI To check EC2 instances EIPs. 1aws ec2 describe-addresses To allocate new EIP 1aws ec2 allocate-address To release the EIP 1aws ec2 release-address --allocation-id (your_allocation_id) Global Accelerator Provides two anycast IPv4 addresses. While ELP is bound to a AWS region, Global Accelerator IPs doesn’t, Users connects to a global accelerator static IP will be routed to a nearest POP(points-of-presence), which then will provide you with resources in any region. VPC Architecture Public Subnet: has full access to the internet, can also be reached from the internet. Private Subnet: is isolated from the internet, cannot reach internet nor be reached from the internet. NAT Gateway: Provides outbound internet access for instance in Private Subnet Create VPC with Public Subnet and Private Subnet. Public Subnet has a default Route Rule which route all requests(0.0.0.0/0) to a IGW(Internet Gateway), this allows instance in Public Subnet access public internet(inbound and outbound). Private Subnet has a default Route Rule which route all requests(0.0.0.0/0) to a NAT(NAT Gateway), this allows instance in Private Subnet outbound only access to internet. NAT Gateway: Instance in private subnet send outbound traffic to NAT Gateway, NAT Gateway then sends traffic to Internet Gateway. Create multiple Public and Private subnets for redundency. To find a subnet by its CIDR block, we will be using the subnet ID to launch the instance. 1aws ec2 describe-subnets --filters Name&#x3D;cidr-block,Values&#x3D;&quot;10.0.11.0&#x2F;24&quot; Launch an EC2 instance into a public subnet: Note: subnetId is the ID of your public subnet, which you can get by using the describe-subnets command above. ImageID is the ID of the EC2 instance, it specify some options about the instance you want to launch. key-name is the name of the SSH key pair you created, which you can use later to login to the instance. You can create or manage your SSH key pair under your EC2 panel, NETWORK &amp; SECURITY tab. 1aws ec2 run-instances --subnet-id subnet-0aa8c9baa867b88f0 --image-id ami-0e6449745600ac1da --instance-type t3.micro --key-name hellcyAWSkey Note: You could optionally associate a public IP address to the instance you are about to launch. By using the command 1--associate-public-ip-address It will make EC2 to associate a temporary public IP address to this instance, and will close the ip address when the instance is stopped. I will not do that because I want to keep the IP and so I will associate an EIP to this instance. To allocate a new EIP Note before we have associated the EIP to the NAT gateway. Now we are going to associate the new EIP to the EC2 instacne 1aws ec2 allocate-address To associate the new EIP to the new EC2 instance 1aws ec2 associate-address --instance-id Your_Instance_Id --allocation-id Your_EIP_Allocation_Id To terminate the EC2 instance 1aws ec2 terminate-instances --instance-ids Your_Instance_Id To release the EIP so AWS will not charge us 1aws ec2 release-address --allocation-id Your_EIP_Allocation_Id Launch an EC2 instance into private subnet 1aws ec2 run-instances --subnet-id [private_subnet_id] --image-id ami-0e6449745600ac1da --instance-type t3.micro --key-name hellcyAWSkey To delete NAT gateway 1aws ec2 delete-nat-gateway --nat-gateway-id Your_NAT_Gateway_Id Don’t forget to release the EIP associated with the NAT gateway.(They will charge for un-associated EIP) AWS Shield Standard Free service that detects against DDoS attacks, always ON Direct Connect Low-latency connection to an AWS region. Bypasses the internet, Two types: Dedicated, Hosted Dedicated: Physical connection that terminates at a Direct Connection location, fast, 1 or 10 Gbps Hosted: Last-mile connection provided by a Direct Connect partner(Local ISP). 50 Mbps to 10 Gbps VPN Connection Encrypted IPsec connection over the internet, Unpredicatable latency, Can be implemented in two ways: Virtual private gateway, Transit gateway. Virtual private gateway: Enables you to establish a VPN tunnel with only one VPC. Doesn’t scale well when you have multiple VPCs, then you need to create multiple Virtual private gateway for each VPC you want to connect. Transit Gateway: Connects VPCs and on-premises networks, 1. Terminates multiple VPN connections, 2. Supports Direct Connect. Connects multiple VPCs together. Transit Gateway Route Tables: Control how traffic is routed between subnets. Can block traffic. To create a Transit Gateway 1aws ec2 create-transit-gateway To create a VPC 1aws ec2 create-vpc --cidr-block 127.27.0.0&#x2F;16 To create a Subnet in the VPC 1aws ec2 create-subnet --vpc-id Your_VPC_Id --cidr-block 172.27.1.0&#x2F;24 --availability-zone ap-southeast-2a To attach Transit Gateway to the subnet of the VPC 1aws ec2 create-transit-gateway-vpc-attachment --transit-gateway-id Your_TGW_Id --vpc-id Your_VPC_Id --subnet-ids Your_Subnet_Ids Section Three Summary Allocating and assigning EIP addresses Creating VPCs Creating public and private subnets Launching instances into subnets Transit gateways Section Four: Automated Deployments with CloudFormation Overview of the architecture: The architecture has two tiers, the web tier and the application tier. The client connects to the internet facing application load balancer, it proxies the connection to one of the instances in the web tier, and all of the instances in the web tier are running a web server. The web tier instance then opens a back-end connection to the internal load balancer, which then proxies the connection to one of the instances in the application tier. The idea is that the web tier instance grabs some information from an instance in the app tier, and it displays that information to a webpage, which presents to the client. The instances in the web tier and the app tier are going to be part of two different Auto Scaling groups. Auto Scaling is going to launch these isntances and make sure we always have a minimum number of healthy instances. If an instance fail, Auto Scaling will terminate it and launch a new one. CloudFormation JSON or YAML document that describes AWS resources. Infrastructrue as code. Used to create a stack. Stack: Created by a template, is a COLLECTION OF RESOURCES that you create, update, and delete as a single unit. You can manually manage individual resources in a stack. Multiple templates: Different teams manage different resources. Resources have different lifecycles. Distributing resources across different stacks makes them easier to manage. Template for this course can be downloaded from here. Name: app-stack.json and network-stack.json. app-stack.json depends on network-stack.json, so it calls network-stack.json to create the nested stack first, then it will create the parent stack by using some of the outputs from network-stack.json. Stack output: key-value pairs that CloudFormation makes available to other stacks and via the aws cloudformation describe-stacks CLI command. Application Load Balancers Supports HTTP and HTTPS traffic You can use any TCP port, default is 80 and 443 ALB listener receives connection from a client and proxies it to an instance in the target group Uses round-robin load balancing by default Can monitor health of instances ALB Schemes internet-facing: reachable from the internet, public IP address, Public DNS name internel: Not reachable from the internet, private IP address, Private DNS name Health Checks Each instance must pass its health check before receiving traffic. ALB will send HTTP GET request and looks for a success code every 10 seconds. Auto Scaling Groups Launch a certain number of instances into the Auto Scaling group Add the instacnes to the ALB target group Terminate and recreate unhealthy instances Scale in or out based on average group CPU utilization Follow the steps to deploy stack to AWS Cloudformation First validate the templates, you will see the output parameters if template format is correct. 1aws cloudformation validate-template --template-body file:&#x2F;&#x2F;app-stack.json 1aws cloudformation validate-template --template-body file:&#x2F;&#x2F;network-stack.json deploy the stack to AWS cloudformation 1aws cloudformation deploy --template-file &quot;app-stack.json&quot; --stack-name &quot;app-stack&quot; Change the TLS certificate ARN Change the S3 URL to yours Change the SSH key pairs for logging into EC2 instance Change the EC2 instance image ID Note: the template will only work for us-east-1 region, tried using ap-southeast-2 but failed when waiting for the cfn-signal. Probably because the application doesn’t exist in ap-southeast-2 docker market. 1aws cloudformation describe-stacks --stack-name &quot;app-stack&quot; Using the command above we can find the URL of the Internet-facing application load balancer. We securely(HTTPS) connect to this load balancer. And it redirect us to one of the instance in web tier. Note we do added a TLS certificate in the template. But the TLS certficate is for my website theyuancheng.com, and the domain of the EC2 instance does not match. So we are connecting using HTTP protocol. Also pay attention to the EC2 hostname, Web tier server information, ip-10-0-1-42 belongs to Public Subnet A, and one of the instance is running inside this subnet. App server information, ip-10-0-102-180 belongs to Private Subnet B, one of the instance is running inside this subnet too. If you refresh the URL a couple of times, you can see that the hostname ip we are connecting to changes, which means the load balancer redirect us to a different instance. Now, let us try to terminate both of the web tier instances and see if Auto Scaling will recreate the instances for us. 1aws autoscaling describe-auto-scaling-instances This command will list all the instances, we can find the instance ids in the list. 1aws ec2 termin ate-instances --instance-ids We can see Auto Scaling automatically recreate another two instances, the intance ids are different. Use this command to delete the stack. 1aws cloudformation delete-stack --stack-name &quot;app-stack&quot; After deleting the stack, use this command to check if the stack has been deleted. 1aws cloudformation describe-stacks Section Four Summary Use Stack template to deploy Auto Scaling multi-tier web application with load balancer. Stack will automatically rollback everything if deploy failed. Elastic load balancing and Auto Scaling work together. ELB provides health checks, Auto Scaling adds instances to the ELB target group. Section Five: Multi-region Applications with Route 53 Deploying a multi-region application Active-active redundancy using weighted resource records Active-passive redundancy using failover resource records Route 53 health checks We are going to deploy two cloudFormation stacks into the same region to simulate the multi-region application deployment. But because we have two URLs for the two Internet facing ALB, we need Route 53 to send traffic to these two ALBs. This is called an active-active scanario, because they are both active. We are going to create two weighted resource record sets with equal weight, so Route 53 will distribute traffic evenly. See the image above to create a new record. Create another record and route traffic to the two load balancers evenly. Checklist for creating records Routing Policy: Weighted Record name: www Turn on Alias Record Type: A Route traffic to: Classic load balancer, region (us-east-1), webtier-app-stack-1 Weight: 50 Record ID: app-stack-1 The connection to the instance is now secure. (Notice the lock icon at top left corner, in front of the URL) How to check if Route53 distribute the traffic evenly to two load balancers? Go to DNS checker and type in www.theyuancheng.com. And you will see that half of the traffic ending in one IP. Active-passive Redundancy using Failover Resource Records Primary region services all requests Secondary region does not service any requests unless the primary fails Also called active-standby architecture Two ways to run this architecture Pilot Light: Secondary region runs minimal amount of resources to keep costs down. (in our case, maybe only one instance in the web tier and one instance in the app tier (normally should be 2 and 2)). When we need the secondary region, Auto Scaling can increase the instance number when needed. Warm Standby: Secondary region has roughly the same capacity as the primary region. Quicker to start, doesn’t need Auto Scanling. Similar to what we did before, this time we create two records, one pointing to app-stack-1 and the other is pointing to app-stack-2. As long as app-stack-1 is healthy, Route 53 will not send any traffic to app-stack-2. For the Routing policy we choose Failover and Failover Record Type is Primary for the first record.(Secondary for the second record). Now both records are created. We can go the DNS checker and check the differences. Now they all resolve to the same set of IP addresses. Now let us try to shut down app-stack-1. 1aws cloudformation delete-stack --stack-name &quot;app-stack-1&quot; Now the DNS checker returns a different set of ip addresses over time. (from 236, 12 to 252, 207) Route 53 Health Checks We are going to use the two instances in app-stack-2, use below command to get the IPs 1aws ec2 describe-instances --query &quot;Reservations[*].Instances[*].PublicIpAddress&quot; --output&#x3D;text Create Route 53 health checks. Type in the IPs of the instances. Once both health checks have been created, we can try to shut down one of them. Create another record with instance IP and health check. Route 53 will distribute traffic evenly to both instances, if one of the instances fail, the Route 53 health check will detect that and Route 53 will stop sending traffic to it. If you don’t need ELB, DNS based load balancing is a cost-effective option. Course Summary Architecture for availability Setting up AWS environment VPC(Subnets, NAT Gateways, Direct Connect, VPN, Transit Gateways) CloudFormation, Elastic Load Balancing, Auto Scaling Multi-region Applications(Route 53, Active-active weighted records, Active-passive failover records)","categories":[],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://hellcy.github.io/tags/AWS/"}]},{"title":"AWS SAM and CloudFront","slug":"AWS-SAM-and-CloudFront","date":"2020-10-07T03:13:00.000Z","updated":"2021-05-24T07:27:02.657Z","comments":true,"path":"2020/10/07/AWS-SAM-and-CloudFront/","link":"","permalink":"http://hellcy.github.io/2020/10/07/AWS-SAM-and-CloudFront/","excerpt":"","text":"Part One: AWS SAM Part Two: AWS SSO Part Three: AWS CloudFront Part One: AWS SAM Note: This is a brief introduction about how to setup a Serverless Application Model using VS Code and Nodejs. I will probably be adding more details later. Visual Studio Code VS Code is an perfect IDE for writing/testing/deploying SAM. Some key points need attention are listed. AWS credentials in Users/UserName/.aws folder. Create yaml file with resources: lambda function, policies, runtime language, environment variable etc… Writing lambda function in Nodejs, CROS policy… CRUD operation: marshall/unmarshall object etc… AWS CLI: package and deploy SAM to AWS AWS CLI command to package and deploy SAM to AWS. 1sam deploy --template-file output-yamlFileName.yaml --stack-name Your_Stack_Name --capabilities CAPABILITY_IAM 1sam package --template-file yamlFileName.yaml --s3-bucket S3_Bucket_Name --output-template-file output-yamlFileName.yaml A very useful course I took about AWS SAM: Deploying Serverless Applications in AWS Using the Serverless Application Model Part Two: AWS SSO Create Custom SAML Application We can use AWS SSO as an IDP for our web application. Create new Custom SAML 2.0 application. This is IDP metadata, we will download it after finishing configuring return attributes. This is SP metadata, which we will prepare and upload. This is where we config the return attribute in SAML response. Supported attribute list can be found [here](https://docs.aws.amazon.com/singlesignon/latest/userguide/attributemappingsconcept.html?icmpid=docs_sso_console) Create Users Users can be created by simply fill this form. You can also setup MFA device after creating the user. Part Three: AWS CloudFront Restricting Access to Files in Amazon S3 Buckets You can optionally secure the content in your Amazon S3 bucket so that users can access it through CloudFront but cannot access it directly by using Amazon S3 URLs. This prevents someone from bypassing CloudFront and using the Amazon S3 URL to get content that you want to restrict access to. (Using Origin Access Identity) Block all public access to S3 bucket When creating new distribution in CloudFront, do the following steps Select Web distribution Select the S3 bucket you want to connect to Select Redirect HTTP to HTTPS if you don’t want people to access your content by HTTP requests Select Yes for ‘Restrict Viewer Access’ Select Self as trusted signer Create Trusted Signer Note When 'Restrict Viewer Access' is selected, you can specify which account is the 'Trusted Signer'. Which means they have the permission to create signed URL or signed cookie for people to access your private content. Self is the default 'Truested Signer', which is the account your are currently using. You can also add another accounts by entering their account ID. Create another behavior Login page should be accessiable by public, so as the js, css and image files. So we should create another behavior to let CloudFront know which file access is retricted and which are not. Path Pattern decides which files can be set to public(also select No for 'Retrict Viewer Access' this time) Rules about Path Pattern can be found [here](https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-web-values-specify.html#DownloadDistValuesPathPattern) Create CloudFront Key Pairs We need CloudFront key pairs to create signed URLs and signed Cookies, they are a pair of public and private keys AWS uses to encrypt requests people send to CloudFront, so it knows whether they are authenticated users. This step can only be done using AWS root account, IAM account cannot create CloudFront key pairs. Save the private key pem file and Access key ID to a save place. We will use it later. Create Signed URL This is the most important part. I used two ways to create signed URL, nodejs and C#. I use nodejs to create a lambda function as an API, which will return the signed URL generated. I also add this feature to the SAML project, so when IDP returned SAML response, I can add signed details to the URL and redirect user to the home page. Note that yaml file supports multiple line string (a vertical line followed by a hyphen), so we can add private key string in the yaml file as a environment variable, so as the public key. Also note expiry time input are in [Unix Epoch Time format](https://www.epochconverter.com/) in miliseconds(13 digits). However, the expires argument in the signed URL are in seconds format (10 digits). Also note that C# doesn't recognize private key string in PEM format. We have to convert it to XML format before create signed URL. The signed URL created will append three arguments at the end of the original URL: Expires, Signature and Key-Pair-Id Note the signature contains information about the original URL so you cannot reuse it with different URLs. We have to generate new signed URLs when direct user to other pages.(this will also refresh the session time, which is we want.) Create Signed Cookies NodeJs: Signed Cookies can be created using below code. I used this post as a reference. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&quot;use strict&quot;const AWS &#x3D; require(&quot;aws-sdk&quot;)exports.handler &#x3D; async (event, context, callback) &#x3D;&gt; &#123; var cfsign &#x3D; require(&#39;aws-cloudfront-sign&#39;); &#x2F;&#x2F; 5 seconds var expireTime &#x3D; Math.floor((+new Date() + 1000 * 300) &#x2F; 1000); var signingParams &#x3D; &#123; keypairId: process.env.PUBLIC_KEY, privateKeyString: process.env.PRIVATE_KEY, &#x2F;&#x2F; Optional - this can be used as an alternative to privateKeyString &#x2F;&#x2F;privateKeyPath: &#39;&#x2F;path&#x2F;to&#x2F;private&#x2F;key&#39;, expireTime: expireTime &#125; const body &#x3D; JSON.parse(event.body); &#x2F;&#x2F; Method 2: Generating singed Cookies let policy &#x3D; &#123; &#39;Statement&#39;: [&#123; &#39;Resource&#39;: body.url + &#39;*&#39;, &#39;Condition&#39;: &#123; &#39;DateLessThan&#39;: &#123;&#39;AWS:EpochTime&#39;: expireTime&#125; &#125; &#125;] &#125;; let policyString &#x3D; JSON.stringify(policy); const signer &#x3D; new AWS.CloudFront.Signer(signingParams.keypairId, signingParams.privateKeyString); const options &#x3D; &#123; url: body.url, policy: policyString &#125;; const signedCookie &#x3D; signer.getSignedCookie(options); var response &#x3D; &#123; statusCode: 200, headers: &#123; &quot;Access-Control-Allow-Origin&quot; : &quot;*&quot; &#125;, body: JSON.stringify(signedCookie) &#125; callback(null, response);&#125;; By default, CloudFront caches a response from Amazon S3 for 24 hours, so if you just updated contents in S3 bucket, CloudFront may still serve you the outdated content. Use the below code in cmd to force CloudFront to update its files from S3. 1aws cloudfront create-invalidation --distribution-id &#39;YOUR DISTRIBUTION ID&#39; --paths &quot;&#x2F;*&quot; References Task List for Serving Private Content using S3 and CloudFront Restricting Access to Amazon S3 Content by Using an Origin Access Identity Specifying the AWS Accounts That Can Create Signed URLs and Signed Cookies (Trusted Signers) Reformatting the CloudFront Private Key (.NET and Java Only) Using Signed URLs Creating a Signed URL Using a Canned Policy Code Example: Creating Amazon CloudFront Signed URLs in Node.js Code Example: Create a URL Signature Using C# and the .NET Framework Code Example: Create Signed Cookies using NodeJs Test Signed Cookies using Postman Epoch &amp; Unix Timestamp Conversion Tools Why is CloudFront serving outdated content from Amazon S3? RSA public/private keys in YAML Convert PEM to XML in C# CloudFront Path Pattern Rules","categories":[],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://hellcy.github.io/tags/AWS/"}]},{"title":"Wishlist 2021","slug":"Wishlist-2021","date":"2020-10-06T03:11:24.000Z","updated":"2021-05-24T07:27:02.660Z","comments":true,"path":"2020/10/06/Wishlist-2021/","link":"","permalink":"http://hellcy.github.io/2020/10/06/Wishlist-2021/","excerpt":"","text":"Get AWS SAA C02 certificate Finish 1500+ Leetcode Problems (at least 2 problems per day) Get 2000+ points in Leetcode contests Setup a simple LAMP website Get a new job by the end of year 2021","categories":[],"tags":[{"name":"Wishlist","slug":"Wishlist","permalink":"http://hellcy.github.io/tags/Wishlist/"}]},{"title":"Dynamic Programming","slug":"Dynamic-Programming","date":"2020-08-27T04:08:01.000Z","updated":"2021-05-24T07:27:02.659Z","comments":true,"path":"2020/08/27/Dynamic-Programming/","link":"","permalink":"http://hellcy.github.io/2020/08/27/Dynamic-Programming/","excerpt":"","text":"Lecture 1 Introduction 什么是动态规划？ 1.计数型 有多少种方式走到右下角 有多少种方法选出k个数使得和是Sum 2.求最大最小值 从左上角到右下角的路径的最大数字和 最长上升子序列长度 3.求存在性 取石子游戏，先手是否必胜 能不能选出k个数使得和是sum Coin Change(最大最小型) 一般想法：先用面值大的硬币，最后想办法用小硬币 动态规划四个步骤 确定状态 一般来说，解决动态规划需要开一个数组，可能是一维的或者二维的，要确定数组的每一个元素代表什么 转移方程有几个变量就需要创建几维数组 确定状态需要两个意识：最后一步是什么，子问题是什么 转移方程 每个子问题到下一个子问题的过程 初始条件和边界情况 什么时候停下来？初始条件是什么? 计算顺序 一般是从小到大 Coin Change 从第一步算到m步，每一步算n次，其中m为最后的硬币sum，n为总共有多少种不用的硬币，时间复杂度为O（m*n） 最后一步是由前面几步的最小值确定的，所以先确定前面的值，从小到大，就能判断出最后一步的值 Unique Path:计数型 Jump Game：存在型 Lecture 2 Coordinates and Bit Operation 序列型：前i个，最小，方式数，可行性。。 Paint House 分别记录每栋房子之前的房子的每种颜色的最小花费 划分型 Decode ways 解密数字串即划分成若干段数字，每段数字对应一个字母 知道前N-1和N-2个数字分别有多少种方式，再相加 坐标型 需要找到序列中某些子序列或者网格中的某条路径：计数，最大，最小，存在性 Minimum Path Sum 空间优化：计算第i行时，只需要i行和i-1行的f值（滚动数组） Bomb Enemy 给定输入为序列或者网格矩阵 问题一般为：以第i个元素结尾的某种性质，到格子（i， j）的路径的性质 Minimum path sum打印路径：新建一个二维数组，记录每次的方向，然后从最后（右下角）往前推，最后记住要反转数组才是从开始到结束的顺序 位操作型动态规划 Counting bits: removing the last bits Lecture 3 Sequence 给定一个序列，转移方程f（i）下标i表示前i个元素的某种性质， f(0)就是空序列的性质 Paint House II: Similar to Paint House I, Optimization: pick the smallest and the second smallest cost of all colors, reduce the min calculation to O(1) and totoal time complexity from O(N * K * K) to O(N * K * 2), where N is the number of houses and K is the number of colors House Robber House Robber II:想办法把圈断开，分两种情况处理，变成两种序列情况 Buy and Sell Stock III:分成五个状态，分别记录下每天每个状态的情况（类似于Paint house） Russian Doll Envelope Lecture 4 划分型，博弈型，背包型 划分型 Perfect Squares Palindrome Partitioning II:1. find all possible palindrome from the string s ans store them in a 2d array expand palindrome start and end index to both sides. 2. partition dp: dp[i] = min(dp[i], dp[j] &amp;&amp; isPalin(s[j][i - 1])) Copy Books(LintCode) 划分型dp关键字：连续！Substring, continuous subarray 博弈型(两方游戏) 从第一部开始分析!!!问题规模会越来越小。 Coins in a line: Alince and Bob takes one or two coins each turn Alice先手还剩N个Coin，与Bob先手还剩N-1个Coin是一样的，所以每个局面都可以看成是先手但是剩下不同数量的Coin 背包型 你有一个背包，背包有最大承重 商店里有若干物品，都是免费拿 目标： 1. 装下最多重量的物品， 2. 装下最大总价值的物品。 3. 有多少种方式正好带走满满一书包物品 给定背包最大承重M， 物品的重量都是整数 每个方案的总重量都是从0到M 对于每个重量方案，我们要知道能不能做到 Note：背包问题中，dp数组大小和总承重有关 现在需要知道前N个物品能否拼出重量W 如果前N-1个物品能拼出W，当然前N个物品也可以拼出W 如果前N-1个物品能拼出W-A(N-1),A(N-1)为第N个物品的重量，那么前N个物品也能拼出W BackPack I - V Coin Change 1, 2 当每个物品只能用一次时，需要多开一维的dp数组去计算前N个物品的方式 Lecture 5 背包型, 区间型 背包型 Backpack II：现在每个物品有价值，求能带走最大多少价值的物品 f[i][j]: 用前i个物品拼出重量j时的最大总价值，j = -1表示不能拼出 dp[i][j] = Math.max(dp[i - 1][j], dp[i - 1][j - nums[i - 1]] + Value[i - 1]) 区间型：当子问题还是连续的index时 Scramble String Burst Ballons 消去型的题目要从后往前想，最后一步只剩一个，然后往前想 先从小的len开始计算 Lecture 6 双序列型 有两个序列 每个序列本身是一维的 可以转化为二维的动态规划 查看最后一个字符是否匹配，缩减问题规模 易错点： 记得初始化，空串处理，结果是否 + 1 Longest common subsequence Interleaving String Edit Distance Distinct Distance Regular Expression Matching Wildcard Matching Ones and Zeros","categories":[],"tags":[{"name":"Dynamic Programming","slug":"Dynamic-Programming","permalink":"http://hellcy.github.io/tags/Dynamic-Programming/"}]},{"title":"Harvard CS75 Web Development","slug":"Harvard-CS75-Web-Development","date":"2020-06-30T06:49:58.000Z","updated":"2021-05-24T07:27:02.659Z","comments":true,"path":"2020/06/30/Harvard-CS75-Web-Development/","link":"","permalink":"http://hellcy.github.io/2020/06/30/Harvard-CS75-Web-Development/","excerpt":"","text":"Chapter 0: HTTP Chapter 1: PHP Chapter 2: PHP Continued Chapter 3: MVC XML Chapter 4: SQL Chapter 5: SQL Continued Chapter 6: JavaScript Chapter 7: AJAX Chapter 8: Security Chapter 9: Scalability Chapter 0: HTTP What happens after you pressing Enter? The URL address will be translate to an IP address. 我们现在所用的IP address是ipv4,它由四组0-255的数字组成，总共32bits，可以有40亿总可能，我们现在每个人都有很多设备，ipv4的组合已经快不够用了。 所以新的ipv6要替代原来的ip address，它由8组4位的16进制组成，总共有128bits 怎么样将hostname网址转换成IP address呢？我们需要用到DNS（Domain name server）,他储存有ip address到hostname的一个mapping table，如果你访问的网址不在这个DNS里，他就会不断的访问上级服务器，直到访问到root server，root server知道谁有可能知道这个ip address，在不断的访问到下级服务器/DNS，直到找到并把hostname转换成ip address 互联网就像一个邮件系统，我们现在知道邮件该送给谁，我们知道自己的ip address(return address). 我们就可以把信息送给我们想送的网站，比如google.com，他收到信后，会拆开看我们相访问哪个网址，比如index.html,然后把我们想要的内容装进信封，颠倒送件人和收件人，然后送回来，我们拆开信封看到html信息，浏览器就会显示这些信息 Private Ip address 对于一个家庭来说，所有的设备共享一个公共ip，但是每个设备都会有自己的private ip，192.168.x.y. 或者172.16.x.y. 当你需要很多设备时，比如在大型公司，你可以使用10.x.y.z TCP/IP IP用来确认谁要向谁传送信息，TCP就是传送协议 Port Number 信息的传送有很多种，不光是HTTP，还有邮件，短信等等，我们使用不同的port number来让服务器知道进来的request是哪种请求，比如HTTP: TCP 80，我们让服务器听取port 80的网页请求，还可以SMTP: TCP 25让服务器听取port 25 的邮件请求， HTTPS： TCP 443, 加密的网页请求。 现在的浏览器会自动在网址后面加上port number Getting your own domain name 我们的设备虽然可以联网，但是他只有一个公共ip，如果我们想host我们自己的网站，我们就需要有一个域名 GoDaddy, NameCheap Hosting your own website 当我们有了域名之后，我们还需要一个web server用来存放我们的网站相关文件，HTML， CSS， JAVASCRIPT等等，这需要我们再找一个提供DNS服务的公司（dreamhost.com），向他们租用一些online storeage，他们也会提供两个ip addresses（还有一个是备用的）。并且与我们的域名关联 DNS 例子：如果你的网站是一个邮件服务网站，比如Google email。我们的email虽然可以是yuan@unicard.com，但是其实我们使用的是Google的邮件服务，DNS识别出以unicard结尾的邮件地址是属于Google的一个服务，并把他发送到Google的服务器。 NS Name Server 一个NS record的作用是告诉大家哪个name server知道关于我们域名的一些信息 NS stands for ‘name server’ and this record indicates which DNS server is authoritative for that domain (which server contains the actual DNS records). A domain will often have multiple NS records which can indicate primary and backup name servers for that domain A A record的作用是把ip address和域名相连(Domain name to ip address) CNAME Canonical name 与A record不同的是CNAME是把域名和域名相连(Domain name to domain name)，因为比如我们相用Google的邮件服务，所以我们想把yuan@unicard.com，关联到yuan@google.com,然后Google用他们呢的DNS server去把他转换成ip address，我们就不用担心Google改变他的ip address了。 再比如说，如果Dell公司的客户服务是外包出去的，那么我们访问Dell的网站，在通过Dell官网进入到他们的客户服务网站，我们就会发现我们从Dell.com 到了customerService.com，这样可能不太好，Dell想让他的网站看起来是一个整体，所以就可以用CNAME让customerService.com的名字隐藏起来，只显示成support.dell.com MX Mail Exchange MX record把负责处理请求的server和他们的ip address相连，这样就可以知道进来的email请求该由哪个server负责 What happens when you reach the target website? Web host Web host companies host multiple websites with one ip address, they share one ip address. Server response with different content based on the headers in the request If the hosting server is using Php v4.3, you have to use the same. If the hosting server is down, all websites related to this server is also down. VPS(Virtual Private Server) VMware, Parallels, Virtual Box Install multiple instances of Windows or Linux or MacOS on the server, and you can control the software and tools on that VPS SSH/SFTP SSH: Connecting to a remote server and execute commands on it. SFTP: Transfer files to a remote server. 123456telnet www.google.com 80GET &#x2F; HTTP&#x2F;1.1(press enter twice) If your webiste is hosted by a server that are shared with other website, you have to send a get request with a host header specify your domain name. Otherwise the server don’t know what content to return. nslookup google.com will list ip address for that host sudo vi /etc/hosts this is a local ip address &lt;-&gt; domain name mapping table, browser will check this file first before sending any request Chapter 1: PHP Apache Configuration file for Apache web server: httpd.conf, apache.conf, apache2.conf listen to port 80 of any ip addresses of incoming requests ServerName and ServerAlias: the destination of the incoming requests, both will need an A record in DNS to work (or CNAME) CustomLog, ErrorLog: Specify where to save the log files DocumentRoot: Root path of your website port 443 uses SSL(Secure socket layer), needs a certificate to be installed on the server. SSL: there are two keys, public key and private key, when a user visits our website, the website sends the public key to the user’s machine, user uses it to encrypt the message. Then when our website receives the message from the user, we use the private to decrypt it to get the original message. But this is not enough, we need to ask some Certificate Authorization(CA) for a certificate. This is because user doesn’t trust our website. but because our website is trusted by a CA, so the user can trust our website. Certificate needs to be digitally signed. SSLCertificateKeyFile: the private key on the server SSLCertificateFile: the certificate 12345mod_rewriteRewriteEngine OnRewriteCond %&#123;HTTP_HOST&#125; !^www\\.cs75\\.net [NC]RewriteRule (.*) https:&#x2F;&#x2F;www.cs75.net&#x2F;$1 [R&#x3D;301, L] HTTP_HOST is an environment variable, it is the host name. In English, the first line is a condition, it is saying if the host name is not starting with www.cs75.net(Regex), do the following line, [NC], no case, case insensetive (.*) one or more any characters, it remembers what user was typing, redirect user to the correct URL, 301 move permanently, the browser saves the result and next time will redirect you automatically. whereas 302 is move temporarily. The reason to do this is to make sure the URL in user’s browser is the website URL. Because there are multiple ways to visit the website and not typing the website URl. We could use ip address, we could use ‘udo vi /etc/hosts’(see end of lecture 0). So this will make sure that the URL will always be www.cs75.net no matter what user originally typed. XAMPP Linux, Apache, MySQL, PHP, Perl We can set up our dynamic website without using remote virtual server, people from outside world cannot visit it. But it is good for development purposes GET/POST GET: will change the state of the url, add parameters behind the quesiont mark ‘?’, parameters are separated by &amp;, everything will be shown in URL, not good to send sensitive or huge information POST: can upload files(images), it is not in URL, can send sensitive information. Post request cannot be copied. One of the downsides of POST is that when user click reload or backbutton, browser will try to submit the form again, you may end up buying things twice. One of the solutions would be, whenever user submitted a form, immediately redirect user to another website page with only GET request, so they cannot revisit the POST request page anymore. PHP Very well documented. Interpreted(alternative to compiled) language, you don’t need to compile it first then to run it, you can just give your code to a interpreter and it will run. Downside is performance. Once a C++ language be compiled, the complied code can be run by CPU superfast. whereas PHP needs to be interpreted everytime. suPHP Web servers usually have root user(administrator) and other users. If you are user A, and you want the web server to be able to use your PHP code. You have to set them to be readable. Then another user B would be able to see your PHP code. Use suPHP could solve this issue. It makes sure that web server can only execute A’s code when A’s logged in. And B cannot see it when B’s logged in. And A can only delete A’s file, so no one else could modify or break A’s code. If A’s website’s users upload files or images, they are stored in the server where only A can see. Variables Data Types(loose in PHP), PHP functions will return different data types based on situations Superglobals $_COOKIE, key values from browser $_ENV, lower details of user’s machine $_FILES $_GET, hash table $_POST, array $_REQUEST, details from requests $_SERVER, user agent, browser and OS $_SESSION, states, save values Command line mkdir, make directory cd, change directory cat/more, show content of a file ls, list content of a directory . current folder … parent folder ls -al, list permission settings for all files in current directory chmod, change mode of a file or directory: e.g. chmod a+r filename: give read access to a file called filename permission settings looks like this: -rw-rw-r–, the first - means it is a file or it can be ‘d’ for directory, it can then be split into three groups, they are the owner, the group and the world. Use $_GET[‘username’] to get the variable values user send by GET request. Use htmlspecialchars to escape all html tags to sanity check user inputs Chapter 2: PHP Continued PHP is an interpreted language, it can be run at anywhere no matter what the PC is like. Compiled language depends on the PC, it may run at one PC and may not run at another. POST request 123&lt;pre&gt; &lt;?php print_r($_POST) ?&gt;&lt;&#x2F;pre&gt; use print_r to recursivly display all data inside the POST request 123456&lt;? if (empty($_POST[&#39;fname&#39;]) || empty($_POST[&#39;lname&#39;])) &#123; header(&quot;Location: http:&#x2F;&#x2F;localhost&#x2F;yuan&quot;); exit; &#125;?&gt; check if necessary form information is filled(not empty). If not, redirect user back to the previous form page. header(“Location: URL”) is to redirect user 123456&lt;? if (empty($_POST[&#39;fname&#39;]) || empty($_POST[&#39;lname&#39;])): ?&gt; You must provide your full name and gender to continue. Go &lt;a href&#x3D;&quot;index.html&quot;&gt;back&lt;&#x2F;a&gt;&lt;? else: ?&gt; You are registered! &lt;pre&gt;&lt;? print_r($_POST) ?&gt;&lt;&#x2F;pre&gt;&lt;? endif ?&gt; 123456&lt;? if (empty($_POST[&#39;fname&#39;]) || empty($_POST[&#39;lname&#39;])) &#123; ?&gt; You must provide your full name and gender to continue. Go &lt;a href&#x3D;&quot;index.html&quot;&gt;back&lt;&#x2F;a&gt;&lt;? &#125; else &#123; ?&gt; You are registered! &lt;pre&gt;&lt;? print_r($_POST) ?&gt;&lt;&#x2F;pre&gt;&lt;? &#125; ?&gt; if else conditions in PHP supports both colon and curly brackets 12345678910111213if (!empty($_POST[&#39;fname&#39;]) &amp;&amp; !empty($_POST[&#39;lname&#39;])) &#123; $to &#x3D; &#39;chengyuan82281681@hotmail.com&#39;; $subject &#x3D; &#39;Registration&#39;; $body &#x3D; &quot;This person just registered!\\n\\n&quot; . $_POST[&#39;fname&#39;] . &quot;\\n&quot; . $_POST[&#39;lname&#39;]; $headers &#x3D; &quot;From: chengyuan82281681@hotmail.com\\r\\n&quot;; mail($to, $subject, $body, $headers);&#125;else &#123; header(&quot;Location: http:&#x2F;&#x2F;localhost&#x2F;yuan&#x2F;index.html&quot;); exit;&#125; Dot symbol is a concatenation symbol, connect two strings into one This mail function comes with PHP doesn’t uaually work on local network, because ISP blocks outbound port 25 for SMTP. Same reason as they block port 80. 1234567891011&lt;? if (isset($_POST[&#39;action&#39;])) &#123; if (empty($_POST[&#39;fname&#39;]) || empty($_POST[&#39;lname&#39;])) &#123; $error &#x3D; true; &#125; &#125;?&gt;&lt;? if ($error): ?&gt; &lt;div style&#x3D;&quot;color: red&quot;&gt;You must fill out the form!&lt;&#x2F;div&gt;&lt;? endif ?&gt; To be able to check form errors using PHP code, index.html has to be changed to index.php in index.php, setup a variable named ‘action’(other names work too) and send it to the backend, the server code will know if user submit a form by checking by variable. if form has errors, send user back to itself with errors. 1234$DORMS &#x3D; array(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;);&lt;? foreach ($DORMS as $dorm): ?&gt; &lt;option value&#x3D;&quot;&lt;?&#x3D; $dorm ?&gt;&quot;&gt;&lt;?&#x3D; $dorm ?&gt;&lt;&#x2F;option&gt; &lt;? endforeach ?&gt; Define array in PHP Foreach loop in PHP 12345678&lt;? foreach ($DORMS as $dorm) &#123; if (isset($_POST[&quot;dorm&quot;]) &amp;&amp; $_POST[&quot;dorm&quot;] &#x3D;&#x3D; $dorm) echo &quot;&lt;option selected&#x3D;&#39;selected&#39; value&#x3D;&#39;$dorm&#39;&gt;$dorm&lt;&#x2F;option&gt;&quot;; else echo &quot;&lt;option value&#x3D;&#39;$dorm&#39;&gt;$dorm&lt;&#x2F;option&gt;&quot;; &#125;?&gt; When redirect user back because there are some errors in the form, the selected value will stay Xdebug: extension of PHP to debug. Let website remember your login with sessions 1234567891011121314151617181920212223242526272829&lt;? &#x2F;&#x2F; 1 session_start(); &#x2F;&#x2F; 2 define(&quot;USER&quot;, &quot;yuan&quot;); define(&quot;PASS&quot;, &quot;123&quot;); &#x2F;&#x2F; 3 if (isset($_POST[&quot;user&quot;]) &amp;&amp; isset($_POST[&quot;pass&quot;])) &#123; if ($_POST[&quot;user&quot;] &#x3D;&#x3D; USER &amp;&amp; $_POST[&quot;pass&quot;] &#x3D;&#x3D; PASS) &#123; $_SESSION[&quot;authenticated&quot;] &#x3D; true; &#x2F;&#x2F; 4 save user in cookie for a week setcookie(&quot;user&quot;, $_POST[&quot;user&quot;], time() + 7 * 24 * 60 * 60); &#x2F;&#x2F; redirect user to home page, using absolute path. redirect(&quot;home.php&quot;); &#125; &#125; &#x2F;&#x2F; 5 function redirect($file) &#123; $host &#x3D; $_SERVER[&quot;HTTP_HOST&quot;]; $path &#x3D; rtrim(dirname($_SERVER[&quot;PHP_SELF&quot;]), &quot;&#x2F;\\\\&quot;); &#x2F;&#x2F; current php directory, trim out unwanted leading slashes header(&quot;Location: http:&#x2F;&#x2F;$host$path&#x2F;$file&quot;); exit; &#125;?&gt; this will enable session, must be at the top of your code. Make sure no whitespaces or any code in front of this. Define constants check user form data are exist and valid Session will be saved on the web server on the disk with a unique session id. Cookie will saved on the client machine. Everytime user visit the website, it will show us the cookies, web server will quickly open up the file saved with the same session id, and grab all the values(key-value pairs) to our webpage. Webpage also can access to the user Cookies. define functions in PHP Note: make sure to give web server user the write permission to the session folder. Otherwise it cannot write session variables to the file. Also, make sure to use session_start(); in home.php as well. So it can have access to the session variables after redirecting. Any sensitive information should not be stored in the Cookies. Note: make sure to give web server user the write permission to the session folder. Otherwise it cannot write session variables to the file. Also, make sure to use session_start(); in home.php as well. So it can have access to the session variables after redirecting. Chapter 3: MVC XML MVC Change permission to write and read directory or files: Read: r = 4 Write: w = 2 Execute: x = 1 adds them up to get the mode code. e.g. sudo chmod 644 filename means: give the file the permission level: -rw-r–r-- sudo chmod 700 filename: give the file the permission level -rwx------ commonly used mode of files: 644: can be read and write by the file owner, also can be read by other group of users and the whole world. 600: can be read and write by the file owner only. html 644 gif 644 jpg 644 css 644 js 644 png 644 php 600 For directory: Read means user can list all content inside a directory(same as the ls command in terminal). Execute means user can go into this directory(same as the cd command). Common permission level for directory: dir 711: user can go into this directory, can read/write all its files. Other groups or outside world can only go into this directory. If they know the exact filename in this directory and has read permission to that particular file. They can read it. But they can’t list all filenames of that directory. dir 755: user can go into this directory, can read/write all its files, Other groups or outside world can go inside and list all files. Use different hostname with only one web server. Change the hosts table file to give your domain a different name locally instead of localhost. sudo vi /etc/hosts Use RewriteModule to manipulate the URL, route user to correct places with cleaner URLs XML XML is an extensible markup language where you can extend structure without breaking existing data and applications. Adding more children to an element is 100% fine. Config files can be XML, you can add more KEYs and variables to the config files later. Escape entities(pre-defined keywords) in XML: &amp;amp;amp; &amp;amp;lt; &amp;amp;gt; &amp;amp;apos; &amp;amp;quot; Declare your own entity: &amp;lt;!ENTITY nbsp &quot;&amp;amp;#160;&quot;&amp;gt; SimpleXML API: See XML in a Tree Structure DOM(Document Object Model) RSS In PHP, we can use SimpleXML API to read an XML file and load its contents. 123456789&gt;? $dom &#x3D; simplexml_load_file(&quot;lectures.xml&quot;); foreach ($dom-&gt;xpath(&quot;&#x2F;lectures&#x2F;lecture&quot;) as $lecture) &#123; print &quot;&quot;; print &quot;Lecture &quot; . $lecture[&quot;number&quot;] . &quot;: &quot;; print $lecture-&gt;title; print &quot;&quot;; &#125;?&lt; Recall dot symbol . in PHP means concatenation. Select XML node from PHP using xpath: If you only want to display certain lecture, for example, lecture 3, you could add additional condition in xpath $dom-&gt;xpath(&quot;/lectures/lecture[@number='3']&quot;) @ is short for attributes, we can expend it as ‘attributes::’ We can also start at any given node and go to its parent, chlid or siblings by define the axis in the path(below is just an example and will not work): $dom-&gt;xpath(&quot;/parent::lectures/child::lecture[attributes::number='3']&quot;) Chapter 4: SQL CSV(comma separated values) PSV(Pipe separated values) pipe is the vertical line in the keyboard | TSV(Tab separated values) CSV fgetcsv: load csv file content into an array of arrays fputcsv: write content to a csv file XML: SimpleXML MySQL: database SQLite: Allow you to use SQL without an actual Database, it is just a file stored in your disk. SQL CREATE ALTER DROP SELECT INSERT UPDATE DELETE Connection MySQL to PHP: MyPHPAdmin 123456789101112131415161718192021222324252627282930313233343536373839404142&gt;? &#x2F;&#x2F; enable sessions session_start(); &#x2F;&#x2F; connect to databsae if (($connection &#x3D; mysqli_connect(&quot;localhost&quot;, &quot;yuan&quot;, &quot;123&quot;, &quot;yuan_lecture&quot;)) &#x3D;&#x3D;&#x3D; false) die(&quot;Could not connect to database&quot;); &#x2F;&#x2F; if username and password were submitted, check them if (isset($_POST[&quot;user&quot;]) &amp;&amp; isset($_POST[&quot;pass&quot;])) &#123; &#x2F;&#x2F; prepare SQL $sql &#x3D; sprintf(&quot;SELECT * FROM users WHERE username&#x3D;&#39;%s&#39;&quot;, mysqli_real_escape_string($connection, $_POST[&quot;user&quot;])); &#x2F;&#x2F; execute query $result &#x3D; mysqli_query($connection, $sql); if ($result &#x3D;&#x3D;&#x3D; false) die(&quot;Could not query database&quot;); &#x2F;&#x2F; check whether we found a row if (mysqli_num_rows($connection, $result) &#x3D;&#x3D; 1) &#123; &#x2F;&#x2F; fetch row $row &#x3D; mysqli_fetch_assoc($connection, $result); &#x2F;&#x2F; check password if ($row[&quot;password&quot;] &#x3D;&#x3D; $_POST[&quot;pass&quot;]) &#123; &#x2F;&#x2F; remember that user&#39;s logged in $_SESSION[&quot;authenticated&quot;] &#x3D; true; &#x2F;&#x2F; redirect user to home page, using absolute path. redirect(&quot;home.php&quot;); &#125; &#125; &#125; function redirect($file) &#123; $host &#x3D; $_SERVER[&quot;HTTP_HOST&quot;]; $path &#x3D; rtrim(dirname($_SERVER[&quot;PHP_SELF&quot;]), &quot;&#x2F;\\\\&quot;); &#x2F;&#x2F; current php directory, trim out unwanted leading slashes header(&quot;Location: http:&#x2F;&#x2F;$host$path&#x2F;$file&quot;); exit; &#125;?&lt; in mysql_connect(), the first variable is the DB server, second is username of the DB, thrid is the password of the DB mysql_real_escape_string is preventing SQL injection attack. $result is a temporary table get from DB mysql_num_rows return number of rows in the temp table mysql_fetch_assoc return an associated array with keys and values from the temp table One way hash password It is not good to store password in the DB in plain text. So we should use a hash function to hash the password into some random characters, whenever user logs in, we use the same algorithm to hash the password and check if it equals to the same random characters in the DB. SQL indexes, Constraints PRIMARY KEY INDEX: doing a binary search or some other tree structure to a column, so it will be much faster to run a query. Cost more disk space. The below image shows that this table has two indexes, and it is using BTREE structure to store all values. UNIQUE FULLTEXT BLOB (Binary Large Object) -&gt; etc. Images Although you can store images into DB, it cost space, it would be better to store it in a folder(file system), and store the link to this file into the DB. Foriegn Key: is a primary key in another table Chapter 5: SQL Continued CRUD (Create Read Update Delete) model VARCHAR will save more space than using CHAR, because it uses different length of chars for each value. CHAR will use same length of chars for all values, but it will run query faster, because it knows the length of values, it can move to next value by adding the length to the current position. (For VARCHAR it has to keep searching until reach to the end of the value.) AI (Auto Increment) Good for IDs, plus one each time. When you delete the ID, the ID number will NOT be reused. Float numbers: 32-bit or 64-bit numbers are finite. If we are using it to represents real numbers(infinite), SQL will round the number to its closest number that it can find. e.g. if you enter 1.9, it might give you 1.89999999 instead. So it is not good to use Float to represent Money etc… important values MySQL Functions PDO(Portable Data Object) Assign variables to values, so when you change database next time, you don’t have to change the code. You just need to change the variables of PDO arguments. JOIN Join tables together. Get data from multiple tables at once. In the above example, we could further create another table that has Product_Id and Product_Name, and use only Product_Id in the orders table. Only the person that have sold products are displayed. 123SELECT Employees.Name, Orders.ProductFROM EmployeesJOIN Orders ON Employees.Employee_ID &#x3D; Orders.Employee_ID This is another syntax to use to join tables. This is the same as the other SQL syntax shown above. Left Join, Right Join Their are differnt type of joins, they decides which table should carry more weight in this query. For example, in the Employees table, if someone has left the company and is no longer exist in the Employees table. But his sell history is still in the orders table. We want to keep the sell history. Then we could use a Right Join, it will display all sell history related. But will show NULL in the Employee_ID(because there is no corresponding Employee_ID in the Employees table). Race Conditions(Atomicity) In computer programming, an operation done by a computer is considered atomic if it is guaranteed to be isolated from other operations that may be happening at the same time. Put another way, atomic operations are indivisible. INSERT INTO table (a,b,c) VALUES (1,2,3) ON DUPLICATE KEY UPDATE c=c+1; This will help you to merge SELECT and UPDATE into one query. Potentially solve the race conditions issue(NOT enough though). Transactions Transactions means do the following queries atomically, do not allow any other queries perform in the meantime. 1234START TRANSACTION;UPDATE ACCOUNT SET BALANCE &#x3D; BALANCE - 1000 WHERE NUMBER &#x3D; 2;UPDATE ACCOUNT SET BALANCE &#x3D; BALANCE + 1000 WHERE NUMBER &#x3D; 1;COMMIT; In the example above, we transfer 1000 balance from account 1 to account 2 at the same time. 123456START TRANSACTION;UPDATE ACCOUNT SET BALANCE &#x3D; BALANCE - 1000 WHERE NUMBER &#x3D; 2;UPDATE ACCOUNT SET BALANCE &#x3D; BALANCE + 1000 WHERE NUMBER &#x3D; 1;SELECT BALANCE FROM ACCOUNT WHERE NUMBER &#x3D; 2;# suppose account number 2 has a negative balance here!ROLLBACK; In the example above, if we find something wrong happened after we perform the transaction, ROLLBACK will undo all the changes in the transaction. Locks (MyISAM) 1234LOCK TABLES account WRITE;SELECT balance FROM account WHERE number &#x3D; 2;UPDATE account SET balance &#x3D; 1500 WHERE number &#x3D; 2;UNLOCK TABLES; ‘LOCK TABLES account WRITE;’’ will lock the table ‘account’, prevening people from WRITING to the table. One downside is that LOCK will lock the entire table, so no one can write to the table even if they are updating other accounts. Add Foreign key constraints so that the DB knows the primary key in one table is related to another foreign key in another table. ON DELETE RESTRICT and ON UPDATE RESTRICT means if we want to delete something that is actually a primary key in a table, DB will reject it because it is related to another tables. If we changed it to CASCADE, then if we delete a record that is a primary key, DB will delete all records that are related to this primary key in other tables too. Chapter 6: JavaScript Javacript, like PHP, is also an interpreted language. Node.js is a server side js language. Global objects Array Boolean Date Function Math Number Object RegExp String Array 123var array &#x3D; [];array[0] &#x3D; &#39;abc&#39;;array.push(&#39;abc&#39;); Array doesn’t have a fixed length, you can use index or ‘push’ method to add elements. Put cursor in form field that is empty. Document is a super global object. It is a DOM(document object model) 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;html&gt;&lt;head&gt;&lt;script&gt; function validate(f) &#123; if (f.email.value &#x3D;&#x3D; &quot;&quot;) &#123; alert(&quot;You must provide an email adddress.&quot;); return false; &#125; else if (f.password1.value &#x3D;&#x3D; &quot;&quot;) &#123; alert(&quot;You must provide a password.&quot;); return false; &#125; else if (f.password1.value !&#x3D; f.password2.value) &#123; alert(&quot;You must provide the same password twice.&quot;); return false; &#125; else if (!f.agreement.checked) &#123; alert(&quot;You must agree to our terms and conditions.&quot;); return false; &#125; return true; &#125;&lt;&#x2F;script&gt;&lt;title&gt;&lt;&#x2F;title&gt;&lt;&#x2F;head&gt;&lt;body&gt;&lt;form action&#x3D;&quot;process.php&quot; method&#x3D;&quot;get&quot; name&#x3D;&quot;registration&quot; onsubmit&#x3D;&quot;return validate(this);&quot;&gt; Email: &lt;input name&#x3D;&quot;email&quot; type&#x3D;&quot;text&quot;&gt; &lt;br&gt; Password: &lt;input name&#x3D;&quot;password1&quot; type&#x3D;&quot;password&quot;&gt; &lt;br&gt; Password (again): &lt;input name&#x3D;&quot;password2&quot; type&#x3D;&quot;password&quot;&gt; &lt;br&gt; I agree to the terms and conditions: &lt;input name&#x3D;&quot;agreement&quot; type&#x3D;&quot;checkbox&quot;&gt; &lt;br&gt;&lt;br&gt; &lt;input type&#x3D;&quot;submit&quot; value&#x3D;&quot;Submit&quot;&gt;&lt;&#x2F;form&gt;&lt;&#x2F;body&gt;&lt;&#x2F;html&gt; check the form fields values at client side using Javascript. validate(this), is passing ‘document.forms.registration’ to the function. Both client side and server side form validation and necessary. User’s can change js using tools like inspector console and bypass the client side validation. Regular Expressions Object 1234var obj &#x3D; &#123;&#125;;obj.key &#x3D; value;obj[&#39;key&#39;] &#x3D; value;var obj &#x3D; &#123;key: value&#125;; Event handlers onblur onchange onclick onfocus onkeydown onkeyup onload onmousedown onmouseup onmouseout onmouseover onresize onselect onsubmit Call a function as a reference 123456789101112131415161718192021222324&lt;html&gt; &lt;head&gt; &lt;script&gt; function blinker() &#123; var blinks &#x3D; document.getElementsByTagName(&quot;blink&quot;); for (var i &#x3D; 0; i &lt; blinks.length; i++) &#123; if (blinks[i].style.visibility &#x3D;&#x3D; &quot;hidden&quot;) blinks[i].style.visibility &#x3D; &quot;visible&quot;; else blinks[i].style.visibility &#x3D; &quot;hidden&quot;; &#125; &#125; window.setInterval(blinker, 500); &lt;&#x2F;script&gt; &lt;title&gt;&lt;&#x2F;title&gt; &lt;&#x2F;head&gt; &lt;body&gt; &lt;center&gt; &lt;blink&gt;&lt;h1&gt;hello, world&lt;&#x2F;h1&gt;&lt;&#x2F;blink&gt; &lt;&#x2F;center&gt; &lt;&#x2F;body&gt;&lt;&#x2F;html&gt; Notice in the code above, when we call the blinker function in window.setInterval(blinker, 500), we are not adding () at the end of the function name. This is because we are passing a reference of that function(blinker) to it. If we use window.setInterval(blinker(), 500), we are passing the return result of blinker function to it, which will not work because blinker function doesn’t return anything. Anonymous function(lambda function) window.setInterval(function() { alert(“HI”); }, 5000); Javascript code can be minimized to save traffic. Variable names and spaces will be shrinked. Chapter 7: AJAX XML and json and data transfer machanism, json tends to be much more popular thesedays XMLHttpRequest abort() getAllResponseHeaders() getResponseHeader() open(method, url) open(method, url, async) open(method, url, async, user) open(method, url, async, user, password) send() send(data) setRequestHeader(header, value) XMLHttpRequest properties onreadystatechange readyState(0 unitialized, 1 open, 2 sent, 3 receiving, 4 loaded) responseBody responseText responseXML status(200 OK, 404 Not Found, 500 Internal Server Error) statusText 1234567891011121314151617181920212223242526272829303132333435363738function handler() &#123; &#x2F;&#x2F; only handle requests in &quot;loaded&quot; state if (xhr.readyState &#x3D;&#x3D; 4) &#123; if (xhr.status &#x3D;&#x3D; 200) &#123; &#x2F;&#x2F; get XML var xml &#x3D; xhr.responseXML; &#x2F;&#x2F; update price var prices &#x3D; xml.getElementsByTagName(&quot;price&quot;); if (prices.length &#x3D;&#x3D; 1) &#123; var price &#x3D; prices[0].firstChild.nodeValue; document.getElementById(&quot;price&quot;).innerHTML &#x3D; price; &#125; &#x2F;&#x2F; update low var lows &#x3D; xml.getElementsByTagName(&quot;low&quot;); if (lows.length &#x3D;&#x3D; 1) &#123; var low &#x3D; lows[0].firstChild.nodeValue; document.getElementById(&quot;low&quot;).innerHTML &#x3D; low; &#125; &#x2F;&#x2F; update high var highs &#x3D; xml.getElementsByTagName(&quot;high&quot;); if (highs.length &#x3D;&#x3D; 1) &#123; var high &#x3D; highs[0].firstChild.nodeValue; document.getElementById(&quot;high&quot;).innerHTML &#x3D; high; &#125; &#125; else alert(&quot;Error with Ajax call!&quot;); &#125; &#125; if PHP return data as XML type, ajax has a function called responseXML, but it is not very easy to get the data you want. Because XML data structure is quite complex. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879&lt;html&gt; &lt;head&gt; &lt;script&gt; &#x2F;&#x2F; an XMLHttpRequest var xhr &#x3D; null; &#x2F;* * void * quote() * * Gets a quote. *&#x2F; function quote() &#123; &#x2F;&#x2F; instantiate XMLHttpRequest object try &#123; xhr &#x3D; new XMLHttpRequest(); &#125; catch (e) &#123; xhr &#x3D; new ActiveXObject(&quot;Microsoft.XMLHTTP&quot;); &#125; &#x2F;&#x2F; handle old browsers if (xhr &#x3D;&#x3D; null) &#123; alert(&quot;Ajax not supported by your browser!&quot;); return; &#125; &#x2F;&#x2F; get symbol var symbol &#x3D; document.getElementById(&quot;symbol&quot;).value; &#x2F;&#x2F; construct URL var url &#x3D; &quot;quote7.php?symbol&#x3D;&quot; + symbol; &#x2F;&#x2F; get quote xhr.onreadystatechange &#x3D; function() &#123; &#x2F;&#x2F; only handle loaded requests if (xhr.readyState &#x3D;&#x3D; 4) &#123; if (xhr.status &#x3D;&#x3D; 200) &#123; &#x2F;&#x2F; evaluate JSON var quote &#x3D; eval(&quot;(&quot; + xhr.responseText + &quot;)&quot;); &#x2F;&#x2F; show JSON in textarea document.getElementById(&quot;code&quot;).value &#x3D; xhr.responseText; &#x2F;&#x2F; insert quote into DOM var div &#x3D; document.createElement(&quot;div&quot;); var text &#x3D; document.createTextNode(symbol + &quot;: &quot; + quote.price); div.appendChild(text); document.getElementById(&quot;quotes&quot;).appendChild(div); &#125; else alert(&quot;Error with Ajax call!&quot;); &#125; &#125; xhr.open(&quot;GET&quot;, url, true); xhr.send(null); &#125; &lt;&#x2F;script&gt; &lt;title&gt;&lt;&#x2F;title&gt; &lt;&#x2F;head&gt; &lt;body&gt; &lt;form onsubmit&#x3D;&quot;quote(); return false;&quot;&gt; Symbol: &lt;input id&#x3D;&quot;symbol&quot; type&#x3D;&quot;text&quot;&gt; &lt;br&gt;&lt;br&gt; &lt;input type&#x3D;&quot;submit&quot; value&#x3D;&quot;Get Quote&quot;&gt; &lt;&#x2F;form&gt; &lt;br&gt;&lt;br&gt; &lt;div id&#x3D;&quot;quotes&quot;&gt;&lt;&#x2F;div&gt; &lt;br&gt;&lt;br&gt; &lt;textarea cols&#x3D;&quot;80&quot; id&#x3D;&quot;code&quot; rows&#x3D;&quot;16&quot;&gt;&lt;&#x2F;textarea&gt; &lt;&#x2F;body&gt;&lt;&#x2F;html&gt; Encode ajax response to json and return to js as an object. json_encode is a PHP function that convert data into json string. ‘eval’ is a js function that convert json data into js object. 12345678910111213141516$(document).ready(function() &#123; $(&quot;#form&quot;).submit(function() &#123; $.ajax(&#123; url: &quot;quote7.php&quot;, data: &#123; symbol: $(&quot;#symbol&quot;).val() &#125;, success: function(data) &#123; $(&quot;#price&quot;).html(data.price); $(&quot;#high&quot;).html(data.high); $(&quot;#low&quot;).html(data.low); &#125; &#125;); return false; &#125;);&#125;); Another even cleaner example is to using jQuery. Dollar sign $ is short for ‘jQuery’. $(&quot;#form&quot;) is equals to jQuery(&quot;#form&quot;) jQuery is a library that provides more functionality to your code. $(document) is passing document to the jQuery library so you can use the extra features that jQuery provides. .ready is to make sure the whole html page is being loaded correctly. Because some of the code in ready function may require html elements. .ajax function takes one argument, which is in the parentheses, the argument is an object. JS only has two data structures, array and object, which represented by [] and {} respectively. the object in .ajax function has three keys, url, data and success. url takes a string, which is the url we will go to. data takes an object, which is the data we send. success takes an anonymous function, it is only being called when ajax request is success.(state is ready and response code is 200) the anonymous function after the .submit event handler return false because we don’t want to submit the form again, we already got the data from the ajax call. Content Types Specify the data type of the current file. HTML (text/html) (default) XML (text/XML) JSON (application/json) PHP + JSON json_encode($value): convert data to json on server side to be ready to send eval(string): convert data from json to object so we can access it on the client side Same Origin Policy We are not allowed to display data we get from another domain. We can make ajax call at JS and get response, but we cannot display it. You cannot embed it into your DOM. CORS can override this. Chapter 8: Security Obvious Threats Telnet, FTP, HTTP, MySQL suPHP, all users can only access to their own files. No one can delete or modify your files. Session Hijacking(scenarios) Physical Access Packet Sniffing: For website not using HTTPS Session Fixation: Guess the session ID XSS: Cross site scripting attack SSL Certificate Public key Cryptography There is a public key and a private key. Imagine we want to buy something from a website. Before we sending credit card information to the website. The website will send me the public key(can be see by everyone). And we are going to use the public key to encrypt the information. Only the private key can be used to decrypt the information. And only the website has the private key. Likewise, if the website wants to send me some information. I need to send it the public key too. And use my private key to decrypt it when I receive the information. SQL injection attacks mysql_real_escape_string(): put backslash to quote etc… Same-Origin Policy: You can only get data from the same origin as your HTML DOM. (ajax calls) CORS can override same origin policy, jsonp Attacks CSRF (Cross-site scripting forgery): If you login to some stock trade website recently and saved your login session. And you visited the bad website in the meantime and being tricked to click the link in their website. The link is actually a request and will send a request to the stock trade website to buy some stock. Note: User click a link could send both GET/POST request. Forms can be hidden and submitted by JS code. So just change the buying request to POST request doesn’t solve this issue. 1.The way to prevent this is whenever you want to send a request, the website will send a random session token back to you. And you have to add this token in the request to be able to make the request work. The CSRF link will never know what the token is. 2.CAPTCHA: enter some words that easy for human to see but not for machine. 3.Whenever you want to checkout, the website will make you log out immediately when you click the checkout button. XSS You can access to the Cookie from JS And there is a flawed website which writing values to its body, and you can be tricked to click the link and send your Cookie to other people. An attacker can use XSS to send a malicious script to an unsuspecting user. The end user’s browser has no way to know that the script should not be trusted, and will execute the script. Because it thinks the script came from a trusted source, the malicious script can access any cookies, session tokens, or other sensitive information retained by the browser and used with that site. Escape HTML special chars Chapter 9: Scalability Vertical Scaling 增加服务器的CPU，内存，硬盘等，但总会不够用 CPU: cores, L2 cache… Disk: PATA, SATA, SAS, RAID RAID(Redundent array of independent disks) RAID 0 :如果你有n块磁盘，原来只能同时写一块磁盘，写满了再下一块，做了RAID 0之后，n块可以同时写，速度提升很快，但由于没有备份，可靠性很差。n最少为2。 RAID 1: 正因为RAID 0太不可靠，所以衍生出了RAID1。如果你有n块磁盘，把其中n/2块磁盘作为镜像磁盘，在往其中一块磁盘写入数据时，也同时往另一块写数据。坏了其中一块时，镜像磁盘自动顶上，可靠性最佳，但空间利用率太低。n最少为2。 RAID 10: 是RAID 0 和RAID 1 的结合，同时写入n/2的硬盘并将剩下n/2作为备份，可靠性和速度都有，但是需要两倍的钱。 RAID 3：为了说明白RAID 5，先说RAID 3.RAID 3是若你有n块盘，其中1块盘作为校验盘，剩余n-1块盘相当于作RAID 0同时读写，当其中一块盘坏掉时，可以通过校验码还原出坏掉盘的原始数据。这个校验方式比较特别，奇偶检验，1 XOR 0 XOR 1=0，0 XOR 1 XOR 0=1，最后的数据时校验数据，当中间缺了一个数据时，可以通过其他盘的数据和校验数据推算出来。但是这有个问题，由于n-1块盘做了RAID 0，每一次读写都要牵动所有盘来为它服务，而且万一校验盘坏掉就完蛋了。最多允许坏一块盘。n最少为3. RAID 5：在RAID 3的基础上有所区别，同样是相当于是1块盘的大小作为校验盘，n-1块盘的大小作为数据盘，但校验码分布在各个磁盘中，不是单独的一块磁盘，也就是分布式校验盘，这样做好处多多。最多坏一块盘。n最少为3. RAID 6：在RAID 5的基础上，又增加了一种校验码，和解方程似的，一种校验码一个方程，最多有两个未知数，也就是最多坏两块盘。 RAM Horizontal Scaling 增加更多的服务器，而不是提升每个服务器的配置。当我们拥有多于一个服务器时，当用户向服务器发送请求时，我们要一个load balancer去将进来的request平均分配给所有的服务器。load balancer拥有一个public IP。而每一个服务器有一个private IP，他们不需要public IP Load Balancing 如何给服务器平均分配request？我们可以将所有可用的服务器IP列出来，第一个request给第一个服务器，第二个request给第二个服务器，以此类推直到回到第一个，然后循环，这种方法叫做round-robin，优点是他不需要主动询问服务器的当前状态如何 Caching 当用户通过load balancer登录到一号服务器时，他的登录信息如果保存在一号服务器，那么在他下一个request被分配到其他服务器时，他就需要再次登录，如果他在使用一个购物网站，他将一件商品加入到一号服务器的购物车中，然后又在二号服务器登录却找不到他的购物车，也不能结帐，这就会成为一个大问题 Shared Session State(Sticky session) 我们可以将session，也就是用户信息储存在另外一个服务器中 Shared Storage FC (Fiber Channel), iSCSI, MySQL, NFS Replicate your database, use more than one database to store sessions in case one goes down Cookie 当用户首次登陆时，load balancer可以想用户电脑中加入一个cookie，包含一些加密的服务器信息，所以当用户在短时间内再次访问时，load balancer就知道该将用户的请求发送到哪个服务器 Load Balancer Software: ELB(Amazon’s Elastic Load Balancer), HAProxy(High Availability Proxy), LVS(Linux Virtual Server) Hardware: Barracuda, Cisco, Citrix, F5 PHP Accelerators 当我们在调用python程序时，我们需要先将以py结尾的代码文件编译成可直接执行的文件，然后再运行可执行文件得到结果。这样做的目的是当我们想再次得到结果时，我们不需要再次编译，可以直接运行执行文件。 这样做可以提升效率，但是如果我们有任何的代码改动，我们就需要重新编译。 PHP Accelerators有一样的逻辑，用户在发送相同的请求时，网站会直接运行可执行文件以提升速度 Caching .html Caching就是一种将你经常访问的数据提前保存到你的电脑上以便下次快速显示的技术。对于PHP来说，HTML网页是自动生成的，意味着每次用户访问时PHP都会重新生成一个新的重复的HTML文件。 如果我们将所有的HTML网页都事先编译好储存在服务器上，用户访问时就可以快速拿到这些静态网页，因为不需要每次都进行编译。这就是一种Caching 这样做的坏处是，当你需要更改整个网站的风格时，你就需要更改所有的HTML文件。 MySQL Query Cache：MySQL会将一些query的结果caching，第一次运行时如果你的table很大，或者你要找的column没有index，他会运行一段时间，但是下次你就会更快的看到结果 memcached memory cache， 内存的读写要比硬盘快很多，所以我们如果有一百万个用户，服务器SQL拿到一个用户数据可能会需要很长时间，我们可以将这个用户数据保存在memory里面，下次就可以快速得到 下面是PHP将用户数据保存到memcache的代码 12345678910$memcache &#x3D; memchache_connect(HOST, PORT);$user &#x3D; memcache_get($memcache, $id);&#x2F;&#x2F; 如果内存里面没有这个用户的id，我们就从数据库中拿取，之后把他添加到内存中if (is_null($user))&#123; $bdh &#x3D; new PDO(DSN, USER, PASS; $result &#x3D; $dbh-&gt;query(&quot;SELECT * FROM users WHERE id &#x3D; $id&quot;); $user &#x3D; $result-&gt;fetch(PDO:FETCH_ASSOC); &#x2F;&#x2F; this is to get the associated array of data(username, email address,...) memcache_set($memcache, $user[&#39;id&#39;], $user)&#125; 如果我们一直将数据添加到内存中，内存总有一天会不够用，这时我们就需要删除一些数据来释放空间，我们可以删除最早的数据（LRU， Least Recent Used）或者最少用到的数据(LFU, Least Frequent Used) Data Replication: Master: slave 主从关系的服务器复制，所有的附属服务器要从主服务器中拿取数据，要将新数据写入主服务器，一切以主服务器为准，优点在于当主服务器down机时，我们可以自动化一个过程：因为所有服务器的数据都是一样的，我们可以将一个附属服务器晋升为新的主服务器。以保证服务不间断 适用于读多于写的网站，所有的读取都去附属服务器，所有的写入都去主服务器 缺点是当主服务器down机时，写入会短暂失效一段时间直到其中一个附属服务器成为新的主服务器 Data Replication: Master: Master - 当其中一个主服务器失效时，我们还有另外一个，从而保证不会有服务间断的时间.同样，读取请求发送到附属服务器，写入发送到主服务器 上面的图片还是有一个缺点，就是如果load balancer失效了，整个服务还是会断开。所以我们需要有两个相同作用的load balancer Load Balancer: active: active 每个load balancer都负责分配任务，并且他们会不断的每个一段时间向另一个load balancer发送一个heart beat，以证明自己的存在。如果任何一个load balancer没有收到另一个的心跳，他就将负责所有的流量 Load Balancer: active: passive 与之前相似，只不过一开始只有一个load balancer负责所有的流量，并且向passive的load balancer发送心跳，如果passive load balancer没有接收到心跳，他就把自己提升为active load balancer，并开始负责所有的任务。 Partitioning 将整个服务系统复制，供多个不同的客户使用，Facebook早期将不同学校的用户分到不同的服务器中，类似于harvard.facebook.com, MIT.facebook.com,以此来降低流量的压力。这样的话当你想联系不同大学的人时，就会有些困难。另外一个例子是我们可以将用户分配到不同的服务器中based on他们的名字，A-M到第一个，N-Z到第二个 High Availiability 不同的服务器之间互相听取对方的心跳，并随时准备take over当另外的服务器offline 网络层和web server层之间需要load balancer web server层和DB层之间也需要load balancer，load balancer会将第一个返回的DB的信息加到Cookie中返回给用户，这样用户在Cookie过期之前都会被route到同一个服务器, 这样就保证用户不会被分配到另一个服务器里面却没有他最新的数据，服务器之间也会相互同步。 每一层之间的load balancer也需要多个以保证一个offlice不会影响全局。可以使用active active或者active passive， DB也需要多个，可以是Master Master或者Master Slave. 最后就是这样的一个Data center也需要多个，就像AWS一样在US， Aisa， Europe都会有服务器。 Security 什么样的traffic可以进入data center？TCP 80和443 什么样的traffic可以从load balancer到web server？TCP 80. 我们可以在load balancer中加入证书并解密所有的traffic，然后之后的所有traffic都保持不加密的状态，因为我们已经进入到data center，不需要在担心安全问题，所以让load balancer去做揭秘这样的繁重工作，web server只负责应付无秘traffic 什么样的traffic从web server到DB？一般的SQL queries 也是 TCP 3306（port number 3306 is the default number SQL query uses） 注意web server之间并不能交流。 我们之所以设置这些规则，只让这些port的traffic进入，是因为加如其中一个web server被攻占了，那么它也只能向DB发送SQL请求，不能向其他web server发送443或者80请求，将破坏控制在最小。 Reference S75 (Summer 2012) Lecture 9 Scalability Harvard Web Development David Malan","categories":[],"tags":[{"name":"Web Development","slug":"Web-Development","permalink":"http://hellcy.github.io/tags/Web-Development/"}]},{"title":"Data Structures Advanced","slug":"Data-Structures-Advanced","date":"2020-05-10T06:33:35.000Z","updated":"2021-05-24T07:27:02.658Z","comments":true,"path":"2020/05/10/Data-Structures-Advanced/","link":"","permalink":"http://hellcy.github.io/2020/05/10/Data-Structures-Advanced/","excerpt":"","text":"sliding window 123456789101112&#x2F;&#x2F;通过两层for循环改进算法for (i &#x3D; 0, i &lt; n; ++i) &#123; while (j &lt; n) &#123; if (满足条件) &#123; j++; 更新j状态 &#125; else if (不满足条件) &#123; break; &#125; &#125; &#x2F;&#x2F;更新i状态&#125; 在一维字符串或者数组中找到符合条件的字串 前向型指针题目 窗口类 remove nth node from end of list Minimum size subarray sum Longest substring without rapeating characters Minimum window substring Longest Substring with at most k distinct characters Longest Repeating Character Replacement Longest Turbulent subarray 快慢类 find the middle of the linked list linked list cycle 1 and 2 优化类型 优化思想通过两层for循环而来 外层指针依然是一次遍历 内层指针证明是否需要退回 two pointers题型分类 前向型 窗口型 快慢型 相向型 两个数组 第k大或者第k小问题 Union Find 并查集 一种用来解决集合查询合并的数据结构 支持O(1) find and O(1) union，O(n) space 检查两个元素是否属于同一集合 合并两个集合，将root node指向另一个root node 可以使用array或者哈希表实现Union find 查找 find O(n) time 123456public int find(int x) &#123; if (father[x] &#x3D;&#x3D; x) &#123; return x; &#125; return find(father[x]);&#125; 合并 union, O(n) time, 之合并两个root nodes，不管child nodes 12345678public void union(int a, int b) &#123; int root_a &#x3D; find(a); int root_b &#x3D; find(b); &#x2F;&#x2F; 如果两个root nodes已经相等，则两个集合已经合并，不需要再操作 if (root_a !&#x3D; root_b) &#123; father[root_a] &#x3D; root_b; &#x2F;&#x2F; 将root_a指向root_b &#125;&#125; 路径压缩：将find和union的时间复杂度变成O(1) 在查找元素的father的时候，第一次需要O(n)的时间，但是当找到最终的father时，将每一个路径中的father都更新成最终的father，以后在查找路径中的father就只需要O(1) 123456public int find(int x) &#123; if (father[x] &#x3D;&#x3D; x) &#123; return x; &#125; return father[x] &#x3D; find(father[x]); &#x2F;&#x2F; 将当前点的father更新为最终father&#125; Connecting graph 3 Connecting cities with minimum costs Number of Operations to Make Network Connected The Earliest Moment When Everyone Become Friends Lexicographically Smallest Equivalent String Number of Islands II Union find问题总结 原生操作 查询两个元素是否在用一个集合内。 合并两个元素所在的集合 派生操作 查询某个元素所在集合的元素个数。 查询当前集合的个数 Trie 常见考点 Trie直接实现 利用Trie前缀特性解题 矩阵类里面，字符串一个一个字符，深度优先遍历的问题 Trie和Hash拥有相同的时间复杂度，但是Trie的空间复杂度更小 Implement Trie Add and search word word search 2 -&gt; Trie + DFS Heap Trapping rain water 2 怎么通过Trapping rain water 1拓展到这道题的思路 怎么样想到利用heap？ 怎么想到由外向内遍历？ Find Median from Data Stream Sliding Window Median","categories":[],"tags":[{"name":"Data Structures","slug":"Data-Structures","permalink":"http://hellcy.github.io/tags/Data-Structures/"}]},{"title":"Think Python","slug":"Think-Python","date":"2020-04-03T03:18:28.000Z","updated":"2021-05-24T07:27:02.660Z","comments":true,"path":"2020/04/03/Think-Python/","link":"","permalink":"http://hellcy.github.io/2020/04/03/Think-Python/","excerpt":"","text":"Chapter 1: The First Program Chapter 2: Variables, expressions and statements Chapter 3: Functions Chapter 4: Conditionals and recursion Chapter 5: Fruitful functions Chapter 6: Iteration Chapter 7: Strings Chapter 8: Lists Chapter 9: Dictionaries Chapter 10: Tuples Chapter 1: The First Program Python interpreter Type python in the command line to start interpreter 1234Python 3.4.0 (default, Jun 19 2015, 14:20:21)[GCC 4.8.2] on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; The first three lines contain information about the interpreter and the operating system it’s running on, so it might be different for you. But you should check that the version number, which is 3.4.0 in this example, begins with 3, which indicates that you are running Python 3. If it begins with 2, you are running (you guessed it) Python 2. The last line is a prompt that indicates that the interpreter is ready for you to enter pre. If you type a line of pre and hit Enter, the interpreter displays the result: 12&gt;&gt;&gt; 1 + 12 Basic Arthmetic 123456&gt;&gt;&gt; 40 + 242&gt;&gt;&gt; 43 - 142&gt;&gt;&gt; 6 * 742 The operator / performs division: 12&gt;&gt;&gt; 84 &#x2F; 242.0 You might wonder why the result is 42.0 instead of 42. I’ll explain in the next section. Finally, the operator ** performs exponentiation; that is, it raises a number to a power: 12&gt;&gt;&gt; 6**2 + 642 In some other languages, ^ is used for exponentiation, but in Python it is a bitwise operator called XOR. If you are not familiar with bitwise operators, the result will surprise you: 12&gt;&gt;&gt; 6 ^ 24 Values and Types If you are not sure what type a value has, the interpreter can tell you: 123456&gt;&gt;&gt; type(2)&lt; class &#39;int&#39;&gt;&gt;&gt;&gt; type(42.0)&lt; class &#39;float&#39;&gt;&gt;&gt;&gt; type(&#39;Hello, World!&#39;)&lt; class &#39;str&#39;&gt; Chapter 2: Variables, Expressions and Statements Statement An assignment statement creates a new variable and gives it a value: 123&gt;&gt;&gt; message &#x3D; &#39;And now for something completely different&#39;&gt;&gt;&gt; n &#x3D; 17&gt;&gt;&gt; pi &#x3D; 3.1415926535897932 Expressions An expression is a combination of values, variables, and operators. A value all by itself is considered an expression, and so is a variable, so the following are all legal expressions: 123456&gt;&gt;&gt; 4242&gt;&gt;&gt; n17&gt;&gt;&gt; n + 2542 When you type an expression at the prompt, the interpreter evaluates it, which means that it finds the value of the expression. In this example, n has the value 17 and n + 25 has the value 42. A statement is a unit of pre that has an effect, like creating a variable or displaying a value. Order of operations Parentheses have the highest precedence and can be used to force an expression to evaluate in the order you want. Since expressions in parentheses are evaluated first, 2 * (3-1) is 4, and (1+1)**(5-2) is 8. You can also use parentheses to make an expression easier to read, as in (minute * 100) / 60, even if it doesn’t change the result. Exponentiation has the next highest precedence, so 1 + 2**3 is 9, not 27, and 2 * 3**2 is 18, not 36. Multiplication and Division have higher precedence than Addition and Subtraction. So 2*3-1 is 5, not 4, and 6+4/2 is 8, not 5. Operators with the same precedence are evaluated from left to right (except exponentiation). So in the expression degrees / 2 * pi, the division happens first and the result is multiplied by pi. To divide by 2π, you can use parentheses or write degrees / 2 / pi. Comments comments, and they start with the # symbol. “”“fdsfsdfsd”&quot;&quot; for multiple lines of comments Chapter 3: Functions In the context of programming, a function is a named sequence of statements that performs a computation. When you define a function, you specify the name and the sequence of statements. Later, you can “call” the function by name. It is common to say that a function “takes” an argument and “returns” a result. The result is also called the return value. Python has a math module that provides most of the familiar mathematical functions. A module is a file that contains a collection of related functions. Before we can use the functions in a module, we have to import it with an import statement: 1&gt;&gt;&gt;&gt; import math Adding new functions So far, we have only been using the functions that come with Python, but it is also possible to add new functions. A function definition specifies the name of a new function and the sequence of statements that run when the function is called. 123def print_lyrics(): print(&quot;I&#39;m a lumberjack, and I&#39;m okay.&quot;) print(&quot;I sleep all night and I work all day.&quot;) The first line of the function definition is called the header; the rest is called the body. The header has to end with a colon and the body has to be indented. By convention, indentation is always four spaces. The body can contain any number of statements. A function can be inside another function Parameters and arguments Some of the functions we have seen require arguments. For example, when you call math.sin you pass a number as an argument. Some functions take more than one argument: math.pow takes two, the base and the exponent When you create a variable inside a function, it is local, which means that it only exists inside the function Encapsulation Wrapping a piece of pre up in a function is called encapsulation. One of the benefits of encapsulation is that it attaches a name to the pre, which serves as a kind of documentation. Another advantage is that if you re-use the pre, it is more concise to call a function twice than to copy and paste the body! Chapter 4: Conditionals and recursion Floor divisions and modulus The floor division operator, //, divides two numbers and rounds down to an integer e the modulus operator, %, which divides two numbers and returns the remainder Boolean expressions A boolean expression is an expression that is either true or false. The following examples use the operator ==, which compares two operands and produces True if they are equal and False otherwise: 1234&gt;&gt;&gt; 5 &#x3D;&#x3D; 5True&gt;&gt;&gt; 5 &#x3D;&#x3D; 6False Logical operators AND OR NOT Conditional execution 1234if x % 2 &#x3D;&#x3D; 0: print(&#39;x is even&#39;)else: print(&#39;x is odd&#39;) Chained conditions 123456if x &lt; y: print(&#39;x is less than y&#39;)elif x &gt; y: print(&#39;x is greater than y&#39;)else: print(&#39;x and y are equal&#39;) Recursion It is legal for one function to call another; it is also legal for a function to call itself. 123456def countdown(n): if n &lt;&#x3D; 0: print(&#39;Blastoff!&#39;) else: print(n) countdown(n-1) Keyboard input Python provides a built-in function called input that stops the program and waits for the user to type something. When the user presses Return or Enter, the program resumes and input returns what the user typed as a string 1234&gt;&gt;&gt; text &#x3D; input()What are you waiting for?&gt;&gt;&gt; text&#39;What are you waiting for?&#39; Chapter 5: Fruitful functions Functions that return a value 12345def absolute_value(x): if x &lt; 0: return -x else: return x Incremental development Start with a working program and make small incremental changes. At any point, if there is an error, you should have a good idea where it is. Chapter 6: Iteration The ability to run a block of statements repeatedly The while statement 12345def countdown(n): while n &gt; 0: print(n) n &#x3D; n - 1 print(&#39;Blastoff!&#39;) Determine whether the condition is true or false. If false, exit the while statement and continue execution at the next statement. If the condition is true, run the body and then go back to step 1. Break Sometimes you don’t know it’s time to end a loop until you get half way through the body. In that case you can use the break statement to jump out of the loop 123456while True: line &#x3D; input(&#39;&gt; &#39;) if line &#x3D;&#x3D; &#39;done&#39;: break print(line)print(&#39;Done!&#39;) Chapter 7: Strings Strings are not like integers, floats, and booleans. A string is a sequence of characters, which means it is an ordered collection of other values. In this chapter you’ll see how to access the characters that make up a string, and you’ll learn about some of the methods strings provide 123456&gt;&gt;&gt; fruit &#x3D; &#39;banana&#39;&gt;&gt;&gt; letter &#x3D; fruit[1]&gt;&gt;&gt; letter&#39;a&#39;&gt;&gt;&gt; len(fruit)6 Traversal with a for loop A lot of computations involve processing a string one character at a time. Often they start at the beginning, select each character in turn, do something to it, and continue until the end. This pattern of processing is called a traversal. One way to write a traversal is with a while loop: 12345index &#x3D; 0while index &lt; len(fruit): letter &#x3D; fruit[index] print(letter) index &#x3D; index + 1 another way to traverse is to use a for loop 12for letter in fruit: print(letter) Strings slices A segment of a string is called a slice. Selecting a slice is similar to selecting a character: 12345&gt;&gt;&gt; s &#x3D; &#39;Monty Python&#39;&gt;&gt;&gt; s[0:5]&#39;Monty&#39;&gt;&gt;&gt; s[6:12]&#39;Python&#39; The operator [n:m] returns the part of the string from the “n-eth” character to the “m-eth” character, including the first but excluding the last If you omit the first index (before the colon), the slice starts at the beginning of the string. If you omit the second index, the slice goes to the end of the string: 12345678&gt;&gt;&gt; fruit &#x3D; &#39;banana&#39;&gt;&gt;&gt; fruit[:3]&#39;ban&#39;&gt;&gt;&gt; fruit[3:]&#39;ana&#39;&gt;&gt;&gt; fruit &#x3D; &#39;banana&#39;&gt;&gt;&gt; fruit[3:3]&#39;&#39; Strings are immutable 123&gt;&gt;&gt; greeting &#x3D; &#39;Hello, world!&#39;&gt;&gt;&gt; greeting[0] &#x3D; &#39;J&#39;TypeError: &#39;str&#39; object does not support item assignment The in operator The word in is a boolean operator that takes two strings and returns True if the first appears as a substring in the second: 1234&gt;&gt;&gt; &#39;a&#39; in &#39;banana&#39;True&gt;&gt;&gt; &#39;seed&#39; in &#39;banana&#39;False String comparison Upper case letters come before lower case letters, we can use &gt; or &lt; or == to compare strings Chapter 8: Lists List is a sequence Like a string, a list is a sequence of values. In a string, the values are characters; in a list, they can be any type. The values in a list are called elements or sometimes items. There are several ways to create a new list; the simplest is to enclose the elements in square brackets ([ and ]): The elements of a list don’t have to be the same type. 12345&gt;&gt;&gt; cheeses &#x3D; [&#39;Cheddar&#39;, &#39;Edam&#39;, &#39;Gouda&#39;]&gt;&gt;&gt; numbers &#x3D; [42, 123]&gt;&gt;&gt; empty &#x3D; []&gt;&gt;&gt; print(cheeses, numbers, empty)[&#39;Cheddar&#39;, &#39;Edam&#39;, &#39;Gouda&#39;] [42, 123] [] Lists are mutable 1234&gt;&gt;&gt; numbers &#x3D; [42, 123]&gt;&gt;&gt; numbers[1] &#x3D; 5&gt;&gt;&gt; numbers[42, 5] Traversing a list 12for i in range(len(numbers)): numbers[i] &#x3D; numbers[i] * 2 List operations 123456789&gt;&gt;&gt; a &#x3D; [1, 2, 3]&gt;&gt;&gt; b &#x3D; [4, 5, 6]&gt;&gt;&gt; c &#x3D; a + b&gt;&gt;&gt; c[1, 2, 3, 4, 5, 6]&gt;&gt;&gt; [0] * 4[0, 0, 0, 0]&gt;&gt;&gt; [1, 2, 3] * 3[1, 2, 3, 1, 2, 3, 1, 2, 3] List slices 1234567&gt;&gt;&gt; t &#x3D; [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;]&gt;&gt;&gt; t[1:3][&#39;b&#39;, &#39;c&#39;]&gt;&gt;&gt; t[:4][&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;]&gt;&gt;&gt; t[3:][&#39;d&#39;, &#39;e&#39;, &#39;f&#39;] List methods append adds a new element to the end of a list: extend takes a list as an argument and appends all of the elements: sort arranges the elements of the list from low to high: 12345678910111213&gt;&gt;&gt; t &#x3D; [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]&gt;&gt;&gt; t.append(&#39;d&#39;)&gt;&gt;&gt; t[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;]&gt;&gt;&gt; t1 &#x3D; [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]&gt;&gt;&gt; t2 &#x3D; [&#39;d&#39;, &#39;e&#39;]&gt;&gt;&gt; t1.extend(t2)&gt;&gt;&gt; t1[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;]&gt;&gt;&gt; t &#x3D; [&#39;d&#39;, &#39;c&#39;, &#39;e&#39;, &#39;b&#39;, &#39;a&#39;]&gt;&gt;&gt; t.sort()&gt;&gt;&gt; t[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;] Deleting elements If you know the index of the element you want, you can use pop: pop modifies the list and returns the element that was removed. If you don’t provide an index, it deletes and returns the last element. 123456&gt;&gt;&gt; t &#x3D; [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]&gt;&gt;&gt; x &#x3D; t.pop(1)&gt;&gt;&gt; t[&#39;a&#39;, &#39;c&#39;]&gt;&gt;&gt; x&#39;b&#39; If you don’t need the removed value, you can use the del operator: 1234&gt;&gt;&gt; t &#x3D; [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]&gt;&gt;&gt; del t[1]&gt;&gt;&gt; t[&#39;a&#39;, &#39;c&#39;] If you know the element you want to remove (but not the index), you can use remove: 1234&gt;&gt;&gt; t &#x3D; [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]&gt;&gt;&gt; t.remove(&#39;b&#39;)&gt;&gt;&gt; t[&#39;a&#39;, &#39;c&#39;] Objects and values In one case, a and b refer to two different objects that have the same value. In the second case, they refer to the same object. 12345678910&gt;&gt;&gt; a &#x3D; &quot;word1&quot;&gt;&gt;&gt; b &#x3D; &quot;word1&quot;&gt;&gt;&gt; a is bTrue&gt;&gt;&gt; a &#x3D; [1,2,3]&gt;&gt;&gt; b &#x3D; [1,2,3]&gt;&gt;&gt; a is bFalse&gt;&gt;&gt; a &#x3D;&#x3D; bTrue Aliasing If a refers to an object and you assign b = a, then both variables refer to the same object, even for a list Its also called shallow copy 1234&gt;&gt;&gt; a &#x3D; [1, 2, 3]&gt;&gt;&gt; b &#x3D; a&gt;&gt;&gt; b is aTrue For objects that may take lots of memory space, the program will prefer to only make a reference to its original object when you create another variable to points to it. List arguments When you pass a list to a function, the function gets a reference to the list. If the function modifies the list, the caller sees the change. 1234567def delete_head(t): del t[0]&gt;&gt;&gt; letters &#x3D; [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]&gt;&gt;&gt; delete_head(letters)&gt;&gt;&gt; letters[&#39;b&#39;, &#39;c&#39;] Chapter 9: Dictionaries A dictionary contains a collection of indices, which are called keys, and a collection of values. Each key is associated with a single value. The association of a key and a value is called a key-value pair or sometimes an item The function dict creates a new dictionary with no items. Because dict is the name of a built-in function, you should avoid using it as a variable name 123456&gt;&gt;&gt; eng2sp &#x3D; dict()&gt;&gt;&gt; eng2sp&#123;&#125;&gt;&gt;&gt; eng2sp[&#39;one&#39;] &#x3D; &#39;uno&#39; # add an item with key &#x3D; &#39;one&#39; and value &#x3D; &#39;uno&#39;&gt;&gt;&gt; eng2sp&#123;&#39;one&#39;: &#39;uno&#39;&#125; The order of the key-value pairs might not be the same. If you type the same example on your computer, you might get a different result. In general, the order of items in a dictionary is unpredictable. This is because when we insert items into the dictionary, it randomly put items into buckets, so it could be different everytime. (Hash) check whether a dictionary contains some key 1234&gt;&gt;&gt; &#39;one&#39; in eng2spTrue&gt;&gt;&gt; &#39;uno&#39; in eng2spFalse check whether a dictionary contains some value 123&gt;&gt;&gt; vals &#x3D; eng2sp.values()&gt;&gt;&gt; &#39;uno&#39; in valsTrue Python dictionaries use a data structure called a hashtable that has a remarkable property: the in operator takes about the same amount of time no matter how many items are in the dictionary. Instant lookup time! Dictionary as a collection of counters Suppose you are given a string and you want to count how many times each letter appears. There are several ways you could do it You could create 26 variables, one for each letter of the alphabet. Then you could traverse the string and, for each character, increment the corresponding counter, probably using a chained conditional. You could create a list with 26 elements. Then you could convert each character to a number (using the built-in function ord), use the number as an index into the list, and increment the appropriate counter. You could create a dictionary with characters as keys and counters as the corresponding values. The first time you see a character, you would add an item to the dictionary. After that you would increment the value of an existing item. An implementation is a way of performing a computation; some implementations are better than others. For example, an advantage of the dictionary implementation is that we don’t have to know ahead of time which letters appear in the string and we only have to make room for the letters that do appear. 12345678def histogram(s): d &#x3D; dict() for c in s: if c not in d: d[c] &#x3D; 1 else: d[c] +&#x3D; 1 return d Looping and dictionaries 123def print_hist(h): for c in h: print(c, h[c]) Given a dictionary d and a key k, it is easy to find the corresponding value v = d[k]. This operation is called a lookup. But what if you have v and you want to find k? You have two problems: first, there might be more than one key that maps to the value v. Depending on the application, you might be able to pick one, or you might have to make a list that contains all of them. Second, there is no simple syntax to do a reverse lookup; you have to search 12345def reverse_lookup(d, v): for k in d: if d[k] &#x3D;&#x3D; v: return k raise LookupError() Chapter 10: Tuples Tuples are immutable A tuple is a sequence of values. The values can be any type, and they are indexed by integers, so in that respect tuples are a lot like lists. The important difference is that tuples are immutable. 123&gt;&gt;&gt; t &#x3D; tuple()&gt;&gt;&gt; t() Most list operators also work on tuples. The bracket operator indexes an element: 1234567&gt;&gt;&gt; t &#x3D; (&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;)&gt;&gt;&gt; t[0]&#39;a&#39;&gt;&gt;&gt; t[1:3](&#39;b&#39;, &#39;c&#39;)&gt;&gt;&gt; t[0] &#x3D; &#39;A&#39;TypeError: object doesn&#39;t support item assignment Tuples and return values Strictly speaking, a function can only return one value, but if the value is a tuple, the effect is the same as returning multiple values. For example, if you want to divide two integers and compute the quotient and remainder, it is inefficient to compute x//y and then x%y. It is better to compute them both at the same time The built-in function divmod takes two arguments and returns a tuple of two values, the quotient and remainder. You can store the result as a tuple: 123&gt;&gt;&gt; t &#x3D; divmod(7, 3)&gt;&gt;&gt; t(2, 1)","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"http://hellcy.github.io/tags/Python/"}]},{"title":"Data Structures","slug":"Data-Structures","date":"2020-03-02T03:04:10.000Z","updated":"2021-05-24T07:27:02.658Z","comments":true,"path":"2020/03/02/Data-Structures/","link":"","permalink":"http://hellcy.github.io/2020/03/02/Data-Structures/","excerpt":"","text":"Bianry Search Use O(1) to make a T(n) problem T(n/2). So the total time complexity would be O(logn). Ignore half of the problems in O(1) time. First Bad Version Search in a Big Sorted Array. Double the search number every time, then serach from n to 2n Find Minimum in Rotated Sorted Array. Divide the array into a normal sorted array and a smaller rotated sorted array. Search in a 2D matrix. Perform Binary Search 2 times. First find the row, then perform binary search on that row. Search for a Range. Find the target number then perform binary search on its left and right. Maximum Number in Mountain Sequence. Check mid number to see if it is incresing or decresing, we can return any mountain value. Bianry Tree and Divide &amp; Conquer There are 3 ways to traverse a binary tree. Pre order, In order and post order You need to know both resursive version and iterative version. DFS includes pre order, in order, post order, divide &amp; conquer Bianry tree has height from O(logn) to O(n), traverse a binary tree takes O(n) time. In order traverse a binary search tree is an increasing order traverse. Maximum depth of Binary tree. Resursive: Divide and conquer/ traverse Subtree with Maximum Average Lowest Common Ancestor: Divide &amp; Conquer, check leftsubtree and rightsubtree. See if they return A or B or null Validate Binary Search Tree. Bottom up, return max and min return to the parent node. Convert Binary Search Tree to Doubly Linked List. Inorder traverse it into a list and convert it. Flattern Binary Tree to Linked List. node.right = head of left subtree, tail of left subtree = head of right subtree. Insert and delete a node from a Binary Search Tree BFS make a list and put all start nodes into the list traverse the list to get new nodes for the next level use Queue for BFS Graph BFS Social Network 六度理论 你和世界上任何一个人之间最多间隔6个人 Linkedin BFS看第几层有相同好友 树和图的区别，树是单向的，图可以是双向的（或者单项） 在遍历图中，会有环，可以用HashSet检查是否曾经访问过某个节点 树的特性，树中如果有N个点，就会有N-1条边。树中的所有点连通。用Queue和Set访问并保存所有Graph中的点 构造Graph， 可以用 Map&lt;Integer, Set&lt;Integer&gt;&gt; Graph其实就是保存着（每个点和与他相邻的点的Set）的Map BFS on a 2D-array Number of islands Wall and Gates 什么时候使用BFS？ Tree的层次遍历 2D-array中求连通性，灌水 拓扑排序 图的最短路径 DFS Recursion Combination Permutation Graph Non-Recursion 什么时候使用DFS？ 找所有方案，排列，组合 找最优方案（最短，最长）（大部分是动态规划，也有可能是DFS） Questions Combination sum Palindrome Partitioning 所有的切割问题都是组合问题 切割abc字符串，有两个切割位 a1b2c， 可以切ab之间也可以切bc之间，把数字12放入代表切割位，所以切割的方式有 a b c [1,2] a bc [1] ab c [2] abc [] 以上可以看出四种切割方式可以用数字表示 所以n个字母的切割问题可以看作是n - 1个数字的组合问题 Backtracking Permutation的去重与Combination相似，可以先定义一个boolean数组存放visited信息 N皇后 每一行和每一列都是1…n的一种排列 如何判断皇后在同一斜线上： 横坐标与纵坐标之差相等，或者横坐标与纵坐标之和相等 Word Ladder: BFS, 把ListWord转换成graph的形式，对于每个word，先找到所有可能的变换，总共有单词长度*26种，然后这些变换中存在于Wordlist中的就是他的neighbor，就可以变成标准的BFS问题 Word Ladder 2：Backtracking + BFS， 先从End往Begin做BFS找到每个单词距离End的长度，保证Backtrack时不会遍历更远的单词。再从Begin往End做backtracking Linked List and Array Reverse linked list Reverse linked list in k group Use dummy node to save the list head 画图去理解linked list的变化 dummy node practices partition-list merge two sorted list reverse linked list 2 swap two nodes in linked list reorder list rotate list Copy list with random pointer -&gt; similar to clone graph Linked List Cycle 1 and 2 -&gt; Floyd’s Tortoise and Hare Sort List -&gt; how many sort algorithm has time complexity O(nlogn)? Quick Sort, with O(1) Space Complexity Merge Sort, with O(n) space Heap Sort Merge two sorted array Merge small array into big array intersection of two arrays Median of two sorted arrays -&gt; find the (m + n) / 2th number, use O(logn) Median Kth largest element Merge Sort practice Quick Sort practice Same integers will not remain their relative order in the old list after using quick sort. Merge sort will keep the relative order of same integers Merge sort will first split the array into two subarray until there is only one number left in the array, then sort, then merge the two sorted array back to one array. From small array to big array Qucik sort will first pick a pivot value, sort the entire array based on the pivot value. Then sort the two small array. From big array two small array Note in Quick Sort, when we find a value equals to the pivot value, we don’t swap it, leave it as where it is. We need to split these values as even as possible. Quick sort while loop condition: while (left &lt;= right). Don’t forget the equal sign Subarray PrefixSum, HashMap to store prefixsum, then linear scan, So O(n) time and space Maximum subarray Minimum subarray subarray sum equals k number of subarray equals k Two pointers O(n) time complexity 同向双指针 Move zeros Remove duplicate number in array Remove duplicate numbers in sorted array -&gt; tortise and hare cycle detection 相向双指针 valid palindrome rotate string -&gt; three step reverse, when reverse a string, one start from begin and another start from end recover rotated sorted array -&gt; similar to above, find the rotate point, three step reverse. Two Sum 1-7 Two Sum 1 -&gt; 最普通的Two Sum， 可以使用HashMap，或者先排序在使用相向双指针，这样可以不是用额外空间，但是时间复杂度是O(nlogn) Two Sum 2 - Data Structure Design -&gt; HashMap Two Sum 3 - Array is sorted -&gt; 相向双指针 Two sum 7 - unique pairs -&gt; 找到所有符合的数对,相向双指针，当找到一对时，left++,right–,并继续。如果遇到重复比如1,1,3,4,4,每次我们移动时，移动到与之前的数不一样的数为止。注意此方法要求数组是有序的。 3Sum -&gt; 使用Two sum的结果，对于array中的每一个不等的数，检查是否有一对数的和等于它的相反数。可以使用HashMap或者two pointers，记住two pointers必须先排序数组。Two pointers的速度远快于HashMap Valid Triangle Number -&gt; 检查有多少组三个数可以组成合法的三角形的三条边。注意我们只需要检查最小的两个数的和大于第三个数即可. 从最大的数开始loop，使用Two pointers，对于每一个符合的left and right， 所有大于left的数都是符合的，所以每当我们找到一组合法的left and right，count += （right - left）. 详情查看leetcode 611 对于求2个变量如何组合的问题，可以循环其中一个变量，然后研究另外一个变量如何变化 对于求3个变量如何组合的问题，可以循环其中一个变量，然后研究另外2个变量如何变化 对于求4个变量如何组合的问题，可以循环其中两个变量，然后研究另外2个变量如何变化 Two Sum less than k Two Sum greater than k -&gt; same as triangle count Two Sum closest to target -&gt; two pointers start from begin and end, keep updating diff 3 Sum closest to target -&gt; similar to above, loop one value and use two sum as a template 4 Sum Two Sum - difference equals to target -&gt; 同向双指针。两数之差等于target，先排序，两个pointers都在开始，如果他们的差大于target，小数往后移，如果他们的差小于target，大数往后移 O(n) time complexity Partition array move elements &lt; k to the left and elements &gt;= k to the right, this is a smaller step in quick sort Parition array while loop condition: while (left &lt; right). No equal sign Letters by case Partition array by parity Interleaving positive and negative numbers -&gt; first count positive and negative numbers, then decide starts from positive or negative, then use two pointers in the same direction. Sort Colors sort 3 colors in group, we can use partition array two times, first time split one color, next split the rest two colors. We could also count the number of each color and modify the array to match the occurance of colors three pointers i pointer only moves when find ones and zeros, if it finds two, it will swap it with right. Throw two to the right so left pointer will never find two. so when i pointer finds zero, after swap it with left pointer, throw zero to the left, left pointer will only throw one back, so they can both move to right by 1 Sort Colors 2 (rainbow sort) -&gt; 使用多次Partition， 每次将一般的颜色分到array的左右，比如只有四种颜色，一次partition将1，2分到左边，3，4分到右边。花费O（n）的时间将T(k)的问题变成T(k/2)的问题。总共的时间复杂度为O(nlogk) 这个解法有点像Quick Sort。注意Quick sort and Rainbow sort的while loop条件均为 while(left &lt; right)。可以不用要等号 其他比较高频的排序方法： Pancake Sort Sleep Sort Spaghetti Sort Bogo Sort 3 Step Reverse Three step reverse Recover rotated sorted array -&gt; First use 3 step reverse then two pointer reverse. 3 step reverse First find the rotate point Reverse the first part(before rotate point) of the String/array Reverse the second part(after rotate point) of the String/array Reverse the entire String/array Quick Select Quick Select 快速选择算法 思想类似于快速排序,利用O(n)的时间找到前right个大数，再看k与right的关系决定下一步recursion的范围 O(n) + O(n/2) + O(n/4) +… = O(n) time kth largest element Median kth smallest element Median of two sorted arrays Hash &amp; Heap 了解他们的原理和应用 TreeMap 队列Queue 支持操作O(1) push O(1) pop O(1) top,多做跟BFS有关的题目 栈Stack 支持操作O(1) push O(1) pop O(1) top,非递归实现DFS的主要数据结构 哈希表Hash 支持操作O(1) insert O(1) find O(1) delete, Hash table / Hash map / Hash set的区别是什么 Hash Set只存key不存value Hash map存key和value Hash table，多线程安全，当多个线程同时访问一个Hash table时，它可以保证数据安全，Hash Map无法做到 Hash function -&gt; 对于任意的Key，得到一个固定且无规律的介于0到capacity - 1的整数 数据结构分为连续性和离散型，array为连续性，List为离散型 一些著名的Hash算法：MD5， SHA-1， SHA-2，主要用于加密 用于算法中的Hash function很想进制转换 12345678int hashfun(String key) &#123; int sum &#x3D; 0; for (int i &#x3D; 0; i &lt; key.length(); ++i) &#123; sum &#x3D; sum * 31 + (int)(key.charAt(i)); sum &#x3D; sum % HASH_TABLE_SIZE; &#125; return sum;&#125; Magic number - 31 通过经验得出31的冲突更少（Collision） Magic number取质数更好，如果数太大影响效率，数太小冲突太多 Closed Hashing - line sweep 当哈希表发生冲突时，把新的数据插入到下一个空的位置 寻找，不断的找下一个位置直到找到value或者找到空位为止 删除，把值删除后用一个deleted标记出来，这个位置并不为空 缺点，当我们插入和删除的次数很多时，很多位置都会被标记为deleted，寻找的效率会变低 Open Hashing 每一个位置都是一个链表，当发生冲突时加到链表的开头，这样不用每次都遍历到链表末尾，寻找时搜寻整个链表 Rehashing 当hash table size不够用了怎么办？ 像ArrayList那样不断倍增 怎么定义满？当实际的存储个数达到总共空间的1/10(经验值)时，我们就需要rehash 回顾ArrayList的倍增：当ArrayList满时，把size扩大两倍，把前面的所有数复制到后一半新扩大的ArrayList中 Hash Table的倍增：如果移动之前的数，会影响到hash function，所以我们会先扩大hash table， 再把hash table中的所有值重新放到hash function算出它在新的hash table中的位置，重新插入 Rehashing很慢，所以在定义hash table的时候最好提前定义一个size，让他尽量不要rehash 在存储快的和存储慢的介质之间都会存在Cache的问题，不仅在CPU和内存之间有 使用链表储存数据的的插入顺序，使用哈希表判断将要插入的数据是否已经存在于链表中 LinkedHashMap = DoublyLinkedList + HashMap LRU Cache -&gt; 使用HashMap + DoublyLinkedList可以解决 Heap 支持操作O(logn) add O(logn) remove O(1) MIN or MAX,求最大值或最小值只可取其一 ugly number 2 top k largest number 2 -&gt; 使用PriorityQueue只保存k个数 merge k sorted list -&gt; Add all list heads to a heap, poll the smallest head, add to ans, then add next node to heap. 注意要会写heap的comparator Practice high five k closest points data stream median kth smallest number in sorted matrix Dynamic Programming 动态规划的分类 Triangle -&gt; 入门题 注意以下代码中n为三角形的高度 第一种方法 DFS Traverse, Top-down 123456789101112131415void traverse(int x, int y, int sum) &#123; if (x &#x3D;&#x3D; n) &#123; &#x2F;&#x2F; found a whole path from top to bottom if (sum &lt; best) &#123; best &#x3D; sum; &#125; return; &#125; traverse(x + 1, y, sum + A[x][y]); traverse(x + 1, y + 1, sum + A[x][y]);&#125;best &#x3D; MAXINT;traverse(0, 0, 0); 每一个节点都分出来两条路径，相当于一个binary tree， 它的节点个数是2^n, 所以这个方法的时间复杂度是O(2^n) 第二种方法 DFS Divide and Conquer, bottom-up 123456789101112&#x2F;&#x2F; return minimum path from (x, y) to bottomint divideConquer(int x, int y) &#123; if (x &#x3D;&#x3D; n) &#123; return 0; &#125; return A[x][y] + Math.min( divideConquer(x + 1, y), divideConquer(x + 1, y + 1) );&#125;divideConquer(0, 0); 与之前一样，每一个节点都分出来两条路径，相当于一个binary tree， 它的节点个数是2^n, 所以这个方法的时间复杂度是O(2^n) DFS实际上是在枚举，把所有的方案都列出来然后看哪个更好 我们做了很多重复计算，因为实际上我们只需要计算三角形所有节点（n2个）的最短路径，DFS却计算了（2n个）节点，很多节点我们计算了很多遍。所以我们需要把每个节点的结果保存下来，下次需要的时候就不需要重新算了 第三种方法 DFS Divide and conquer + Memorization 12345678910111213141516&#x2F;&#x2F; return minimum path from (x, y) to bottomint divideConquer(int x, int y) &#123; &#x2F;&#x2F; row index from 0 to n - 1 if (x &#x3D;&#x3D; n) return 0; &#x2F;&#x2F; if we already got the minimum path from (x, y) to bottom, just return it if (hash[x][y] !&#x3D; Integer.MAX_VALUE) return hash[x][y] &#x2F;&#x2F; set before return hash[x][y] &#x3D; A[x][y] + Math.min(divideConquer(x + 1, y), divideConquer(x + 1, y + 1)); return hash[x][y]&#125;initialize: hash[*][*] &#x3D; Integer.MAX_VALUE;answer: divideConquer(0, 0); 在每次计算节点最小值之前，先看看之前有没有算过这个节点的结果，如果有直接从数组中拿到结果并返回，没有算过我们再递归, O(n^2) time 记忆化搜索的本质：动态规划，省去了重复计算 多重循环 vs 记忆化搜索 第四种方法 多重循环，自底向上 1234567891011121314151617int[][] dp &#x3D; new int[row][row]; &#x2F;&#x2F; dp[i][j] 表示从i， j出发走到最后一层的最小路径长度&#x2F;&#x2F; 初始化，终点先有值,最后一层for (int i &#x3D; 0; i &lt; n; ++i) &#123; dp[n - 1][i] &#x3D; triangle[n - 1][i];&#125;&#x2F;&#x2F; 循环递推求解for (int i &#x3D; n - 2; i &gt;&#x3D; 0; --i) &#123; for (int j &#x3D; 0; j &lt;&#x3D; i; ++j) &#123; dp[i][j] &#x3D; Math.min(dp[i + 1][j], dp[i + 1][j +1]) + A[i][j] &#125;&#125;&#x2F;&#x2F; 求结果： 起点return dp[0][0];&#125; O(n^2) time,没有递归 第五种方法 多重循环，自顶向下 12345678910111213141516171819int[][] dp &#x3D; new int[row][row];&#x2F;&#x2F; 初始化，起点dp[0][0] &#x3D; triangle[0][0];&#x2F;&#x2F; 初始化三角形的左边和右边for (int i &#x3D; 1; i &lt; row; ++i) &#123; dp[i][0] &#x3D; dp[i - 1][0] + triangle[i][0]; &#x2F;&#x2F; 左边 dp[i][i] &#x3D; dp[i - 1][i - 1] + triangle[i][i]; &#x2F;&#x2F; 右边&#125;&#x2F;&#x2F; top downfor (int i &#x3D; 1; i &lt; row; ++i) &#123; for (int j &#x3D; 1; j &lt; i; ++j) &#123; dp[i][j] &#x3D; Math.min(dp[i - 1][j], dp[i - 1][j - 1]) + triangle[i][j]; &#125;&#125;Math.min(dp[row - 1][0], dp[row - 1][1], dp[row - 1][2]...); 这个方法中dp[x][y]表示从上到下到这个点的最短路径 O(n^2) time,没有递归,但是这个方法我们必须提前算出三角形的左边和右边，因为对于三角形的每一个结点dp[x][y]，我们在计算到他的最短路径的时候，我们需要用到它前一层的两个点dp[x-1][y]和dp[x-1][y-1].但是对于每一层的最左边和最右边的点，我们再上一层找不到再靠左边或者右边的点，所以为了避免越界，我们必须提前算出两条边的所有点。 什么情况下使用动态规划？ 满足下满三个条件之一： 求最大值最小值 判断是否可行 统计方案个数 上面这三个情况极有可能需要使用动态规划 什么情况下不使用动态规划？ 求出所有具体的方案，而不是方案的个数 -&gt; palindrome-paritioning 输入数据是一个集合而不是序列,意思是如果我们可以将数据调换位置，则很有可能不使用动态规划，动态规划需要有方向性 -&gt; longest-consecutive-sequence 暴力算法的复杂度已经是多项式级别。 动态规划擅长优化指数级别的复杂度（2^n, n!）到多项式级别的复杂度(n^2, n^3) 动态规划四要素 状态，储存小规模问题的结果 方程，状态之间怎么联系 初始化，最极限的小状态是什么，起点 答案，最终的状态是什么，终点 动态规划的类型，按照状态分类 坐标型 triangle 10% 接龙型 20% 划分型 匹配型 背包型 区间型 longest palindrome 树图型 tree matrix 博弈型 判断是否可行 坐标型动态规划 状态 f[x]:表示我从起点走到坐标x。。。 f[x][y]:表示我从起点走到坐标x, y… 方程：研究走到x， y这个点之前的一步 practice: minimum path sum 动态规划不应该存在循环依赖，从一个状态不会回到之前的一个状态 当我们初始化一个二维数组的动态规划时，需要初始化第0行和第0列 Unique path Unique path 2 Climbing Stairs Jump game Jump game 2 接龙型动态规划 告诉你一个规则然后求最长的状态可以是多少，比如数组中求最大递增子序列 Longest increasing subsequence Russian Doll Envelopes Largest Divisible Subset Frog jump 总结 动态规划的实质是记忆化搜索，避免重复计算中间结果 动态规划四要素：初始化，方程，起点，终点 什么时候使用动态规划:最优，可行，方案数（而非具体方案） 什么时候不使用：求具体方案，输入数据为集合而非序列（可调整顺序），暴力算法时间复杂度已经是O(n^2, n^3)","categories":[],"tags":[{"name":"Data Structures","slug":"Data-Structures","permalink":"http://hellcy.github.io/tags/Data-Structures/"}]},{"title":"Single Sign On Introduction","slug":"Single-Sign-On-Introduction","date":"2019-10-24T02:54:58.000Z","updated":"2021-05-24T07:27:02.660Z","comments":true,"path":"2019/10/24/Single-Sign-On-Introduction/","link":"","permalink":"http://hellcy.github.io/2019/10/24/Single-Sign-On-Introduction/","excerpt":"","text":"What is Single Sign On? Single-sign-on是一个很方便的东西，现在无论什么网站都需要登陆，而记住每个网站不同的用户名和密码又非常困难，那么作为一个好的产品，从用户的角度出发，就应该想到，如果我们只需要让用户登陆一次，就可以去到同一个平台下任何其他的产品，而不需要重复登陆，那该多好。 比如说Google Chrome，当你在浏览器中登陆了，那么你再去到Youtube或者Gmail等其他Google公司的产品，你将不再需要再次登陆。这是因为Google在你登陆的时候保存了 那么，这是怎么做到的呢，在single sign on with SAML的世界中，有两个非常重要的概念，一个是IDP，identity provider，另一个是SP，service provider。我们还是拿Google来举例子，当你需要登陆Youtube时，Youtube会将你跳转到一个Google登陆界面，登陆后他会保存你的登陆信息，然后再将你跳转回Youtube，你就发现你已经登陆上了，这时你需要查看Gmail，Gmail也会将你跳转到Google登陆界面，但是界面发现因为你已经登陆了Youtube，所以你所有的登陆信息已经被保存了，不需要你再次输入，于是自动把你跳转到Gmail，你就以为你什么都没做就自动登陆了Gmail。(虽然Google可能不是用SAML来登陆的) 什么是SAML? SAML可以认为是IDP和SP之间转递用户信息的一种格式规范，为了方便接收方能够理解传递过去的信息，必须规定一种规范使接收方很容易解码信息。 Broker 现在我们要做的是一个中间人的角色，用户所有的请求都会先到我们这里，我们会检查request header，如果我们发现这是一个GET request，我们就会直接把用户跳转到SSO的登陆界面。 如果我们发现这是一个POST request，并且成功解码了一起发过来的SAML，我们就要重新加密用户信息，并把用户跳转到相应的网页，由最终的Service provider来再次解码用户信息 如果SAML解码失败，我们也会将用户跳转到SSO登陆界面。让用户再次登陆 加密信息的方法有很多，我用的是windows自带的RijndaelManaged Class Reference Microsoft RijndaelManaged Class SAML How SSO works One Potential Security Issue 如果我们仔细想想这个流程，就会发现这中间存在一个安全隐患，如果用户在IDP输入完用户信息并验证通过后，IDP会把SAML response发回给SP，这时如果这个SAML被拦截并被篡改，SP并不知道这个SAML有没有被改动，还是会按照SAML上面的信息将用户登陆。 要解决这个问题，我们就需要检查SAML Response，这个检查分为两步，Signing check和Certificate check Signing Check 其实就是一种checksum，我们把整个SAML response转换成一种加密的text。这个text随着SAML一起返回给SP，当我们解密这个text后得到的SAML和返回的SAML对不上，我们就知道这个SAML已经被篡改过了。举个例子：我们收到了一个来自Sam的SAML response，当我们检查了signing之后，我们就能确定这个response自从从Sam手上发出后就没有被篡改过。但是另一个问题是，如果我们得信息被Tony拦截，Tony完全替换了整个SAML并发给我们，我们虽然知道SAML自从从Tony手中发出后没有被篡改，但是我们还是没有拿到正确的SAML。 Certificate check 这就需要Certificate check了，他其实就是提前保存在用户电脑中的受信任的证书，当我们发现SAML来自Tony而不是Sam，Tony并没有在受信名单中，那我们还是会拒绝这个SAML。只有当response来自我们所信任的人，并且这个response自从从他手上发出后就没有更改，我们才选择接受。 Reference SAML: Why is the certificate within the Signature? CheckSignature(X509Certificate2, Boolean) How to validate a SAML signature value How to: Verify the Digital Signatures of XML Documents Asp.Net Core SAML Response Signature Validation","categories":[],"tags":[{"name":"SSO","slug":"SSO","permalink":"http://hellcy.github.io/tags/SSO/"}]},{"title":"Learn Android Apprentice in 10 days","slug":"Learn-Android-Apprentice-in-10-days","date":"2019-09-02T10:01:47.000Z","updated":"2021-02-26T12:08:47.159Z","comments":true,"path":"2019/09/02/Learn-Android-Apprentice-in-10-days/","link":"","permalink":"http://hellcy.github.io/2019/09/02/Learn-Android-Apprentice-in-10-days/","excerpt":"","text":"开始学习使用Android Studio 在iOS的学习告一段落了之后，现在开始学习Android应用的开发 他总共包括六个部分，前四个部分每一部分教你编写一个app，难度从低到高。后面两部分会告诉你怎么向下兼容和发布。跟之前的iOS教程很像。 TimeFighter Checklist Conclusion TimeFighter 这个app会从怎么set up Android Studio开始，我们直接跳过，到最开始写代码的部分 Constraint Layouts 和iOS App很像，手机app必须考虑到对象在手机屏幕上的位置问题，Android有提供很多种layoutdexuanze，其中Constraint是最常用的一种，他可以规定目标到屏幕的相对位置 Activities 在确定了诸如Textview，Button等对象的位置之后，我们需要在代码层面对其进行操作，我们可以在Aciticity中创建这些变量对象，然后通过在Layout中设置的ID找到他们，Activity其实就是iOS中的ViewController。 Strings 我们会将一个app中用到的所有文字集中在一个文件中，这个文件叫做Strings.xml，这样以后本地化加其他语言或者更改一个单词，这个单词虽然在app中可能出现了很多次，但是我们只需要在Strings里面改一次就可以了 Oriendtation changes 在手机屏幕方向改变时，系统会做三件事，1.save properties, 2. destroys current activity, 3. recreates the activity for the new orientation by calling onCreate and resets any properties specified by the developer 所以在改变方向时，我们需要及时保存需要用到的变量，在接下来现实的Activity中显示，保证过程不会丢失。 val and var Basically, val and var both are used to declare a variable. var is like a general variable and can be assigned multiple times and is known as the mutable variable in Kotlin. Whereas val is a constant variable and can not be assigned multiple times and can be Initialized only single time and is known as the immutable variable in Kotlin. App colors and styles Android project中有许多文件夹，其中res包含着app需要用到的所有资源resources，常用的Strings，Animations，Menus，Colors and Styles都在这里, 通过直接更改Colors里面颜色的hex值来改变app中元素的颜色，更方便的管理同一种类型的东西 Animations Animations也在res文件夹里，她负责调用以及调配动画，图片里的动画效果是使用内置的bounce_interpolator，在2秒钟内把目标元素增大2倍，以50%处为中心，并缩小至原来的大小。 Menu Menu同样他也在res文件夹中，他管理所有跟系统菜单相关的元素，比如我们想在屏幕上方的菜单栏中加入一个button，就需要在这里定义 我们加了一个Menu，当点击时会冒出一个AlertDialog 这就是第一个app所讲的全部内容了，基本就是把project中需要用到的功能讲了一遍，没有用到任何复杂的语法，更多的讲的是Android Studio这个IDE的使用。接下来进行第二个app Checklist RecyclerView The RecyclerView asks the Adapter for an item, or a ViewHolder at a given position. 2. The Adapter reaches into a pool of ViewHolders that have been created. 3. Either a a new ViewHolder is returned, or a new one is created. 4. The Adapter then binds this ViewHolder to a data item at the given position. 5. The ViewHolder is returned back to the RecyclerView for display In general, Adapters give your RecyclerView the data it wants to show. They have a clever way to calculate how many rows of data you want to show, which you’ll cover shortly. ViewHolders are the visual containers for your item. Think of them as cells in the table. This is where you tell your RecyclerView what each item should look like. These are basically little tiny layout items used to display the data at any given position in the list of data. As you scroll through a RecyclerView, instead of creating new ViewHolders, RecyclerView will recycle ViewHolders that have moved offscreen and populate them with new data, ready to be shown at the bottom of the list. This process repeats endlessly as you scroll through your RecyclerView. This recycling of ViewHolder to display list items helps to avoid janking in your app. RecycleView 的本质是循环使用table中的cell，当一个cell网上滑出屏幕时，我们可以让他重新出现在底部，但是显示不同的数据，这就要求我们在写代码时要把table，cell和数据分开来，每个部分各司其职 这个是cell部分，它由两个textview组成。对应上图中的viewHolder 这个是table部分，它包含多个cell，并可以循环利用cell。对应上图中的adapter。我们需要在adapter中implement recycleview必须的成分例如包含多少个viewholder，每个viewholder的数据应该从哪里取。。 除了recycleview本身，我们应该把data source设置成动态的，也就是说我们可以输入自己的数据，并加进recycleview中。 下面我们在代码层面解释一下如何构建一个recycleView 首先我们需要继承RecyclerView Adapter并implement这三个function，RecyclerView还有很多其他function可以override但是这三个是必须的 123override fun getItemCount(): Int &#123; return accounts.size&#125; getItemCount return一个Int，它表示这个表格中有几行，一般是return数据的size 12345678override fun onCreateViewHolder( parent: ViewGroup, viewType: Int): CustomViewHolder &#123; val view &#x3D; LayoutInflater.from(parent.context).inflate(R.layout.view_holder_custom, parent, false) return CustomViewHolder(view)&#125; onCreateViewHolder定义一个table cell的layout，我们返回一个layout文件，所以对于每个不同的recyclerView，我们还需要新建一个Layout file用于储存cell的layout 123456override fun onBindViewHolder(holder: CustomViewHolder, position: Int) &#123; holder.label.text &#x3D; &quot;Some text&quot; holder.itemView.setOnClickListener &#123; clickListener.listItemClicked(position) &#125;&#125; onBindViewHolder会把我们的数据放到我们新建的cell layout中，另外注意到我加了一个ClickListener，所以之后我们点击每行的时候就会运行listItemClicked function，然后在那里就可以添加另外的代码，可以跳到另一个View等。 123class CustomViewHolder(itemView: View): RecyclerView.ViewHolder(itemView) &#123; val sampleData &#x3D; itemView.findViewById(R.id.sampleData) as TextView&#125; 我们还需要一个class去连接table cell layout file 这样基本上一个RecyclerView就完成了，之后我们只需要将数据从Activity或者Fragment传入RecyclerView Adapter就可以了 SharedPreferences SharedPreferences lets you save small collections of key-value pairs that you can retrieve later. If you need a way to quickly save small bits of data in your app, SharedPreferences is one of the first solutions you should consider 这就需要用到sharedpreference，它类似于一个dictionary，里面由key-value pairs组成。可以储存size较小的数据。类似于表格信息 EditText 12val listTitleEditText &#x3D; EditText(this) listTitleEditText.inputType &#x3D; InputType.TYPE_CLASS_TEXT 创建一个input text field，并给它指明一个InputType， 这样Android就会显示合适的keyboard Intent 当我们需要让一个页面与另一个页面进行交流时，我们需要通过Intent将数据传送过去。 12345678private fun showListDetail(list: TaskList) &#123; val listDetailIntent &#x3D; Intent(this, ListDetailActivity::class.java) listDetailIntent.putExtra(INTENT_LIST_KEY, list) startActivity(listDetailIntent)&#125;&#x2F;&#x2F; get from other Activitylist &#x3D; intent.getParcelableExtra(MainActivity.INTENT_LIST_KEY) 在上面这个function中，this是我们现在所在的Activity，ListDetailActivity是我们将要过去的Activity，TaskList是我们要传送的数据。 我们需要规定一个Key，这样的新的页面中我们就知道用Key来获取相应的数据。 但是还有一个问题，就是自定义的object不能直接通过intent传送，我们需要把他变成Parcelable的object Parcelable 在定义object的class中，implement parcelable，Android Studio会自动把需要的function写好 Fragment Fragment是android语言中一个非常重要的部分，他必须附属于一个Activity，Fragment的本质是可以让相同的部分用同一个Fragment表示，并在多处使用，以节省代码长度，让App保持整洁一致。 12345678910111213141516171819202122232425262728293031323334353637383940class ListSelectionFragment : Fragment() &#123; &#x2F;&#x2F; 1 private var listener: OnListItemFragmentInteractionListener? &#x3D; null interface OnListItemFragmentInteractionListener &#123; fun onListItemClicked(list: TaskList) &#125; &#x2F;&#x2F; 2 companion object &#123; fun newInstance(): ListSelectionFragment &#123; val fragment &#x3D; ListSelectionFragment() return fragment &#125; &#125;&#x2F;&#x2F; 3override fun onAttach(context: Context) &#123; super.onAttach(context) if (context is OnListItemFragmentInteractionListener) &#123; listener &#x3D; context &#125; else &#123; throw RuntimeException(context.toString() + &quot; must implementOnListItemFragmentInteractionListener&quot;) &#125;&#125; &#x2F;&#x2F; 4 override fun onCreate(savedInstanceState: Bundle?) &#123; super.onCreate(savedInstanceState) &#125; &#x2F;&#x2F; 5 override fun onCreateView(inflater: LayoutInflater, container:ViewGroup?, savedInstanceState: Bundle?): View? &#123; return inflater.inflate(R.layout.fragment_list_selection, container,false) &#125; &#x2F;&#x2F; 6 override fun onDetach() &#123; super.onDetach() listener &#x3D; null &#125;&#125; Fragment由几个重要部分组成，首先，当Fragment第一次被附属于某个Activity时onAttach会被执行。然后onCreate， 在这两个地方你可以initialize一些变量等 123456789override fun onCreate(savedInstanceState: Bundle?) &#123; super.onCreate(savedInstanceState) transactions &#x3D; arguments?.getParcelableArrayList&lt;WestpacTransaction&gt;(&quot;Transactions&quot;)!! refundedAmount &#x3D; arguments?.getDouble(&quot;RefundedAmount&quot;)!! refundAmount &#x3D; arguments?.getDouble(&quot;RefundAmount&quot;)!! updatedBalance &#x3D; arguments?.getDouble(&quot;UpdatedBalance&quot;)!! primaryAccount &#x3D; paperCutAccountManager.readPrimaryAccount()&#125; 之后onCreateView，这个地方会把数据等object显示在View中，所以需要在这里把变量和UI object绑定。 1234567891011121314151617181920212223242526override fun onCreateView( inflater: LayoutInflater, container: ViewGroup?, savedInstanceState: Bundle?): View? &#123; val activity &#x3D; activity as AppCompatActivity? if (activity !&#x3D; null) &#123; activity.supportActionBar!!.show() activity.supportActionBar?.setDisplayHomeAsUpEnabled(false) activity.supportActionBar?.title &#x3D; &quot;Refund Complete&quot; activity.nav_view.isVisible &#x3D; false &#125; &#x2F;&#x2F; Inflate the layout for this fragment val view &#x3D; inflater.inflate(R.layout.fragment_refund_complete, container, false) view.AccountNameLabel.text &#x3D; primaryAccount.AccountName view.AccountBalanceLabel.text &#x3D; &quot;$&quot; + &quot;%.2f&quot;.format(updatedBalance) view.refundAmount.text &#x3D; &quot;$&quot; + &quot;%.2f&quot;.format(refundedAmount) view.DoneButton.setOnClickListener &#123; v -&gt; doneButtonPressed() &#125; view.refundCompleteTable.adapter &#x3D; RefundCompleteTableViewAdapter(transactions, this) view.refundCompleteTable.layoutManager &#x3D; LinearLayoutManager(activity) return view&#125; 之后是Companion object，当这个Fragment被创建时，如果你需要给它传值，它需要在这里被定义，有点像是Fragment的Constructor 1234567891011121314companion object &#123; val TAG &#x3D; RefundCompleteFragment::class.java.simpleName @JvmStatic fun newInstance(transactions: ArrayList&lt;WestpacTransaction&gt;, refundedAmount: Double, refundAmount: Double, updatedBalance: Double): RefundCompleteFragment &#123; val fragment &#x3D; RefundCompleteFragment() val args &#x3D; Bundle() args.putParcelableArrayList(&quot;Transactions&quot;, transactions) args.putDouble(&quot;RefundedAmount&quot;, refundedAmount) args.putDouble(&quot;RefundAmount&quot;, refundAmount) args.putDouble(&quot;UpdatedBalance&quot;, updatedBalance) fragment.arguments &#x3D; args return fragment &#125;&#125;","categories":[],"tags":[{"name":"Kotlin","slug":"Kotlin","permalink":"http://hellcy.github.io/tags/Kotlin/"},{"name":"Android Studio","slug":"Android-Studio","permalink":"http://hellcy.github.io/tags/Android-Studio/"}]},{"title":"Swift tips and tricks","slug":"Swift-tips-and-tricks","date":"2019-08-16T09:47:36.000Z","updated":"2021-02-26T12:08:47.159Z","comments":true,"path":"2019/08/16/Swift-tips-and-tricks/","link":"","permalink":"http://hellcy.github.io/2019/08/16/Swift-tips-and-tricks/","excerpt":"","text":"Passing messages around view controllers 三种在view controllers中传递参数的方法，Delegation pattern, Notifications, Closures and action handlers。可以在这篇帖子中找到。 CS193P open course notes MVC Swift Programming Language More Swift Please find all relevant materials for Standford Programming course cs193p in here MVC Controller can talk to both Model and View. But Model and View should never speak to each other. For the View, it can communicate to the Controller, but in certain ways. Because View are all generic UI objects, to change some of its properties to fits the app’s objective, we need to send the UI objects, like buttons and labels back to the controller, let controller to implement its properties like background color, label content etc… so we use Action method to target the function that will be calling when certain UI objects are triggered. Another way to talk to controller is to use Delegate, for more complicated objects like scroll view or tables, we need to let controller know what we are doing at the moment, and controller is responsible for implementing the extra tasks while we are doing this things. Another important thing is that views do not own the data they display, they ask for the controller and controller grab the data from Data source and give it to the View, because if you have 50000 songs in a table, if table owns the data, it will be too big and costy to create such table object. So instead we use Data Source to provide data to the view. What about Model, can Model talk to the Controller? Yes, but not directly, because Model is UI independent, and Controller is UI dependent, so if a Model is updated and he wants everybody that is interested to be informed, it will broadcast this information to all the controllers, and those controllers that are listening will be notified and talk to Model and grab the changes. This way is called notifications One MVC model usually controls one screen on iPhone, and when multiple MVCs are talking to each other, they often treats other MVC as its View. So when one Screen wants to talk to another Screen, it uses delegate! Do not implement your app this way! struct and class They are similar, contains methods and variables, but struct has no inheritance, Another difference is structs are value types, and classes are reference types, so when we assign it to another variable, it gets copied. Arrays, ints, strings, dictionary are all structs, but swift doesn’t make a copy of all of them when we need it, it only copy them when a user modifies it. It’s called copy-on-write semantics. For classes, we do not make a copy of it when we need it, we make a reference to the class, so when we modify the properties of that class, the real class gets modified too. Try not to use initialiser in the view controller stride In swift, we don’t have for(; 😉 structrue, so we need stride method for a range with specific count value Swift Programming Language tuples They are nothing but a group of values, different types of values could be inside the same tuple, vars and methods are not allowed in tuples, its good for return multiple values from a method because a method can only return a single thing. stored properties(normal properties) and computed properties Computed properties are properties with get and set methods, you can have read only computed properties, which only has get method. get and set part will be executed when we get or set the variable. we use computed property because sometimes we can derive property from other place, like indexOfOneAndOnlyFaceUpCard GET can be derived by looking at all the cards and see if you can get only one card facing up and return that index. And SET can give the card that is facing up to the property. You can omit the GET word if it is a read only computed property Access control Protecting our internal implementations, by only give other people names of the methods that are allowed to be called. Internal: usable by any object in my app or framwork, its default private: callable only within this object private(set): means its only readable from outside the object, but not settable filePrivate: accessiable by any object in this source file public(for frameworks only): can be used by object outside this framework open(for frameworks only): public AND can sub-class(override) assertion: a method that in your program when you assert something is true, is not, the app will crash. It is a good way to protect your API. Extension Add vars and methods to other classes even if you don’t have the source. But there are restrictions: you can’t re-implement the methods that are already there. You can only add new ones. And, properties you add can have no stroage associated with them.(computed only) Enum Another variety of data structrue apart from struct and class. It can only have discrete states. Enum is a VALUE type, like structs, so it gets copied as it is passed around. Enum in Swift can have an associated data. Enum with associated value Checking enum’s state with Switch cases syntax using associated value in switch cases Enum can have methods, and you can test a enum’s state within that method with self keyword You can even change the enum’s state in its methods, by giving that method a mutating keyword to let Swift know. Optionals Optional is just an enum, it has two cases, one is nil, which measns it is not set yet, the other is some, which means it has some associated value with it. If you are trying to force unwrap an optional, what Swift really do it just throw an exception when that enum is in case nil, and do whatever you want to do with that enum in case ‘some’. Memory Management Automatic reference counting: Reference types are stored in the heap, everytime you create a pointer to a reference type in the heap, Swift will add One to a counter for that reference type, everytime when a pointer goes out of scope, Swift decrement the counter. And when the counter decrement to zero, Swift will instantly remove that reference type out of heap. Influence ARC by using ‘strong’, ‘weak’ and ‘unowned’ structs More Swift Protocol is the fourth data structure in Swift. It is basically a type, which contains a list of variables and a list of methods, without implementation. Any class or structs or enum that want to inherit protocol must implement all methods declared in that protocol. But, for objective C methods, implementations are optional. This is why when we override some will, did, set methods for some UI obejcts, we dont need to implement all methods from that protocol. Mutating functions: in protocol, some functions may be marked as mutating, when structs trying to inherit a protocol, because structs are value types, so structs get copied when we want to use it. However, it would be very inefficient if we make a copy every time we see it. So Swift uses copy-on-write system, we only make a copy of that struct when we are trying to modify it, in other words, mutating it. So we a struct is trying to change something in a function, and that function is inherted from a protocol, then this function has to be marked as mutating. Init: init functions are allowed to exist in protocol, however, in a class inherited that protocol, we need to add requried keyword before init function, this is because this class could have some other subclasses, and these classes also have to implement init function. Use protocol as a type Delegation: a very important use of protocol is delegation. Mutiple inheritance: if you want to use certain functions in some protocols, you could inherit that protocol and implement the functions you want to use.","categories":[],"tags":[{"name":"Swift","slug":"Swift","permalink":"http://hellcy.github.io/tags/Swift/"}]},{"title":"AWS Overview","slug":"AWS-Overview","date":"2019-08-05T09:03:22.000Z","updated":"2021-02-26T12:08:47.158Z","comments":true,"path":"2019/08/05/AWS-Overview/","link":"","permalink":"http://hellcy.github.io/2019/08/05/AWS-Overview/","excerpt":"","text":"什么是AWS？ AWS是Amazon的云服务，我现在用到的是其中的API Gateway和Lambda，API Gateway就是API网关，当网关收到request时，可以运行对应的Lambda function，生成response，然后返回。 Lambda function and API Gateway Introduction Create AWS Serverless Application 更改API域名 Custom Domain Names change lambda function outbound IP address to static Use IAM to restrict API Use S3 to host webpage AWS Simple Email Services Lambda function and API Gateway API Gateway 他总共分成6个部分，第一个部分是Test，也就是send test request的地方，sample request会先到达Method Request，在这里你可以往request里面加入Query string parameters, Http headers, Request body来让request符合Lambda的要求。 再下一个部分是Integration Request，在这里可以选择对应的Lambda function，让request知道该去往哪个Lambda，并且可以勾选Use Lambda Proxy integration, 如果勾选，它代表着AWS会帮你把request中的信息(包括query parameter, header, body等)保存到一个类似Dictionary的结构中，在lambda里面可以直接通过key name调用，不用手动提取信息。在下一部分就是运行相应的Lambda function了，这个在接下来的Lambda部分中讲。当Lambda运行完之后会生成一个response，如果勾选了之前的Proxy integration，这个地方就是灰色的，不能查看，因为它会帮你把response里的信息自动填充到header，body。。。并且使用自带的response template model，所以你就不用操心这个了。不然的话你可以手动设置response的格式。最后一个部分是Method response，当设置好reponse格式之后，你可以把response status code，连同optional的header和body返回给用户。还可以设置body的格式，比如JSON。 Lambda function 这里是你真正处理请求并返回数据的地方，AWS支持很多种语言的function。 我是用C#，这需要在Visual Studio中安装AWS package，在unget manager里面搜索AWS就可以找到AWS SDK了。安装之后就可以新建AWS solution并publish到AWS Lambda中。 这次我需要写的function就是调用Westpac API，所以其实是用户先调用AWS API，然后这个API再调用Westpac API。。。 如果request中含有parameter或者body信息，那么在function中的APIGatewayProxyRequest中就会含有这些参数信息，这就是之前勾选了proxy integration的好处 在上传时新建一个Lambda function，另外下面的Method name要对应刚刚C#中的method name，因为有时候我们会在一个solution中写多个method，连接多个Lambda function，所以要一一对应。 Test API Gateway and Lambda function 之后就是用AWS测试刚刚写好的API了，注意测试之前要先deploy API Gateway，确保与Lambda function对应，这个可以在lambda function中的API Gateway endpoint里看到，如果能看到endpoint url，就说明对应成功了。 测试的时候可以加query strings，就是request中的parameters，右边可以看到测试结果，因为这个是GET request，所以我们不能加Request Body。在POST request中是可以的。 这个是另外一个POST request with JSON body Create AWS Serverless Application 这更像是一个Lambda project，可以让API gateway一次连接多个Lambda functions，也可以在Visual Studio里调整API Gateway的一些设置 这是project包含的template文件，我们可以设置API的类型，Request的类型，路径，以及这个API对AWS的可操作权限等 发布后在API Gateway中就可以看到这个层级结构和template是完全一样的 之前讲到我们可以在API Gateway中测试API，其实在Visual Studio里，发布之前我们就可以debug他，就是debug所在的位置，只不过现在显示的是Mock test tool 他长这个样子 其中有两个需要注意的地方，第一个是我们需要调用的function，因为这是一个lambda projects，包含多个lambda functions，所以调用哪一个必须提前声明 还有一个就是input，因为我使用的proxy，所以在列表中选择proxy，会生成一个template，然后我们需要什么input就在相应的地方加就可以了 比如如果要在request body里加，就找到body所在的位置，query parameter和path parameter同理 最后说一下如何发布，跟之前的lambda function一样，只不过我们需要创建一个S3 bucket来存放所有的历史版本。 他会自动清理之前旧版的project，当状态显示的是update complete，我们就知道他已经可以使用了 Calling trusted frame from swift 另外一个任务是，因为我们不能经受任何信用卡信息，所以我们需要用到westpac trusted frame，通过调用这个Javascript library来让用户将信用卡信息直接发送到westpac的服务器，然后处理westpac的response就可以了。但是有一个问题是，我们希望用户能在我们的手机app上也可以调用westpac API，可以这个trusted frame是一个只支持web application的Javascript library，这就需要我们在Swift中加入WebKit，同时在用户在含有trusted frame的web page中submit form时，将返回的信息发送到Swift的某个Method中。简而言之，我们需要在javascript中调用Swift 更改API域名 Custom Domain Names AWS API的标准名字是这样的格式 1https:&#x2F;&#x2F;api-id.execute-api.region.amazonaws.com&#x2F;stage 这很复杂而且跟API的功能也没有任何联系 我们可以更改他的域名，让他的名字更有意义 在新建域名时，我们可以给域名增加certificate，这需要通过在AWS ACM(certificate manager)中新增certificate来实现 我们还需要在internet中新建一个我们想要的域名，然后用route 53来把这个域名和API关联起来，上图中的Target domain name就是自定义域名需要关联的域名。在route 53中找到hosted zones，然后新增一行record，把target domain name填入，再自定义一个域名就可以了 AWS API分为两种，一种是Edge Optimized，另一个是Regional，在API Gateway中每一个API的settings中可以看到，也可以更改其Endpoint type 最后测试一下看看域名是不是成功了，记住route 53需要一点时间才能把域名建好并且go live，所以等几分钟再试 本节参考了这些文章，可以点击以获取更多信息。 Set Up a Custom Domain Name for an API in API Gateway How to Create an Edge-Optimized Custom Domain Name change lambda function outbound IP address to static 我们还可以设置API outbound request的IP，有些时候，当我们需要调用外部API时，他们会有IP地址的限制，只有来自特定whitelist的IP地址发送的请求才会被接受。所以我们需要设置我们发送API时请求的IP地址。因为Lambda function是通过AWS发送的，在被发送时它的IP地址是随机的，虽然不是动态IP，但是每次发送的地址都不一样，我们没办法把所有的IP都加近whitelist。 针对这个问题，我们可以通过把lambda function加入VPC来解决，VPC可以看作是包含一组IP地址的内部云，我们给它加上一个出口，让所有在此VPC的请求都通过这个出口发送出去，这样所有的lambda都会只有一个我们指定的IP了。 我们具体来解释一下AWS VPC的构造 如果AWS EC2是一个云服务器，那么VPC就是这个云服务器的网络层，负责设备之间的信息传输。它由几个重要部分构成 Subnet: 包含一组指定范围的IP，IP格式参照CIDR Route table: 包含信息传输的规则，什么地方来的请求应该到什么地方去，类似一个交通枢纽，负责指挥数据的方向 Internet gateway: VPC的一个重要组成部分，负责VPC内部信息和外部网络的交流，就是这个VPC的出口 Elastic IP: 一个公开的IPv4地址，我们要把它赋给NAT，这样就可以让外部和NAT内部通过这个公开IP进行交流 NAT Gateway: Network Address Translator Gateway, 与Internet Gateway类似，不同的是它可以让private subnet中的数据通过它与外部网络交流 具体做法 新建一个VPC 新建一个Internet Gateway，与VPC相连 新建一个Public subnet，并在route table中新建一个规则，让所有通过这个public subnet的数据流向Internet Gateway 新建一个Elastic IP 新建一个NAT Gateway，把Elastic IP赋给它，并将它放入public subnet中 新建一个private subnet，并在route table中新建一个规则，让所有通过这个private subnet的数据流向NAT Gateway 将lambda function放入private subnet 这样一切就设置完成了，当lambda被执行时，数据会通过private subnet，根据route table的规则流向NAT gateway NAT Gateway将数据赋予Elastic IP，因为NAT在public subnet中，根据route table规则流向Internet Gateway Internet Gateway将数据发给外部网络，此时所有数据都会来自同一个Elastic IP 需要注意的点 在将lambda function放入subnet时，只给它private subnet，不要给public subnet，因为这样他就有可能不通过NAT gateway 给lambda function加VPC需要一个AWS permission 可以创建另一个lambda function，只接受特定IP来测试整个流程是否成功。图为限制IP的policy Reference AWS Lambda functions with a static IP Configuring a Lambda Function to Access Resources in a VPC AWS — Difference between Internet gateway and NAT gateway What Is Amazon VPC? What Is Amazon EC2? Elastic IP Addresses Use IAM to restrict API HTTP basic authentication是一种保护API免受外界攻击的方式，当我们尝试打开某些URL时，有时会出现这个界面让我们输入用户名和密码，这就是一种Basic authentication 这种机制依赖于HTTP Authentication Framework，他的步骤是： 某些人尝试访问一个受保护的URL 服务器返回401未授权的HTTP code，包括一个WWW-Authenticate header with value Basic 浏览器弹出要求用户输入用户名和密码的窗口 请求再次被发送，包括用户输入的授权信息在header中 那么这个简单的API authentication怎么实现呢？ 首先我们去到已经建好的API Gateway中，点击Gateway responses选项，选中Unauthorized，在这里我们可以设置返回什么样的信息给用户当他们尝试访问这个URL时。 当我们添加了WWW-Authenticate header，浏览器就会弹出窗口要求用户自证身份 之后我们需要写一个Lambda function去检查用户提交的信息是否是正确的，也就是检查用户名和密码。这个function也叫做custom authorizer 接下来我们需要让我们的API知道当他接收到Authentication信息时需要调用哪个lambda function来检查，所以去到API gateway的Authorizer选项，新建一个Authorizer，在lambda function中选中我们刚刚写好的lambda function 最后我们还需要让API gateway知道哪个URL endpoint是需要保护的，因为一个API gatewat往往包括很多个URL，我们需要指定一个或多个URL调用刚刚新建的Authorizer 最后别忘了Deploye API，不然所有的设置并不会生效 我们可以测试一下看看访问相同的URL，如果不添加authentication information的话，服务器就会返回401 Unauthorized 除了使用自定义的Authorizer，AWS也内置有IAM (Identity Access Management),在之前的Method Request如果我们选择使用AWS_IAM的话，也可以限制用户对于API的访问 但是我们必须在request中添加AWS signature，这需要使用到AWS给每个account的access key和secret key，其中secret key只有在一开始generate的时候才会看到，之后就看不到了，所以一定要保存在一个安全的地方，要不然的话只能重新generate一对新的key 另外我们可以在resource policy中限制可以访问API的ip address，所以即使用户输入了正确的Authentication information，我们也不能让没有权限的区域访问API 这种IP address limitation也可以在自定义的lambda function中使用 另外，如果要blacklist or whitelist a range of ip addresses，可以使用CIDR notation net mask，在ip address后面加一个斜杠和一个数字，数字表示从左往右有多少bit是在范围外的。 例如“110.142.216.1/24&quot; 就表示了ip range from 110.142.216.1 to 110.142.216.255 Reference HTTP Basic Auth with API Gateway and Serverless Control access to your APIs using Amazon API Gateway resource policies How do I use a resource policy to whitelist certain IP addresses to access my API Gateway API? API Gateway Resource Policy Examples Classless Inter-Domain Routing Use S3 to host webpage S3是一个储存文件的服务，一般来说我们需要把网页放到服务器里去host它，但是S3也提供了host webpage的功能，我们只需要新建一个bucket。 上传我们需要host的webpage 注意在设置里面关闭block public access，毕竟我们需要访问它来获得数据 最后我们需要打开hosting 这样的话我们就可以通过AWS S3来host webpage，不需要使用自己的服务器了 Reference AWS S3 Getting Started What is AWS S3? AWS Simple Email Services 使用AWS发送Email是一件非常简单的事情，通过以下步骤可以创建一个AWS User with email sending policyies并使用C#发送邮件 首先我们需要创建一个AWS User，拿到发送Email的Credentials 然后我们需要设置想用什么邮箱地址发送邮件，我们需要验证，并登陆对应邮箱点击验证链接 之后我们可以测试一下能不能发送Test Email，这里不需要用到Credentials 然后我们就可以看代码了 1234567891011121314151617181920212223242526272829303132333435363738394041public void SendEmail() &#123; String FROM &#x3D; &quot;sender email address&quot;; String FROMNAME &#x3D; &quot;Your Name&quot;; String TO &#x3D; &quot;receiver email address&quot;; String SMTP_USERNAME &#x3D; &quot;Credentials Username&quot;; String SMTP_PASSWORD &#x3D; &quot;Credentials Password&quot;; String HOST &#x3D; &quot;Your AWS host location&quot;; int PORT &#x3D; 587; String SUBJECT &#x3D; &quot;Email Subject&quot;; String BODY &#x3D; &quot;&amp;lth1&amp;gtEmail Title&amp;lt&#x2F;h1&amp;gt&quot; + &quot;&amp;ltp&amp;gtEmail Content&amp;lt&#x2F;p&amp;gt&quot;; MailMessage message &#x3D; new MailMessage(); message.IsBodyHtml &#x3D; true; message.From &#x3D; new MailAddress(FROM, FROMNAME); message.To.Add(new MailAddress(TO)); message.Subject &#x3D; SUBJECT; message.Body &#x3D; BODY; using (var client &#x3D; new System.Net.Mail.SmtpClient(HOST, PORT)) &#123; client.UseDefaultCredentials &#x3D; false; client.Credentials &#x3D; new NetworkCredential(SMTP_USERNAME, SMTP_PASSWORD); client.EnableSsl &#x3D; true; try &#123; Console.WriteLine(&quot;Attempting to send email...&quot;); client.Send(message); Console.WriteLine(&quot;Email sent!&quot;); &#125; catch (Exception ex) &#123; Console.WriteLine(&quot;The email was not sent.&quot;); Console.WriteLine(&quot;Error message: &quot; + ex.Message); &#125; &#125; &#125; 执行这个function几次看看能不能收到邮件，如何可以的话就成功了 AWS 还有统计邮件成功率的工具，也在SES tab里面 另外就是Configuration set是一个optional的设置，可以在AWS里面添加 除了用SMTP，我们还可以用AWS SDK发送邮件，这里就不介绍了，大致都是一样的，代码需要改一下 当你新建一个AWS用户时，你的邮件功能可以会受到限制，也就是说在Sandbox里面，收发数量，频率都会受限，可以给Amazon发送请求移除Sandbox，具体做法可以参考下面链接 Reference Sending a test email Send an email using SMTP Using AWS SES Configuration sets Moving out of sandbox","categories":[],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://hellcy.github.io/tags/AWS/"}]},{"title":"Payment Gateway API","slug":"Payment-Gateway-API","date":"2019-07-23T08:59:28.000Z","updated":"2021-02-26T12:08:47.159Z","comments":true,"path":"2019/07/23/Payment-Gateway-API/","link":"","permalink":"http://hellcy.github.io/2019/07/23/Payment-Gateway-API/","excerpt":"","text":"什么是PCI compliance？ 现在很多公司都允许客户通过信用卡在网上直接付款购买公司的服务和产品，那么必不可少的就是公司需要对用户输入的信用卡信息和其他个人隐私保护，使得外人不能窃取这些信息，PCI DSS是一种数据安全协议，通过参与这个协议，客户就可以放心的将信用卡信息填在公司的网站上而不用担心泄露。因为如果客户的信息泄露了，公司将会受到严重的利息损失，其他客户也将不再愿意相信此公司的信誉。 WestPac QuickStream是一个第三方的payment gateway。我们可以使用这个API来管理用户的付款，他们提供一种trusted frame，使用它，所有的敏感信息将不会经过公司的服务器，而是直接从用户的电脑到Westpac的服务器，由他们来负责保护这些关键信息。 Trusted Frame将用户信息加密(tokenize)，并将加密后的token发送到公司服务器，这样即使公司也无法知道用户信息了。 详细的API使用可以在这里找到。","categories":[],"tags":[{"name":"API","slug":"API","permalink":"http://hellcy.github.io/tags/API/"}]},{"title":"Learn iOS apprentice in 10 days","slug":"Learn-iOS-apprentice-in-10-days","date":"2019-07-03T05:25:31.000Z","updated":"2021-02-26T12:08:47.159Z","comments":true,"path":"2019/07/03/Learn-iOS-apprentice-in-10-days/","link":"","permalink":"http://hellcy.github.io/2019/07/03/Learn-iOS-apprentice-in-10-days/","excerpt":"","text":"什么是iOS apprentice？ 在完成了上一个任务之后，我总算迎来了又一个更加巨大的挑战，这次直接换了一个新的平台：iOS。我从来没有接触过iOS的编程，之前只是听说过Swift和Cocoa Touch，但是Xcode完全没有用过。于是经过一番上网查找，我发现了一个非常适合新手入门的教材： raywenderlich的iOS apprentice！ 他总共包括四个部分，每一个部分教你编写一个app，难度从低到高。 Bull’s Eye Checklist MyLocation StoreSearch Conclusion Bull’s Eye 从怎么样创建一个新的single view app说起，非常容易上手 Project Navigator Obejct Library Drag item to view Make connections from object item to View Controller Attributes Inspector Item Outlet Another view controller Segue Add Constraints 第一个app基本上解决了很多界面上的问题，storyboard和editor之前的交流也讲了很多，@IBAction， @IBOutlet，segue等等一切都有涉及。之后第二个app就会更深层次的接触到iOS特有的模式了，比如delegate，还有一切经典的design pattern，比如MVC Checklist 第二个app就没有那么简单了，他先讲了table view和navigation bar 跟普通的view不同的是它由一行行的cell组成，这些cell可以被重复使用，当用户往下滑动时，更多的内容会被显示但是并不是每一行data都被存放在一个新的table cell里。离开显示范围的cell会重新出现在底部，并显示出新的data。 Protocol 什么是protocol？他其实是一种已经被写好了的methods的集合，UITableView就是一个protocol，我们通过它来显示table view，但是如果我们想改变一些显示方式，让他更适应我们自己的app，那么就要override其中一些method，这很常见 一般让一个table view更好的显示，我们需要override三个methods 12345override func tableView(_ tableView: UITableView, numberOfRowsInSection section: Int) -&gt; Intoverride func tableView(_ tableView: UITableView, cellForRowAt indexPath: IndexPath) -&gt; UITableViewCelloverride func tableView(_ tableView: UITableView, didSelectRowAt indexPath: IndexPath) MVC model MVC model是一种常见的设计模式，将代码分割成三个部分，每一个部分只负责他自己的任务，这样让程序结构更清晰。Model主要负责储存数据，view负责显示数据给用户，而controller负责显示正确的数据，包括运算等等 Array 这个app将table cells中的数据储存在一个array中，新建了一个checklistItem model,这样的话每次如果有数据变动就只需要增加和删除array中的数据。 Initializer 在Swift语言中，所有的variable， obejct都必须被初始化，所以很多时候我们需要一个初始化器来负责检查漏掉的变量。注意当我们有两个view controller需要传递data时，method的执行顺序是：假设A呼叫B 123init() from Bprepare() from AviewDidLoad() from B Delegates Delegates是ios编程中非常重要的一个概念，当你需要把一些值从一个view传到另一个view时，你通常不希望这两个view相互知道太多除了需要值之外的其他东西，如果两个view之间的联系太紧密，那么他们和其他view再建立关联就会更麻烦。所以一种通常的办法是写一个protocol，包含所有delegate methods，再让另外一个view成为它的delegate。这种办法称为loose coupling。 A是B的delegate，然而B根本不知道A的存在，只知道他有一个delegate可以接受他想要传递的值。 建立delegate的步骤 在B中建立delegate protocol 在B中建立一个delegate optional variable 在B中，需要传递信息时呼叫delegate method 在A中conformB的delegate protocol（inheritance 告诉B，A是自己的delegate，一般在A的prepare method中做这一步 Optionals Optional variable在declare的时候用？来表示，表明这个变量有可能是nil，在使用的时候也需要加？在varibale name的后面，如果使用了exclamation mark叹号！，则表示在此时不管变量是什么，强行取得其中的值，此时程序员保证变量在此时不可能是nil，风险也由程序员承担。是用叹号叫做force unwrapping Weak Weak表示两个objects之间的关系，当A对B的关系是strong时表示A是B的owner。当两个obejcts之间都是strong的关系我们可能会产生ownership cycle的问题从而导致memroy leak，因为没有人有资格destroy它的owner。所以我们尽量要维护一种一强一弱的对应关系。 一般来说，A如果是B的owner，A给B传值时在A的prepare method中，此时B的instance已经被建立，A很容易把值传给B的properties，并指认成为B的delegate，B给A传值则需要在合适的时候呼叫delegate methods Save data app会在合适的时候将用户数据保存到手机本地，每一个app都有一个属于自己的folder，也叫做sandbox，每个sandbox之间不能访问，这就预防了一些恶意软件在用户不知情的情况下窃取保存在用户手机其他地方的数据。 数据一般会保存在这样的一个path中，我们可以看到application后面接着一串32的字母的应用ID .plist file 什么是.plist文件？它是一种ios用来储存数据的文件，它遵循XML格式，每一个app都有一个info.plist file，他就是用来保存这个app的配置信息 Special comments 在编写代码时我们可以使用 // MARK：- 的形式来告诉Xcode我们开始了一个section，这样在jump bar中我们就可以快速定位variable，methods的位置。 Type casts 我们使用 as! 来给一个variable赋予一种data type，告诉Swift以后把它当成某一种type来处理，因为有时候我们知道它的type，可是Swift却不知道。 Array of arrays 当app的结构变得复杂时，数据的结构也要相应的变化以适应这些变化，我们可以使用嵌套的array来储存更多的数据 AppDelegate.swift 这个文件用来负责当app刚启动时或快要结束时的一些情况，我们不需要每过一会就储存数据，只需要每当用户退出app或者切换app时，所以这些method需要在AppDelegate里面修改 Dictionary 和array类似，dictionary也是一种储存数据的类型，只不过它是将数据按照key-value pair来排列的，当需要拿到某一个数据时，我们需要给dictionary相应的key。 User Defaults User Defaults就是一个dictionary类型的数据储存文件，它包含户用的配置信息，我们使用它储存一些app刚开始时的默认配置。 Local Notifications 当获得用户许可后，app可以定时在app不活跃时像互用手机发送提醒 这些基本就是第二个app的全部内容了，关于代码的部分可以在我的github的iOSApprenticePratice里面找到，下面是整个app的final storyboard MyLocation App Overview 第三个app我们要做一个可以通过GPS显示当前位置信息，并可以储存，增加照片和类别，在以后可以查看的app。完成之后的效果如下 Tabbed Application 之前的checklist我们学会了如何制作一个有navigation bar的app，这回我们要在app中增加一个tab bar，就是下屏幕最低端有一个导航条，可以切换不同的页面。许多主流的app都有类似的功能。 CoreLocation and ask for permission 要想让app获得GPS信息，我们需要现象用户获得许可，如果用户拒绝让app使用GPS，我们则无法获得权限。我们需要在info.plist里面增加一个record，表示我们需要获得许可，之后我们还会请求照片查看和地图view的许可。 Reverse geocoding 当我们获得了GPS信息，也就是当前位置的经纬度之后，我们还需要将他们转换成地址信息，否则用户也无法直接通过经纬度对当前位置有什么具体的概念。我们要做的是使用swift内置的CLGeocoder.reverseGeocodeLocation来转换。然后我们就可以得到地址信息了。 Auto-resizing 自动调整尺寸大小是一个非常重要的功能，现在市面上的iPhone屏幕尺寸很多，我们如果想对每一个尺寸做优化，为非常耗时，所以使用auto-resizing，让swift知道element在屏幕上的相对位置，比如距离屏幕底端100px，宽度等于屏幕宽度。这样swift就可以画出他的坐标，对于不同大小的屏幕也不会超出屏幕之外。 Class Inheritance, overriding and casts 现在我们来说一下OOP中非常重要的一个概念，class。object就是class的一个具象，而class是这个具象的类。inheritance就是子类可以继承他的parent class的信息。而overriding是说子类可以改变parent class的一些信息，让他有自己的特点。比如汽车是一个parent class，而公交车就是汽车这个class的一个子类，汽车如果有一个property是说自己的轮子个数为4.那么公交车就可以overr这个property，将轮子个数改为8，或者12，或任意。。。casts则是说某些时候swift并不知道现在的变量到底是什么类，只知道他是属于哪个大类的，那么我们如果要使用只存在于子类的properties，我们就需要将这个变量cast成我们想要的类。一般用as! Tag Location Screen 接下来我们看看怎么给现在获得的位置信息添加一些其他的信息，比如description，photo，category。那么我们就需要一个table，这个table我们知道他会有多少行，所以不需要使用prototype cells，使用static cells就可以了。制作一个这样的table非常基本，description用text view，image picker我们之后会讲，category使用disclosure indicator，其他cell就用right detailed就可以。 The unwind segue 当我们点击category时会进入到另一个table with prototype cells。再选一个category后就会回到之前的这个tag location screen，像这种返回式的我们可以使用unwind segue来实现 HUD heads-up display是一种popover view，其实他就是一种view，只不过正常的view现实时其他的view会先被destory以节省memory，但是HUD往往会将背景设置成本透明并保留之前的view，让app有一种层叠的感觉。 Core Data Core Data相当于储存在本地的数据，swift使用SqlLite数据库储存本地数据，我们需要将所有的location信息储存在Core Data中，以便以后打开app时查看之前tag的地点 Notification center 跟iPhone提醒不一样的是，swift有一个Notification center可以让开发者方便的listen从app任何地方发出的notification。比如我想在用户任何时候对储存在Core Data里的Locations信息进行读取，增加，删除，修改的时候得到提醒，我就可以在appDelegate里设置一个notification method，任何地方发出的LocationsUpdatedNotification都会被我捕捉到，并在这个method里面进行相应的操作。 The Locations Tab: 这个view就是显示所有储存在Core Data Locations里面的信息。基本的table with prototype cells，难点在于将Core Data信息提取并转换成相应的type，还有就是在不关闭app的状态下，新增的location可以马上更新到Core Data并显示在此view中，不过有了notification center相信各位也知道怎么做了。 Custom table view cell: 将一个cell的layout写在一个新的文件中，使得代码更易读。跟写在LocationsTabViewController是一样的，只不过拉outlets的时候选新的文件就好了。 Map Kit View: 我们可以在info.plist里增加map view来获得显示apple map的许可。 Image Picker: 同样，请求获取照片查看器的许可 Ownership cycle in closure 先复习一下什么是closure，他其实就是一个method，没什么特殊的，只不过他需要依附于另一个method才能存在。在某些条件被满足时，closure block里面的代码会被执行，比如一段时间过后，api返回成功之后等等。在执行closure时，我们往往会用到被依附的method的property，这时我们需要使用self来显式调用。然而这表示我们对这个property有一种strong reference，并可能导致在closure被执行之前，即使被依附的method所在的class无法被destory，造成memory leak，这是我们就需要使用weak self来破坏ownership cycle。 剩下的就是一些外观，音效和动画的改变了，这里就不赘述了。 StoreSearch App Overview 这本书的最后一个app将用到向apple store发送request获取信息，使用version contorl tools，对iPad等大屏幕设备的适配，异步通信以及把app上传到app store，可以说是一个简单的软件开发流程了。最终完成的结果如下 Git version control 是一个代码管理软件，当我们完成一个阶段的代码后，希望把他保存成一个副本，以后可以随时返回到这个地方。Xcode可以接连到github等网站进行更好的代码管理，也可以使用terminal。我比较喜欢使用terminal，常用的几个指令是： 123git add *git commit -m &quot;commit message&quot;git push -u origin master 当我们想在已经工作的代码中新加一些功能却又害怕出错，然后又改不回来，我们可以使用git创建一个新的branch，然后在新的branch中肆意更改，不用害怕出问题，这就相当于一个副本，如果改不会去了可以直接删掉，git会保存最后工作的版本。若果一切顺利，也可以将新的branch与master合并 当我们在View Controller中创建outlet时，应该使用weak relationship，这是因为每一个view都基本是从另一个super view中继承而来的，所以如果使用strong relationship，将导致view无法被摧毁。 Create branch and merge NeXT Interface Builder: nib file or xib file, 是一种局部storyboard，比如如果我们想设计一种table cell，就可以创建一个新的nib file，然后将这种custom table cell发给任何一个storyboard中的table view， nib file给我们提供多的灵活性 Debug using Xcode 与其他IDE相似，可以设置breakpoint来暂停程序，查看此时各个变量的值。在debug console中输入p instanceName 可以print出想要查看的object的值 Calling the web service 这个app的第一个重头戏就是send API request, 这也是软件开发中最常见的也是必不可少的技能，API request最常见的有两种，GET 和 POST， GET一般用来从远端提取数据，POST一般用来添加或改变远端数据，而API就是本地程序和远端数据连接的接口。本书使用了最简单的没有任何限制的GET request。 encode the url text to escape special characters: 在向API发送请求时我们经常需要一同发送一些parameters，但是space和很多其他它特殊符号都是不能被正常处理的，所以我们需要encode url再发送 Parse JSON data: 返回的数据一般是以JSON的形式组成的，所以我们需要deserilize，Swift有提供官方的decoder可以直接使用 using network link conditioner: 从发送API请求到收到数据总会有那么几秒钟时间，这时如果你的程序是在主线程上，你将无法执行任何操作。直到获取数据。如果网络速度很慢，那么结果将非常糟糕，我们可以使用network link conditioner这一额外开发工具来模拟网速极慢的状态。 Asychronous networking 那么如果解决这几秒钟的类似于死机的状态呢？我们可以使用多线程，并将API请求的操作放到另外一个线程中，这样主线程将不受影响，注意，所有和界面变化相关的操作都应该放在主线程。所以即使数据没有收到，用户也可以进行其他操作，比如取消请求。。。 URLSession: 这是一个专门用来负责多线程的API。他可以负责下载请求，数据请求等很多工作。本书使用URLSession来处理异步通信问题。 Segmented Control: 这是一个很常用的UI模块, 每次切换时可以把segmentedIndex的值传给controller来负责update UI DownloadTask Show DetailView with Present Modally segue: 当点击每个table cell时，会出现这样的一个显示详细信息的窗口，并且也可以看到下面的table view，这个做法其实很简单，每当swift切换到一个新的view时，之前的view默认会被摧毁，但是我们可以改变delegate method，让之前的view保留，并把新的view背景设置成透明。 Dynamic type text: 一些app的字体可以根据用户的系统设置而改变，这就要求我们使用默认字体大小，类似于headline 对于一款手机app来说，好的排版是非常重要的，因为涉及到不同的屏幕尺寸，使用auto-resizing让排版适应所有类型的手机可以扩大目标受众，而不是只为一款手机开发 Landscape 对于像iPad和iPhone Plus的机型来说，很多时候我们会把手机横置，这个时候因为屏幕的宽度和高度变化，我们希望app可以呈现出另一种不同的layout以适应变化的屏幕。 对于这种情况，swift定义了size classes，我们可以通过查看size class区分手机什么时候是横置的。拿iPhone 6 Plus来举例。如下图，当手机竖置的时候，手机屏幕的高度（vertical）是regular模式，而宽度是compact模式，而当手机处于横置的状态时，手机的高度变成了compact模式，而宽度变成了regular模式。这样，我们在写代码的时候，就可以对每一种situation，制定不同的显示模式了。 Enums with associated values: 在StoreSearch这个app中，用户有没有perform search action一共有四种状态，1.还没有search。 2.正在searching。 3. search结束，并且没有找到任何结果。 4.search结束，并且找到了至少一种结果。 那么对于这样一种状态，与其定义四个变量然后在viewcontroller里面查看这四个变量的true/false值，不如直接定义一个enum然后只需查看这一个enum的值即可。 Internationalization 有时候，我们希望让我们的app被来自不同国家使用不同语言的人使用，那么我们就需要将我们的app翻译成不同的语言。我们可以在info tab里新加一种语言。 另外，针对不同的view，我们还需要对每个view新加对应的语言文件。 至于那些不在storyboard里显示的语言信息，我们需要使用NSLocalizedString把所有的语言文本标记出来，再添加到strings文件中去 split view contorlle for iPad: split view是大屏幕设备常用的显示模式，例如iPad和iPhone plus。它可以轻松的利用空间，显示出原本需要两个view才能显示出的内容。 config elements in storyboard based on size class: 但如果我们用之前的view size，在iPad等设备上就会显得很小，所以我们需要针对大屏幕设备进行优化。我们可以在attribute tab找到constant，点击加号来增加一个针对不同情况的尺寸，之前说到iPad设备在横置模式（landscape）下高度和宽度都是regular的，所以这里wR hR就是width Regular, height Regular。这种情况下我们将view size改为500. popovers view controller: 如图所示，这是一个在一个view之上的popover view,可以用来表示一个新的menu email compose sheet: 这是一个可以在app中打开的内建email系统，提前设置好标题和收件人，当用户执行这个method，直接输入email的内容，就可以发送到开发者的邮箱，前提是用户必须提前设置好email账户。 beta testing (test flight): 当你完成一个app之后，可以把它发布到app store，这需要几个步骤，首先你需要提交一个build，在进入iTunes connect查看提交的app，在这里你可以分配给同一个team的其他测试者，这一步称为internal testing，如果一切都没问题，你可以submit app to app store. 如果app通过apple的审查，就可以进行external testing，将app的测试码发给任何人，他们可以通过测试码下载并测试app。 Conclusion 本来想用10天的时间看完这本将近1100页的书，最后用了将近20天才完成。在做最后一个app的时候又有其他的工作加进来，周末又一直有活动，才又延长了这么长时间，不过完成了就是好的，对于一个对iOS没有任何经验的人来说，的确是一本不可多得的好书，如果对自己的编程能力有信心，之前又接触过Java或者C++,直接读这本是没有任何问题的，不过如果没有任何编程经验，从另外一本Swift Apprentice开始更好，从了解swift语言基本开始，使用Xcode playground。 这四个app基本解决了我制作其他app时的所有问题，常用的storyboard object都用了，constraints，delegate, extension, custom with nib, localizition, API calling, local library, local database, simple animation, multi-threading, git, debug到最后app publish都有涉及。 不过在跟着做完所有app之后，我觉得还是需要自己制作一个app，在脱离了guide之后，靠自己的能力解决所有过程中的问题，能使学到的知识更加牢固。","categories":[],"tags":[{"name":"iOS","slug":"iOS","permalink":"http://hellcy.github.io/tags/iOS/"},{"name":"Swift","slug":"Swift","permalink":"http://hellcy.github.io/tags/Swift/"}]},{"title":"Mifare card read and write","slug":"Mifare-card-read-and-write","date":"2019-06-24T05:17:06.000Z","updated":"2021-02-26T12:08:47.159Z","comments":true,"path":"2019/06/24/Mifare-card-read-and-write/","link":"","permalink":"http://hellcy.github.io/2019/06/24/Mifare-card-read-and-write/","excerpt":"","text":"Mifare card families Mifare卡片有很多种类，每一种卡都有不用的读写方式 Mifare Classic Mifare Plus Mifare Ultralight Mifare DESFire Classic and Mitools Mifare Classic卡是一种卡片类型，它的安全等级不是特别的高，现在已经有可以破解的软件，Mitools就是其中一种。它的界面如下 Mifare卡片总共有16个sector，每一个sector中又有4个block，其中第一个sector是用来卡片生产的过程中记录卡片信息的，一般来说我们不去动他。剩下的15个sector可以给我们用来记录我们想要的信息，其中每个sector的前3个block可以自由使用，而第4个block是用来记录两个密码Key A和Key B。中间的7为则用来记录密码的形式，一般我们也不去动他。密码层在图中用粉色表示。 这是其中一张卡片读取后显示的信息 现在我们来看看怎么从sector7中提取出这张卡片的site code和card number 可以看到第一个block中含有我们需要的信息，而剩下的block2，block3都是0. 我们需要做的就是拿出block1中的信息，这个信息是Hexadecimal也就是16进制的，所以我们先把它变成2进制。1101 1000 1010 0011 1111 1000 0000 0000‬ 因为我们用的是 26 bit format 所以取前26位数 除去第一位even parity，取第二位往后8位：1011 0001，换成十进制就是177 再往后取16位：0100 0111 1111 0000. 十进制就是18416 这样我们就得到了site code: 177, card number: 18416 Ultralight card 与Classic相似的是，Ultralight卡也有很多可以读写的分区，只是不叫sector，而叫做page，从第四个到第15个page是提供给使用者读写的，其他则是与卡本身相关的信息。 每一个page可以保存四个byte的信息 需要注意的是，page2的第2，3个byte保存有lock bits，可以lock其他的page，而且一旦lock，就不能在改变回unlock的状态，比如，0是unlock，1是lock，如果把第二个byte中的第4个bit从0改变为1，那么page4就会被lock，我们不再拥有write page4的权利，但是可以read，page2中的lock bit也无法从1再变回成0. DESFire card DESFire卡的保护机制更加复杂，其中存储信息的空间叫做application，我们需要先选择正确的application和adpu command，然后伴随sw1, sw2两个parameter，最后还有加上一个expected response length 如果要write，就要再加上想要写入的data和数据长度。随着iOS13对于NFC的开放，使用iphone读写DESFire card有可能实现。 Reference Mifare Ultralight lock bits APDU response code list Use APDU commands to get some information for a card","categories":[],"tags":[{"name":"Mifare","slug":"Mifare","permalink":"http://hellcy.github.io/tags/Mifare/"}]},{"title":"Deploy api to IIS manager","slug":"Deploy-api-to-IIS-manager","date":"2019-06-20T05:06:58.000Z","updated":"2021-02-26T12:08:47.158Z","comments":true,"path":"2019/06/20/Deploy-api-to-IIS-manager/","link":"","permalink":"http://hellcy.github.io/2019/06/20/Deploy-api-to-IIS-manager/","excerpt":"","text":"Publish API using visual studio API 完成之后，我们还需要把它deploy到client server里。所以我们先用visual studio publish它 go to Build-&gt;Publish API, 然后点publish，记住publis的路径 这些文件就是一会要copy到client server的文件，也就是api 用remote desktop连接到client server 这个就是client server的IIS manager了，可以看到已经有很多API和app在列表中了 接下来新建一个app connection，路径上新建一个文件夹，把刚才的api文件放进去 更改一下web.config，连接到正确的client database，database name也要一致 测试一下，api有反应，那么就算deploy成功了","categories":[],"tags":[{"name":"API","slug":"API","permalink":"http://hellcy.github.io/tags/API/"},{"name":"IIS","slug":"IIS","permalink":"http://hellcy.github.io/tags/IIS/"}]},{"title":"How to use Gatling load testing tool","slug":"How-to-use-Gatling-load-testing-tool","date":"2019-06-18T03:05:31.000Z","updated":"2021-02-26T12:08:47.159Z","comments":true,"path":"2019/06/18/How-to-use-Gatling-load-testing-tool/","link":"","permalink":"http://hellcy.github.io/2019/06/18/How-to-use-Gatling-load-testing-tool/","excerpt":"","text":"What is load testing load and stress testing. Load testing verifies how the system function under a heavy number of concurrent clients sending requests over a certain period of time. However, the main goal of that type of tests is to simulate the standard traffic similar to that, which may arise on production. Stress testing takes load testing and pushes your app to the limits to see how it handles an extremely heavy load. 使用一些load testing tool往往比自己写一个console application来test要有效，不单单是因为它提供很多可视化的图标可以参考在正常情况下用户的访问情况，还因为它对用户访问处理的算法也更好，可以模拟同时访问的情况而不同我们自己写平行运算。 Gatling 这次我选的是Gatling. 一是因为它是免费的，二是因为它提供很多可视化图表 文件解压后可以看到这些文件夹，其中bin包含程序本身的运行文件。conf是程序的配置文件config，results会有每次测试的报告，一开始应该是空的。user_file是用户的测试配置文件，里面有两个文件夹，一个是resources，所有用到的关联文件类似csv file都应该放在里面。还有就是simulations，这个就是每次测试的配置文件，使用scala写的。但是也很容易懂。 scala文件就长这个样子，需要注意的就是baseUrl，feeder file students.csv，get后面的url剩余部分，还有就是setup里面的同时访问数量。现在我们没有用到任何csv file，但是如果有用到就把他放在resources文件夹里 然后进入bin并运行gatling.bat 选择一个simulation 我们可以看到100个request都完成了 图表也非常丰富 接下来我们看看如果模拟1000个不同的用户在接下来的20秒，因为不需要同时接受1000个用户，所以我们更改setup，使用rampUser 1setUp(scn.inject(rampUsers(1000) over (20 seconds)).protocols(httpProtocol)) 运行报错，但是用console看起来太不方便了。我们更改下config让他把error log导出到一个文件中 找到logback.xml,然后更改成这样，这样每次报错就会生成gatling.log 打开log发现他说：value over is not a member of io.gatling.core.Predef.RampBuilder。 说明没有识别关键词over，google一下这句话。发现是因为这个是旧版本的语法了。。。可是官方guide居然还没有更新。。。 好吧找到migration guide，发现over被替换成during了。。嗯。。真好 重新运行一下gatling.bat，现在行了，还挺像模像样的 现在大部分request都小于800ms 细看的话，同时在线人数基本在50以上，我们用不到那么多。。。并且将近一半的request其实只用了36ms。。 ok，还有一个问题就是这个report中response time的上下限太高了，我们平均都不会超过100所以要更改一下上下限 同样，还是去gatling.conf 改一下lowerBound, higherBound, 记住一定要把#去掉，不然这会被算作comment而没有实际作用 可以看到现在图表中的response time变成100ms何200ms了","categories":[],"tags":[{"name":"Load Testing","slug":"Load-Testing","permalink":"http://hellcy.github.io/tags/Load-Testing/"}]},{"title":"Create a Restful api using C#","slug":"Create-a-Restful-api-using-C-Sharp","date":"2019-06-13T02:26:52.000Z","updated":"2021-02-26T12:08:47.158Z","comments":true,"path":"2019/06/13/Create-a-Restful-api-using-C-Sharp/","link":"","permalink":"http://hellcy.github.io/2019/06/13/Create-a-Restful-api-using-C-Sharp/","excerpt":"","text":"今天拿到了一个任务 要写一个API，要求是每次学生登陆之后可以看到他的学生卡的相关信息，包括卡号，有效期，余额，还有可不可以自动充值等等。 那么我们就要先写一个stored procedure把相关信息提取出来,这些信息牵扯到4个table来自于两个database。 随便打一个StudentID试一下看看能不能成功运行 接着在Microsoft Doc tutorial可以帮助我们写一个简单的api模版。在用connectionString连接上database然后用postman测试一下 这样基本上api就算写的差不多了，接下来还要把格式改成要求的样子 所以把它改成JSON Object这样好改一点，刚才都是直接return DataTable。 结构基本就是这样，然后再测试一下看看能不能拿到相同的格式 要求中还说到要有基本的authentication。有可能就是在function前面加上authorize attribute，等下周问问leader。另外就是要log所有的api calls。包括api整个的运行时间（response time），StudentID，现在的系统时间。用stopwatch计算出每次call所需的时间，其他的都好弄。我先把output写在debug console里了，回头再改看看要不要直接output到一个file里面。 接下来就是要写一个console application来call我们的api了，毕竟不能一直用postman做测试啊。 用HttpClient去call api，已经成功了，但是有两个问题，一个是如果连续call10次的话每次用的时间都很长，用postman的时候很多时候只有20ms，但是现在有上千。。。第二个问题就是我还需要做一个simultaneously call。 一个周末过去了。。 然后就是每次同时call10次api，这个的话我上网查了查，同样只要改await就可以. 这个async，await的意思是：如果task前面有await，那么程序会暂停直到拿到task的返回值或task结束运行之后才会继续。而如果task前面没有await，意味着在它被创建的时候程序可以继续运行之后的代码，只要它们不依靠task的结果。所以我们可以创建10个没有await的task，最后在一起await然后output。 这样的话虽然每次api call的时间比一次一次call要长很多但是如果计算500次call的总时间的话平行运算还是有优势的 平行运算时每次api call的时间 500次call的总时间，总共算了10次，基本在8秒左右 单次运算时每次api call的时间 单次运算时每500次的总时间，总共算了10次，基本都超过了10秒 关于在api中加入basic authenticaiton：To access the web API method, we have to pass the user credentials in the request header. If we do not pass the user credentials in the request header, then the server returns 401 (unauthorized) status code indicating the server supports Basic Authentication. 新建一个class， inhert from IHttpModule，这样就可以让api support basic authentication了。但是我们还要让console在request中加入auth header。 试了一下可以运行，那么这个task到现在就基本完成了。看看leader有什么别的要求再说吧。","categories":[],"tags":[{"name":"C#","slug":"C","permalink":"http://hellcy.github.io/tags/C/"},{"name":"API","slug":"API","permalink":"http://hellcy.github.io/tags/API/"}]}],"categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://hellcy.github.io/tags/Java/"},{"name":"TCP/IP","slug":"TCP-IP","permalink":"http://hellcy.github.io/tags/TCP-IP/"},{"name":"LINQ","slug":"LINQ","permalink":"http://hellcy.github.io/tags/LINQ/"},{"name":"Entity Framework","slug":"Entity-Framework","permalink":"http://hellcy.github.io/tags/Entity-Framework/"},{"name":"GraphQL","slug":"GraphQL","permalink":"http://hellcy.github.io/tags/GraphQL/"},{"name":"Design Patterns","slug":"Design-Patterns","permalink":"http://hellcy.github.io/tags/Design-Patterns/"},{"name":"Selenium","slug":"Selenium","permalink":"http://hellcy.github.io/tags/Selenium/"},{"name":"Functional Tests","slug":"Functional-Tests","permalink":"http://hellcy.github.io/tags/Functional-Tests/"},{"name":"Dependency Injection","slug":"Dependency-Injection","permalink":"http://hellcy.github.io/tags/Dependency-Injection/"},{"name":"SQL","slug":"SQL","permalink":"http://hellcy.github.io/tags/SQL/"},{"name":"Unit Tests","slug":"Unit-Tests","permalink":"http://hellcy.github.io/tags/Unit-Tests/"},{"name":".NET","slug":"NET","permalink":"http://hellcy.github.io/tags/NET/"},{"name":"JavaScript","slug":"JavaScript","permalink":"http://hellcy.github.io/tags/JavaScript/"},{"name":"AWS","slug":"AWS","permalink":"http://hellcy.github.io/tags/AWS/"},{"name":"React","slug":"React","permalink":"http://hellcy.github.io/tags/React/"},{"name":"ASP.NET Core","slug":"ASP-NET-Core","permalink":"http://hellcy.github.io/tags/ASP-NET-Core/"},{"name":"C#","slug":"C","permalink":"http://hellcy.github.io/tags/C/"},{"name":"Wishlist","slug":"Wishlist","permalink":"http://hellcy.github.io/tags/Wishlist/"},{"name":"Dynamic Programming","slug":"Dynamic-Programming","permalink":"http://hellcy.github.io/tags/Dynamic-Programming/"},{"name":"Web Development","slug":"Web-Development","permalink":"http://hellcy.github.io/tags/Web-Development/"},{"name":"Data Structures","slug":"Data-Structures","permalink":"http://hellcy.github.io/tags/Data-Structures/"},{"name":"Python","slug":"Python","permalink":"http://hellcy.github.io/tags/Python/"},{"name":"SSO","slug":"SSO","permalink":"http://hellcy.github.io/tags/SSO/"},{"name":"Kotlin","slug":"Kotlin","permalink":"http://hellcy.github.io/tags/Kotlin/"},{"name":"Android Studio","slug":"Android-Studio","permalink":"http://hellcy.github.io/tags/Android-Studio/"},{"name":"Swift","slug":"Swift","permalink":"http://hellcy.github.io/tags/Swift/"},{"name":"API","slug":"API","permalink":"http://hellcy.github.io/tags/API/"},{"name":"iOS","slug":"iOS","permalink":"http://hellcy.github.io/tags/iOS/"},{"name":"Mifare","slug":"Mifare","permalink":"http://hellcy.github.io/tags/Mifare/"},{"name":"IIS","slug":"IIS","permalink":"http://hellcy.github.io/tags/IIS/"},{"name":"Load Testing","slug":"Load-Testing","permalink":"http://hellcy.github.io/tags/Load-Testing/"}]}